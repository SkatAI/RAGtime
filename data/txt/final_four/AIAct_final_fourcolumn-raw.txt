
TTTXX TABLE: 1 XXTTT
== ROW 1.0 ==
-- COL 1.0.0 --

-- COL 1.0.1 --

-- COL 1.0.2 --

-- COL 1.0.3 --
Commission Proposal 
-- COL 1.0.4 --
EP Mandate 
-- COL 1.0.5 --
Council Mandate 
-- COL 1.0.6 --
Draft Agreement
-- COL 1.0.7 --

-- COL 1.0.8 --

== ROW 1.1 ==
-- COL 1.1.0 --

-- COL 1.1.1 --

-- COL 1.1.2 --
Formula
-- COL 1.1.3 --

-- COL 1.1.4 --

-- COL 1.1.5 --

-- COL 1.1.6 --

-- COL 1.1.7 --

-- COL 1.1.8 --

== ROW 1.2 ==
-- COL 1.2.0 --
G 
-- COL 1.2.1 --

-- COL 1.2.2 --
1
-- COL 1.2.3 --
2021/0106 (COD) 
-- COL 1.2.4 --
2021/0106 (COD) 
-- COL 1.2.5 --
2021/0106 (COD) 
-- COL 1.2.6 --
2021/0106 (COD) 
Text Origin: Commission  
Proposal
-- COL 1.2.7 --
G
-- COL 1.2.8 --

== ROW 1.3 ==
-- COL 1.3.0 --

-- COL 1.3.1 --

-- COL 1.3.2 --
Proposal Title
-- COL 1.3.3 --

-- COL 1.3.4 --

-- COL 1.3.5 --

-- COL 1.3.6 --

-- COL 1.3.7 --

-- COL 1.3.8 --

== ROW 1.4 ==
-- COL 1.4.0 --
G 
-- COL 1.4.1 --

-- COL 1.4.2 --
2
-- COL 1.4.3 --
Proposal for a 
REGULATION OF THE  
EUROPEAN PARLIAMENT AND  OF THE COUNCIL 
LAYING DOWN HARMONISED  RULES ON ARTIFICIAL  
INTELLIGENCE (ARTIFICIAL  INTELLIGENCE ACT) AND  AMENDING CERTAIN UNION  LEGISLATIVE ACTS
-- COL 1.4.4 --
Proposal for a 
REGULATION OF THE  
EUROPEAN PARLIAMENT AND  OF THE COUNCIL 
LAYING DOWN HARMONISED  RULES ON ARTIFICIAL  
INTELLIGENCE (ARTIFICIAL  INTELLIGENCE ACT) AND  AMENDING CERTAIN UNION  LEGISLATIVE ACTS
-- COL 1.4.5 --
Proposal for a 
REGULATION OF THE  
EUROPEAN PARLIAMENT AND  OF THE COUNCIL 
LAYING DOWN HARMONISED  RULES ON ARTIFICIAL  
INTELLIGENCE (ARTIFICIAL  INTELLIGENCE ACT) AND  AMENDING CERTAIN UNION  LEGISLATIVE ACTS
-- COL 1.4.6 --
Proposal for a 
REGULATION OF THE  
EUROPEAN PARLIAMENT AND  OF THE COUNCIL 
LAYING DOWN HARMONISED  RULES ON ARTIFICIAL  
INTELLIGENCE (ARTIFICIAL  INTELLIGENCE ACT) AND  AMENDING CERTAIN UNION  LEGISLATIVE ACTS 
Text Origin: Commission  
Proposal
-- COL 1.4.7 --
G
-- COL 1.4.8 --

== ROW 1.5 ==
-- COL 1.5.0 --

-- COL 1.5.1 --

-- COL 1.5.2 --
Formula
-- COL 1.5.3 --

-- COL 1.5.4 --

-- COL 1.5.5 --

-- COL 1.5.6 --

-- COL 1.5.7 --

-- COL 1.5.8 --

== ROW 1.6 ==
-- COL 1.6.0 --
G 
-- COL 1.6.1 --

-- COL 1.6.2 --
3
-- COL 1.6.3 --
THE EUROPEAN PARLIAMENT 
-- COL 1.6.4 --
THE EUROPEAN PARLIAMENT 
-- COL 1.6.5 --
THE EUROPEAN PARLIAMENT 
-- COL 1.6.6 --
THE EUROPEAN PARLIAMENT 
-- COL 1.6.7 --
G
-- COL 1.6.8 --


TTTXX TABLE: 2 XXTTT
== ROW 2.0 ==
-- COL 2.0.0 --

-- COL 2.0.1 --

-- COL 2.0.2 --

-- COL 2.0.3 --
Commission Proposal 
-- COL 2.0.4 --
EP Mandate 
-- COL 2.0.5 --
Council Mandate 
-- COL 2.0.6 --
Draft Agreement
-- COL 2.0.7 --

-- COL 2.0.8 --

== ROW 2.1 ==
-- COL 2.1.0 --

-- COL 2.1.1 --

-- COL 2.1.2 --

-- COL 2.1.3 --
AND THE COUNCIL OF THE  EUROPEAN UNION,
-- COL 2.1.4 --
AND THE COUNCIL OF THE  EUROPEAN UNION,
-- COL 2.1.5 --
AND THE COUNCIL OF THE  EUROPEAN UNION,
-- COL 2.1.6 --
AND THE COUNCIL OF THE  EUROPEAN UNION, 
Text Origin: Commission  
Proposal
-- COL 2.1.7 --

-- COL 2.1.8 --

== ROW 2.2 ==
-- COL 2.2.0 --

-- COL 2.2.1 --

-- COL 2.2.2 --
Citation 1
-- COL 2.2.3 --

-- COL 2.2.4 --

-- COL 2.2.5 --

-- COL 2.2.6 --

-- COL 2.2.7 --

-- COL 2.2.8 --

== ROW 2.3 ==
-- COL 2.3.0 --
G 
-- COL 2.3.1 --

-- COL 2.3.2 --
4
-- COL 2.3.3 --
Having regard to the Treaty on the  Functioning of the European Union,  and in particular Articles 16 and 114  thereof,
-- COL 2.3.4 --
Having regard to the Treaty on the  Functioning of the European Union,  and in particular Articles 16 and 114  thereof,
-- COL 2.3.5 --
Having regard to the Treaty on the  Functioning of the European Union,  and in particular Articles 16 and 114  thereof,
-- COL 2.3.6 --
Having regard to the Treaty on the  Functioning of the European Union,  and in particular Articles 16 and 114  thereof, 
Text Origin: Commission  
Proposal
-- COL 2.3.7 --
G
-- COL 2.3.8 --

== ROW 2.4 ==
-- COL 2.4.0 --

-- COL 2.4.1 --

-- COL 2.4.2 --
Citation 2
-- COL 2.4.3 --

-- COL 2.4.4 --

-- COL 2.4.5 --

-- COL 2.4.6 --

-- COL 2.4.7 --

-- COL 2.4.8 --

== ROW 2.5 ==
-- COL 2.5.0 --
G 
-- COL 2.5.1 --

-- COL 2.5.2 --
5
-- COL 2.5.3 --
Having regard to the proposal from  the European Commission,
-- COL 2.5.4 --
Having regard to the proposal from  the European Commission,
-- COL 2.5.5 --
Having regard to the proposal from  the European Commission,
-- COL 2.5.6 --
Having regard to the proposal from  the European Commission, 
Text Origin: Commission  
Proposal
-- COL 2.5.7 --
G
-- COL 2.5.8 --

== ROW 2.6 ==
-- COL 2.6.0 --

-- COL 2.6.1 --

-- COL 2.6.2 --
Citation 3
-- COL 2.6.3 --

-- COL 2.6.4 --

-- COL 2.6.5 --

-- COL 2.6.6 --

-- COL 2.6.7 --

-- COL 2.6.8 --

== ROW 2.7 ==
-- COL 2.7.0 --
G 
-- COL 2.7.1 --

-- COL 2.7.2 --
6
-- COL 2.7.3 --
After transmission of the draft  legislative act to the national  
parliaments,
-- COL 2.7.4 --
After transmission of the draft  legislative act to the national  
parliaments,
-- COL 2.7.5 --
After transmission of the draft  legislative act to the national  
parliaments,
-- COL 2.7.6 --
After transmission of the draft  legislative act to the national  
parliaments, 
Text Origin: Commission  
Proposal
-- COL 2.7.7 --
G
-- COL 2.7.8 --

== ROW 2.8 ==
-- COL 2.8.0 --

-- COL 2.8.1 --

-- COL 2.8.2 --
Citation 4
-- COL 2.8.3 --

-- COL 2.8.4 --

-- COL 2.8.5 --

-- COL 2.8.6 --

-- COL 2.8.7 --

-- COL 2.8.8 --

== ROW 2.9 ==
-- COL 2.9.0 --
G 
-- COL 2.9.1 --

-- COL 2.9.2 --
7 
-- COL 2.9.3 --

-- COL 2.9.4 --

-- COL 2.9.5 --

-- COL 2.9.6 --

-- COL 2.9.7 --
G
-- COL 2.9.8 --


TTTXX TABLE: 3 XXTTT
== ROW 3.0 ==
-- COL 3.0.0 --

-- COL 3.0.1 --

-- COL 3.0.2 --

-- COL 3.0.3 --
Commission Proposal 
-- COL 3.0.4 --
EP Mandate 
-- COL 3.0.5 --
Council Mandate 
-- COL 3.0.6 --
Draft Agreement
-- COL 3.0.7 --

-- COL 3.0.8 --

== ROW 3.1 ==
-- COL 3.1.0 --

-- COL 3.1.1 --

-- COL 3.1.2 --

-- COL 3.1.3 --
Having regard to the opinion of the  European Economic and Social  Committee1, 
_________ 
1. OJ C […], […], p. […].
-- COL 3.1.4 --
Having regard to the opinion of the  European Economic and Social  Committee1, 
_________ 
1. OJ C […], […], p. […].
-- COL 3.1.5 --
Having regard to the opinion of the  European Economic and Social  Committee1, 
_________ 
1. OJ C […], […], p. […].
-- COL 3.1.6 --
Having regard to the opinion of the  European Economic and Social  Committee1, 
_________ 
1. OJ C […], […], p. […]. 
Text Origin: Commission  
Proposal
-- COL 3.1.7 --

-- COL 3.1.8 --

== ROW 3.2 ==
-- COL 3.2.0 --

-- COL 3.2.1 --

-- COL 3.2.2 --
Citation 4a
-- COL 3.2.3 --

-- COL 3.2.4 --

-- COL 3.2.5 --

-- COL 3.2.6 --

-- COL 3.2.7 --

-- COL 3.2.8 --

== ROW 3.3 ==
-- COL 3.3.0 --
G 
-- COL 3.3.1 --

-- COL 3.3.2 --
7a
-- COL 3.3.3 --

-- COL 3.3.4 --
Having regard to the opinion of the  European Central Bank,
-- COL 3.3.5 --

-- COL 3.3.6 --
Having regard to the opinion of the  European Central Bank1, 
_________ 
1. Reference to ECB opinion 
Text Origin: EP Mandate
-- COL 3.3.7 --
G
-- COL 3.3.8 --

== ROW 3.4 ==
-- COL 3.4.0 --

-- COL 3.4.1 --

-- COL 3.4.2 --
Citation 4b
-- COL 3.4.3 --

-- COL 3.4.4 --

-- COL 3.4.5 --

-- COL 3.4.6 --

-- COL 3.4.7 --

-- COL 3.4.8 --

== ROW 3.5 ==
-- COL 3.5.0 --
G 
-- COL 3.5.1 --

-- COL 3.5.2 --
7b
-- COL 3.5.3 --

-- COL 3.5.4 --
Having regard to the joint opinion  of the European Data Protection  Board and the European Data  Protection Supervisor,
-- COL 3.5.5 --

-- COL 3.5.6 --
Having regard to the joint opinion  of the European Data Protection  Board and the European Data  Protection Supervisor, 
Text Origin: EP Mandate
-- COL 3.5.7 --
G
-- COL 3.5.8 --

== ROW 3.6 ==
-- COL 3.6.0 --

-- COL 3.6.1 --

-- COL 3.6.2 --
Citation 5
-- COL 3.6.3 --

-- COL 3.6.4 --

-- COL 3.6.5 --

-- COL 3.6.6 --

-- COL 3.6.7 --

-- COL 3.6.8 --

== ROW 3.7 ==
-- COL 3.7.0 --
G 
-- COL 3.7.1 --

-- COL 3.7.2 --
8
-- COL 3.7.3 --
Having regard to the opinion of the  Committee of the Regions1, 
_________ 
1. OJ C […], […], p. […].
-- COL 3.7.4 --
Having regard to the opinion of the  Committee of the Regions1, 
_________ 
1. OJ C […], […], p. […].
-- COL 3.7.5 --
Having regard to the opinion of the  Committee of the Regions1, 
_________ 
1. OJ C […], […], p. […].
-- COL 3.7.6 --
Having regard to the opinion of the  Committee of the Regions1, 
_________ 
1. OJ C […], […], p. […]. 
Text Origin: Commission  
Proposal
-- COL 3.7.7 --
G
-- COL 3.7.8 --


TTTXX TABLE: 4 XXTTT
== ROW 4.0 ==
-- COL 4.0.0 --

-- COL 4.0.1 --

-- COL 4.0.2 --

-- COL 4.0.3 --
Commission Proposal 
-- COL 4.0.4 --
EP Mandate 
-- COL 4.0.5 --
Council Mandate 
-- COL 4.0.6 --
Draft Agreement
-- COL 4.0.7 --

-- COL 4.0.8 --

== ROW 4.1 ==
-- COL 4.1.0 --

-- COL 4.1.1 --

-- COL 4.1.2 --

-- COL 4.1.3 --

-- COL 4.1.4 --

-- COL 4.1.5 --

-- COL 4.1.6 --

-- COL 4.1.7 --

-- COL 4.1.8 --

== ROW 4.2 ==
-- COL 4.2.0 --

-- COL 4.2.1 --

-- COL 4.2.2 --
Citation 5a
-- COL 4.2.3 --

-- COL 4.2.4 --

-- COL 4.2.5 --

-- COL 4.2.6 --

-- COL 4.2.7 --

-- COL 4.2.8 --

== ROW 4.3 ==
-- COL 4.3.0 --
G 
-- COL 4.3.1 --

-- COL 4.3.2 --
8a
-- COL 4.3.3 --

-- COL 4.3.4 --

-- COL 4.3.5 --
5a Having regard to the opinion of  the European Central Bank1,  _________ 
1. Reference to ECB opinion
-- COL 4.3.6 --

-- COL 4.3.7 --
G
-- COL 4.3.8 --

== ROW 4.4 ==
-- COL 4.4.0 --

-- COL 4.4.1 --

-- COL 4.4.2 --
Citation 6
-- COL 4.4.3 --

-- COL 4.4.4 --

-- COL 4.4.5 --

-- COL 4.4.6 --

-- COL 4.4.7 --

-- COL 4.4.8 --

== ROW 4.5 ==
-- COL 4.5.0 --
G 
-- COL 4.5.1 --

-- COL 4.5.2 --
9
-- COL 4.5.3 --
Acting in accordance with the  ordinary legislative procedure,
-- COL 4.5.4 --
Acting in accordance with the  ordinary legislative procedure,
-- COL 4.5.5 --
Acting in accordance with the  ordinary legislative procedure,
-- COL 4.5.6 --
Acting in accordance with the  ordinary legislative procedure, 
Text Origin: Commission  
Proposal
-- COL 4.5.7 --
G
-- COL 4.5.8 --

== ROW 4.6 ==
-- COL 4.6.0 --

-- COL 4.6.1 --

-- COL 4.6.2 --
Formula
-- COL 4.6.3 --

-- COL 4.6.4 --

-- COL 4.6.5 --

-- COL 4.6.6 --

-- COL 4.6.7 --

-- COL 4.6.8 --

== ROW 4.7 ==
-- COL 4.7.0 --
G 
-- COL 4.7.1 --

-- COL 4.7.2 --
10
-- COL 4.7.3 --
Whereas: 
-- COL 4.7.4 --
Whereas: 
-- COL 4.7.5 --
Whereas: 
-- COL 4.7.6 --
Whereas: 
Text Origin: Commission  
Proposal
-- COL 4.7.7 --
G
-- COL 4.7.8 --

== ROW 4.8 ==
-- COL 4.8.0 --

-- COL 4.8.1 --

-- COL 4.8.2 --
Recital 1
-- COL 4.8.3 --

-- COL 4.8.4 --

-- COL 4.8.5 --

-- COL 4.8.6 --

-- COL 4.8.7 --

-- COL 4.8.8 --

== ROW 4.9 ==
-- COL 4.9.0 --
G 
-- COL 4.9.1 --

-- COL 4.9.2 --
11
-- COL 4.9.3 --
(1) The purpose of this Regulation  is to improve the functioning of the  internal market by laying down a  uniform legal framework in  
particular for the development,  marketing and use of artificial  intelligence in conformity with  Union values. This Regulation  pursues a number of overriding 
-- COL 4.9.4 --
(1) The purpose of this Regulation  is to    
p romote the  uptake of human centric and  trustworthy artificial intelligence  and to ensure a high level of 
-- COL 4.9.5 --
(1) The purpose of this Regulation  is to improve the functioning of the  internal market by laying down a  uniform legal framework in  
particular for the development,  marketing and use of artificial  intelligence in conformity with  Union values. This Regulation  pursues a number of overriding 
-- COL 4.9.6 --
(1) The purpose of this Regulation  is to improve the functioning of the  internal market by laying down a  uniform legal framework in  
particular for the development,  lacing on the  market, putting into service and the  use of artificial intelligence systems  in the Union in conformity with 
-- COL 4.9.7 --
G
-- COL 4.9.8 --


TTTXX TABLE: 5 XXTTT
== ROW 5.0 ==
-- COL 5.0.0 --

-- COL 5.0.1 --

-- COL 5.0.2 --

-- COL 5.0.3 --
Commission Proposal 
-- COL 5.0.4 --
EP Mandate 
-- COL 5.0.5 --
Council Mandate 
-- COL 5.0.6 --
Draft Agreement
-- COL 5.0.7 --

-- COL 5.0.8 --

== ROW 5.1 ==
-- COL 5.1.0 --

-- COL 5.1.1 --

-- COL 5.1.2 --

-- COL 5.1.3 --
reasons of public interest, such as a  high level of protection of health,  safety and fundamental rights, and it  ensures the free movement of AI based goods and services cross border, thus preventing Member  States from imposing restrictions on  the development, marketing and use  of AI systems, unless explicitly  authorised by this Regulation.
-- COL 5.1.4 --
protection of health, safety,  
fundamental rights, democracy and  rule of law and the environment  from harmful effects of artificial  intelligence systems in the Union  while supporting innovation and  improving the functioning of the  internal market . This Regulation  p    lays down a uniform legal  
framework in particular for the  development, the placing on the  market, the putting into service and  the use of artificial intelligence in  conformity with Union values and  ensures the free movement of AI based goods and services cross border, thus preventing Member  States from imposing restrictions on  the development, marketing and use  of Artificial Intelligence systems  (AI systems), unless explicitly  authorised by this Regulation. Certain AI systems can also have  an impact on democracy and rule of  law and the environment. These  concerns are specifically addressed  in the critical sectors and use cases  listed in the annexes to this  
Regulation.
-- COL 5.1.5 --
reasons of public interest, such as a  high level of protection of health,  safety and fundamental rights, and it  ensures the free movement of AI based goods and services cross border, thus preventing Member  States from imposing restrictions on  the development, marketing and use  of AI systems, unless explicitly  authorised by this Regulation.
-- COL 5.1.6 --
Union values p   to promote the uptake of human  centric and trustworthy artificial  intelligence while ensuring a high  level of protection of health, safety  fundamental rights enshrined  in the Charter, including  
democracy and rule of law and  environmental protection, against  harmful effects of artificial  
intelligence systems in the Union  and to support innovation. This  regulation ensures the free  movement of AI-based goods and  services cross-border, thus  
preventing Member States from  imposing restrictions on the  
development, marketing and use of  Artificial Intelligence systems (AI  systems), unless explicitly  
authorised by this Regulation.
-- COL 5.1.7 --

-- COL 5.1.8 --

== ROW 5.2 ==
-- COL 5.2.0 --

-- COL 5.2.1 --

-- COL 5.2.2 --
Recital 1a
-- COL 5.2.3 --

-- COL 5.2.4 --

-- COL 5.2.5 --

-- COL 5.2.6 --

-- COL 5.2.7 --

-- COL 5.2.8 --


TTTXX TABLE: 6 XXTTT
== ROW 6.0 ==
-- COL 6.0.0 --

-- COL 6.0.1 --

-- COL 6.0.2 --

-- COL 6.0.3 --
Commission Proposal 
-- COL 6.0.4 --
EP Mandate 
-- COL 6.0.5 --
Council Mandate 
-- COL 6.0.6 --
Draft Agreement
-- COL 6.0.7 --

-- COL 6.0.8 --

== ROW 6.1 ==
-- COL 6.1.0 --
G 
-- COL 6.1.1 --

-- COL 6.1.2 --
11a
-- COL 6.1.3 --

-- COL 6.1.4 --
(1a) This Regulation should  preserve the values of the Union  facilitating the distribution of  artificial intelligence benefits  across society, protecting  
individuals, companies, democracy  and rule of law and the  
environment from risks while  boosting innovation and  
employment and making the Union  a leader in the field 
-- COL 6.1.5 --

-- COL 6.1.6 --
(1a) This Regulation should be  applied in conformity with the  values of the Union enshrined in  the Charter facilitating the  
protection of individuals,  
companies, democracy and rule of  law and the environment while  boosting innovation and  
employment and making the Union  a leader in the uptake of  
trustworthy AI.
-- COL 6.1.7 --
G
-- COL 6.1.8 --

== ROW 6.2 ==
-- COL 6.2.0 --

-- COL 6.2.1 --

-- COL 6.2.2 --
Recital 2
-- COL 6.2.3 --

-- COL 6.2.4 --

-- COL 6.2.5 --

-- COL 6.2.6 --

-- COL 6.2.7 --

-- COL 6.2.8 --

== ROW 6.3 ==
-- COL 6.3.0 --
G 
-- COL 6.3.1 --

-- COL 6.3.2 --
12
-- COL 6.3.3 --
(2) Artificial intelligence systems  (AI systems) can be easily deployed  in multiple sectors of the economy  and society, including cross border,  and circulate throughout the Union.  Certain Member States have already  explored the adoption of national  rules to ensure that artificial  
intelligence is safe and is developed  and used in compliance with  
fundamental rights obligations.  Differing national rules may lead to  fragmentation of the internal market  and decrease legal certainty for  operators that develop or use AI  systems. A consistent and high level  of protection throughout the Union  should therefore be ensured, while  divergences hampering the free  circulation of AI systems and related  products and services within the 
-- COL 6.3.4 --
(2) A AI systems can be easily deployed  in multiple sectors of the economy  and society, including cross border,  and circulate throughout the Union.  Certain Member States have already  explored the adoption of national  rules to ensure that artificial  
intelligence is trustworthy and safe  and is developed and used in  
compliance with fundamental rights  obligations. Differing national rules  may lead to fragmentation of the  internal market and decrease legal  certainty for operators that develop  or use AI systems. A consistent and high level of protection throughout  the Union should therefore be  ensured in order to achieve  
trustworthy AI, while divergences  hampering the free circulation, 
-- COL 6.3.5 --
(2) Artificial intelligence systems  (AI systems) can be easily deployed  in multiple sectors of the economy  and society, including cross border,  and circulate throughout the Union.  Certain Member States have already  explored the adoption of national  rules to ensure that artificial  
intelligence is safe and is developed  and used in compliance with  
fundamental rights obligations.  Differing national rules may lead to  fragmentation of the internal market  and decrease legal certainty for  operators that develop, import or use  AI systems. A consistent and high  level of protection throughout the  Union should therefore be ensured,  while divergences hampering the  free circulation of AI systems and  related products and services within 
-- COL 6.3.6 --
(2) A AI systems can be easily deployed  in multiple sectors of the economy  and society, including cross border,  and circulate throughout the Union.  Certain Member States have already  explored the adoption of national  rules to ensure that artificial  
intelligence is trustworthy and safe  and is developed and used in  
compliance with fundamental rights  obligations. Differing national rules  may lead to fragmentation of the  internal market and decrease legal  certainty for operators that develop,  import or use AI systems. A  
consistent and high level of  
protection throughout the Union  should therefore be ensured in order  to achieve trustworthy AI, while  divergences hampering the free 
-- COL 6.3.7 --
G
-- COL 6.3.8 --


TTTXX TABLE: 7 XXTTT
== ROW 7.0 ==
-- COL 7.0.0 --

-- COL 7.0.1 --

-- COL 7.0.2 --

-- COL 7.0.3 --
Commission Proposal 
-- COL 7.0.4 --
EP Mandate 
-- COL 7.0.5 --
Council Mandate 
-- COL 7.0.6 --
Draft Agreement
-- COL 7.0.7 --

-- COL 7.0.8 --

== ROW 7.1 ==
-- COL 7.1.0 --

-- COL 7.1.1 --

-- COL 7.1.2 --

-- COL 7.1.3 --
internal market should be prevented,  by laying down uniform obligations  for operators and guaranteeing the  uniform protection of overriding  reasons of public interest and of  rights of persons throughout the  internal market based on Article 114  of the Treaty on the Functioning of  the European Union (TFEU). To the  extent that this Regulation contains  specific rules on the protection of  individuals with regard to the  processing of personal data  
concerning restrictions of the use of  AI systems for ‘real-time’ remote  biometric identification in publicly  accessible spaces for the purpose of  law enforcement, it is appropriate to  base this Regulation, in as far as  those specific rules are concerned,  on Article 16 of the TFEU. In light  of those specific rules and the  recourse to Article 16 TFEU, it is  appropriate to consult the European  Data Protection Board.
-- COL 7.1.4 --
innovation, deployment and uptake of AI systems and related products  and services within the internal  market should be prevented, by  laying down uniform obligations for  operators and guaranteeing the  uniform protection of overriding  reasons of public interest and of  rights of persons throughout the  internal market based on Article 114  of the Treaty on the Functioning of  the European Union (TFEU).     p 

-- COL 7.1.5 --
the internal market should be  
prevented, by laying down uniform  obligations for operators and  
guaranteeing the uniform protection  of overriding reasons of public  interest and of rights of persons  throughout the internal market based  on Article 114 of the Treaty on the  Functioning of the European Union  (TFEU). To the extent that this  Regulation contains specific rules on  the protection of individuals with  regard to the processing of personal  data concerning restrictions of the  use of AI systems for ‘real-time’  remote biometric identification in  publicly accessible spaces for the  purpose of law enforcement, it is  appropriate to base this Regulation,  in as far as those specific rules are  concerned, on Article 16 of the  TFEU. In light of those specific  rules and the recourse to Article 16  TFEU, it is appropriate to consult  the European Data Protection Board.
-- COL 7.1.6 --
circulation, innovation, deployment  and uptake of AI systems and  related products and services within  the internal market should be  
prevented, by laying down uniform  obligations for operators and  
guaranteeing the uniform protection  of overriding reasons of public  interest and of rights of persons  throughout the internal market based  on Article 114 of the Treaty on the  Functioning of the European Union  (TFEU). To the extent that this  Regulation contains specific rules on  the protection of individuals with  regard to the processing of personal  data concerning restrictions of the  use of AI systems for  remote biometric identification   por the  purpose of law enforcement, for the  use of AI systems for risk  
assessments of natural persons for  the purpose of law enforcement and  for the use of AI systems of  
biometric categorization for the  purpose of law enforcement, it is  appropriate to base this Regulation,  in as far as those specific rules are  concerned, on Article 16 of the  TFEU. In light of those specific  rules and the recourse to Article 16  TFEU, it is appropriate to consult  the European Data Protection Board.
-- COL 7.1.7 --

-- COL 7.1.8 --

== ROW 7.2 ==
-- COL 7.2.0 --

-- COL 7.2.1 --

-- COL 7.2.2 --
Recital 2a
-- COL 7.2.3 --

-- COL 7.2.4 --

-- COL 7.2.5 --

-- COL 7.2.6 --

-- COL 7.2.7 --

-- COL 7.2.8 --


TTTXX TABLE: 8 XXTTT
== ROW 8.0 ==
-- COL 8.0.0 --

-- COL 8.0.1 --

-- COL 8.0.2 --

-- COL 8.0.3 --
Commission Proposal 
-- COL 8.0.4 --
EP Mandate 
-- COL 8.0.5 --
Council Mandate 
-- COL 8.0.6 --
Draft Agreement
-- COL 8.0.7 --

-- COL 8.0.8 --

== ROW 8.1 ==
-- COL 8.1.0 --
G 
-- COL 8.1.1 --

-- COL 8.1.2 --
12a
-- COL 8.1.3 --

-- COL 8.1.4 --
(2a) As artificial intelligence often  relies on the processing of large  volumes of data, and many AI  systems and applications on the  processing of personal data, it is  appropriate to base this Regulation  on Article 16 TFEU, which  
enshrines the right to the protection  of natural persons with regard to  the processing of personal data and  provides for the adoption of rules  on the protection of individuals  with regard to the processing of  personal data. 
-- COL 8.1.5 --

-- COL 8.1.6 --

-- COL 8.1.7 --
G
-- COL 8.1.8 --

== ROW 8.2 ==
-- COL 8.2.0 --

-- COL 8.2.1 --

-- COL 8.2.2 --
Recital 2b
-- COL 8.2.3 --

-- COL 8.2.4 --

-- COL 8.2.5 --

-- COL 8.2.6 --

-- COL 8.2.7 --

-- COL 8.2.8 --

== ROW 8.3 ==
-- COL 8.3.0 --
G 
-- COL 8.3.1 --

-- COL 8.3.2 --
12b
-- COL 8.3.3 --

-- COL 8.3.4 --
(2b) The fundamental right to the  protection of personal data is  safeguarded in particular by  Regulations (EU) 2016/679 and  (EU) 2018/1725 and Directive  2016/680. Directive 2002/58/EC  additionally protects private life and  the confidentiality of  
communications, including  
providing conditions for any  personal and non-personal data  storing in and access from terminal  equipment. Those legal acts provide  the basis for sustainable and  responsible data processing,  
including where datasets include a  mix of personal and nonpersonal  data. This Regulation does not seek 
-- COL 8.3.5 --

-- COL 8.3.6 --

-- COL 8.3.7 --
G
-- COL 8.3.8 --


TTTXX TABLE: 9 XXTTT
== ROW 9.0 ==
-- COL 9.0.0 --

-- COL 9.0.1 --

-- COL 9.0.2 --

-- COL 9.0.3 --
Commission Proposal 
-- COL 9.0.4 --
EP Mandate 
-- COL 9.0.5 --
Council Mandate 
-- COL 9.0.6 --
Draft Agreement
-- COL 9.0.7 --

-- COL 9.0.8 --

== ROW 9.1 ==
-- COL 9.1.0 --

-- COL 9.1.1 --

-- COL 9.1.2 --

-- COL 9.1.3 --

-- COL 9.1.4 --
to affect the application of existing  Union law governing the processing  of personal data, including the  tasks and powers of the  
independent supervisory authorities  competent to monitor compliance  with those instruments. This  
Regulation does not affect the  fundamental rights to private life  and the protection of personal data  as provided for by Union law on  data protection and privacy and  enshrined in the Charter of  
Fundamental Rights of the  
European Union (the ‘Charter’). 
-- COL 9.1.5 --

-- COL 9.1.6 --

-- COL 9.1.7 --

-- COL 9.1.8 --

== ROW 9.2 ==
-- COL 9.2.0 --

-- COL 9.2.1 --

-- COL 9.2.2 --
Recital 2c
-- COL 9.2.3 --

-- COL 9.2.4 --

-- COL 9.2.5 --

-- COL 9.2.6 --

-- COL 9.2.7 --

-- COL 9.2.8 --

== ROW 9.3 ==
-- COL 9.3.0 --
G 
-- COL 9.3.1 --

-- COL 9.3.2 --
12c
-- COL 9.3.3 --

-- COL 9.3.4 --
(2c) Artificial intelligence systems  in the Union are subject to relevant  product safety legislation that  provides a framework protecting  consumers against dangerous  products in general and such  legislation should continue to  apply. This Regulation is also  without prejudice to the rules laid  down by other Union legal acts  related to consumer protection and  product safety, including including  Regulation (EU) 2017/2394,  
Regulation (EU) 2019/1020 and Directive 2001/95/EC on general  product safety and Directive  2013/11/EU. 
-- COL 9.3.5 --

-- COL 9.3.6 --

-- COL 9.3.7 --
G
-- COL 9.3.8 --


TTTXX TABLE: 10 XXTTT
== ROW 10.0 ==
-- COL 10.0.0 --

-- COL 10.0.1 --

-- COL 10.0.2 --

-- COL 10.0.3 --
Commission Proposal 
-- COL 10.0.4 --
EP Mandate 
-- COL 10.0.5 --
Council Mandate 
-- COL 10.0.6 --
Draft Agreement
-- COL 10.0.7 --

-- COL 10.0.8 --

== ROW 10.1 ==
-- COL 10.1.0 --

-- COL 10.1.1 --

-- COL 10.1.2 --
Recital 2d
-- COL 10.1.3 --

-- COL 10.1.4 --

-- COL 10.1.5 --

-- COL 10.1.6 --

-- COL 10.1.7 --

-- COL 10.1.8 --

== ROW 10.2 ==
-- COL 10.2.0 --
G 
-- COL 10.2.1 --

-- COL 10.2.2 --
12d
-- COL 10.2.3 --

-- COL 10.2.4 --
(2d) In accordance with Article  114(2) TFEU, this Regulation  complements and should not  undermine the rights and interests  of employed persons. This  
Regulation should therefore not  affect Union law on social policy  and national labour law and  practice, that is any legal and  contractual provision concerning  employment conditions, working  conditions, including health and  safety at work and the relationship  between employers and workers,  including information, consultation  and participation. This Regulation  should not affect the exercise of  fundamental rights as recognised in  the Member States and at Union  level, including the right or freedom  to strike or to take other action  covered by the specific industrial  relations systems in Member States,  in accordance with national law  and/or practice. Nor should it affect  concertation practices, the right to  negotiate, to conclude and enforce  collective agreement or to take  collective action in accordance with  national law and/or practice. It  should in any event not prevent the  Commission from proposing  specific legislation on the rights  and freedoms of workers affected  by AI systems.
-- COL 10.2.5 --

-- COL 10.2.6 --

-- COL 10.2.7 --
G
-- COL 10.2.8 --


TTTXX TABLE: 11 XXTTT
== ROW 11.0 ==
-- COL 11.0.0 --

-- COL 11.0.1 --

-- COL 11.0.2 --

-- COL 11.0.3 --
Commission Proposal 
-- COL 11.0.4 --
EP Mandate 
-- COL 11.0.5 --
Council Mandate 
-- COL 11.0.6 --
Draft Agreement
-- COL 11.0.7 --

-- COL 11.0.8 --

== ROW 11.1 ==
-- COL 11.1.0 --

-- COL 11.1.1 --

-- COL 11.1.2 --

-- COL 11.1.3 --

-- COL 11.1.4 --

-- COL 11.1.5 --

-- COL 11.1.6 --

-- COL 11.1.7 --

-- COL 11.1.8 --

== ROW 11.2 ==
-- COL 11.2.0 --

-- COL 11.2.1 --

-- COL 11.2.2 --
Recital 2e
-- COL 11.2.3 --

-- COL 11.2.4 --

-- COL 11.2.5 --

-- COL 11.2.6 --

-- COL 11.2.7 --

-- COL 11.2.8 --

== ROW 11.3 ==
-- COL 11.3.0 --
G 
-- COL 11.3.1 --

-- COL 11.3.2 --
12e
-- COL 11.3.3 --

-- COL 11.3.4 --
(2e) This Regulation should not  affect the provisions aiming to  improve working conditions in  platform work set out in Directive ...  [COD 2021/414/EC].
-- COL 11.3.5 --

-- COL 11.3.6 --

-- COL 11.3.7 --
G
-- COL 11.3.8 --

== ROW 11.4 ==
-- COL 11.4.0 --

-- COL 11.4.1 --

-- COL 11.4.2 --
Recital 2f
-- COL 11.4.3 --

-- COL 11.4.4 --

-- COL 11.4.5 --

-- COL 11.4.6 --

-- COL 11.4.7 --

-- COL 11.4.8 --

== ROW 11.5 ==
-- COL 11.5.0 --
G 
-- COL 11.5.1 --

-- COL 11.5.2 --
12f
-- COL 11.5.3 --

-- COL 11.5.4 --
(2f) This Regulation should help in  supporting research and innovation  and should not undermine research  and development activity and  
respect freedom of scientific  
research. It is therefore necessary  to exclude from its scope AI systems  specifically developed for the sole  purpose of scientific research and  development and to ensure that the  Regulation does not otherwise  affect scientific research and  development activity on AI systems.  Under all circumstances, any  research and development activity  should be carried out in accordance  with the Charter, Union law as well  as the national law.
-- COL 11.5.5 --

-- COL 11.5.6 --

-- COL 11.5.7 --
G
-- COL 11.5.8 --

== ROW 11.6 ==
-- COL 11.6.0 --

-- COL 11.6.1 --

-- COL 11.6.2 --
Recital 3
-- COL 11.6.3 --

-- COL 11.6.4 --

-- COL 11.6.5 --

-- COL 11.6.6 --

-- COL 11.6.7 --

-- COL 11.6.8 --

== ROW 11.7 ==
-- COL 11.7.0 --
G 
-- COL 11.7.1 --

-- COL 11.7.2 --
13 
-- COL 11.7.3 --
(3) Artificial intelligence is a fast  evolving family of technologies that 
-- COL 11.7.4 --
(3) Artificial intelligence is a fast  evolving family of technologies that 
-- COL 11.7.5 --
(3) Artificial intelligence is a fast  evolving family of technologies that 
-- COL 11.7.6 --
(3) Artificial intelligence is a fast  evolving family of technologies that 
-- COL 11.7.7 --
G
-- COL 11.7.8 --


TTTXX TABLE: 12 XXTTT
== ROW 12.0 ==
-- COL 12.0.0 --

-- COL 12.0.1 --

-- COL 12.0.2 --

-- COL 12.0.3 --
Commission Proposal 
-- COL 12.0.4 --
EP Mandate 
-- COL 12.0.5 --
Council Mandate 
-- COL 12.0.6 --
Draft Agreement
-- COL 12.0.7 --

-- COL 12.0.8 --

== ROW 12.1 ==
-- COL 12.1.0 --

-- COL 12.1.1 --

-- COL 12.1.2 --

-- COL 12.1.3 --
can contribute to a wide array of  economic and societal benefits  across the entire spectrum of  
industries and social activities. By  improving prediction, optimising  operations and resource allocation,  and personalising digital solutions  available for individuals and  
organisations, the use of artificial  intelligence can provide key  
competitive advantages to  
companies and support socially and  environmentally beneficial  
outcomes, for example in healthcare,  farming, education and training,  infrastructure management, energy,  transport and logistics, public  services, security, justice, resource  and energy efficiency, and climate  change mitigation and adaptation.
-- COL 12.1.4 --
can nd already  
contributes to a wide array of  economic, environmental and  societal benefits across the entire  spectrum of industries and social  activities if developed in accordance  with relevant general principles in  line with the Charter and the values  on which the Union is founded. By  improving prediction, optimising  operations and resource allocation,  and personalising digital solutions  available for individuals and  
organisations, the use of artificial  intelligence can provide key  
competitive advantages to  
companies and support socially and  environmentally beneficial  
outcomes, for example in healthcare,  farming, food safety, education and  training, media, sports, culture,  infrastructure management, energy,  transport and logistics, crisis  
management, public services,  security, justice, resource and energy  efficiency, environmental  
monitoring, the conservation and  restoration of biodiversity and  ecosystems and climate change  mitigation and adaptation.
-- COL 12.1.5 --
can contribute to a wide array of  economic and societal benefits  across the entire spectrum of  
industries and social activities. By improving prediction, optimising  operations and resource allocation,  and personalising digital solutions  available for individuals and  
organisations, the use of artificial  intelligence can provide key  
competitive advantages to  
companies and support socially and  environmentally beneficial  
outcomes, for example in healthcare,  farming, education and training,  infrastructure management, energy,  transport and logistics, public  services, security, justice, resource  and energy efficiency, and climate  change mitigation and adaptation.
-- COL 12.1.6 --

personalising digital solutions  available for individuals and  
organisations, the use of artificial  intelligence can provide key  
competitive advantages to  
companies and support socially and  environmentally beneficial  
outcomes, for example in healthcare,  farming, food safety, education and  training, media, sports, culture,  infrastructure management, energy,  transport and logistics, public  services, security, justice, resource  and energy efficiency,  
environmental monitoring, the  conservation and restoration of  biodiversity and ecosystems and  
climate change mitigation and  adaptation .
-- COL 12.1.7 --

-- COL 12.1.8 --

== ROW 12.2 ==
-- COL 12.2.0 --

-- COL 12.2.1 --

-- COL 12.2.2 --
Recital 3a
-- COL 12.2.3 --

-- COL 12.2.4 --

-- COL 12.2.5 --

-- COL 12.2.6 --

-- COL 12.2.7 --

-- COL 12.2.8 --

== ROW 12.3 ==
-- COL 12.3.0 --
G 
-- COL 12.3.1 --

-- COL 12.3.2 --
13a 
-- COL 12.3.3 --

-- COL 12.3.4 --
(3a) To contribute to reaching the  carbon neutrality targets, European  companies should seek to utilise all 
-- COL 12.3.5 --

-- COL 12.3.6 --

-- COL 12.3.7 --
G
-- COL 12.3.8 --


TTTXX TABLE: 13 XXTTT
== ROW 13.0 ==
-- COL 13.0.0 --

-- COL 13.0.1 --

-- COL 13.0.2 --

-- COL 13.0.3 --
Commission Proposal 
-- COL 13.0.4 --
EP Mandate 
-- COL 13.0.5 --
Council Mandate 
-- COL 13.0.6 --
Draft Agreement
-- COL 13.0.7 --

-- COL 13.0.8 --

== ROW 13.1 ==
-- COL 13.1.0 --

-- COL 13.1.1 --

-- COL 13.1.2 --

-- COL 13.1.3 --

-- COL 13.1.4 --
available technological  
advancements that can assist in  realising this goal. Artificial  
Intelligence is a technology that has  the potential of being used to  process the ever-growing amount of  data created during industrial,  environmental, health and other  processes. To facilitate investments  in AI-based analysis and  
optimisation tools, this Regulation  should provide a predictable and  proportionate environment for low risk industrial solutions. 
-- COL 13.1.5 --

-- COL 13.1.6 --

-- COL 13.1.7 --

-- COL 13.1.8 --

== ROW 13.2 ==
-- COL 13.2.0 --

-- COL 13.2.1 --

-- COL 13.2.2 --
Recital 4
-- COL 13.2.3 --

-- COL 13.2.4 --

-- COL 13.2.5 --

-- COL 13.2.6 --

-- COL 13.2.7 --

-- COL 13.2.8 --

== ROW 13.3 ==
-- COL 13.3.0 --
G 
-- COL 13.3.1 --

-- COL 13.3.2 --
14
-- COL 13.3.3 --
(4) At the same time, depending on  the circumstances regarding its  specific application and use,  
artificial intelligence may generate  risks and cause harm to public  interests and rights that are protected  by Union law. Such harm might be  material or immaterial.
-- COL 13.3.4 --
(4) At the same time, depending on  the circumstances regarding its  specific application and use, as well  as the level of technological  
development, artificial intelligence  may generate risks and cause harm  to public or private interests and  fundamental rights of natural  persons that are protected by Union  law. Such harm might be material or  immaterial, including physical,  psychological, societal or economic  harm.
-- COL 13.3.5 --
(4) At the same time, depending on  the circumstances regarding its  specific application and use,  
artificial intelligence may generate  risks and cause harm to public  interests and rights that are protected  by Union law. Such harm might be  material or immaterial.
-- COL 13.3.6 --
(4) At the same time, depending on  the circumstances regarding its  specific application, use, and level  of technological development  , artificial intelligence may  generate risks and cause harm to  public interests and fundamental  rights that are protected by Union  law. Such harm might be material or  immaterial, including physical,  psychological, societal or economic  harm.
-- COL 13.3.7 --
G
-- COL 13.3.8 --

== ROW 13.4 ==
-- COL 13.4.0 --

-- COL 13.4.1 --

-- COL 13.4.2 --
Recital 4a
-- COL 13.4.3 --

-- COL 13.4.4 --

-- COL 13.4.5 --

-- COL 13.4.6 --

-- COL 13.4.7 --

-- COL 13.4.8 --

== ROW 13.5 ==
-- COL 13.5.0 --
G 
-- COL 13.5.1 --

-- COL 13.5.2 --
14a 
-- COL 13.5.3 --

-- COL 13.5.4 --
(4a) Given the major impact that  artificial intelligence can have on 
-- COL 13.5.5 --

-- COL 13.5.6 --
(4a) Given the major impact that  artificial intelligence can have on 
-- COL 13.5.7 --
G
-- COL 13.5.8 --


TTTXX TABLE: 14 XXTTT
== ROW 14.0 ==
-- COL 14.0.0 --

-- COL 14.0.1 --

-- COL 14.0.2 --

-- COL 14.0.3 --
Commission Proposal 
-- COL 14.0.4 --
EP Mandate 
-- COL 14.0.5 --
Council Mandate 
-- COL 14.0.6 --
Draft Agreement
-- COL 14.0.7 --

-- COL 14.0.8 --

== ROW 14.1 ==
-- COL 14.1.0 --

-- COL 14.1.1 --

-- COL 14.1.2 --

-- COL 14.1.3 --

-- COL 14.1.4 --
society and the need to build trust, it  is vital for artificial intelligence and  its regulatory framework to be  developed according to Union  values enshrined in Article 2 TEU,  the fundamental rights and  
freedoms enshrined in the Treaties,  the Charter, and international  human rights law. As a pre 
requisite, artificial intelligence  should be a human-centric  
technology. It should not substitute  human autonomy or assume the  loss of individual freedom and  should primarily serve the needs of  the society and the common good.  Safeguards should be provided to  ensure the development and use of  ethically embedded artificial  
intelligence that respects Union  values and the Charter. 
-- COL 14.1.5 --

-- COL 14.1.6 --
society and the need to build trust, it  is vital for artificial intelligence and  its regulatory framework to be  developed according to Union  values enshrined in Article 2 TEU,  the fundamental rights and  
freedoms enshrined in the Treaties,  the Charter. As a pre-requisite,  artificial intelligence should be a  human-centric technology. It  should serve as a tool for people,  with the ultimate aim of increasing  human well-being. 
(4aa) In order to ensure a  
consistent and high level of  
protection of public interests as  regards health, safety and  
fundamental rights, common rules  for all high-risk AI systems should  be established. Those rules should  be consistent with the Charter of  
fundamental rights of the European  Union (the Charter) and should be  non-discriminatory and in line with  
the Union’s international trade  commitments. They should also  take into account the European  Declaration on Digital Rights and  
Principles for the Digital Decade  (2023/C 23/01) and the Ethics  Guidelines for Trustworthy  
Artificial Intelligence (AI) of the High-Level Expert Group on  Artificial Intelligence. 
-- COL 14.1.7 --

-- COL 14.1.8 --

== ROW 14.2 ==
-- COL 14.2.0 --

-- COL 14.2.1 --

-- COL 14.2.2 --
Recital 5
-- COL 14.2.3 --

-- COL 14.2.4 --

-- COL 14.2.5 --

-- COL 14.2.6 --

-- COL 14.2.7 --

-- COL 14.2.8 --


TTTXX TABLE: 15 XXTTT
== ROW 15.0 ==
-- COL 15.0.0 --

-- COL 15.0.1 --

-- COL 15.0.2 --

-- COL 15.0.3 --
Commission Proposal 
-- COL 15.0.4 --
EP Mandate 
-- COL 15.0.5 --
Council Mandate 
-- COL 15.0.6 --
Draft Agreement
-- COL 15.0.7 --

-- COL 15.0.8 --

== ROW 15.1 ==
-- COL 15.1.0 --
G 
-- COL 15.1.1 --

-- COL 15.1.2 --
15
-- COL 15.1.3 --
(5) A Union legal framework laying  down harmonised rules on artificial  intelligence is therefore needed to  foster the development, use and  uptake of artificial intelligence in the  internal market that at the same time  meets a high level of protection of  public interests, such as health and  safety and the protection of  
fundamental rights, as recognised  and protected by Union law. To  achieve that objective, rules  
regulating the placing on the market  and putting into service of certain AI  systems should be laid down, thus  ensuring the smooth functioning of  the internal market and allowing  those systems to benefit from the  principle of free movement of goods  and services. By laying down those  rules, this Regulation supports the  objective of the Union of being a  global leader in the development of  secure, trustworthy and ethical  artificial intelligence, as stated by  the European Council1, and it  ensures the protection of ethical  principles, as specifically requested  by the European Parliament2. 
_________ 
1. European Council, Special meeting of the  European Council (1 and 2 October 2020) – Conclusions, EUCO 13/20, 2020, p. 6. 2. European Parliament resolution of 20  October 2020 with recommendations to the  Commission on a framework of ethical  aspects of artificial intelligence, robotics and 
-- COL 15.1.4 --
(5) A Union legal framework laying  down harmonised rules on artificial  intelligence is therefore needed to  foster the development, use and  uptake of artificial intelligence in the  internal market that at the same time  meets a high level of protection of  public interests, such as health and  safety protection of  
fundamental rights, democracy and  rule of law and the environment, as  recognised and protected by Union  law. To achieve that objective, rules  regulating the placing on the market,  the  putting into service and the  use of certain AI systems should be  laid down, thus ensuring the smooth  functioning of the internal market  and allowing those systems to  benefit from the principle of free  movement of goods and services.  These rules should be clear and  robust in protecting fundamental  rights, supportive of new innovative  solutions, and enabling to a  
European ecosystem of public and  private actors creating AI systems  in line with Union values. By laying  down those rules as well as  
measures in support of innovation  with a particular focus on SMEs  and start-ups, this Regulation  supports the objective of promoting  the AI made in Europe, of the  Union of being a global leader in the  development of secure, trustworthy 
-- COL 15.1.5 --
(5) A Union legal framework laying  down harmonised rules on artificial  intelligence is therefore needed to  foster the development, use and  uptake of artificial intelligence in the  internal market that at the same time  meets a high level of protection of  public interests, such as health and  safety and the protection of  
fundamental rights, as recognised  and protected by Union law. To  achieve that objective, rules  
regulating the placing on the market  and putting into service of certain AI  systems should be laid down, thus  ensuring the smooth functioning of  the internal market and allowing  those systems to benefit from the  principle of free movement of goods  and services. By laying down those  rules and building on the work of  the High-level Expert Group on  Artificial Intelligence as reflecetd in  the Guidelines for Trustworthy  Artificial Intelligence in the EU,  this Regulation supports the  
objective of the Union of being a  global leader in the development of  secure, trustworthy and ethical  artificial intelligence,as stated by  the European Council1, and it  ensures the protection of ethical  principles, as specifically requested  by the European Parliament2. 
_________ 
1. [1] European Council, Special 
-- COL 15.1.6 --
(5) A Union legal framework laying  down harmonised rules on artificial  intelligence is therefore needed to  foster the development, use and  uptake of artificial intelligence in the  internal market that at the same time  meets a high level of protection of  public interests, such as health and  safety and the protection of  
fundamental rights, including  democracy, rule of law and  
environmental protection as  
recognised and protected by Union  law. To achieve that objective, rules  regulating the placing on the market  putting into service and use of  
certain AI systems should be laid  down, thus ensuring the smooth  functioning of the internal market  and allowing those systems to  benefit from the principle of free  movement of goods and services.  These rules should be clear and  robust in protecting fundamental  rights, supportive of new innovative  solutions, enabling to a European  ecosystem of public and private  actors creating AI systems in line  with Union values and unlocking  the potential of the digital  
transformation across all regions of  the Union. By laying down those  rules as well as measures in support  of innovation with a particular  focus on SMEs including startups,  this Regulation supports the 
-- COL 15.1.7 --
G
-- COL 15.1.8 --


TTTXX TABLE: 16 XXTTT
== ROW 16.0 ==
-- COL 16.0.0 --

-- COL 16.0.1 --

-- COL 16.0.2 --

-- COL 16.0.3 --
Commission Proposal 
-- COL 16.0.4 --
EP Mandate 
-- COL 16.0.5 --
Council Mandate 
-- COL 16.0.6 --
Draft Agreement
-- COL 16.0.7 --

-- COL 16.0.8 --

== ROW 16.1 ==
-- COL 16.1.0 --

-- COL 16.1.1 --

-- COL 16.1.2 --

-- COL 16.1.3 --
related technologies, 2020/2012(INL). 
-- COL 16.1.4 --
and ethical artificial intelligence, as  stated by the European Council1, and  it ensures the protection of ethical  principles, as specifically requested  by the European Parliament2. 
_________ 
1. European Council, Special meeting of the  European Council (1 and 2 October 2020) – Conclusions, EUCO 13/20, 2020, p. 6. 2. European Parliament resolution of 20  October 2020 with recommendations to the  Commission on a framework of ethical  aspects of artificial intelligence, robotics and  related technologies, 2020/2012(INL).
-- COL 16.1.5 --
meeting of the European Council (1 and 2  October 2020) – Conclusions, EUCO 13/20,  2020, p. 6. 
2. [2] European Parliament resolution  of 20 October 2020 with recommendations  to the Commission on a framework of ethical  aspects of artificial intelligence, robotics and  related technologies, 2020/2012(INL).
-- COL 16.1.6 --
objective of promoting the  
European human-centric approach  to AI and being a  global leader in the development of  secure, trustworthy and ethical  artificial intelligence,as stated by  the European Council1, and it  ensures the protection of ethical  principles, as specifically requested  by the the European Parliament2. _________ 
1. European Council, Special meeting of the  European Council (1 and 2 October 2020) – Conclusions, EUCO 13/20, 2020, p. 6. 2. European Parliament resolution of 20  October 2020 with recommendations to the  Commission on a framework of ethical  aspects of artificial intelligence, robotics and  related technologies, 2020/2012(INL).
-- COL 16.1.7 --

-- COL 16.1.8 --

== ROW 16.2 ==
-- COL 16.2.0 --

-- COL 16.2.1 --

-- COL 16.2.2 --
Recital 5a
-- COL 16.2.3 --

-- COL 16.2.4 --

-- COL 16.2.5 --

-- COL 16.2.6 --

-- COL 16.2.7 --

-- COL 16.2.8 --

== ROW 16.3 ==
-- COL 16.3.0 --
G 
-- COL 16.3.1 --

-- COL 16.3.2 --
15a
-- COL 16.3.3 --

-- COL 16.3.4 --

-- COL 16.3.5 --
(5a) The harmonised rules on the  placing on the market, putting into  service and use of AI systems laid  
down in this Regulation should  apply across sectors and, in line  with its New Legislative Framework  approach, should be without  prejudice to existing Union law,  notably on data protection,  
consumer protection, fundamental  rights, employment and product  safety, to which this Regulation is  complementary. As a consequence  all rights and remedies afforded by  such Union law to consumers and 
-- COL 16.3.6 --
(5a) The harmonised rules on the  placing on the market, putting into  service and use of AI systems laid  
down in this Regulation should  apply across sectors and, in line  with its New Legislative Framework  approach, should be without  prejudice to existing Union law,  notably on data protection,  
consumer protection, fundamental  rights, employment, and protection  of workers, and product safety, to  which this Regulation is  
complementary. As a consequence  all rights and remedies provided for 
-- COL 16.3.7 --
G
-- COL 16.3.8 --


TTTXX TABLE: 17 XXTTT
== ROW 17.0 ==
-- COL 17.0.0 --

-- COL 17.0.1 --

-- COL 17.0.2 --

-- COL 17.0.3 --
Commission Proposal 
-- COL 17.0.4 --
EP Mandate 
-- COL 17.0.5 --
Council Mandate 
-- COL 17.0.6 --
Draft Agreement
-- COL 17.0.7 --

-- COL 17.0.8 --

== ROW 17.1 ==
-- COL 17.1.0 --

-- COL 17.1.1 --

-- COL 17.1.2 --

-- COL 17.1.3 --

-- COL 17.1.4 --

-- COL 17.1.5 --
other persons who may be  
negatively impacted by AI systems,  including as regards the  
compensation of possible damages  pursuant to Council Directive  85/374/EEC of 25 July 1985 on the  approximation of the laws,  
regulations and administrative  provisions of the Member States  concerning liability for defective  products, remain unaffected and  fully applicable. On top of that, this  Regulation aims to strengthen the  effectiveness of such existing rights  and remedies by establishing  specific requirements and  
obligations, including in respect of  transparency, technical  
documentation and record-keeping  of AI systems. Furthermore, the  obligations placed on various  operators involved in the AI value  chain under this Regulation should  apply without prejudice to national  laws, in compliance with Union  law, having the effect of limiting  the use of certain AI systems where  such laws fall outside the scope of  this Regulation or pursue other  legitimate public interest objectives  than those pursued by this  
Regulation. For example, national  labour law and the laws on the  protection of minors (i.e. persons  below the age of 18) taking into  account the United Nations General  Comment No 25 (2021) on 
-- COL 17.1.6 --
by such Union law to consumers,  and other persons who may be  negatively impacted by AI systems,  including as regards the  
compensation of possible damages  pursuant to Council Directive  85/374/EEC of 25 July 1985 on the  approximation of the laws,  
regulations and administrative  provisions of the Member States  concerning liability for defective  products, remain unaffected and  fully applicable. Furthermore, in  the context of employment and  protection of workers, this  
Regulation should therefore not  affect Union law on social policy  and national labour law, in  
compliance with Union law,  
concerning employment and  working conditions, including  health and safety at work and the  relationship between employers and  workers. This Regulation should  also not affect the exercise of  fundamental rights as recognised in  the Member States and at Union  level, including the right or freedom  to strike or to take other action  covered by the specific industrial  relations systems in Member States  as well as, the right to negotiate, to  conclude and enforce collective  agreements or to take collective  action in accordance with national  law. [This Regulation should not  affect the provisions aiming to 
-- COL 17.1.7 --

-- COL 17.1.8 --


TTTXX TABLE: 18 XXTTT
== ROW 18.0 ==
-- COL 18.0.0 --

-- COL 18.0.1 --

-- COL 18.0.2 --

-- COL 18.0.3 --
Commission Proposal 
-- COL 18.0.4 --
EP Mandate 
-- COL 18.0.5 --
Council Mandate 
-- COL 18.0.6 --
Draft Agreement
-- COL 18.0.7 --

-- COL 18.0.8 --

== ROW 18.1 ==
-- COL 18.1.0 --

-- COL 18.1.1 --

-- COL 18.1.2 --

-- COL 18.1.3 --

-- COL 18.1.4 --

-- COL 18.1.5 --
children’s rights, insofar as they  are not specific to AI systems and  pursue other legimitate public  interest objectives, should not be  affected by this Regulation.
-- COL 18.1.6 --
improve working conditions in  platform work set out in Directive ...  [COD 2021/414/EC]] On top of  that, this Regulation aims to  
strengthen the effectiveness of such  existing rights and remedies by  establishing specific requirements  and obligations, including in  respect of transparency, technical  documentation and record-keeping  of AI systems. Furthermore, the  obligations placed on various  operators involved in the AI value  chain under this Regulation should  apply without prejudice to national  laws, in compliance with Union  law, having the effect of limiting  the use of certain AI systems where  such laws fall outside the scope of  this Regulation or pursue other  legitimate public interest objectives  than those pursued by this  
Regulation. For example, national  labour law and the laws on the  protection of minors (i.e. persons  below the age of 18) taking into  account the United Nations General  Comment No 25 (2021) on  
children’s rights, insofar as they  are not specific to AI systems and  pursue other legimitate public  interest objectives, should not be  affected by this Regulation. 
(5aa) The fundamental right to the  protection of personal data is  safeguarded in particular by 
-- COL 18.1.7 --

-- COL 18.1.8 --


TTTXX TABLE: 19 XXTTT
== ROW 19.0 ==
-- COL 19.0.0 --

-- COL 19.0.1 --

-- COL 19.0.2 --

-- COL 19.0.3 --
Commission Proposal 
-- COL 19.0.4 --
EP Mandate 
-- COL 19.0.5 --
Council Mandate 
-- COL 19.0.6 --
Draft Agreement
-- COL 19.0.7 --

-- COL 19.0.8 --

== ROW 19.1 ==
-- COL 19.1.0 --

-- COL 19.1.1 --

-- COL 19.1.2 --

-- COL 19.1.3 --

-- COL 19.1.4 --

-- COL 19.1.5 --

-- COL 19.1.6 --
Regulations (EU) 2016/679 and  (EU) 2018/1725 and Directive  2016/680. Directive 2002/58/EC  additionally protects private life and  the confidentiality of  
communications, including by way  of providing conditions for any  personal and non-personal data  storing in and access from terminal  equipment. Those Union legal acts  provide the basis for sustainable  and responsible data processing,  including where datasets include a  mix of personal and non-personal  data. This Regulation does not seek  to affect the application of existing  Union law governing the processing  of personal data, including the  tasks and powers of the  
independent supervisory authorities  competent to monitor compliance  with those instruments. 
It also does not affect the  
obligations of providers and  
deployers of AI systems in their role  as data controllers or processors  stemming from national or Union  law on the protection of personal  data in so far as the design, the  development or the use of AI  systems involves the processing of  personal data. It is also appropriate  to clarify that data subjects  
continue to enjoy all the rights and  guarantees awarded to them by  such Union law, including the 
-- COL 19.1.7 --

-- COL 19.1.8 --


TTTXX TABLE: 20 XXTTT
== ROW 20.0 ==
-- COL 20.0.0 --

-- COL 20.0.1 --

-- COL 20.0.2 --

-- COL 20.0.3 --
Commission Proposal 
-- COL 20.0.4 --
EP Mandate 
-- COL 20.0.5 --
Council Mandate 
-- COL 20.0.6 --
Draft Agreement
-- COL 20.0.7 --

-- COL 20.0.8 --

== ROW 20.1 ==
-- COL 20.1.0 --

-- COL 20.1.1 --

-- COL 20.1.2 --

-- COL 20.1.3 --

-- COL 20.1.4 --

-- COL 20.1.5 --

-- COL 20.1.6 --
rights related to solely automated  individual decision-making,  
including profiling. Harmonised  rules for the placing on the market,  the putting into service and the use  of AI systems established under this  Regulation should facilitate the  effective implementation and  enable the exercise of the data  subjects’ rights and other remedies  guaranteed under Union law on the  protection of personal data and of  other fundamental rights. 
(5ab) This Regulation should be  without prejudice to the provisions  regarding the liability of  
intermediary service providers set  out in Directive 2000/31/EC of the  European Parliament and of the  Council [as amended by the Digital  Services Act].
-- COL 20.1.7 --

-- COL 20.1.8 --

== ROW 20.2 ==
-- COL 20.2.0 --

-- COL 20.2.1 --

-- COL 20.2.2 --
Recital 5a
-- COL 20.2.3 --

-- COL 20.2.4 --

-- COL 20.2.5 --

-- COL 20.2.6 --

-- COL 20.2.7 --

-- COL 20.2.8 --

== ROW 20.3 ==
-- COL 20.3.0 --
G 
-- COL 20.3.1 --

-- COL 20.3.2 --
15b
-- COL 20.3.3 --

-- COL 20.3.4 --
(5a) Furthermore, in order to  foster the development of AI  systems in line with Union values,  the Union needs to address the  main gaps and barriers blocking  the potential of the digital  
transformation including the  shortage of digitally skilled  
workers, cybersecurity concerns,  lack of investment and access to  investment, and existing and 
-- COL 20.3.5 --

-- COL 20.3.6 --

-- COL 20.3.7 --
G
-- COL 20.3.8 --


TTTXX TABLE: 21 XXTTT
== ROW 21.0 ==
-- COL 21.0.0 --

-- COL 21.0.1 --

-- COL 21.0.2 --

-- COL 21.0.3 --
Commission Proposal 
-- COL 21.0.4 --
EP Mandate 
-- COL 21.0.5 --
Council Mandate 
-- COL 21.0.6 --
Draft Agreement
-- COL 21.0.7 --

-- COL 21.0.8 --

== ROW 21.1 ==
-- COL 21.1.0 --

-- COL 21.1.1 --

-- COL 21.1.2 --

-- COL 21.1.3 --

-- COL 21.1.4 --
potential gaps between large  companies, SME’s and start-ups.  Special attention should be paid to  ensuring that the benefits of AI and  innovation in new technologies are  felt across all regions of the Union  and that sufficient investment and  resources are provided especially to  those regions that may be lagging  behind in some digital indicators. 
-- COL 21.1.5 --

-- COL 21.1.6 --

-- COL 21.1.7 --

-- COL 21.1.8 --

== ROW 21.2 ==
-- COL 21.2.0 --

-- COL 21.2.1 --

-- COL 21.2.2 --
Recital 6
-- COL 21.2.3 --

-- COL 21.2.4 --

-- COL 21.2.5 --

-- COL 21.2.6 --

-- COL 21.2.7 --

-- COL 21.2.8 --

== ROW 21.3 ==
-- COL 21.3.0 --
G 
-- COL 21.3.1 --

-- COL 21.3.2 --
16
-- COL 21.3.3 --
(6) The notion of AI system should  be clearly defined to ensure legal  certainty, while providing the  flexibility to accommodate future  technological developments. The  definition should be based on the  key functional characteristics of the  software, in particular the ability, for  a given set of human-defined  
objectives, to generate outputs such  as content, predictions,  
recommendations, or decisions  which influence the environment  with which the system interacts, be it in a physical or digital dimension.  AI systems can be designed to  operate with varying levels of  autonomy and be used on a stand alone basis or as a component of a  product, irrespective of whether the  system is physically integrated into  the product (embedded) or serve the  functionality of the product without 
-- COL 21.3.4 --
(6) The notion of AI system in this  Regulation should be clearly defined  and closely aligned with the work of  international organisations working  on artificial intelligence to ensure  legal certainty, harmonization and  wide acceptance, while providing  the flexibility to accommodate  fhe rapid technological  developments in this field.  
Moreover, it should  be based on ey characteristics of  p   p    rtificial  
intelligence, such as its learning,  reasoning or modelling capabilities, 
-- COL 21.3.5 --
(6) The notion of AI system should  be clearly defined to ensure legal  certainty, while providing the  flexibility to accommodate future  technological developments. The  definition should be based on  key functional characteristics of  rtificial intelligence such  as its learning, reasoning or  
modelling capabilities,  
distinguishing it from simpler  software systems and programming  approaches. In particular, for the  purposes of this Regulation AI  systems should have the ability, f n the basis of machine  and/or human-based data and  inputs, to infer the way to achieve a set of inal objectives given to them by humans, using  machine learning and/or logic- and  knowledge based approaches and to  produce,outputs such as 
-- COL 21.3.6 --
(6) The notion of AI system in this  Regulation should be clearly defined  and closely aligned with the work of  international organisations working  on artificial intelligence to ensure  legal certainty, facilitate  
international convergence and wide  acceptance, while providing the  flexibility to accommodate fhe  rapid technological developments in this field.  
Moreover, it should be based on  ey characteristics of     

-- COL 21.3.7 --
G
-- COL 21.3.8 --


TTTXX TABLE: 22 XXTTT
== ROW 22.0 ==
-- COL 22.0.0 --

-- COL 22.0.1 --

-- COL 22.0.2 --

-- COL 22.0.3 --
Commission Proposal 
-- COL 22.0.4 --
EP Mandate 
-- COL 22.0.5 --
Council Mandate 
-- COL 22.0.6 --
Draft Agreement
-- COL 22.0.7 --

-- COL 22.0.8 --

== ROW 22.1 ==
-- COL 22.1.0 --

-- COL 22.1.1 --

-- COL 22.1.2 --

-- COL 22.1.3 --
being integrated therein (non 
embedded). The definition of AI  system should be complemented by  a list of specific techniques and  approaches used for its development,  which should be kept up-to–date in the light of market and technological  developments through the adoption  of delegated acts by the Commission  to amend that list.
-- COL 22.1.4 --
so as to distinguish it from simpler  software systems or programming  approaches. AI systems are 
designed to operate with varying  levels of autonomy, meaning that  they have at least some degree of  
independence of actions from  human controls and of capabilities  to operate without human  
intervention. The term “machine based” refers to the fact that AI  systems run on machines. The  reference to explicit or implicit  objectives underscores that AI  systems can     

objectives of the AI system may be  different from the intended purpose  of the AI system in a specific  context. The reference to  
predictions includes content, which  is considered in this Regulation a  form of prediction as one of the  p  

-- COL 22.1.5 --
content for generative AI systems  (e.g. text, video or images),  
predictions, recommendations,or  decisions, influencing 

systems can be designed to operate  with varying levels of autonomy and  be used on a stand-alone basis or as  a component of a product,  
irrespective of whether the system is  physically integrated into the  
product (embedded) or serve the  functionality of the product without  being integrated therein (non 
embedded). The     

oncept of the autonomy of an  AI system relates to the degree to  which such a system functions  without human involvement.
-- COL 22.1.6 --
natural persons to automatically  execute operations. A key  
characteristic of AI systems is their  capability to infer. This inference  refers to the process of obtaining  the outputs, such as  
predictions, content,  recommendations, or decisions, which can influence    A   p   f hysical  and virtual environments and to a  capability of AI systems to derive  models and/or algorithms from  inputs/data. The techniques that  enable inference while building an  AI system include machine learning  approaches that learn from data  how to achieve certain objectives;  and logic- and knowledge-based  approaches that infer from encoded  knowledge or symbolic  
representation of the task to be  solved. The capacity of an AI  system to infer goes beyond basic  data processing, enable learning,  reasoning or modelling. 
-- COL 22.1.7 --

-- COL 22.1.8 --


TTTXX TABLE: 23 XXTTT
== ROW 23.0 ==
-- COL 23.0.0 --

-- COL 23.0.1 --

-- COL 23.0.2 --

-- COL 23.0.3 --
Commission Proposal 
-- COL 23.0.4 --
EP Mandate 
-- COL 23.0.5 --
Council Mandate 
-- COL 23.0.6 --
Draft Agreement
-- COL 23.0.7 --

-- COL 23.0.8 --

== ROW 23.1 ==
-- COL 23.1.0 --

-- COL 23.1.1 --

-- COL 23.1.2 --

-- COL 23.1.3 --

-- COL 23.1.4 --

environment, even by merely  introducing new information to it.
-- COL 23.1.5 --

-- COL 23.1.6 --
The term “machine-based” refers to  the fact that AI systems run on  machines. The reference to explicit  or implicit objectives underscores  that AI systems can operate  
according to explicit defined  objectives or to implicit objectives.  The objectives of the AI system   may be different from the intended  purpose of the AI system in a  specific   
ontext. For the purposes of  this Regulation, environments should be     understood as the  contexts in which the AI systems  operate, whereas outputs generated  by the AI system, reflect different  functions performed by AI systems  and include predictions, content,  recommendations or decisions.  
AI systems are designed to operate  with varying levels of autonomy,  meaning that they have some  degree of independence of actions  from human involvement and of  capabilities to operate without  human intervention. The  
adaptiveness that an AI system could exhibit after deployment, 
-- COL 23.1.7 --

-- COL 23.1.8 --


TTTXX TABLE: 24 XXTTT
== ROW 24.0 ==
-- COL 24.0.0 --

-- COL 24.0.1 --

-- COL 24.0.2 --

-- COL 24.0.3 --
Commission Proposal 
-- COL 24.0.4 --
EP Mandate 
-- COL 24.0.5 --
Council Mandate 
-- COL 24.0.6 --
Draft Agreement
-- COL 24.0.7 --

-- COL 24.0.8 --

== ROW 24.1 ==
-- COL 24.1.0 --

-- COL 24.1.1 --

-- COL 24.1.2 --

-- COL 24.1.3 --

-- COL 24.1.4 --

-- COL 24.1.5 --

-- COL 24.1.6 --
refers to self-learning capabilities,  allowing the system to change while  in use. AI systems can be used on a  stand-alone basis or as a  
component of a product,  
irrespective of whether the system is  physically integrated into the  product (embedded) or serve the  functionality of the product without  being integrated therein (non embedded). 
Text Origin: GSC
-- COL 24.1.7 --

-- COL 24.1.8 --

== ROW 24.2 ==
-- COL 24.2.0 --

-- COL 24.2.1 --

-- COL 24.2.2 --
Recital 6a
-- COL 24.2.3 --

-- COL 24.2.4 --

-- COL 24.2.5 --

-- COL 24.2.6 --

-- COL 24.2.7 --

-- COL 24.2.8 --

== ROW 24.3 ==
-- COL 24.3.0 --
G 
-- COL 24.3.1 --

-- COL 24.3.2 --
16a
-- COL 24.3.3 --

-- COL 24.3.4 --

-- COL 24.3.5 --
(6a) Machine learning approaches  focus on the development of  systems capable of learning and  inferring from data to solve an  application problem without being  explicitly programmed with a set of  step-by-step instructions from input  to output. Learning refers to the  computational process of  
optimizing from data the  
parameters of the model, which is a  mathematical construct generating  an output based on input data. The  
range of problems addressed by  machine learning typically involves  tasks for which other approaches  fail, either because there is no  suitable formalisation of the  
problem, or because the resolution  of the problem is intractable with 
-- COL 24.3.6 --

-- COL 24.3.7 --
G
-- COL 24.3.8 --


TTTXX TABLE: 25 XXTTT
== ROW 25.0 ==
-- COL 25.0.0 --

-- COL 25.0.1 --

-- COL 25.0.2 --

-- COL 25.0.3 --
Commission Proposal 
-- COL 25.0.4 --
EP Mandate 
-- COL 25.0.5 --
Council Mandate 
-- COL 25.0.6 --
Draft Agreement
-- COL 25.0.7 --

-- COL 25.0.8 --

== ROW 25.1 ==
-- COL 25.1.0 --

-- COL 25.1.1 --

-- COL 25.1.2 --

-- COL 25.1.3 --

-- COL 25.1.4 --

-- COL 25.1.5 --
non-learning approaches. Machine  learning approaches include for  instance supervised, unsupervised  and reinforcement learning, using  a variety of methods including deep  learning with neural networks,  statistical techniques for learning  and inference (including for  instance logistic regression,  
Bayesian estimation) and search  and optimisation methods.
-- COL 25.1.6 --

-- COL 25.1.7 --

-- COL 25.1.8 --

== ROW 25.2 ==
-- COL 25.2.0 --

-- COL 25.2.1 --

-- COL 25.2.2 --
Recital 6a
-- COL 25.2.3 --

-- COL 25.2.4 --

-- COL 25.2.5 --

-- COL 25.2.6 --

-- COL 25.2.7 --

-- COL 25.2.8 --

== ROW 25.3 ==
-- COL 25.3.0 --
G 
-- COL 25.3.1 --

-- COL 25.3.2 --
16b
-- COL 25.3.3 --

-- COL 25.3.4 --
(6a) AI systems often have  
machine learning capacities that  allow them to adapt and perform  new tasks autonomously. Machine  learning refers to the computational  process of optimizing the  
parameters of a model from data,  which is a mathematical construct  generating an output based on  input data. Machine learning  approaches include, for instance,  supervised, unsupervised and  reinforcement learning, using a  variety of methods including deep  learning with neural networks. This  Regulation is aimed at addressing  new potential risks that may arise  by delegating control to AI systems,  in particular to those AI systems  that can evolve after deployment.  The function and outputs of many  of these AI systems are based on 
-- COL 25.3.5 --

-- COL 25.3.6 --

-- COL 25.3.7 --
G
-- COL 25.3.8 --


TTTXX TABLE: 26 XXTTT
== ROW 26.0 ==
-- COL 26.0.0 --

-- COL 26.0.1 --

-- COL 26.0.2 --

-- COL 26.0.3 --
Commission Proposal 
-- COL 26.0.4 --
EP Mandate 
-- COL 26.0.5 --
Council Mandate 
-- COL 26.0.6 --
Draft Agreement
-- COL 26.0.7 --

-- COL 26.0.8 --

== ROW 26.1 ==
-- COL 26.1.0 --

-- COL 26.1.1 --

-- COL 26.1.2 --

-- COL 26.1.3 --

-- COL 26.1.4 --
abstract mathematical relationships  that are difficult for humans to  understand, monitor and trace back  to specific inputs. These complex  and opaque characteristics (black  box element) impact accountability  and explainability. Comparably  simpler techniques such as  
knowledge-based approaches,  Bayesian estimation or decision trees may also lead to legal gaps  that need to be addressed by this  Regulation, in particular when they  are used in combination with  machine learning approaches in  hybrid systems.
-- COL 26.1.5 --

-- COL 26.1.6 --

-- COL 26.1.7 --

-- COL 26.1.8 --

== ROW 26.2 ==
-- COL 26.2.0 --

-- COL 26.2.1 --

-- COL 26.2.2 --
Recital 6b
-- COL 26.2.3 --

-- COL 26.2.4 --

-- COL 26.2.5 --

-- COL 26.2.6 --

-- COL 26.2.7 --

-- COL 26.2.8 --

== ROW 26.3 ==
-- COL 26.3.0 --
G 
-- COL 26.3.1 --

-- COL 26.3.2 --
16c
-- COL 26.3.3 --

-- COL 26.3.4 --

-- COL 26.3.5 --
(6b) Logic- and knowledge based  approaches focus on the  
development of systems with logical  reasoning capabilities on  
knowledge to solve an application  problem. Such systems typically  involve a knowledge base and an  inference engine that generates  outputs by reasoning on the  
knowledge base. The knowledge  base, which is usually encoded by  human experts, represents entities  and logical relationships relevant  for the application problem through  formalisms based on rules,  
ontologies, or knowledge graphs.  The inference engine acts on the 
-- COL 26.3.6 --

-- COL 26.3.7 --
G
-- COL 26.3.8 --


TTTXX TABLE: 27 XXTTT
== ROW 27.0 ==
-- COL 27.0.0 --

-- COL 27.0.1 --

-- COL 27.0.2 --

-- COL 27.0.3 --
Commission Proposal 
-- COL 27.0.4 --
EP Mandate 
-- COL 27.0.5 --
Council Mandate 
-- COL 27.0.6 --
Draft Agreement
-- COL 27.0.7 --

-- COL 27.0.8 --

== ROW 27.1 ==
-- COL 27.1.0 --

-- COL 27.1.1 --

-- COL 27.1.2 --

-- COL 27.1.3 --

-- COL 27.1.4 --

-- COL 27.1.5 --
knowledge base and extracts new  information through operations  such as sorting, searching,  
matching or chaining. Logic- and  knowledge based approaches  include for instance knowledge  representation, inductive (logic)  programming, knowledge bases,  inference and deductive engines,  (symbolic) reasoning, expert  systems and search and  
optimisation methods.
-- COL 27.1.6 --

-- COL 27.1.7 --

-- COL 27.1.8 --

== ROW 27.2 ==
-- COL 27.2.0 --

-- COL 27.2.1 --

-- COL 27.2.2 --
Recital 6b
-- COL 27.2.3 --

-- COL 27.2.4 --

-- COL 27.2.5 --

-- COL 27.2.6 --

-- COL 27.2.7 --

-- COL 27.2.8 --

== ROW 27.3 ==
-- COL 27.3.0 --
G 
-- COL 27.3.1 --

-- COL 27.3.2 --
16d
-- COL 27.3.3 --

-- COL 27.3.4 --
(6b) AI systems can be used as  stand-alone software system,  integrated into a physical product  (embedded), used to serve the  functionality of a physical product  without being integrated therein  (non-embedded) or used as an AI  component of a larger system. If  this larger system would not  
function without the AI component  in question, then the entire larger  system should be considered as one  single AI system under this  
Regulation. 
-- COL 27.3.5 --

-- COL 27.3.6 --

-- COL 27.3.7 --
G
-- COL 27.3.8 --

== ROW 27.4 ==
-- COL 27.4.0 --

-- COL 27.4.1 --

-- COL 27.4.2 --
Recital 6c
-- COL 27.4.3 --

-- COL 27.4.4 --

-- COL 27.4.5 --

-- COL 27.4.6 --

-- COL 27.4.7 --

-- COL 27.4.8 --

== ROW 27.5 ==
-- COL 27.5.0 --
G 
-- COL 27.5.1 --

-- COL 27.5.2 --
16e 
-- COL 27.5.3 --

-- COL 27.5.4 --

-- COL 27.5.5 --
(6c) In order to ensure uniform  conditions for the implementation  of this Regulation as regards 
-- COL 27.5.6 --

-- COL 27.5.7 --
G
-- COL 27.5.8 --


TTTXX TABLE: 28 XXTTT
== ROW 28.0 ==
-- COL 28.0.0 --

-- COL 28.0.1 --

-- COL 28.0.2 --

-- COL 28.0.3 --
Commission Proposal 
-- COL 28.0.4 --
EP Mandate 
-- COL 28.0.5 --
Council Mandate 
-- COL 28.0.6 --
Draft Agreement
-- COL 28.0.7 --

-- COL 28.0.8 --

== ROW 28.1 ==
-- COL 28.1.0 --

-- COL 28.1.1 --

-- COL 28.1.2 --

-- COL 28.1.3 --

-- COL 28.1.4 --

-- COL 28.1.5 --
machine learning approaches and  logic- and knowledged based  approaches and to take account of  market and technological  
developments, implementing powers  should be conferred on the  
Commission.
-- COL 28.1.6 --

-- COL 28.1.7 --

-- COL 28.1.8 --

== ROW 28.2 ==
-- COL 28.2.0 --

-- COL 28.2.1 --

-- COL 28.2.2 --
Recital 6a
-- COL 28.2.3 --

-- COL 28.2.4 --

-- COL 28.2.5 --

-- COL 28.2.6 --

-- COL 28.2.7 --

-- COL 28.2.8 --

== ROW 28.3 ==
-- COL 28.3.0 --
G 
-- COL 28.3.1 --

-- COL 28.3.2 --
16f
-- COL 28.3.3 --

-- COL 28.3.4 --

-- COL 28.3.5 --
(6d) The notion of ‘user’ referred  to in this Regulation should be  interpreted as any natural or legal  person, including a public  
authority, agency or other body,  using an AI system under whose  authority the system is used.  
Depending on the type of AI system,  the use of the system may affect  persons other than the user.
-- COL 28.3.6 --
(6a) The notion of ‘deployer’  referred to in this Regulation  should be interpreted as any  
natural or legal person, including a  public authority, agency or other  body, using an AI system under its  authority, except where the AI  system is used in the course of a  personal non professional activity.  Depending on the type of AI system,  the use of the system may affect  persons other than the deployer. 
-- COL 28.3.7 --
G
-- COL 28.3.8 --

== ROW 28.4 ==
-- COL 28.4.0 --

-- COL 28.4.1 --

-- COL 28.4.2 --
Recital 7
-- COL 28.4.3 --

-- COL 28.4.4 --

-- COL 28.4.5 --

-- COL 28.4.6 --

-- COL 28.4.7 --

-- COL 28.4.8 --

== ROW 28.5 ==
-- COL 28.5.0 --
G 
-- COL 28.5.1 --

-- COL 28.5.2 --
17
-- COL 28.5.3 --
(7) The notion of biometric data  used in this Regulation is in line  with and should be interpreted  consistently with the notion of  biometric data as defined in Article  4(14) of Regulation (EU) 2016/679  of the European Parliament and of  the Council1, Article 3(18) of  Regulation (EU) 2018/1725 of the  European Parliament and of the 
-- COL 28.5.4 --
(7) The notion of biometric data  used in this Regulation is in line  with and should be interpreted  consistently with the notion of  biometric data as defined in Article  4(14) of Regulation (EU) 2016/679  of the European Parliament and of  the Council1. Biometrics-based data  are additional data resulting from  specific technical processing 
-- COL 28.5.5 --
(7) The notion of biometric data  used in this Regulation  should be interpreted  
consistently with the notion of  biometric data as defined in Article  4(14) of Regulation (EU) 2016/679  of the European Parliament and of  the Council1, Article 3(18) of  Regulation (EU) 2018/1725 of the  European Parliament and of the 
-- COL 28.5.6 --
(7) The notion of biometric data  used in this Regulation  should be interpreted  

Parliament and of the Council 1, Article 3(18) of Regulation (EU)  2018/1725 of the European 
-- COL 28.5.7 --
G
-- COL 28.5.8 --


TTTXX TABLE: 29 XXTTT
== ROW 29.0 ==
-- COL 29.0.0 --

-- COL 29.0.1 --

-- COL 29.0.2 --

-- COL 29.0.3 --
Commission Proposal 
-- COL 29.0.4 --
EP Mandate 
-- COL 29.0.5 --
Council Mandate 
-- COL 29.0.6 --
Draft Agreement
-- COL 29.0.7 --

-- COL 29.0.8 --

== ROW 29.1 ==
-- COL 29.1.0 --

-- COL 29.1.1 --

-- COL 29.1.2 --

-- COL 29.1.3 --
Council2and Article 3(13) of  Directive (EU) 2016/680 of the  European Parliament and of the  Council3. 
_________ 
1. Regulation (EU) 2016/679 of the  
European Parliament and of the Council of  27 April 2016 on the protection of natural  persons with regard to the processing of  personal data and on the free movement of  such data, and repealing Directive 95/46/EC  (General Data Protection Regulation) (OJ L  119, 4.5.2016, p. 1). 
2. Regulation (EU) 2018/1725 of the  European Parliament and of the Council of  23 October 2018 on the protection of natural  persons with regard to the processing of  personal data by the Union institutions,  bodies, offices and agencies and on the free  movement of such data, and repealing  Regulation (EC) No 45/2001 and Decision  No 1247/2002/EC (OJ L 295, 21.11.2018, p.  39) 
3. Directive (EU) 2016/680 of the European  Parliament and of the Council of 27 April  2016 on the protection of natural persons  with regard to the processing of personal  data by competent authorities for the  purposes of the prevention, investigation,  detection or prosecution of criminal offences  or the execution of criminal penalties, and on  the free movement of such data, and  repealing Council Framework Decision  2008/977/JHA (Law Enforcement Directive)  (OJ L 119, 4.5.2016, p. 89).
-- COL 29.1.4 --
relating to physical, physiological  or behavioural signals of a natural  person, such as facial expressions,  movements, pulse frequency, voice,  key strikes or gait, which may or  may not allow or confirm the  unique identification of a natural  person,   A  

1. Regulation (EU) 2016/679 of the  
European Parliament and of the Council of  27 April 2016 on the protection of natural  persons with regard to the processing of  personal data and on the free movement of  such data, and repealing Directive 95/46/EC  (General Data Protection Regulation) (OJ L  119, 4.5.2016, p. 1). 

. D     p   
-- COL 29.1.5 --
Council2and Article 3(13) of  Directive (EU) 2016/680 of the  European Parliament and of the  Council3. 
_________ 
1. [1] Regulation (EU) 2016/679 of  the European Parliament and of the Council  of 27 April 2016 on the protection of natural  persons with regard to the processing of  personal data and on the free movement of  such data, and repealing Directive 95/46/EC  (General Data Protection Regulation) (OJ L  119, 4.5.2016, p. 1). 
2. [2] Regulation (EU) 2018/1725 of  the European Parliament and of the Council  of 23 October 2018 on the protection of  natural persons with regard to the processing  of personal data by the Union institutions,  bodies, offices and agencies and on the free  movement of such data, and repealing  Regulation (EC) No 45/2001 and Decision  No 1247/2002/EC (OJ L 295, 21.11.2018, p.  39) 
3. [3] Directive (EU) 2016/680 of the  European Parliament and of the Council of  27 April 2016 on the protection of natural  persons with regard to the processing of  personal data by competent authorities for  the purposes of the prevention, investigation,  detection or prosecution of criminal offences  or the execution of criminal penalties, and on  the free movement of such data, and  repealing Council Framework Decision  2008/977/JHA (Law Enforcement Directive)  (OJ L 119, 4.5.2016, p. 89).
-- COL 29.1.6 --
Parliament and of the Council 2 and Article 3(13) of Directive  (EU) 2016/680 of the European  Parliament and of the Council 3.Biometric data can allow for the  authentication, identification or  categorisation of natural persons  and for the recognition of emotions  of natural persons. 
_________ 
1. Regulation (EU) 2016/679 of the  
European Parliament and of the Council of  27 April 2016 on the protection of natural  persons with regard to the processing of  personal data and on the free movement of  such data, and repealing Directive 95/46/EC  (General Data Protection Regulation) (OJ L  119, 4.5.2016, p. 1). 
2. Regulation (EU) 2018/1725 of the  European Parliament and of the Council of  23 October 2018 on the protection of natural  persons with regard to the processing of  personal data by the Union institutions,  bodies, offices and agencies and on the free  movement of such data, and repealing  Regulation (EC) No 45/2001 and Decision  No 1247/2002/EC (OJ L 295, 21.11.2018, p.  39) 
3. Directive (EU) 2016/680 of the European  Parliament and of the Council of 27 April  2016 on the protection of natural persons  with regard to the processing of personal  data by competent authorities for the  purposes of the prevention, investigation,  detection or prosecution of criminal offences  or the execution of criminal penalties, and on  the free movement of such data, and  repealing Council Framework Decision  2008/977/JHA (Law Enforcement Directive)  (OJ L 119, 4.5.2016, p. 89).
-- COL 29.1.7 --

-- COL 29.1.8 --


TTTXX TABLE: 30 XXTTT
== ROW 30.0 ==
-- COL 30.0.0 --

-- COL 30.0.1 --

-- COL 30.0.2 --

-- COL 30.0.3 --
Commission Proposal 
-- COL 30.0.4 --
EP Mandate 
-- COL 30.0.5 --
Council Mandate 
-- COL 30.0.6 --
Draft Agreement
-- COL 30.0.7 --

-- COL 30.0.8 --

== ROW 30.1 ==
-- COL 30.1.0 --

-- COL 30.1.1 --

-- COL 30.1.2 --

-- COL 30.1.3 --

-- COL 30.1.4 --

-- COL 30.1.5 --

-- COL 30.1.6 --

-- COL 30.1.7 --

-- COL 30.1.8 --

== ROW 30.2 ==
-- COL 30.2.0 --

-- COL 30.2.1 --

-- COL 30.2.2 --
Recital 7a
-- COL 30.2.3 --

-- COL 30.2.4 --

-- COL 30.2.5 --

-- COL 30.2.6 --

-- COL 30.2.7 --

-- COL 30.2.8 --

== ROW 30.3 ==
-- COL 30.3.0 --
G 
-- COL 30.3.1 --

-- COL 30.3.2 --
17a
-- COL 30.3.3 --

-- COL 30.3.4 --
(7a) The notion of biometric  identification as used in this  
Regulation should be defined as the  automated recognition of physical,  physiological, behavioural, and  psychological human features such  as the face, eye movement, facial  expressions, body shape, voice,  speech, gait, posture, heart rate,  blood pressure, odour, keystrokes,  psychological reactions (anger,  distress, grief, etc.) for the purpose  of establishing an individual’s  identity by comparing biometric  data of that individual to stored  biometric data of individuals in a  database (one-to-many  
identification), irrespective of  whether the individual has given its  consent or not. 
-- COL 30.3.5 --

-- COL 30.3.6 --
(7a) The notion of biometric  identification as used in this  
Regulation should be defined as the  automated recognition of physical,  physiological and behavioural  human features such as the face,  eye movement, body shape, voice,  prosody, gait, posture, heart rate,  blood pressure, odour, keystrokes  characteristics, for the purpose of  establishing an individual’s identity  by comparing biometric data of that  individual to stored biometric data  of individuals in a reference  
database, irrespective of whether  the individual has given its consent  or not.  
This excludes AI systems intended  to be used for biometric  
verification, which includes  
authentication, whose sole purpose  is to confirm that a specific natural  person is the person he or she  claims to be and to confirm the  identity of a natural person for the  sole purpose of having access to a  service, unlocking a device or  having security access to premises.
-- COL 30.3.7 --
G
-- COL 30.3.8 --

== ROW 30.4 ==
-- COL 30.4.0 --

-- COL 30.4.1 --

-- COL 30.4.2 --
Recital 7b
-- COL 30.4.3 --

-- COL 30.4.4 --

-- COL 30.4.5 --

-- COL 30.4.6 --

-- COL 30.4.7 --

-- COL 30.4.8 --


TTTXX TABLE: 31 XXTTT
== ROW 31.0 ==
-- COL 31.0.0 --

-- COL 31.0.1 --

-- COL 31.0.2 --

-- COL 31.0.3 --
Commission Proposal 
-- COL 31.0.4 --
EP Mandate 
-- COL 31.0.5 --
Council Mandate 
-- COL 31.0.6 --
Draft Agreement
-- COL 31.0.7 --

-- COL 31.0.8 --

== ROW 31.1 ==
-- COL 31.1.0 --
G 
-- COL 31.1.1 --

-- COL 31.1.2 --
17b
-- COL 31.1.3 --

-- COL 31.1.4 --
(7b) The notion of biometric  categorisation as used in this  Regulation should be defined as  assigning natural persons to  specific categories or inferring their  characteristics and attributes such  as gender, sex, age, hair colour, eye  colour, tattoos, ethnic or social  origin, health, mental or physical  ability, behavioural or personality,  traits language, religion, or  
membership of a national minority  or sexual or political orientation on  the basis of their biometric or  biometric-based data, or which can  be inferred from such data. 
-- COL 31.1.5 --

-- COL 31.1.6 --
(7b) The notion of biometric  categorisation as used in this  Regulation should be defined as  assigning natural persons to  specific categories on the basis of  their biometric data. Such specific  categories can relate to aspects  such as sex, age, hair colour, eye  colour, tattoos, behavioural or  personality traits, language,  
religion, membership of a national  minority, sexual or political  
orientation. This does not include  biometric categorization systems  that are a purely ancillary feature  intrinsically linked to another  commercial service meaning that  the feature cannot, for objective  technical reasons, be used without  the principal service and the  integration of that feature or  functionality is not a means to  circumvent the applicability of the  rules of this Regulation. For  example, filters categorizing facial  or body features used on online  marketplaces could constitute such  an ancillary feature as they can  only be used in relation to the  principal service which consists in  selling a product by allowing the  consumer to preview the display of  the product on him or herself and  help the consumer to make a  purchase decision. Filters used on  online social network services 
-- COL 31.1.7 --
G
-- COL 31.1.8 --


TTTXX TABLE: 32 XXTTT
== ROW 32.0 ==
-- COL 32.0.0 --

-- COL 32.0.1 --

-- COL 32.0.2 --

-- COL 32.0.3 --
Commission Proposal 
-- COL 32.0.4 --
EP Mandate 
-- COL 32.0.5 --
Council Mandate 
-- COL 32.0.6 --
Draft Agreement
-- COL 32.0.7 --

-- COL 32.0.8 --

== ROW 32.1 ==
-- COL 32.1.0 --

-- COL 32.1.1 --

-- COL 32.1.2 --

-- COL 32.1.3 --

-- COL 32.1.4 --

-- COL 32.1.5 --

-- COL 32.1.6 --
which categorise facial or body  features to allow users to add or  modify pictures or videos could also  be considered as ancillary feature  as such filter cannot be used  without the principal service of the  social network services consisting  in the sharing of content online.
-- COL 32.1.7 --

-- COL 32.1.8 --

== ROW 32.2 ==
-- COL 32.2.0 --

-- COL 32.2.1 --

-- COL 32.2.2 --
Recital 8
-- COL 32.2.3 --

-- COL 32.2.4 --

-- COL 32.2.5 --

-- COL 32.2.6 --

-- COL 32.2.7 --

-- COL 32.2.8 --

== ROW 32.3 ==
-- COL 32.3.0 --
G 
-- COL 32.3.1 --

-- COL 32.3.2 --
18
-- COL 32.3.3 --
(8) The notion of remote biometric  identification system as used in this  Regulation should be defined  functionally, as an AI system  intended for the identification of  natural persons at a distance through  the comparison of a person’s  
biometric data with the biometric  data contained in a reference  
database, and without prior  
knowledge whether the targeted  person will be present and can be  identified, irrespectively of the  particular technology, processes or  types of biometric data used.  
Considering their different  
characteristics and manners in which  they are used, as well as the different  risks involved, a distinction should  be made between ‘real-time’ and  ‘post’ remote biometric  
identification systems. In the case of  ‘real-time’ systems, the capturing of  the biometric data, the comparison  and the identification occur all 
-- COL 32.3.4 --
(8) The notion of remote biometric  identification system as used in this  Regulation should be defined  functionally, as an AI system  
intended for the identification of  natural persons at a distance through  the comparison of a person’s  
biometric data with the biometric  data contained in a reference  
database, and without prior  
knowledge whether the targeted  person will be present and can be  identified, irrespectively of the  particular technology, processes or  types of biometric data used,  
exlcuding verification systems  which merely compare the  
biometric data of an individual to  their previously provided biometric  data (one-to-one). Considering their  different characteristics and manners  in which they are used, as well as the  different risks involved, a distinction  should be made between ‘real-time’  and ‘post’ remote biometric 
-- COL 32.3.5 --
(8) The notion of remote biometric  identification system as used in this  Regulation should be defined  functionally, as an AI system  intended for the identification of  natural persons typically at a  
distance, without their active  involvement, through the  
comparison of a person’s biometric  data with the biometric data  
contained in a reference   

ata repository,  
irrespectively of the particular  technology, processes or types of  biometric data used. Such remote  biometric identification systems are  typically used to perceive (scan)  multiple persons or their behaviour  simultaneously in order to facilitate 
-- COL 32.3.6 --
(8) The notion of remote biometric  identification system as used in this  Regulation should be defined  functionally, as an AI system  
intended for the identification of  natural persons without their active  involvement, typically at a distance, through the comparison of a  
person’s biometric data with the  biometric data contained in a  
reference database, irrespectively  of the particular technology,  processes or types of biometric data  used. Such remote biometric  identification systems are typically  used to perceive multiple persons or  their behaviour simultaneously in  order to facilitate significantly the  identification of natural persons without p     
-- COL 32.3.7 --
G
-- COL 32.3.8 --


TTTXX TABLE: 33 XXTTT
== ROW 33.0 ==
-- COL 33.0.0 --

-- COL 33.0.1 --

-- COL 33.0.2 --

-- COL 33.0.3 --
Commission Proposal 
-- COL 33.0.4 --
EP Mandate 
-- COL 33.0.5 --
Council Mandate 
-- COL 33.0.6 --
Draft Agreement
-- COL 33.0.7 --

-- COL 33.0.8 --

== ROW 33.1 ==
-- COL 33.1.0 --

-- COL 33.1.1 --

-- COL 33.1.2 --

-- COL 33.1.3 --
instantaneously, near 
instantaneously or in any event  without a significant delay. In this  regard, there should be no scope for  circumventing the rules of this  Regulation on the ‘real-time’ use of  the AI systems in question by  providing for minor delays. ‘Real time’ systems involve the use of  ‘live’ or ‘near-‘live’ material, such  as video footage, generated by a  camera or other device with similar  functionality. In the case of ‘post’  systems, in contrast, the biometric  data have already been captured and  the comparison and identification  occur only after a significant delay.  This involves material, such as  pictures or video footage generated  by closed circuit television cameras  or private devices, which has been  generated before the use of the  system in respect of the natural  persons concerned.
-- COL 33.1.4 --
identification systems. In the case of  ‘real-time’ systems, the capturing of  the biometric data, the comparison  and the identification occur all  instantaneously, near 
instantaneously or in any event  without a significant delay. In this  regard, there should be no scope for  circumventing the rules of this  Regulation on the ‘real-time’ use of  the AI systems in question by  providing for minor delays. ‘Real time’ systems involve the use of  ‘live’ or ‘near-‘live’ material, such  as video footage, generated by a  camera or other device with similar  functionality. In the case of ‘post’  systems, in contrast, the biometric  data have already been captured and  the comparison and identification  occur only after a significant delay.  This involves material, such as  pictures or video footage generated  by closed circuit television cameras  or private devices, which has been  generated before the use of the  system in respect of the natural  persons concerned. Given that the  notion of biometric identification is  independent from the individual’s  consent, this definition applies even  when warning notices are placed in  the location that is under  
surveillance of the remote biometric  identification system, and is not de  facto annulled by pre-enrolment. 
-- COL 33.1.5 --
significantly the identification of a  number of persons without their   

ctive involvement. Such a  definition excludes  
verification/authentication systems  whose sole purpose would be to  confirm that a specific natural  person is the person he or she  claims to be, as well as systems that  are used to confirm the identity of a  natural person for the sole purpose  of having access to a service, a  device or premises. This exclusion  is justified by the fact that such  systems are likely to have a minor  impact on fundamental rights of  natural persons compared to  s remote biometric  
identification systems which may be  used for the processing of the  biometric data of a large number of  persons. In the case of ‘real-time’  systems, the capturing of the  
biometric data, the comparison and  the identification occur all  
instantaneously, near 
instantaneously or in any event  without a significant delay. In this  regard, there should be no scope for  circumventing the rules of this  Regulation on the ‘real-time’ use of  the AI systems in question by  providing for minor delays. ‘Real 
-- COL 33.1.6 --

fundamental rights of natural  persons compared to the remote  biometric identification systems  which may be used for the  
processing of the biometric  
ata of a large  number of persons without their  active involvement. In the case of  ‘real-time’ systems, the capturing of  the biometric data, the comparison  and the identification occur all  instantaneously, near 
instantaneously or in any event  without a significant delay. In this  regard, there should be no scope for  circumventing the rules of this  Regulation on the ‘real-time’ use of  the AI systems in question by 
-- COL 33.1.7 --

-- COL 33.1.8 --


TTTXX TABLE: 34 XXTTT
== ROW 34.0 ==
-- COL 34.0.0 --

-- COL 34.0.1 --

-- COL 34.0.2 --

-- COL 34.0.3 --
Commission Proposal 
-- COL 34.0.4 --
EP Mandate 
-- COL 34.0.5 --
Council Mandate 
-- COL 34.0.6 --
Draft Agreement
-- COL 34.0.7 --

-- COL 34.0.8 --

== ROW 34.1 ==
-- COL 34.1.0 --

-- COL 34.1.1 --

-- COL 34.1.2 --

-- COL 34.1.3 --

-- COL 34.1.4 --

-- COL 34.1.5 --
time’ systems involve the use of  ‘live’ or ‘near-‘live’ material, such  as video footage, generated by a  camera or other device with similar  functionality. In the case of ‘post’  systems, in contrast, the biometric  data have already been captured and  the comparison and identification  occur only after a significant delay.  This involves material, such as  pictures or video footage generated  by closed circuit television cameras  or private devices, which has been  generated before the use of the  system in respect of the natural  persons concerned.
-- COL 34.1.6 --
providing for minor delays. ‘Real time’ systems involve the use of  ‘live’ or ‘near-‘live’ material, such  as video footage, generated by a  camera or other device with similar  functionality. In the case of ‘post’  systems, in contrast, the biometric  data have already been captured and  the comparison and identification  occur only after a significant delay.  This involves material, such as  pictures or video footage generated  by closed circuit television cameras  or private devices, which has been  generated before the use of the  system in respect of the natural  persons concerned.
-- COL 34.1.7 --

-- COL 34.1.8 --

== ROW 34.2 ==
-- COL 34.2.0 --

-- COL 34.2.1 --

-- COL 34.2.2 --
Recital 8a
-- COL 34.2.3 --

-- COL 34.2.4 --

-- COL 34.2.5 --

-- COL 34.2.6 --

-- COL 34.2.7 --

-- COL 34.2.8 --

== ROW 34.3 ==
-- COL 34.3.0 --
G 
-- COL 34.3.1 --

-- COL 34.3.2 --
18a
-- COL 34.3.3 --

-- COL 34.3.4 --
(8a) The identification of natural  persons at a distance is understood  to distinguish remote biometric  identification systems from close  proximity individual verification  systems using biometric  
identification means, whose sole  purpose is to confirm whether or  not a specific natural person  presenting themselves for  
identification is permitted, such as  in order to gain access to a service,  a device, or premises. 
-- COL 34.3.5 --

-- COL 34.3.6 --

-- COL 34.3.7 --
G
-- COL 34.3.8 --

== ROW 34.4 ==
-- COL 34.4.0 --

-- COL 34.4.1 --

-- COL 34.4.2 --
Recital 8a
-- COL 34.4.3 --

-- COL 34.4.4 --

-- COL 34.4.5 --

-- COL 34.4.6 --

-- COL 34.4.7 --

-- COL 34.4.8 --


TTTXX TABLE: 35 XXTTT
== ROW 35.0 ==
-- COL 35.0.0 --

-- COL 35.0.1 --

-- COL 35.0.2 --

-- COL 35.0.3 --
Commission Proposal 
-- COL 35.0.4 --
EP Mandate 
-- COL 35.0.5 --
Council Mandate 
-- COL 35.0.6 --
Draft Agreement
-- COL 35.0.7 --

-- COL 35.0.8 --

== ROW 35.1 ==
-- COL 35.1.0 --
G 
-- COL 35.1.1 --

-- COL 35.1.2 --
18b
-- COL 35.1.3 --

-- COL 35.1.4 --

-- COL 35.1.5 --

-- COL 35.1.6 --
(8a) The notion of emotion  
recognition system for the purpose  of in this regulation should be  defined as an AI system for the  purpose of identifying or inferring  emotions or intentions of natural  persons on the basis of their  biometric data. This refers to  emotions or intentions such as  happiness, sadness, anger, surprise,  disgust, embarrassment,  
excitement, shame, contempt,  satisfaction and amusement. It does  not include physical states, such as  pain or fatigue. It refers for  
example to systems used in  
detecting the state of fatigue of  professional pilots or drivers for the  purpose of preventing accidents. It  does also not include the mere  detection of readily apparent  expressions, gestures or  
movements, unless they are used for  identifying or inferring emotions.  These expressions can be basic  facial expressions such as a frown  or a smile, or gestures such as the  movement of hands, arms or head,  or characteristics of a person’s  voice, for example a raised voice or  whispering. 
-- COL 35.1.7 --
G
-- COL 35.1.8 --

== ROW 35.2 ==
-- COL 35.2.0 --

-- COL 35.2.1 --

-- COL 35.2.2 --
Recital 9
-- COL 35.2.3 --

-- COL 35.2.4 --

-- COL 35.2.5 --

-- COL 35.2.6 --

-- COL 35.2.7 --

-- COL 35.2.8 --

== ROW 35.3 ==
-- COL 35.3.0 --
G 
-- COL 35.3.1 --

-- COL 35.3.2 --
19 
-- COL 35.3.3 --
(9) For the purposes of this 
-- COL 35.3.4 --
(9) For the purposes of this 
-- COL 35.3.5 --
(9) For the purposes of this 
-- COL 35.3.6 --
(9) For the purposes of this 
-- COL 35.3.7 --
G
-- COL 35.3.8 --


TTTXX TABLE: 36 XXTTT
== ROW 36.0 ==
-- COL 36.0.0 --

-- COL 36.0.1 --

-- COL 36.0.2 --

-- COL 36.0.3 --
Commission Proposal 
-- COL 36.0.4 --
EP Mandate 
-- COL 36.0.5 --
Council Mandate 
-- COL 36.0.6 --
Draft Agreement
-- COL 36.0.7 --

-- COL 36.0.8 --

== ROW 36.1 ==
-- COL 36.1.0 --

-- COL 36.1.1 --

-- COL 36.1.2 --

-- COL 36.1.3 --
Regulation the notion of publicly  accessible space should be  
understood as referring to any  physical place that is accessible to  the public, irrespective of whether  the place in question is privately or  publicly owned. Therefore, the  notion does not cover places that are  private in nature and normally not  freely accessible for third parties,  including law enforcement  
authorities, unless those parties have  been specifically invited or  
authorised, such as homes, private  clubs, offices, warehouses and  factories. Online spaces are not covered either, as they are not  physical spaces. However, the mere  fact that certain conditions for  accessing a particular space may  apply, such as admission tickets or  age restrictions, does not mean that  the space is not publicly accessible  within the meaning of this  
Regulation. Consequently, in  
addition to public spaces such as  streets, relevant parts of government  buildings and most transport  
infrastructure, spaces such as  
cinemas, theatres, shops and  
shopping centres are normally also  publicly accessible. Whether a given  space is accessible to the public  should however be determined on a  case-by-case basis, having regard to  the specificities of the individual  situation at hand.
-- COL 36.1.4 --
Regulation the notion of publicly  accessible space should be  
understood as referring to any  physical place that is accessible to  the public, irrespective of whether  the place in question is privately or  publicly owned and regardless of  the potential capacity restrictions.  Therefore, the notion does not cover  places that are private in nature and  normally not freely accessible for  third parties, including law  
enforcement authorities, unless those  parties have been specifically invited  or authorised, such as homes, private  clubs, offices, warehouses and  
factories.Online spaces are not  covered either, as they are not  physical spaces. However, the mere  fact that certain conditions for  accessing a particular space may  apply, such as admission tickets or  age restrictions, does not mean that  the space is not publicly accessible  within the meaning of this  
Regulation. Consequently, in  
addition to public spaces such as  streets, relevant parts of government  buildings and most transport  
infrastructure, spaces such as  
cinemas, theatres, sports grounds,  schools, universities, relevant parts  of hospitals and banks, amusement  parks, festivals, shops and shopping  centres are normally also publicly  accessible. Whether a given space is  accessible to the public should 
-- COL 36.1.5 --
Regulation the notion of publicly  accessible space should be  
understood as referring to any  physical place that is accessible to  n undetermined  
number of natural persons, and  irrespective of whether the place in  question is privately or publicly  owned.     


 
museums, concert and conference  halls) leisure or otherwise (for  instance, public roads and squares,  parks, forests, playgrounds).     A place should be classified as 
-- COL 36.1.6 --
Regulation the notion of publicly  accessible space should be  
understood as referring to any  physical place that is accessible to  n undetermined  
number of natural persons, and  irrespective of whether the place in  question is privately or publicly  owned    


 
museums, concert and conference  halls) leisure or otherwise (for  instance, public roads and squares,  parks, forests, playgrounds).     A place should be classified as 
-- COL 36.1.7 --

-- COL 36.1.8 --


TTTXX TABLE: 37 XXTTT
== ROW 37.0 ==
-- COL 37.0.0 --

-- COL 37.0.1 --

-- COL 37.0.2 --

-- COL 37.0.3 --
Commission Proposal 
-- COL 37.0.4 --
EP Mandate 
-- COL 37.0.5 --
Council Mandate 
-- COL 37.0.6 --
Draft Agreement
-- COL 37.0.7 --

-- COL 37.0.8 --

== ROW 37.1 ==
-- COL 37.1.0 --

-- COL 37.1.1 --

-- COL 37.1.2 --

-- COL 37.1.3 --

-- COL 37.1.4 --
however be determined on a case by-case basis, having regard to the  specificities of the individual  
situation at hand.
-- COL 37.1.5 --
publicly accessible also if,  
regardless of potential capacity or  security restrictions, access is  subject to certain predetermined  conditions, which can be fulfilled by  an undetermined number of  
persons  , such as  urchase  of a ticket or title of transport, prior  registration or having a certain age.  By contrast, a place should not be  considered publicly accessible if  access is limited to specific and  defined natural persons through  either Union or national law  directly related to public safety or  security or through the clear  manifestation of will by the person  having the relevant authority on the  place. The factual possibility of  access alone (e.g. an unlocked door,  an open gate in a fence) does not  imply that the lace  is publicly accessible   

pin the presence of indications  or circumstances suggesting the  contrary (e.g. signs prohibiting or  restricting access). Company and  factory premises as well as offices  and workplaces that are intended to  be accessed only by relevant  
employees and service providers are  places that are not publicly  
accessible. Publicly accessible
-- COL 37.1.6 --
publicly accessible also if,  
regardless of potential capacity or  security restrictions, access is  subject to certain predetermined conditions, which can be fulfilled by  an undetermined number of  
persons  , such as  urchase  of a ticket or title of transport, prior  registration or having a certain age.  By contrast, a place should not be  considered publicly accessible if  access is limited to specific and  defined natural persons through  either Union or national law  directly related to public safety or  security or through the clear  manifestation of will by the person  having the relevant authority on the  place. The factual possibility of  access alone (e.g. an unlocked door,  an open gate in a fence) does not  imply that the  place is publicly accessible    in the  
presence of indications or  
circumstances suggesting the  contrary (e.g. signs prohibiting or  restricting access). Company and  factory premises as well as offices  and workplaces that are intended to  be accessed only by relevant p  
-- COL 37.1.7 --

-- COL 37.1.8 --


TTTXX TABLE: 38 XXTTT
== ROW 38.0 ==
-- COL 38.0.0 --

-- COL 38.0.1 --

-- COL 38.0.2 --

-- COL 38.0.3 --
Commission Proposal 
-- COL 38.0.4 --
EP Mandate 
-- COL 38.0.5 --
Council Mandate 
-- COL 38.0.6 --
Draft Agreement
-- COL 38.0.7 --

-- COL 38.0.8 --

== ROW 38.1 ==
-- COL 38.1.0 --

-- COL 38.1.1 --

-- COL 38.1.2 --

-- COL 38.1.3 --

-- COL 38.1.4 --

-- COL 38.1.5 --
spaces    should not include prisons or  border control areas. Some other  areas may be composed of both not  publicly accessible and publicly  accessible areas, such as    

-- COL 38.1.6 --
employees and service providers are  places that are not publicly  
accessible. Publicly accessible  spaces should not include prisons  or border control. Some other areas  may be composed of both not  publicly accessible and publicly  accessible areas, such as    
he hallway of a private  residential building necessary to  access a doctor's office or an  airport. Online spaces are not  covered either, as they are not  physical spaces. Whether a given  space is accessible to the public  should however be determined on a  case-by-case basis, having regard to  the specificities of the individual  situation at hand.
-- COL 38.1.7 --

-- COL 38.1.8 --

== ROW 38.2 ==
-- COL 38.2.0 --

-- COL 38.2.1 --

-- COL 38.2.2 --
Recital 9a
-- COL 38.2.3 --

-- COL 38.2.4 --

-- COL 38.2.5 --

-- COL 38.2.6 --

-- COL 38.2.7 --

-- COL 38.2.8 --

== ROW 38.3 ==
-- COL 38.3.0 --
G 
-- COL 38.3.1 --

-- COL 38.3.2 --
19a
-- COL 38.3.3 --

-- COL 38.3.4 --
(9a) It is important to note that AI  systems should make best efforts to  respect general principles  
establishing a high-level framework  that promotes a coherent human centric approach to ethical and  trustworthy AI in line with the  Charter of Fundamental Rights of  the European Union and the values  on which the Union is founded,  including the protection of  
fundamental rights, human agency 
-- COL 38.3.5 --

-- COL 38.3.6 --

-- COL 38.3.7 --
G
-- COL 38.3.8 --


TTTXX TABLE: 39 XXTTT
== ROW 39.0 ==
-- COL 39.0.0 --

-- COL 39.0.1 --

-- COL 39.0.2 --

-- COL 39.0.3 --
Commission Proposal 
-- COL 39.0.4 --
EP Mandate 
-- COL 39.0.5 --
Council Mandate 
-- COL 39.0.6 --
Draft Agreement
-- COL 39.0.7 --

-- COL 39.0.8 --

== ROW 39.1 ==
-- COL 39.1.0 --

-- COL 39.1.1 --

-- COL 39.1.2 --

-- COL 39.1.3 --

-- COL 39.1.4 --
and oversight, technical robustness  and safety, privacy and data  
governance, transparency, non discrimination and fairness and  societal and environmental  
wellbeing. 
-- COL 39.1.5 --

-- COL 39.1.6 --

-- COL 39.1.7 --

-- COL 39.1.8 --

== ROW 39.2 ==
-- COL 39.2.0 --

-- COL 39.2.1 --

-- COL 39.2.2 --
Recital 9b
-- COL 39.2.3 --

-- COL 39.2.4 --

-- COL 39.2.5 --

-- COL 39.2.6 --

-- COL 39.2.7 --

-- COL 39.2.8 --

== ROW 39.3 ==
-- COL 39.3.0 --
G 
-- COL 39.3.1 --

-- COL 39.3.2 --
19b
-- COL 39.3.3 --

-- COL 39.3.4 --
(9b) ‘AI literacy’ refers to skills,  knowledge and understanding that  allows providers, users and affected  persons, taking into account their  respective rights and obligations in  the context of this Regulation, to  make an informed deployment of  AI systems, as well as to gain  awareness about the opportunities  and risks of AI and possible harm it  can cause and thereby promote its  democratic control. AI literacy  should not be limited to learning  about tools and technologies, but  should also aim to equip providers  and users with the notions and  skills required to ensure compliance  with and enforcement of this  Regulation. It is therefore  
necessary that the Commission, the  Member States as well as providers  and users of AI systems, in  
cooperation with all relevant  stakeholders, promote the  
development of a sufficient level of  AI literacy, in all sectors of society,  for people of all ages, including 
-- COL 39.3.5 --

-- COL 39.3.6 --
(9b) In order to obtain the greatest  benefits from AI systems while  protecting fundamental rights,  health and safety and to enable  democratic control, AI literacy  should equip providers, deployers  and affected persons with the  necessary notions to make informed  decisions regarding AI systems.  These notions may vary with regard  to the relevant context and can  include understanding the correct  application of technical elements  during the AI system’s development  phase, the measures to be applied  during its use, the suitable ways in  which to interpret the AI system’s  output, and, in the case of affected  persons, the knowledge necessary to  understand how decisions taken  with the assistance of AI will impact  them. In the context of the  
application this Regulation, AI  literacy should provide all relevant  actors in the AI value chain with  the insights required to ensure the  appropriate compliance and its 
-- COL 39.3.7 --
G
-- COL 39.3.8 --


TTTXX TABLE: 40 XXTTT
== ROW 40.0 ==
-- COL 40.0.0 --

-- COL 40.0.1 --

-- COL 40.0.2 --

-- COL 40.0.3 --
Commission Proposal 
-- COL 40.0.4 --
EP Mandate 
-- COL 40.0.5 --
Council Mandate 
-- COL 40.0.6 --
Draft Agreement
-- COL 40.0.7 --

-- COL 40.0.8 --

== ROW 40.1 ==
-- COL 40.1.0 --

-- COL 40.1.1 --

-- COL 40.1.2 --

-- COL 40.1.3 --

-- COL 40.1.4 --
women and girls, and that progress  in that regard is closely followed. 
-- COL 40.1.5 --

-- COL 40.1.6 --
correct enforcement. Furthermore,  the wide implementation of AI  literacy measures and the  
introduction of appropriate follow up actions could contribute to  improving working conditions and  ultimately sustain the consolidation,  and innovation path of trustworthy  AI in the Union. The European  Artificial Intelligence Board should  support the Commission , to  
promote AI literacy tools, public  awareness and understanding of  the benefits, risks, safeguards,  rights and obligations in relation to  the use of AI systems. In  
cooperation with the relevant  stakeholders, the Commission and  the Member States should facilitate  the drawing up of voluntary codes  of conduct to advance AI literacy  among persons dealing with the  development, operation and use of  AI .
-- COL 40.1.7 --

-- COL 40.1.8 --

== ROW 40.2 ==
-- COL 40.2.0 --

-- COL 40.2.1 --

-- COL 40.2.2 --
Recital 10
-- COL 40.2.3 --

-- COL 40.2.4 --

-- COL 40.2.5 --

-- COL 40.2.6 --

-- COL 40.2.7 --

-- COL 40.2.8 --

== ROW 40.3 ==
-- COL 40.3.0 --
G 
-- COL 40.3.1 --

-- COL 40.3.2 --
20
-- COL 40.3.3 --
(10) In order to ensure a level  playing field and an effective  protection of rights and freedoms of  individuals across the Union, the  rules established by this Regulation  should apply to providers of AI  systems in a non-discriminatory  manner, irrespective of whether they  are established within the Union or 
-- COL 40.3.4 --
(10) In order to ensure a level  playing field and an effective  protection of rights and freedoms of  individuals across the Union and on  international level, the rules  
established by this Regulation  should apply to providers of AI  systems in a non-discriminatory  manner, irrespective of whether they 
-- COL 40.3.5 --
(10) In order to ensure a level  playing field and an effective  protection of rights and freedoms of  individuals across the Union, the  rules established by this Regulation  should apply to providers of AI  systems in a non-discriminatory  manner, irrespective of whether they  are established within the Union or 
-- COL 40.3.6 --
(10) In order to ensure a level  playing field and an effective  protection of rights and freedoms of  individuals across the Union, the  rules established by this Regulation  should apply to providers of AI  systems in a non-discriminatory  manner, irrespective of whether they  are established within the Union or 
-- COL 40.3.7 --
G
-- COL 40.3.8 --


TTTXX TABLE: 41 XXTTT
== ROW 41.0 ==
-- COL 41.0.0 --

-- COL 41.0.1 --

-- COL 41.0.2 --

-- COL 41.0.3 --
Commission Proposal 
-- COL 41.0.4 --
EP Mandate 
-- COL 41.0.5 --
Council Mandate 
-- COL 41.0.6 --
Draft Agreement
-- COL 41.0.7 --

-- COL 41.0.8 --

== ROW 41.1 ==
-- COL 41.1.0 --

-- COL 41.1.1 --

-- COL 41.1.2 --

-- COL 41.1.3 --
in a third country, and to users of AI  systems established within the  Union.
-- COL 41.1.4 --
are established within the Union or  in a third country, and to  

particularly harmful effect to  fundamental rights as enshrined in  the Charter. Therefore it is  
appropriate to prohibit the export of  such AI systems to third countries  by providers residing in the Union.
-- COL 41.1.5 --
in a third country, and to users of AI  systems established within the  Union.
-- COL 41.1.6 --
in a third country, and to  

-- COL 41.1.7 --

-- COL 41.1.8 --

== ROW 41.2 ==
-- COL 41.2.0 --

-- COL 41.2.1 --

-- COL 41.2.2 --
Recital 11
-- COL 41.2.3 --

-- COL 41.2.4 --

-- COL 41.2.5 --

-- COL 41.2.6 --

-- COL 41.2.7 --

-- COL 41.2.8 --

== ROW 41.3 ==
-- COL 41.3.0 --
G 
-- COL 41.3.1 --

-- COL 41.3.2 --
21
-- COL 41.3.3 --
(11) In light of their digital nature,  certain AI systems should fall within  the scope of this Regulation even  when they are neither placed on the  market, nor put into service, nor  used in the Union. This is the case  for example of an operator  
established in the Union that  
contracts certain services to an  operator established outside the  Union in relation to an activity to be  performed by an AI system that  would qualify as high-risk and  whose effects impact natural persons  located in the Union. In those  circumstances, the AI system used 
-- COL 41.3.4 --
(11) In light of their digital nature,  certain AI systems should fall within  the scope of this Regulation even  when they are neither placed on the  market, nor put into service, nor  used in the Union. This is the case  for example of an operator  
established in the Union that  
contracts certain services to an  operator established outside the  Union in relation to an activity to be  performed by an AI system that  would qualify as high-risk and  whose effects impact natural persons  located in the Union. In those  circumstances, the AI system used 
-- COL 41.3.5 --
(11) In light of their digital nature,  certain AI systems should fall within  the scope of this Regulation even  when they are neither placed on the  market, nor put into service, nor  used in the Union. This is the case  for example of an operator  
established in the Union that  
contracts certain services to an  operator established outside the  Union in relation to an activity to be  performed by an AI system that  would qualify as high-risk  . In those  circumstances, the AI system used 
-- COL 41.3.6 --
(11) In light of their digital nature,  certain AI systems should fall within  the scope of this Regulation even  when they are neither placed on the  market, nor put into service, nor  used in the Union. This is the case  for example of an operator  
established in the Union that  
contracts certain services to an  operator established outside the  Union in relation to an activity to be  performed by an AI system that  would qualify as high-risk  . In those  circumstances, the AI system used 
-- COL 41.3.7 --
G
-- COL 41.3.8 --


TTTXX TABLE: 42 XXTTT
== ROW 42.0 ==
-- COL 42.0.0 --

-- COL 42.0.1 --

-- COL 42.0.2 --

-- COL 42.0.3 --
Commission Proposal 
-- COL 42.0.4 --
EP Mandate 
-- COL 42.0.5 --
Council Mandate 
-- COL 42.0.6 --
Draft Agreement
-- COL 42.0.7 --

-- COL 42.0.8 --

== ROW 42.1 ==
-- COL 42.1.0 --

-- COL 42.1.1 --

-- COL 42.1.2 --

-- COL 42.1.3 --
by the operator outside the Union  could process data lawfully collected  in and transferred from the Union,  and provide to the contracting  operator in the Union the output of  that AI system resulting from that  processing, without that AI system  being placed on the market, put into  service or used in the Union. To  prevent the circumvention of this  Regulation and to ensure an  
effective protection of natural  persons located in the Union, this  Regulation should also apply to  providers and users of AI systems  that are established in a third  
country, to the extent the output  produced by those systems is used in  the Union. Nonetheless, to take into  account existing arrangements and  special needs for cooperation with  foreign partners with whom  
information and evidence is  
exchanged, this Regulation should  not apply to public authorities of a  third country and international  organisations when acting in the  framework of international  
agreements concluded at national or  European level for law enforcement  and judicial cooperation with the  Union or with its Member States.  Such agreements have been  
concluded bilaterally between  Member States and third countries or  between the European Union,  Europol and other EU agencies and
-- COL 42.1.4 --
by the operator outside the Union  could process data lawfully collected  in and transferred from the Union,  and provide to the contracting  operator in the Union the output of  that AI system resulting from that  processing, without that AI system  being placed on the market, put into  service or used in the Union. To  prevent the circumvention of this  Regulation and to ensure an  
effective protection of natural  persons located in the Union, this  Regulation should also apply to  providers and users deployers of AI  systems that are established in a  third country, to the extent the  output produced by those systems is  intended to be used in the Union.  Nonetheless, to take into account  existing arrangements and special  needs for cooperation with foreign  partners with whom information and  evidence is exchanged, this  
Regulation should not apply to  public authorities of a third country  and international organisations when  acting in the framework of  
international agreements concluded  at national or European level for law  enforcement and judicial  
cooperation with the Union or with  its Member States. Such agreements  have been concluded bilaterally  between Member States and third  countries or between the European  Union, Europol and other EU 
-- COL 42.1.5 --
by the operator outside the Union  could process data lawfully collected  in and transferred from the Union,  and provide to the contracting  operator in the Union the output of  that AI system resulting from that  processing, without that AI system  being placed on the market, put into  service or used in the Union. To  prevent the circumvention of this  Regulation and to ensure an  
effective protection of natural  persons located in the Union, this  Regulation should also apply to  providers and users of AI systems  that are established in a third  
country, to the extent the output  produced by those systems is used in  the Union. Nonetheless, to take into  account existing arrangements and  special needs for future cooperation  with foreign partners with whom  information and evidence is  
exchanged, this Regulation should  not apply to public authorities of a  third country and international  organisations when acting in the  framework of international  
agreements concluded at national or  European level for law enforcement  and judicial cooperation with the  Union or with its Member States.  Such agreements have been  
concluded bilaterally between  Member States and third countries or  between the European Union,  Europol and other EU agencies and 
-- COL 42.1.6 --
by the operator outside the Union  could process data lawfully collected  in and transferred from the Union,  and provide to the contracting  operator in the Union the output of  that AI system resulting from that  processing, without that AI system  being placed on the market, put into  service or used in the Union. To  prevent the circumvention of this  Regulation and to ensure an  
effective protection of natural  persons located in the Union, this  Regulation should also apply to  providers and eployers of AI  systems that are established in a  third country, to the extent the  output produced by those systems is  intended to be used in the Union.  Nonetheless, to take into account  existing arrangements and special  needs for future cooperation with  foreign partners with whom  
information and evidence is  
exchanged, this Regulation should  not apply to public authorities of a  third country and international  organisations when acting in the  framework of cooperation or  international agreements concluded  at national or European level for law  enforcement and judicial  
cooperation with the Union or with  its Member States, under the  condition that this third country or  international organisations provide  adequate safeguards with respect to 
-- COL 42.1.7 --

-- COL 42.1.8 --


TTTXX TABLE: 43 XXTTT
== ROW 43.0 ==
-- COL 43.0.0 --

-- COL 43.0.1 --

-- COL 43.0.2 --

-- COL 43.0.3 --
Commission Proposal 
-- COL 43.0.4 --
EP Mandate 
-- COL 43.0.5 --
Council Mandate 
-- COL 43.0.6 --
Draft Agreement
-- COL 43.0.7 --

-- COL 43.0.8 --

== ROW 43.1 ==
-- COL 43.1.0 --

-- COL 43.1.1 --

-- COL 43.1.2 --

-- COL 43.1.3 --
third countries and international  organisations.
-- COL 43.1.4 --
agencies and third countries and  international organisations. This  exception should nevertheless be  limited to trusted countries and  international organisation that  share Union values. 
-- COL 43.1.5 --
third countries and international  organisations. Recipient Member  States authorities and Union  institutions, offices, bodies and  bodies making use of such outputs  in the Union remain accountable to  ensure their use comply with Union  law. When those international  agreements are revised or new ones  are concluded in the future, the  contracting parties should  
undertake the utmost effort to align  those agreements with the  
requirements of this Regulation.
-- COL 43.1.6 --
the protection of fundamental  rights and freedoms of individuals.  Where relevant, this may also cover  activities of entities entrusted by the  third countries to carry out specific  tasks in support of such law  
enforcement and judicial  
cooperation. Such framework for  cooperation or agreements  have been established bilaterally between Member States  and third countries or between the  European Union, Europol and other  EU agencies and third countries and  international organisations. The  authorities competent for  
supervision of the law enforcement  and judicial authorities under the  AI Act should assess whether these  frameworks for cooperation or  international agreements include  adequate safeguards with respect to  the protection of fundamental  rights and freedoms of individuals.  Recipient Member States  
authorities and Union institutions,  offices and bodies making use of  such outputs in the Union remain  accountable to ensure their use  complies with Union law. When  those international agreements are  revised or new ones are concluded  in the future, the contracting  parties should undertake the utmost effort to align those agreements  with the requirements of this  Regulation.
-- COL 43.1.7 --

-- COL 43.1.8 --


TTTXX TABLE: 44 XXTTT
== ROW 44.0 ==
-- COL 44.0.0 --

-- COL 44.0.1 --

-- COL 44.0.2 --

-- COL 44.0.3 --
Commission Proposal 
-- COL 44.0.4 --
EP Mandate 
-- COL 44.0.5 --
Council Mandate 
-- COL 44.0.6 --
Draft Agreement
-- COL 44.0.7 --

-- COL 44.0.8 --

== ROW 44.1 ==
-- COL 44.1.0 --

-- COL 44.1.1 --

-- COL 44.1.2 --

-- COL 44.1.3 --

-- COL 44.1.4 --

-- COL 44.1.5 --

-- COL 44.1.6 --

-- COL 44.1.7 --

-- COL 44.1.8 --

== ROW 44.2 ==
-- COL 44.2.0 --

-- COL 44.2.1 --

-- COL 44.2.2 --
Recital 12
-- COL 44.2.3 --

-- COL 44.2.4 --

-- COL 44.2.5 --

-- COL 44.2.6 --

-- COL 44.2.7 --

-- COL 44.2.8 --

== ROW 44.3 ==
-- COL 44.3.0 --
G 
-- COL 44.3.1 --

-- COL 44.3.2 --
22
-- COL 44.3.3 --
(12) This Regulation should also  apply to Union institutions, offices,  bodies and agencies when acting as a  provider or user of an AI system. AI  systems exclusively developed or  used for military purposes should be  excluded from the scope of this  Regulation where that use falls  under the exclusive remit of the  Common Foreign and Security  Policy regulated under Title V of the  Treaty on the European Union  (TEU). This Regulation should be  without prejudice to the provisions  regarding the liability of  
intermediary service providers set  out in Directive 2000/31/EC of the  European Parliament and of the  Council [as amended by the Digital  Services Act].
-- COL 44.3.4 --
(12) This Regulation should also  apply to Union institutions, offices,  bodies and agencies when acting as a  provider or eployer of an AI  system. AI systems exclusively  developed or used for military  purposes should be excluded from  the scope of this Regulation where  that use falls under the exclusive  remit of the Common Foreign and  Security Policy regulated under Title  V of the Treaty on the European  Union (TEU). This Regulation  should be without prejudice to the  provisions regarding the liability of  intermediary service providers set  out in Directive 2000/31/EC of the  European Parliament and of the  Council [as amended by the Digital  Services Act].
-- COL 44.3.5 --
(12) This Regulation should also  apply to Union institutions, offices,  bodies and agencies when acting as a  provider or user of an AI system.     R        

-- COL 44.3.6 --
(12) This Regulation should also  apply to Union institutions, offices,  bodies and agencies when acting as a  provider or eployer of an AI  system.   p        p     
-- COL 44.3.7 --
G
-- COL 44.3.8 --

== ROW 44.4 ==
-- COL 44.4.0 --

-- COL 44.4.1 --

-- COL 44.4.2 --
Recital 12a
-- COL 44.4.3 --

-- COL 44.4.4 --

-- COL 44.4.5 --

-- COL 44.4.6 --

-- COL 44.4.7 --

-- COL 44.4.8 --

== ROW 44.5 ==
-- COL 44.5.0 --
G 
-- COL 44.5.1 --

-- COL 44.5.2 --
22a
-- COL 44.5.3 --

-- COL 44.5.4 --

-- COL 44.5.5 --
(12a) If and insofar AI systems are  placed on the market, put into  service, or used with or without  modification of such systems for  military, defence or national  security purposes, those should be  excluded from the scope of this  Regulation regardless of which type  of entity is carrying out those 
-- COL 44.5.6 --
(12a) If and insofar AI systems are placed on the market, put into  service, or used with or without  modification of such systems for  military, defence or national  security purposes, those should be  excluded from the scope of this  Regulation regardless of which type  of entity is carrying out those 
-- COL 44.5.7 --
G
-- COL 44.5.8 --


TTTXX TABLE: 45 XXTTT
== ROW 45.0 ==
-- COL 45.0.0 --

-- COL 45.0.1 --

-- COL 45.0.2 --

-- COL 45.0.3 --
Commission Proposal 
-- COL 45.0.4 --
EP Mandate 
-- COL 45.0.5 --
Council Mandate 
-- COL 45.0.6 --
Draft Agreement
-- COL 45.0.7 --

-- COL 45.0.8 --

== ROW 45.1 ==
-- COL 45.1.0 --

-- COL 45.1.1 --

-- COL 45.1.2 --

-- COL 45.1.3 --

-- COL 45.1.4 --

-- COL 45.1.5 --
activities, such as whether it is a  public or private entity. As regards  military and defence purposes, such  exclusion is justified both by Article  4(2) TEU and by the specifities of  the Member States’ and the  
common Union defence policy  covered by Chapter 2 of Title V of  the Treaty on European Union  (TEU) that are subject to public  international law, which is  
therefore the more appropriate  legal framework for the regulation  of AI systems in the context of the  use of lethal force and other AI  systems in the context of military  and defence activities. As regards  national security purposes, the  exclusion is justified both by the  fact that national security remains  the sole responsibility of Member  States in accordance with Article  4(2) TEU and by the specific nature  and operational needs of national  security activities and specific  national rules applicable to those  activities. Nonetheless, if an AI  system developed, placed on the  market, put into service or used for  military, defence or national  security purposes is used outside  those temporarily or permanently  for other purposes (for example,  civilian or humanitarian purposes,  law enforcement or public security  purposes), such a system would fall  within the scope of this Regulation. 
-- COL 45.1.6 --
activities, such as whether it is a  public or private entity. As regards  military and defence purposes, such  exclusion is justified both by Article  4(2) TEU and by the specifities of  the Member States’ and the  
common Union defence policy  covered by Chapter 2 of Title V of  the Treaty on European Union  (TEU) that are subject to public  international law, which is  
therefore the more appropriate  legal framework for the regulation  of AI systems in the context of the  use of lethal force and other AI  systems in the context of military  and defence activities. As regards  national security purposes, the  exclusion is justified both by the  fact that national security remains  the sole responsibility of Member  States in accordance with Article  4(2) TEU and by the specific nature  and operational needs of national  security activities and specific  national rules applicable to those  activities. Nonetheless, if an AI  system developed, placed on the  market, put into service or used for  military, defence or national  security purposes is used outside  those temporarily or permanently  for other purposes (for example,  civilian or humanitarian purposes,  law enforcement or public security  purposes), such a system would fall  within the scope of this Regulation. 
-- COL 45.1.7 --

-- COL 45.1.8 --


TTTXX TABLE: 46 XXTTT
== ROW 46.0 ==
-- COL 46.0.0 --

-- COL 46.0.1 --

-- COL 46.0.2 --

-- COL 46.0.3 --
Commission Proposal 
-- COL 46.0.4 --
EP Mandate 
-- COL 46.0.5 --
Council Mandate 
-- COL 46.0.6 --
Draft Agreement
-- COL 46.0.7 --

-- COL 46.0.8 --

== ROW 46.1 ==
-- COL 46.1.0 --

-- COL 46.1.1 --

-- COL 46.1.2 --

-- COL 46.1.3 --

-- COL 46.1.4 --

-- COL 46.1.5 --
In that case, the entity using the  system for other than military,  defence or national security  
purposes should ensure compliance  of the system with this Regulation,  unless the system is already  
compliant with this Regulation. AI  systems placed on the market or put  into service for an excluded (i.e.  military, defence or national  security) and one or more non  excluded purposes (e.g. civilian  purposes, law enforcement, etc.),  fall within the scope of this  
Regulation and providers of those  systems should ensure compliance  with this Regulation. In those cases,  the fact that an AI system may fall  within the scope of this Regulation  should not affect the possibility of  entities carrying out national  security, defence and military  activities, regardless of the type of  entity carrying out those activities,  to use AI systems for national  security, military and defence  purposes, the use of which is  excluded from the scope of this  Regulation. An AI system placed on  the market for civilian or law  enforcement purposes which is used  with or without modification for  military, defence or national  security purposes should not fall  within the scope of this Regulation,  regardless of the type of entity  carrying out those activities.
-- COL 46.1.6 --
In that case, the entity using the  system for other than military,  defence or national security  
purposes should ensure compliance  of the system with this Regulation,  unless the system is already  
compliant with this Regulation. AI  systems placed on the market or put  into service for an excluded (i.e.  military, defence or national  security) and one or more non  excluded purposes (e.g. civilian  purposes, law enforcement, etc.),  fall within the scope of this  
Regulation and providers of those  systems should ensure compliance  with this Regulation. In those cases,  the fact that an AI system may fall  within the scope of this Regulation  should not affect the possibility of  entities carrying out national  security, defence and military  activities, regardless of the type of  entity carrying out those activities,  to use AI systems for national  security, military and defence  purposes, the use of which is  excluded from the scope of this  Regulation. An AI system placed on  the market for civilian or law  enforcement purposes which is used  with or without modification for  military, defence or national  security purposes should not fall  within the scope of this Regulation,  regardless of the type of entity  carrying out those activities.
-- COL 46.1.7 --

-- COL 46.1.8 --


TTTXX TABLE: 47 XXTTT
== ROW 47.0 ==
-- COL 47.0.0 --

-- COL 47.0.1 --

-- COL 47.0.2 --

-- COL 47.0.3 --
Commission Proposal 
-- COL 47.0.4 --
EP Mandate 
-- COL 47.0.5 --
Council Mandate 
-- COL 47.0.6 --
Draft Agreement
-- COL 47.0.7 --

-- COL 47.0.8 --

== ROW 47.1 ==
-- COL 47.1.0 --

-- COL 47.1.1 --

-- COL 47.1.2 --

-- COL 47.1.3 --

-- COL 47.1.4 --

-- COL 47.1.5 --

-- COL 47.1.6 --

-- COL 47.1.7 --

-- COL 47.1.8 --

== ROW 47.2 ==
-- COL 47.2.0 --

-- COL 47.2.1 --

-- COL 47.2.2 --
Recital 12b
-- COL 47.2.3 --

-- COL 47.2.4 --

-- COL 47.2.5 --

-- COL 47.2.6 --

-- COL 47.2.7 --

-- COL 47.2.8 --

== ROW 47.3 ==
-- COL 47.3.0 --
G 
-- COL 47.3.1 --

-- COL 47.3.2 --
22b
-- COL 47.3.3 --

-- COL 47.3.4 --

-- COL 47.3.5 --
(12b) This Regulation should be  without prejudice to the provisions  regarding the liability of  
intermediary service providers set  out in Directive 2000/31/EC of the  European Parliament and of the  Council [as amended by the Digital  Services Act].
-- COL 47.3.6 --

-- COL 47.3.7 --
G
-- COL 47.3.8 --

== ROW 47.4 ==
-- COL 47.4.0 --

-- COL 47.4.1 --

-- COL 47.4.2 --
Recital 12c
-- COL 47.4.3 --

-- COL 47.4.4 --

-- COL 47.4.5 --

-- COL 47.4.6 --

-- COL 47.4.7 --

-- COL 47.4.8 --

== ROW 47.5 ==
-- COL 47.5.0 --
G 
-- COL 47.5.1 --

-- COL 47.5.2 --
22c
-- COL 47.5.3 --

-- COL 47.5.4 --

-- COL 47.5.5 --
(12c) This Regulation should not  undermine research and  
development activity and should  respect freedom of science. It is  therefore necessary to exclude from  its scope AI systems specifically  developed and put into service for  the sole purpose of scientific  research and development and to  ensure that the Regulation does not  otherwise affect scientific research  and development activity on AI  systems. As regards product  
oriented research activity by  
providers, the provisions of this  Regulation should also not apply.  This is without prejudice to the  obligation to comply with this  Regulation when an AI system  falling into the scope of this  
Regulation is placed on the market 
-- COL 47.5.6 --
(12c) This Regulation should  support innovation, respect freedom  of science, and should not  
undermine research and  
development activity. It is therefore  necessary to exclude from its scope  AI systems and models specifically  
developed and put into service for  the sole purpose of scientific  research and development.  
Moreover, it is necessary to ensure  that the Regulation does not  
otherwise affect scientific research  and development activity on AI  systems or models prior to being  placed on the market or put into  service. As regards product oriented  research, testing and development  activity regarding AI systems or  models, the provisions of this  Regulation should also not apply 
-- COL 47.5.7 --
G
-- COL 47.5.8 --


TTTXX TABLE: 48 XXTTT
== ROW 48.0 ==
-- COL 48.0.0 --

-- COL 48.0.1 --

-- COL 48.0.2 --

-- COL 48.0.3 --
Commission Proposal 
-- COL 48.0.4 --
EP Mandate 
-- COL 48.0.5 --
Council Mandate 
-- COL 48.0.6 --
Draft Agreement
-- COL 48.0.7 --

-- COL 48.0.8 --

== ROW 48.1 ==
-- COL 48.1.0 --

-- COL 48.1.1 --

-- COL 48.1.2 --

-- COL 48.1.3 --

-- COL 48.1.4 --

-- COL 48.1.5 --
or put into service as a result of  such research and development  activity and to the application of  
provisions on regulatory sandboxes  and testing in real world conditions.  Furthermore, without prejudice to  the foregoing regarding AI systems  specifically developed and put into  service for the sole purpose of  scientific research and  
development, any other AI system  that may be used for the conduct of  any reaserch and development  activity should remain subject to the  provisions of this Regulation.  Under all circumstances, any  research and development activity  should be carried out in accordance  with recognised ethical and  
professional standards for scientific  research.
-- COL 48.1.6 --
prior to these systems and models  being put into service or placed on  the market. This is without  
prejudice to the obligation to  comply with this Regulation when  an AI system falling into the scope  of this Regulation is placed on the  market or put into service as a  result of such research and  
development activity and to the  application of provisions on  
regulatory sandboxes and testing in  real world conditions. Furthermore,  without prejudice to the foregoing  regarding AI systems specifically  developed and put into service for  the sole purpose of scientific  research and development, any  other AI system that may be used  for the conduct of any research and  development activity should remain  subject to the provisions of this  Regulation. Under all  
circumstances, any research and  development activity should be  carried out in accordance with  recognised ethical and professional  standards for scientific research  and should be conducted according  to applicable Union law.
-- COL 48.1.7 --

-- COL 48.1.8 --

== ROW 48.2 ==
-- COL 48.2.0 --

-- COL 48.2.1 --

-- COL 48.2.2 --
Recital 12d
-- COL 48.2.3 --

-- COL 48.2.4 --

-- COL 48.2.5 --

-- COL 48.2.6 --

-- COL 48.2.7 --

-- COL 48.2.8 --

== ROW 48.3 ==
-- COL 48.3.0 --
G 
-- COL 48.3.1 --

-- COL 48.3.2 --
22d 
-- COL 48.3.3 --

-- COL 48.3.4 --
(12a) The developers of free and  open-source AI components should  not be mandated under this 
-- COL 48.3.5 --

-- COL 48.3.6 --

-- COL 48.3.7 --
G
-- COL 48.3.8 --


TTTXX TABLE: 49 XXTTT
== ROW 49.0 ==
-- COL 49.0.0 --

-- COL 49.0.1 --

-- COL 49.0.2 --

-- COL 49.0.3 --
Commission Proposal 
-- COL 49.0.4 --
EP Mandate 
-- COL 49.0.5 --
Council Mandate 
-- COL 49.0.6 --
Draft Agreement
-- COL 49.0.7 --

-- COL 49.0.8 --

== ROW 49.1 ==
-- COL 49.1.0 --

-- COL 49.1.1 --

-- COL 49.1.2 --

-- COL 49.1.3 --

-- COL 49.1.4 --
Regulation to comply with  
requirements targeting the AI value  chain and, in particular, not  towards the provider that has used  that free and open-source AI  component. Developers of free and  open-source AI components should  however be encouraged to  
implement widely adopted  
documentation practices, such as  model and data cards, as a way to  accelerate information sharing  along the AI value chain, allowing  the promotion of trustworthy AI  systems in the Union. 
-- COL 49.1.5 --

-- COL 49.1.6 --

-- COL 49.1.7 --

-- COL 49.1.8 --

== ROW 49.2 ==
-- COL 49.2.0 --

-- COL 49.2.1 --

-- COL 49.2.2 --
Recital 12e
-- COL 49.2.3 --

-- COL 49.2.4 --

-- COL 49.2.5 --

-- COL 49.2.6 --

-- COL 49.2.7 --

-- COL 49.2.8 --

== ROW 49.3 ==
-- COL 49.3.0 --
G 
-- COL 49.3.1 --

-- COL 49.3.2 --
22e
-- COL 49.3.3 --

-- COL 49.3.4 --

-- COL 49.3.5 --
(12d) In the light of the nature and  complexity of the value chain for AI  systems, it is essential to clarify the  role of actors who may contribute to  the development of AI systems,  notably high-risk AI systems. In  particular, it is necessary to clarify  that general purpose AI systems are  AI systems that are intended by the  provider to perform generally  applicable functions, such as  image/speech recognition, and in a  plurality of contexts. They may be  used as high-risk AI systems by  themselves or be components of  other high risk AI systems.  
Therefore, due to their particular  nature and in order to ensure a fair 
-- COL 49.3.6 --

-- COL 49.3.7 --
G
-- COL 49.3.8 --


TTTXX TABLE: 50 XXTTT
== ROW 50.0 ==
-- COL 50.0.0 --

-- COL 50.0.1 --

-- COL 50.0.2 --

-- COL 50.0.3 --
Commission Proposal 
-- COL 50.0.4 --
EP Mandate 
-- COL 50.0.5 --
Council Mandate 
-- COL 50.0.6 --
Draft Agreement
-- COL 50.0.7 --

-- COL 50.0.8 --

== ROW 50.1 ==
-- COL 50.1.0 --

-- COL 50.1.1 --

-- COL 50.1.2 --

-- COL 50.1.3 --

-- COL 50.1.4 --

-- COL 50.1.5 --
sharing of responsibilities along the  AI value chain, such systems  should be subject to proportionate  and more specific requirements and  obligations under this Regulation  while ensuring a high level of  protection of fundamental rights,  health and safety. In addition, the  providers of general purpose AI  systems, irrespective of whether  they may be used as high-risk AI  systems as such by other providers  or as components of high-risk AI  systems, should cooperate, as  appropriate, with the providers of  the respective high-risk AI systems  to enable their compliance with the  relevant obligations under this  Regulation and with the competent  authorities established under this  Regulation. In order to take into  account the specific characteristics  of general purpose AI systems and  the fast evolving market and  technological developments in the field, implementing powers should  be conferred on the Commission to  specify and adapt the application of  the requirements established under  this Regulation to general purpose  AI systems and to specify the  information to be shared by the  providers of general purpose AI  systems in order to enable the  providers of the respective high-risk  AI system to comply with their  obligations under this Regulation.
-- COL 50.1.6 --

-- COL 50.1.7 --

-- COL 50.1.8 --


TTTXX TABLE: 51 XXTTT
== ROW 51.0 ==
-- COL 51.0.0 --

-- COL 51.0.1 --

-- COL 51.0.2 --

-- COL 51.0.3 --
Commission Proposal 
-- COL 51.0.4 --
EP Mandate 
-- COL 51.0.5 --
Council Mandate 
-- COL 51.0.6 --
Draft Agreement
-- COL 51.0.7 --

-- COL 51.0.8 --

== ROW 51.1 ==
-- COL 51.1.0 --

-- COL 51.1.1 --

-- COL 51.1.2 --

-- COL 51.1.3 --

-- COL 51.1.4 --

-- COL 51.1.5 --

-- COL 51.1.6 --

-- COL 51.1.7 --

-- COL 51.1.8 --

== ROW 51.2 ==
-- COL 51.2.0 --

-- COL 51.2.1 --

-- COL 51.2.2 --
Recital 12f
-- COL 51.2.3 --

-- COL 51.2.4 --

-- COL 51.2.5 --

-- COL 51.2.6 --

-- COL 51.2.7 --

-- COL 51.2.8 --

== ROW 51.3 ==
-- COL 51.3.0 --
G 
-- COL 51.3.1 --

-- COL 51.3.2 --
22f 
-- COL 51.3.3 --

-- COL 51.3.4 --

-- COL 51.3.5 --

-- COL 51.3.6 --

-- COL 51.3.7 --
G
-- COL 51.3.8 --

== ROW 51.4 ==
-- COL 51.4.0 --

-- COL 51.4.1 --

-- COL 51.4.2 --
Recital 12g
-- COL 51.4.3 --

-- COL 51.4.4 --

-- COL 51.4.5 --

-- COL 51.4.6 --

-- COL 51.4.7 --

-- COL 51.4.8 --

== ROW 51.5 ==
-- COL 51.5.0 --
G 
-- COL 51.5.1 --

-- COL 51.5.2 --
22g 
-- COL 51.5.3 --

-- COL 51.5.4 --

-- COL 51.5.5 --

-- COL 51.5.6 --

-- COL 51.5.7 --
G
-- COL 51.5.8 --

== ROW 51.6 ==
-- COL 51.6.0 --

-- COL 51.6.1 --

-- COL 51.6.2 --
Recital 12h
-- COL 51.6.3 --

-- COL 51.6.4 --

-- COL 51.6.5 --

-- COL 51.6.6 --

-- COL 51.6.7 --

-- COL 51.6.8 --

== ROW 51.7 ==
-- COL 51.7.0 --
G 
-- COL 51.7.1 --

-- COL 51.7.2 --
22h 
-- COL 51.7.3 --

-- COL 51.7.4 --

-- COL 51.7.5 --

-- COL 51.7.6 --

-- COL 51.7.7 --
G
-- COL 51.7.8 --

== ROW 51.8 ==
-- COL 51.8.0 --

-- COL 51.8.1 --

-- COL 51.8.2 --
Recital 13
-- COL 51.8.3 --

-- COL 51.8.4 --

-- COL 51.8.5 --

-- COL 51.8.6 --

-- COL 51.8.7 --

-- COL 51.8.8 --

== ROW 51.9 ==
-- COL 51.9.0 --
G 
-- COL 51.9.1 --

-- COL 51.9.2 --
23
-- COL 51.9.3 --
(13) In order to ensure a consistent  and high level of protection of public  interests as regards health, safety and  fundamental rights, common  
normative standards for all high-risk  AI systems should be established.  Those standards should be consistent  with the Charter of fundamental  rights of the European Union (the  Charter) and should be non 
discriminatory and in line with the  Union’s international trade  
commitments.
-- COL 51.9.4 --
(13) In order to ensure a consistent  and high level of protection of public  interests as regards health, safety and  fundamental rights as well as  democracy and rule of law and the  environment, common normative  standards for all high-risk AI  
systems should be established.  Those standards should be consistent  with the Charter, the European  Green Deal, the Joint Declaration  on Digital Rights of  the Union  

Intelligence (AI) of the High-Level  Expert Group on Artificial  
Intelligence, and should be non discriminatory and in line with the  Union’s international trade  
commitments.
-- COL 51.9.5 --
(13) In order to ensure a consistent  and high level of protection of public  interests as regards health, safety and  fundamental rights, common  
normative standards for all high-risk  AI systems should be established.  Those standards should be consistent  with the Charter of fundamental  rights of the European Union (the  Charter) and should be non 
discriminatory and in line with the  Union’s international trade  
commitments.
-- COL 51.9.6 --

-- COL 51.9.7 --
G
-- COL 51.9.8 --


TTTXX TABLE: 52 XXTTT
== ROW 52.0 ==
-- COL 52.0.0 --

-- COL 52.0.1 --

-- COL 52.0.2 --

-- COL 52.0.3 --
Commission Proposal 
-- COL 52.0.4 --
EP Mandate 
-- COL 52.0.5 --
Council Mandate 
-- COL 52.0.6 --
Draft Agreement
-- COL 52.0.7 --

-- COL 52.0.8 --

== ROW 52.1 ==
-- COL 52.1.0 --

-- COL 52.1.1 --

-- COL 52.1.2 --

-- COL 52.1.3 --

-- COL 52.1.4 --

-- COL 52.1.5 --

-- COL 52.1.6 --

-- COL 52.1.7 --

-- COL 52.1.8 --

== ROW 52.2 ==
-- COL 52.2.0 --

-- COL 52.2.1 --

-- COL 52.2.2 --
Recital 14
-- COL 52.2.3 --

-- COL 52.2.4 --

-- COL 52.2.5 --

-- COL 52.2.6 --

-- COL 52.2.7 --

-- COL 52.2.8 --

== ROW 52.3 ==
-- COL 52.3.0 --
G 
-- COL 52.3.1 --

-- COL 52.3.2 --
24
-- COL 52.3.3 --
(14) In order to introduce a  
proportionate and effective set of  binding rules for AI systems, a  clearly defined risk-based approach  should be followed. That approach  should tailor the type and content of  such rules to the intensity and scope  of the risks that AI systems can  generate. It is therefore necessary to  prohibit certain artificial intelligence  practices, to lay down requirements  for high-risk AI systems and  
obligations for the relevant  
operators, and to lay down  
transparency obligations for certain  AI systems.
-- COL 52.3.4 --
(14) In order to introduce a  
proportionate and effective set of  binding rules for AI systems, a  clearly defined risk-based approach  should be followed. That approach  should tailor the type and content of  such rules to the intensity and scope  of the risks that AI systems can  generate. It is therefore necessary to  prohibit certain unacceptable  artificial intelligence practices, to lay  down requirements for high-risk AI  systems and obligations for the  relevant operators, and to lay down  transparency obligations for certain  AI systems
-- COL 52.3.5 --
(14) In order to introduce a  
proportionate and effective set of  binding rules for AI systems, a  clearly defined risk-based approach  should be followed. That approach  should tailor the type and content of  such rules to the intensity and scope  of the risks that AI systems can  generate. It is therefore necessary to  prohibit certain artificial intelligence  practices, to lay down requirements  for high-risk AI systems and  
obligations for the relevant  
operators, and to lay down  
transparency obligations for certain  AI systems.
-- COL 52.3.6 --
(14) In order to introduce a  
proportionate and effective set of  binding rules for AI systems, a  clearly defined risk-based approach  should be followed. That approach  should tailor the type and content of  such rules to the intensity and scope  of the risks that AI systems can  generate. It is therefore necessary to  prohibit certain unacceptable  artificial intelligence practices, to lay  down requirements for high-risk AI  systems and obligations for the  relevant operators, and to lay down  transparency obligations for certain  AI systems.
-- COL 52.3.7 --
G
-- COL 52.3.8 --

== ROW 52.4 ==
-- COL 52.4.0 --

-- COL 52.4.1 --

-- COL 52.4.2 --
Recital 14a
-- COL 52.4.3 --

-- COL 52.4.4 --

-- COL 52.4.5 --

-- COL 52.4.6 --

-- COL 52.4.7 --

-- COL 52.4.8 --

== ROW 52.5 ==
-- COL 52.5.0 --
G 
-- COL 52.5.1 --

-- COL 52.5.2 --
24a
-- COL 52.5.3 --

-- COL 52.5.4 --

-- COL 52.5.5 --

-- COL 52.5.6 --
(14a) While the risk-based  
approach is the basis for a  
proportionate and effective set of  binding rules, it is important to  recall the 2019 Ethics Guidelines  for Trustworthy AI developed by the  independent High-Level Expert  Group on AI (HLEG) appointed by  the Commission. In those  
Guidelines the HLEG developed  seven non-binding ethical  
principles for AI which should help  ensure that AI is trustworthy and 
-- COL 52.5.7 --
G
-- COL 52.5.8 --


TTTXX TABLE: 53 XXTTT
== ROW 53.0 ==
-- COL 53.0.0 --

-- COL 53.0.1 --

-- COL 53.0.2 --

-- COL 53.0.3 --
Commission Proposal 
-- COL 53.0.4 --
EP Mandate 
-- COL 53.0.5 --
Council Mandate 
-- COL 53.0.6 --
Draft Agreement
-- COL 53.0.7 --

-- COL 53.0.8 --

== ROW 53.1 ==
-- COL 53.1.0 --

-- COL 53.1.1 --

-- COL 53.1.2 --

-- COL 53.1.3 --

-- COL 53.1.4 --

-- COL 53.1.5 --

-- COL 53.1.6 --
ethically sound. The seven  
principles include: human agency  and oversight; technical robustness  and safety; privacy and data  
governance; transparency;  
diversity, non-discrimination and  fairness; societal and  
environmental well-being and  accountability. Without prejudice to  the legally binding requirements of  this Regulation and any other  applicable Union law, these  
Guidelines contribute to the design  of a coherent, trustworthy and  human-centric Artificial  
Intelligence, in line with the  
Charter and with the values on  which the Union is founded.  According to the Guidelines of  HLEG, human agency and  
oversight means that AI systems  are developed and used as a tool  that serves people, respects human  dignity and personal autonomy, and  that is functioning in a way that  can be appropriately controlled and  overseen by humans. Technical  robustness and safety means that  AI systems are developed and used  in a way that allows robustness in  case of problems and resilience  against attempts to alter the use or  performance of the AI system so as  to allow unlawful use by third  parties, and minimise unintended  harm . Privacy and data  
governance means that AI systems 
-- COL 53.1.7 --

-- COL 53.1.8 --


TTTXX TABLE: 54 XXTTT
== ROW 54.0 ==
-- COL 54.0.0 --

-- COL 54.0.1 --

-- COL 54.0.2 --

-- COL 54.0.3 --
Commission Proposal 
-- COL 54.0.4 --
EP Mandate 
-- COL 54.0.5 --
Council Mandate 
-- COL 54.0.6 --
Draft Agreement
-- COL 54.0.7 --

-- COL 54.0.8 --

== ROW 54.1 ==
-- COL 54.1.0 --

-- COL 54.1.1 --

-- COL 54.1.2 --

-- COL 54.1.3 --

-- COL 54.1.4 --

-- COL 54.1.5 --

-- COL 54.1.6 --
are developed and used in  
compliance with existing privacy  and data protection rules, while  processing data that meets high  standards in terms of quality and  integrity. Transparency means that  AI systems are developed and used  in a way that allows appropriate  traceability and explainability,  while making humans aware that  they communicate or interact with  an AI system, as well as duly  informing deployers of the  
capabilities and limitations of that  AI system and affected persons  about their rights. Diversity, non discrimination and fairness means  that AI systems are developed and  used in a way that includes diverse  actors and promotes equal access,  gender equality and cultural  diversity, while avoiding  
discriminatory impacts and unfair  biases that are prohibited by Union  or national law. Social and  
environmental well-being means  that AI systems are developed and  used in a sustainable and  
environmentally friendly manner as  well as in a way to benefit all  human beings, while monitoring  and assessing the long-term impacts  on the individual, society and  democracy. The application of these  principles should be translated,  when possible, in the design and  use of AI models. They should in 
-- COL 54.1.7 --

-- COL 54.1.8 --


TTTXX TABLE: 55 XXTTT
== ROW 55.0 ==
-- COL 55.0.0 --

-- COL 55.0.1 --

-- COL 55.0.2 --

-- COL 55.0.3 --
Commission Proposal 
-- COL 55.0.4 --
EP Mandate 
-- COL 55.0.5 --
Council Mandate 
-- COL 55.0.6 --
Draft Agreement
-- COL 55.0.7 --

-- COL 55.0.8 --

== ROW 55.1 ==
-- COL 55.1.0 --

-- COL 55.1.1 --

-- COL 55.1.2 --

-- COL 55.1.3 --

-- COL 55.1.4 --

-- COL 55.1.5 --

-- COL 55.1.6 --
any case serve as a basis for the  drafting of codes of conduct under  this Regulation. All stakeholders,  including industry, academia, civil  society and standardisation  
organisations, are encouraged to  take into account as appropriate the  ethical principles for the  
development of voluntary best  practices and standards. 
-- COL 55.1.7 --

-- COL 55.1.8 --

== ROW 55.2 ==
-- COL 55.2.0 --

-- COL 55.2.1 --

-- COL 55.2.2 --
Recital 15
-- COL 55.2.3 --

-- COL 55.2.4 --

-- COL 55.2.5 --

-- COL 55.2.6 --

-- COL 55.2.7 --

-- COL 55.2.8 --

== ROW 55.3 ==
-- COL 55.3.0 --
G 
-- COL 55.3.1 --

-- COL 55.3.2 --
25
-- COL 55.3.3 --
(15) Aside from the many beneficial  uses of artificial intelligence, that  technology can also be misused and  provide novel and powerful tools for  manipulative, exploitative and social  control practices. Such practices are  particularly harmful and should be  prohibited because they contradict  Union values of respect for human  dignity, freedom, equality,  
democracy and the rule of law and  Union fundamental rights, including  the right to non-discrimination, data  protection and privacy and the rights  of the child.
-- COL 55.3.4 --
(15) Aside from the many beneficial  uses of artificial intelligence, that  technology can also be misused and  provide novel and powerful tools for  manipulative, exploitative and social  control practices. Such practices are  particularly harmful and abusive and  should be prohibited because they  contradict Union values of respect  for human dignity, freedom,  
equality, democracy and the rule of  law and Union fundamental rights,  including the right to non 
discrimination, data protection and  privacy and the rights of the child.
-- COL 55.3.5 --
(15) Aside from the many beneficial  uses of artificial intelligence, that  technology can also be misused and  provide novel and powerful tools for  manipulative, exploitative and social  control practices. Such practices are  particularly harmful and should be  prohibited because they contradict  Union values of respect for human  dignity, freedom, equality,  
democracy and the rule of law and  Union fundamental rights, including  the right to non-discrimination, data  protection and privacy and the rights  of the child.
-- COL 55.3.6 --
(15) Aside from the many beneficial  uses of artificial intelligence, that  technology can also be misused and  provide novel and powerful tools for  manipulative, exploitative and social  control practices. Such practices are  particularly harmful and abusive and  should be prohibited because they  contradict Union values of respect  for human dignity, freedom,  
equality, democracy and the rule of  law and Union fundamental rights,  including the right to non 
discrimination, data protection and  privacy and the rights of the child.
-- COL 55.3.7 --
G
-- COL 55.3.8 --

== ROW 55.4 ==
-- COL 55.4.0 --

-- COL 55.4.1 --

-- COL 55.4.2 --
Recital 16
-- COL 55.4.3 --

-- COL 55.4.4 --

-- COL 55.4.5 --

-- COL 55.4.6 --

-- COL 55.4.7 --

-- COL 55.4.8 --

== ROW 55.5 ==
-- COL 55.5.0 --
G 
-- COL 55.5.1 --

-- COL 55.5.2 --
26
-- COL 55.5.3 --
(16) The placing on the market,  putting into service or use of certain  AI systems intended to distort  human behaviour, whereby physical 
-- COL 55.5.4 --
(16) The placing on the market,  putting into service or use of certain  AI systems with  the objective to or the effect of 
-- COL 55.5.5 --
(16) AI-enabled manipulative  techniques can be used to persuade  persons to engage in unwanted  behaviours, or to deceive them by 
-- COL 55.5.6 --
(16) AI-enabled manipulative  techniques can be used to persuade  persons to engage in unwanted  behaviours, or to deceive them by 
-- COL 55.5.7 --
G
-- COL 55.5.8 --


TTTXX TABLE: 56 XXTTT
== ROW 56.0 ==
-- COL 56.0.0 --

-- COL 56.0.1 --

-- COL 56.0.2 --

-- COL 56.0.3 --
Commission Proposal 
-- COL 56.0.4 --
EP Mandate 
-- COL 56.0.5 --
Council Mandate 
-- COL 56.0.6 --
Draft Agreement
-- COL 56.0.7 --

-- COL 56.0.8 --

== ROW 56.1 ==
-- COL 56.1.0 --

-- COL 56.1.1 --

-- COL 56.1.2 --

-- COL 56.1.3 --
or psychological harms are likely to  occur, should be forbidden. Such AI  systems deploy subliminal  
components individuals cannot  perceive or exploit vulnerabilities of  children and people due to their age,  physical or mental incapacities.  They do so with the intention to  materially distort the behaviour of a  person and in a manner that causes  or is likely to cause harm to that or  another person. The intention may  not be presumed if the distortion of  human behaviour results from  factors external to the AI system  which are outside of the control of  the provider or the user. Research  for legitimate purposes in relation to  such AI systems should not be  stifled by the prohibition, if such  research does not amount to use of  the AI system in human-machine  relations that exposes natural  
persons to harm and such research is  carried out in accordance with  recognised ethical standards for  scientific research.
-- COL 56.1.4 --
materially distorting human  
behaviour, whereby physical or  psychological harms are likely to  occur, should be forbidden. This  limitation should be understood to  include neuro-technologies assisted  by AI systems that are used to  monitor, use, or influence neural  data gathered through brain computer interfaces insofar as they  are materially distorting the  
behaviour of a natural person in a  manner that causes or is likely to  cause that person or another person  significant harm. Such AI systems  deploy subliminal components  individuals cannot perceive or  exploit vulnerabilities of  individuals and specific  groups of persons due to their  known or predicted personality  traits, age, physical or mental  incapacities, social or economic  situation. They do so with the  intention to or the effect of  
materially istorting the  behaviour of a person and in a  manner that causes or is likely to  cause significant harm to that or  another person or groups of persons,  including harms that may be  accumulated over time. The  
intention to distort the behaviour  may not be presumed if the  
distortion  results from factors external to the  AI system which are outside of the 
-- COL 56.1.5 --
nudging them into decisions in a  way that subverts and impairs their  autonomy, decision-making and  free choices. The placing on the  market, putting into service or use of  certain AI systems  aterially distorting human  behaviour, whereby physical or  psychological harms are likely to  occur, are particularly dangerous  and should therefore be forbidden.  Such AI systems deploy subliminal  components uch as  audio, image, video stimuli that  persons cannot perceive as those  stimuli are beyond human  
perception or other subliminal  techniques that subvert or impair  person’s autonomy, decision making or free choices in ways that  people are not consciously aware  of, or even if aware not able to  control or resist, for example in  cases of machine-brain interfaces  or virtual reality. In addition, AI  systems may also otherwise  exploit vulnerabilities of   specific group of  persons due to their age, p  

situation that is likely to make those  persons more vulnerable to  
exploitation such as persons living  in extreme poverty, ethnic or 
-- COL 56.1.6 --
nudging them into decisions in a  way that subverts and impairs their  autonomy, decision-making and  free choices. The placing on the  market, putting into service or use of  certain AI systems  with the objective to or the  effect of materially distorting human behaviour, whereby  
significant harms, in particular  having sufficiently important  adverse impacts on physical,  psychological health or financial  interests are  likely to occur, are particularly  dangerous and should therefore be  forbidden. Such AI systems deploy  subliminal components  

manipulative or deceptive  
techniques that subvert or impair  person’s autonomy, decision making or free choices in ways that  people are not consciously aware  of, or even if aware they are still  deceived or not able to control or  resist. This could be for example,  facilitated by machine-brain  interfaces or virtual reality as they  allow for a higher degree of control  of what stimuli are presented to  persons, insofar as they may be  materially distorting their  
behaviour in a significantly 
-- COL 56.1.7 --

-- COL 56.1.8 --


TTTXX TABLE: 57 XXTTT
== ROW 57.0 ==
-- COL 57.0.0 --

-- COL 57.0.1 --

-- COL 57.0.2 --

-- COL 57.0.3 --
Commission Proposal 
-- COL 57.0.4 --
EP Mandate 
-- COL 57.0.5 --
Council Mandate 
-- COL 57.0.6 --
Draft Agreement
-- COL 57.0.7 --

-- COL 57.0.8 --

== ROW 57.1 ==
-- COL 57.1.0 --

-- COL 57.1.1 --

-- COL 57.1.2 --

-- COL 57.1.3 --

-- COL 57.1.4 --
control of the provider or the user,  such as factors that may not be  reasonably foreseen and mitigated  by the provider or the deployer of  the AI system. In any case, it is not  necessary for the provider or the  deployer to have the intention to  cause the significant harm, as long  as such harm results from the  manipulative or exploitative AI enabled practices. The prohibitions  for such AI practices is  
complementary to the provisions  contained in Directive 2005/29/EC,  according to which unfair  
commercial practices are  
prohibited, irrespective of whether  they carried out having recourse to  AI systems or otherwise. In such  setting, lawful commercial  
practices, for example in the field of  advertising, that are in compliance  with Union law should not in  themselves be regarded as violating  prohibition. Research for legitimate  purposes in relation to such AI  systems should not be stifled by the  prohibition, if such research does not  amount to use of the AI system in  human-machine relations that  exposes natural persons to harm and  such research is carried out in  accordance with recognised ethical  standards for scientific research and  on the basis of specific informed  consent of the individuals that are  exposed to them or, where 
-- COL 57.1.5 --
religious minorities. Such AI  systems can be placed on the  market, put into service or used with the bjective to or  the effect of materially  

distortion  results from factors external to the  AI system which are outside of the  control of the provider or the user,  meaning factors that may not be  reasonably foreseen and mitigated  by the provider or the user of the AI  system. In any case, it is not  
necessary for the provider or the  user to have the intention to cause  the physical or psychological harm,  as long as such harm results from  the manipulative or exploitative AI enabled practices. The prohibitions  for such AI practices are  
complementary to the provisions  contained in Directive 2005/29/EC,  notably that unfair commercial  practices leading to economic or  financial harms to consumers are  prohibited under all circumstances,  irrespective of whether they are put  in place through AI systems or 
-- COL 57.1.6 --
harmful manner.  
In addition, AI systems may also  otherwise exploit vulnerabilities  of  person or a  specific group of persons due to  their age, p 

vulnerable to exploitation such as  persons living in extreme poverty,  ethnic or religious minorities. Such  AI systems can be placed on the  market, put into service or used with the bjective to or  the effect of materially  

including harms that may be  accumulated over time and should  therefore be prohibited. The  
intention to distort the behaviour  may not be presumed if the  
distortion 
-- COL 57.1.7 --

-- COL 57.1.8 --


TTTXX TABLE: 58 XXTTT
== ROW 58.0 ==
-- COL 58.0.0 --

-- COL 58.0.1 --

-- COL 58.0.2 --

-- COL 58.0.3 --
Commission Proposal 
-- COL 58.0.4 --
EP Mandate 
-- COL 58.0.5 --
Council Mandate 
-- COL 58.0.6 --
Draft Agreement
-- COL 58.0.7 --

-- COL 58.0.8 --

== ROW 58.1 ==
-- COL 58.1.0 --

-- COL 58.1.1 --

-- COL 58.1.2 --

-- COL 58.1.3 --

-- COL 58.1.4 --
applicable, of their legal guardian. 
-- COL 58.1.5 --
otherwise. The prohibitions of  manipulative and exploitative  practices in this Regulation should  not affect lawful practices in the  context of medical treatment such  as psychological treatment of a  mental disease or physical  
rehabilitation, when those practices  are 
p  p    carried out in  accordance with  

themselves be regarded as  
constituting harmful manipulative  AI practices.
-- COL 58.1.6 --
  eployer, meaning  factors that may not be reasonably  foreseen and mitigated by the  provider or the deployer of the AI  system. In any case, it is not  
necessary for the provider or the  deployer to have the intention to  cause significant harm, as long as  such harm results from the  
manipulative or exploitative AI enabled practices. The prohibitions  for such AI practices are  
complementary to the provisions  contained in Directive 2005/29/EC,  notably unfair commercial  
practices leading to economic or  financial harms to consumers are  prohibited under all circumstances,  irrespective of whether they are put  in place through AI systems or  otherwise.  
The prohibitions of manipulative  and exploitative practices in this  Regulation should not affect lawful  practices in the context of medical  treatment such as psychological  treatment of a mental disease or  physical rehabilitation, when those  practices are carried out in  
accordance with  

-- COL 58.1.7 --

-- COL 58.1.8 --


TTTXX TABLE: 59 XXTTT
== ROW 59.0 ==
-- COL 59.0.0 --

-- COL 59.0.1 --

-- COL 59.0.2 --

-- COL 59.0.3 --
Commission Proposal 
-- COL 59.0.4 --
EP Mandate 
-- COL 59.0.5 --
Council Mandate 
-- COL 59.0.6 --
Draft Agreement
-- COL 59.0.7 --

-- COL 59.0.8 --

== ROW 59.1 ==
-- COL 59.1.0 --

-- COL 59.1.1 --

-- COL 59.1.2 --

-- COL 59.1.3 --

-- COL 59.1.4 --

-- COL 59.1.5 --

-- COL 59.1.6 --
commercial practices, for example  in the field of advertising, that are  in compliance with the applicable  
law should not in themselves be  regarded as constituting harmful  manipulative AI practices  .
-- COL 59.1.7 --

-- COL 59.1.8 --

== ROW 59.2 ==
-- COL 59.2.0 --

-- COL 59.2.1 --

-- COL 59.2.2 --
Recital 16a
-- COL 59.2.3 --

-- COL 59.2.4 --

-- COL 59.2.5 --

-- COL 59.2.6 --

-- COL 59.2.7 --

-- COL 59.2.8 --

== ROW 59.3 ==
-- COL 59.3.0 --
G 
-- COL 59.3.1 --

-- COL 59.3.2 --
26a
-- COL 59.3.3 --

-- COL 59.3.4 --
(16a) AI systems that categorise  natural persons by assigning them  to specific categories, according to  known or inferred sensitive or  protected characteristics are  particularly intrusive, violate  human dignity and hold great risk  of discrimination. Such  
characteristics include gender,  gender identity, race, ethnic origin,  migration or citizenship status,  political orientation, sexual  
orientation, religion, disability or  any other grounds on which  
discrimination is prohibited under  Article 21 of the Charter of  
Fundamental Rights of the  
European Union, as well as under  Article 9 of Regulation  
(EU)2016/769. Such systems should  therefore be prohibited. 
-- COL 59.3.5 --

-- COL 59.3.6 --
(16a) Biometric categorisation  systems that are based on  
individuals’ biometric data, such as  an individual person’s face or  fingerprint, to deduce or infer an  individuals’ political opinions, trade  union membership, religious or  philosophical beliefs, race, sex life  or sexual orientation should be  prohibited. This prohibition does  not cover the lawful labelling,  filtering or categorisation of  biometric datasets acquired in line  with Union or national law  
according to biometric data, such as  the sorting of images according to  hair colour or eye colour, which  can for example be used in the area  of law enforcement.
-- COL 59.3.7 --
G
-- COL 59.3.8 --

== ROW 59.4 ==
-- COL 59.4.0 --

-- COL 59.4.1 --

-- COL 59.4.2 --
Recital 17
-- COL 59.4.3 --

-- COL 59.4.4 --

-- COL 59.4.5 --

-- COL 59.4.6 --

-- COL 59.4.7 --

-- COL 59.4.8 --

== ROW 59.5 ==
-- COL 59.5.0 --
G 
-- COL 59.5.1 --

-- COL 59.5.2 --
27 
-- COL 59.5.3 --
(17) AI systems providing social 
-- COL 59.5.4 --
(17) AI systems providing social 
-- COL 59.5.5 --
(17) AI systems providing social 
-- COL 59.5.6 --
(17) AI systems providing social 
-- COL 59.5.7 --
G
-- COL 59.5.8 --


TTTXX TABLE: 60 XXTTT
== ROW 60.0 ==
-- COL 60.0.0 --

-- COL 60.0.1 --

-- COL 60.0.2 --

-- COL 60.0.3 --
Commission Proposal 
-- COL 60.0.4 --
EP Mandate 
-- COL 60.0.5 --
Council Mandate 
-- COL 60.0.6 --
Draft Agreement
-- COL 60.0.7 --

-- COL 60.0.8 --

== ROW 60.1 ==
-- COL 60.1.0 --

-- COL 60.1.1 --

-- COL 60.1.2 --

-- COL 60.1.3 --
scoring of natural persons for  general purpose by public authorities  or on their behalf may lead to  discriminatory outcomes and the  exclusion of certain groups. They  may violate the right to dignity and  non-discrimination and the values of  equality and justice. Such AI  
systems evaluate or classify the  trustworthiness of natural persons  based on their social behaviour in  multiple contexts or known or  predicted personal or personality  characteristics. The social score  obtained from such AI systems may  lead to the detrimental or  
unfavourable treatment of natural  persons or whole groups thereof in  social contexts, which are unrelated  to the context in which the data was  originally generated or collected or  to a detrimental treatment that is  disproportionate or unjustified to the  gravity of their social behaviour.  Such AI systems should be therefore  prohibited.
-- COL 60.1.4 --
scoring of natural persons for  general purpose  may lead to  discriminatory outcomes and the  exclusion of certain groups. They  violate the right to dignity and  non-discrimination and the values of  equality and justice. Such AI  
systems evaluate or classify  natural persons or  groups based on multiple data  points and time occurrences related  to their social behaviour in multiple  contexts or known, inferred or  predicted personal or personality  characteristics. The social score  obtained from such AI systems may  lead to the detrimental or  
unfavourable treatment of natural  persons or whole groups thereof in  social contexts, which are unrelated  to the context in which the data was  originally generated or collected or  to a detrimental treatment that is  disproportionate or unjustified to the  gravity of their social behaviour.  Such AI systems should be therefore  prohibited.
-- COL 60.1.5 --
scoring of natural persons f by public  
authorities or y  private actors may lead to  
discriminatory outcomes and the  exclusion of certain groups. They  may violate the right to dignity and  non-discrimination and the values of  equality and justice. Such AI  
systems evaluate or classify  natural persons  based on their social behaviour in  multiple contexts or known or  predicted personal or personality  characteristics. The social score  obtained from such AI systems may  lead to the detrimental or  
unfavourable treatment of natural  persons or whole groups thereof in  social contexts, which are unrelated  to the context in which the data was  originally generated or collected or  to a detrimental treatment that is  disproportionate or unjustified to the  gravity of their social behaviour. AI  systems entailing such  
unacceptable scoring practices A should be therefore  prohibited. This prohibition should  not affect lawful evaluation  
practices of natural persons done  for one or more specific purpose in  compliance with the law.
-- COL 60.1.6 --
scoring of natural persons f by public 

discriminatory outcomes and the  exclusion of certain groups. They  may violate the right to dignity and  non-discrimination and the values of  equality and justice. Such AI  
systems evaluate or classify   
patural persons or groups  thereof based on multiple data  points related to their social  
behaviour in multiple contexts or  known, inferred or predicted  
personal or personality  
characteristics over certain periods  of time. The social score obtained  from such AI systems may lead to  the detrimental or unfavourable  treatment of natural persons or  whole groups thereof in social  contexts, which are unrelated to the  context in which the data was  originally generated or collected or  to a detrimental treatment that is  disproportionate or unjustified to the  gravity of their social behaviour. AI  systems entailing such  
unacceptable scoring practices  leading to such detrimental or  unfavorable outcomes  should be therefore  
prohibited. This prohibition should  not affect lawful evaluation  
practices of natural persons done 
-- COL 60.1.7 --

-- COL 60.1.8 --


TTTXX TABLE: 61 XXTTT
== ROW 61.0 ==
-- COL 61.0.0 --

-- COL 61.0.1 --

-- COL 61.0.2 --

-- COL 61.0.3 --
Commission Proposal 
-- COL 61.0.4 --
EP Mandate 
-- COL 61.0.5 --
Council Mandate 
-- COL 61.0.6 --
Draft Agreement
-- COL 61.0.7 --

-- COL 61.0.8 --

== ROW 61.1 ==
-- COL 61.1.0 --

-- COL 61.1.1 --

-- COL 61.1.2 --

-- COL 61.1.3 --

-- COL 61.1.4 --

-- COL 61.1.5 --

-- COL 61.1.6 --
for a specific purpose in  
compliance with national and  Union law.
-- COL 61.1.7 --

-- COL 61.1.8 --

== ROW 61.2 ==
-- COL 61.2.0 --

-- COL 61.2.1 --

-- COL 61.2.2 --
Recital 18
-- COL 61.2.3 --

-- COL 61.2.4 --

-- COL 61.2.5 --

-- COL 61.2.6 --

-- COL 61.2.7 --

-- COL 61.2.8 --

== ROW 61.3 ==
-- COL 61.3.0 --
G 
-- COL 61.3.1 --

-- COL 61.3.2 --
28
-- COL 61.3.3 --
(18) The use of AI systems for  ‘real-time’ remote biometric  
identification of natural persons in  publicly accessible spaces for the  purpose of law enforcement is  considered particularly intrusive in  the rights and freedoms of the  concerned persons, to the extent that  it may affect the private life of a  large part of the population, evoke a  feeling of constant surveillance and  indirectly dissuade the exercise of  the freedom of assembly and other  fundamental rights. In addition, the  immediacy of the impact and the limited opportunities for further  checks or corrections in relation to  the use of such systems operating in  ‘real-time’ carry heightened risks for  the rights and freedoms of the  persons that are concerned by law  enforcement activities.
-- COL 61.3.4 --
(18) The use of AI systems for  ‘real-time’ remote biometric  
identification of natural persons in  publicly accessible spaces f p is particularly intrusive  o the rights and freedoms of the  concerned persons,  nd can ultimately affect the  private life of a large part of the  population, evoke a feeling of  constant surveillance, give parties  deploying biometric identification  in publicly accessible spaces a  position of uncontrollable power and indirectly dissuade the exercise  of the freedom of assembly and  other fundamental rights at the core  to the Rule of Law. Technical  inaccuracies of AI systems intended  for the remote biometric  
identification of natural persons  can lead to biased results and entail  discriminatory effects. This is  particularly relevant when it comes  to age, ethnicity, sex or disabilities.  In addition, the immediacy of the  impact and the limited opportunities  for further checks or corrections in  relation to the use of such systems 
-- COL 61.3.5 --
(18) The use of AI systems for  ‘real-time’ remote biometric  
identification of natural persons in  publicly accessible spaces for the  purpose of law enforcement is  considered particularly intrusive in  the rights and freedoms of the  concerned persons, to the extent that  it may affect the private life of a  large part of the population, evoke a  feeling of constant surveillance and  indirectly dissuade the exercise of  the freedom of assembly and other  fundamental rights. In addition, the  immediacy of the impact and the  limited opportunities for further  checks or corrections in relation to  the use of such systems operating in  ‘real-time’ carry heightened risks for  the rights and freedoms of the  persons that are concerned by law  enforcement activities.
-- COL 61.3.6 --
(18) The use of AI systems for  ‘real-time’ remote biometric  
identification of natural persons in  publicly accessible spaces for the  purpose of law enforcement is particularly intrusive  to the rights and freedoms of the  concerned persons, to the extent that  it may affect the private life of a  large part of the population, evoke a  feeling of constant surveillance and  indirectly dissuade the exercise of  the freedom of assembly and other  fundamental rights . 
Technical inaccuracies of AI  systems intended for the remote  biometric identification of natural  persons can lead to biased results  and entail discriminatory effects.  This is particularly relevant when it  comes to age, ethnicity, race, sex or  disabilities.  
In addition, the immediacy of the  impact and the limited opportunities  for further checks or corrections in  relation to the use of such systems  operating in ‘real-time’ carry  
heightened risks for the rights and  freedoms of the persons that are  concerned by law enforcement 
-- COL 61.3.7 --
G
-- COL 61.3.8 --


TTTXX TABLE: 62 XXTTT
== ROW 62.0 ==
-- COL 62.0.0 --

-- COL 62.0.1 --

-- COL 62.0.2 --

-- COL 62.0.3 --
Commission Proposal 
-- COL 62.0.4 --
EP Mandate 
-- COL 62.0.5 --
Council Mandate 
-- COL 62.0.6 --
Draft Agreement
-- COL 62.0.7 --

-- COL 62.0.8 --

== ROW 62.1 ==
-- COL 62.1.0 --

-- COL 62.1.1 --

-- COL 62.1.2 --

-- COL 62.1.3 --

-- COL 62.1.4 --
operating in ‘real-time’ carry  
heightened risks for the rights and  freedoms of the persons that are  concerned by law enforcement  activities. The use of those systems  in publicly accessible places should  therefore be prohibited. Similarly,  AI systems used for the analysis of  recorded footage of publicly  
accessible spaces through ‘post’  remote biometric identification  systems should also be prohibited,  unless there is pre-judicial  
authorisation for use in the context  of law enforcement, when strictly  necessary for the targeted search  connected to a specific serious  criminal offense that already took  place, and only subject to a pre judicial authorisation. 
-- COL 62.1.5 --

-- COL 62.1.6 --
activities.
-- COL 62.1.7 --

-- COL 62.1.8 --

== ROW 62.2 ==
-- COL 62.2.0 --

-- COL 62.2.1 --

-- COL 62.2.2 --
Recital 19
-- COL 62.2.3 --

-- COL 62.2.4 --

-- COL 62.2.5 --

-- COL 62.2.6 --

-- COL 62.2.7 --

-- COL 62.2.8 --

== ROW 62.3 ==
-- COL 62.3.0 --
G 
-- COL 62.3.1 --

-- COL 62.3.2 --
29
-- COL 62.3.3 --
(19) The use of those systems for  the purpose of law enforcement  should therefore be prohibited,  except in three exhaustively listed  and narrowly defined situations,  where the use is strictly necessary to  achieve a substantial public interest,  the importance of which outweighs  the risks. Those situations involve  the search for potential victims of  crime, including missing children;  certain threats to the life or physical  safety of natural persons or of a 
-- COL 62.3.4 --
deleted
-- COL 62.3.5 --
(19) The use of those systems for  the purpose of law enforcement  should therefore be prohibited,  except in exhaustively listed  and narrowly defined situations,  where the use is strictly necessary to  achieve a substantial public interest,  the importance of which outweighs  the risks. Those situations involve  the search for potential victims of  crime, including missing children;  certain threats to the life or physical  safety of natural persons or of a 
-- COL 62.3.6 --
(19) The use of those systems for  the purpose of law enforcement  should therefore be prohibited,  except in exhaustively listed  and narrowly defined situations,  where the use is strictly necessary to  achieve a substantial public interest,  the importance of which outweighs  the risks. Those situations involve  the search for pertain  victims of crime,including missing  eople; certain threats to the  life or physical safety of natural 
-- COL 62.3.7 --
G
-- COL 62.3.8 --


TTTXX TABLE: 63 XXTTT
== ROW 63.0 ==
-- COL 63.0.0 --

-- COL 63.0.1 --

-- COL 63.0.2 --

-- COL 63.0.3 --
Commission Proposal 
-- COL 63.0.4 --
EP Mandate 
-- COL 63.0.5 --
Council Mandate 
-- COL 63.0.6 --
Draft Agreement
-- COL 63.0.7 --

-- COL 63.0.8 --

== ROW 63.1 ==
-- COL 63.1.0 --

-- COL 63.1.1 --

-- COL 63.1.2 --

-- COL 63.1.3 --
terrorist attack; and the detection,  localisation, identification or  
prosecution of perpetrators or  suspects of the criminal offences  referred to in Council Framework  Decision 2002/584/JHA1if those  criminal offences are punishable in  the Member State concerned by a  custodial sentence or a detention  order for a maximum period of at  least three years and as they are  defined in the law of that Member  State. Such threshold for the  
custodial sentence or detention order  in accordance with national law  contributes to ensure that the offence  should be serious enough to  
potentially justify the use of ‘real time’ remote biometric identification  systems. Moreover, of the 32  
criminal offences listed in the  Council Framework Decision  2002/584/JHA, some are in practice  likely to be more relevant than  others, in that the recourse to ‘real time’ remote biometric identification  will foreseeably be necessary and  proportionate to highly varying  degrees for the practical pursuit of  the detection, localisation,  
identification or prosecution of a  perpetrator or suspect of the  
different criminal offences listed and  having regard to the likely  
differences in the seriousness,  probability and scale of the harm or  possible negative consequences.
-- COL 63.1.4 --

-- COL 63.1.5 --
terrorist attack; and the detection,  localisation, identification or  
prosecution of perpetrators or  suspects of the criminal offences  referred to in Council Framework  Decision 2002/584/JHA1if those  criminal offences are punishable in  the Member State concerned by a  custodial sentence or a detention  order for a maximum period of at  least three years and as they are  defined in the law of that Member  State. Such threshold for the  
custodial sentence or detention order  in accordance with national law  contributes to ensure that the offence  should be serious enough to  
potentially justify the use of ‘real time’ remote biometric identification  systems. Moreover, of the 32  
criminal offences listed in the  Council Framework Decision  2002/584/JHA, some are in practice  likely to be more relevant than  others, in that the recourse to ‘real time’ remote biometric identification  will foreseeably be necessary and  proportionate to highly varying  degrees for the practical pursuit of  the detection, localisation,  
identification or prosecution of a  perpetrator or suspect of the  
different criminal offences listed and  having regard to the likely  
differences in the seriousness,  probability and scale of the harm or  possible negative consequences. In 
-- COL 63.1.6 --
persons or of a terrorist attack; and  the localisation, 

referred to in  Dnnex IIa  if those criminal offences are 
punishable in the Member State  concerned by a custodial sentence or  a detention order for a maximum  period of at least four years  and as they are defined in the law of  that Member State. Such threshold  for the custodial sentence or  
detention order in accordance with  national law contributes to ensure  that the offence should be serious  enough to potentially justify the use  of ‘real-time’ remote biometric  identification systems. Moreover,  the list of criminal offences as  referred in Annex IIa is based on  the 32 criminal offences listed in the  Council Framework Decision  2002/584/JHA1, taking into account  that ,some are in practice likely to  be more relevant than others, in that  the recourse to ‘real-time’ remote  biometric identification will  
foreseeably be necessary and  
proportionate to highly varying  degrees for the practical pursuit of  the localisation, 

-- COL 63.1.7 --

-- COL 63.1.8 --


TTTXX TABLE: 64 XXTTT
== ROW 64.0 ==
-- COL 64.0.0 --

-- COL 64.0.1 --

-- COL 64.0.2 --

-- COL 64.0.3 --
Commission Proposal 
-- COL 64.0.4 --
EP Mandate 
-- COL 64.0.5 --
Council Mandate 
-- COL 64.0.6 --
Draft Agreement
-- COL 64.0.7 --

-- COL 64.0.8 --

== ROW 64.1 ==
-- COL 64.1.0 --

-- COL 64.1.1 --

-- COL 64.1.2 --

-- COL 64.1.3 --
_________ 
1. Council Framework Decision  
2002/584/JHA of 13 June 2002 on the  European arrest warrant and the surrender  procedures between Member States (OJ L  190, 18.7.2002, p. 1).
-- COL 64.1.4 --

-- COL 64.1.5 --
addition, this Regulation should  preserve the ability for law  
enforcement, border control,  immigration or asylum authorities  to carry out identity checks in the  presence of the person that is  concerned in accordance with the  conditions set out in Union and  national law for such checks. In  particular, law enforcement, border  control, immigration or asylum  authorities should be able to use  information systems, in accordance  with Union or national law, to  identify a person who, during an  identity check, either refuses to be  identified or is unable to state or  prove his or her identity, without  being required by this Regulation to  obtain prior authorisation. This  could be, for example, a person  involved in a crime, being  
unwilling, or unable due to an  accident or a medical condition, to  disclose their identity to law  
enforcement authorities.  
_________ 
1. [1] Council Framework Decision  2002/584/JHA of 13 June 2002 on the  European arrest warrant and the surrender  procedures between Member States (OJ L  190, 18.7.2002, p. 1).
-- COL 64.1.6 --
offences listed and having regard to  the likely differences in the  
seriousness, probability and scale of  the harm or possible negative  consequences. 
An imminent threat to life or  physical safety of natural persons  could also result from a serious  disruption of critical infrastructure,  as defined in Article 2, point (a) of  Directive 2008/114/EC, where the  disruption or destruction of such  critical infrastructure would result  in an imminent threat to life or  physical safety of a person,  
including through serious harm to  the provision of basic supplies to  the population or to the exercise of  the core function of the State.  
In addition, this Regulation should  preserve the ability for law  
enforcement, border control,  immigration or asylum authorities  to carry out identity checks in the  presence of the person that is  concerned in accordance with the  conditions set out in Union and  national law for such checks. In  particular, law enforcement, border  control, immigration or asylum  authorities should be able to use  information systems, in accordance  with Union or national law, to  identify a person who, during an  identity check, either refuses to be 
-- COL 64.1.7 --

-- COL 64.1.8 --


TTTXX TABLE: 65 XXTTT
== ROW 65.0 ==
-- COL 65.0.0 --

-- COL 65.0.1 --

-- COL 65.0.2 --

-- COL 65.0.3 --
Commission Proposal 
-- COL 65.0.4 --
EP Mandate 
-- COL 65.0.5 --
Council Mandate 
-- COL 65.0.6 --
Draft Agreement
-- COL 65.0.7 --

-- COL 65.0.8 --

== ROW 65.1 ==
-- COL 65.1.0 --

-- COL 65.1.1 --

-- COL 65.1.2 --

-- COL 65.1.3 --

-- COL 65.1.4 --

-- COL 65.1.5 --

-- COL 65.1.6 --
identified or is unable to state or  prove his or her identity, without  being required by this Regulation to  obtain prior authorisation. This  could be, for example, a person  involved in a crime, being  
unwilling, or unable due to an  accident or a medical condition, to  disclose their identity to law  
enforcement authorities.  
_________ 
1. Council Framework Decision  
2002/584/JHA of 13 June 2002 on the  European arrest warrant and the surrender  procedures between Member States (OJ L  190, 18.7.2002, p. 1).
-- COL 65.1.7 --

-- COL 65.1.8 --

== ROW 65.2 ==
-- COL 65.2.0 --

-- COL 65.2.1 --

-- COL 65.2.2 --
Recital 20
-- COL 65.2.3 --

-- COL 65.2.4 --

-- COL 65.2.5 --

-- COL 65.2.6 --

-- COL 65.2.7 --

-- COL 65.2.8 --

== ROW 65.3 ==
-- COL 65.3.0 --
G 
-- COL 65.3.1 --

-- COL 65.3.2 --
30
-- COL 65.3.3 --
(20) In order to ensure that those  systems are used in a responsible  and proportionate manner, it is also  important to establish that, in each of  those three exhaustively listed and  narrowly defined situations, certain  elements should be taken into  account, in particular as regards the  nature of the situation giving rise to  the request and the consequences of  the use for the rights and freedoms  of all persons concerned and the  safeguards and conditions provided  for with the use. In addition, the use  of ‘real-time’ remote biometric  identification systems in publicly  accessible spaces for the purpose of  law enforcement should be subject 
-- COL 65.3.4 --
deleted
-- COL 65.3.5 --
(20) In order to ensure that those  systems are used in a responsible  and proportionate manner, it is also  important to establish that, in each of  those exhaustively listed and  narrowly defined situations, certain  elements should be taken into  account, in particular as regards the  nature of the situation giving rise to  the request and the consequences of  the use for the rights and freedoms  of all persons concerned and the  safeguards and conditions provided  for with the use. In addition, the use  of ‘real-time’ remote biometric  identification systems in publicly  accessible spaces for the purpose of  law enforcement should be subject 
-- COL 65.3.6 --
(20) In order to ensure that those  systems are used in a responsible  and proportionate manner, it is also  important to establish that, in each of  thoseexhaustively listed and  narrowly defined situations, certain  elements should be taken into  account, in particular as regards the  nature of the situation giving rise to  the request and the consequences of  the use for the rights and freedoms  of all persons concerned and the  safeguards and conditions provided  for with the use. In addition, the use  of ‘real-time’ remote biometric  identification systems in publicly  accessible spaces for the purpose of  law enforcement should only be 
-- COL 65.3.7 --
G
-- COL 65.3.8 --


TTTXX TABLE: 66 XXTTT
== ROW 66.0 ==
-- COL 66.0.0 --

-- COL 66.0.1 --

-- COL 66.0.2 --

-- COL 66.0.3 --
Commission Proposal 
-- COL 66.0.4 --
EP Mandate 
-- COL 66.0.5 --
Council Mandate 
-- COL 66.0.6 --
Draft Agreement
-- COL 66.0.7 --

-- COL 66.0.8 --

== ROW 66.1 ==
-- COL 66.1.0 --

-- COL 66.1.1 --

-- COL 66.1.2 --

-- COL 66.1.3 --
to appropriate limits in time and  space, having regard in particular to  the evidence or indications regarding  the threats, the victims or  
perpetrator. The reference database  of persons should be appropriate for  each use case in each of the three  situations mentioned above.
-- COL 66.1.4 --

-- COL 66.1.5 --
to appropriate limits in time and  space, having regard in particular to  the evidence or indications regarding  the threats, the victims or  
perpetrator. The reference database  of persons should be appropriate for  each use case in each of the situations mentioned above.
-- COL 66.1.6 --
deployed to confirm the specifically  target individual’s identity and  should be limited to what is strictly  necessary concerning the period of  time as well as geographic and  personal scope  

completed a fundamental rights  impact assessment and, unless  provided otherwise in this  
Regulation, has registered the  system in the database as set out in  this Regulation. The reference  database of persons should be  appropriate for each use case in each  of the situations mentioned  above.
-- COL 66.1.7 --

-- COL 66.1.8 --

== ROW 66.2 ==
-- COL 66.2.0 --

-- COL 66.2.1 --

-- COL 66.2.2 --
Recital 21
-- COL 66.2.3 --

-- COL 66.2.4 --

-- COL 66.2.5 --

-- COL 66.2.6 --

-- COL 66.2.7 --

-- COL 66.2.8 --

== ROW 66.3 ==
-- COL 66.3.0 --
G 
-- COL 66.3.1 --

-- COL 66.3.2 --
31
-- COL 66.3.3 --
(21) Each use of a ‘real-time’  remote biometric identification  system in publicly accessible spaces  for the purpose of law enforcement  should be subject to an express and  specific authorisation by a judicial  authority or by an independent  administrative authority of a 
-- COL 66.3.4 --
deleted
-- COL 66.3.5 --
(21) Each use of a ‘real-time’  remote biometric identification  system in publicly accessible spaces  for the purpose of law enforcement  should be subject to an express and  specific authorisation by a judicial  authority or by an independent  administrative authority of a 
-- COL 66.3.6 --
(21) Each use of a ‘real-time’  remote biometric identification  system in publicly accessible spaces  for the purpose of law enforcement  should be subject to an express and  specific authorisation by a judicial  authority or by an independent  administrative authority whose 
-- COL 66.3.7 --
G
-- COL 66.3.8 --


TTTXX TABLE: 67 XXTTT
== ROW 67.0 ==
-- COL 67.0.0 --

-- COL 67.0.1 --

-- COL 67.0.2 --

-- COL 67.0.3 --
Commission Proposal 
-- COL 67.0.4 --
EP Mandate 
-- COL 67.0.5 --
Council Mandate 
-- COL 67.0.6 --
Draft Agreement
-- COL 67.0.7 --

-- COL 67.0.8 --

== ROW 67.1 ==
-- COL 67.1.0 --

-- COL 67.1.1 --

-- COL 67.1.2 --

-- COL 67.1.3 --
Member State. Such authorisation  should in principle be obtained prior  to the use, except in duly justified  situations of urgency, that is,  
situations where the need to use the  systems in question is such as to  make it effectively and objectively  impossible to obtain an authorisation  before commencing the use. In such  situations of urgency, the use should  be restricted to the absolute  
minimum necessary and be subject  to appropriate safeguards and  conditions, as determined in national  law and specified in the context of  each individual urgent use case by  the law enforcement authority itself.  In addition, the law enforcement  authority should in such situations  seek to obtain an authorisation as  soon as possible, whilst providing  the reasons for not having been able  to request it earlier.
-- COL 67.1.4 --

-- COL 67.1.5 --
Member State. Such authorisation  should in principle be obtained prior  to the use,of the system with  a view to identify a person or  persons. Exceptions to this rule  should be allowed in duly justified  situations of urgency, that is,  
situations where the need to use the  systems in question is such as to  make it effectively and objectively  impossible to obtain an authorisation  before commencing the use. In such  situations of urgency, the use should  be restricted to the absolute  
minimum necessary and be subject  to appropriate safeguards and  conditions, as determined in national  law and specified in the context of  each individual urgent use case by  the law enforcement authority itself.  In addition, the law enforcement  authority should in such situations  seek to obtain an authorisation as  soon as possible, whilst providing  the reasons for not having been able  to request it earlier.
-- COL 67.1.6 --
decision is binding of a Member  State. Such authorisation should in  principle be obtained prior to the  use,of the system with a view  to identify a person or persons.  Exceptions to this rule should be  allowed in duly justified situations  of urgency, that is, situations where  the need to use the systems in  question is such as to make it  effectively and objectively  
impossible to obtain an authorisation  before commencing the use. In such  situations of urgency, the use should  be restricted to the absolute  
minimum necessary and be subject  to appropriate safeguards and  conditions, as determined in national  law and specified in the context of  each individual urgent use case by  the law enforcement authority itself.  In addition, the law enforcement  authority should in such situations request such authorisation  whilst providing the reasons for not  having been able to request it earlier,  without undue delay and, at the  latest within 24 hours.  
If such authorisation is rejected, the  use of real-time biometric  
identification systems linked to that  authorisation should be stopped  with immediate effect and all the  data related to such use should be  discarded and deleted. Such data  includes input data directly 
-- COL 67.1.7 --

-- COL 67.1.8 --


TTTXX TABLE: 68 XXTTT
== ROW 68.0 ==
-- COL 68.0.0 --

-- COL 68.0.1 --

-- COL 68.0.2 --

-- COL 68.0.3 --
Commission Proposal 
-- COL 68.0.4 --
EP Mandate 
-- COL 68.0.5 --
Council Mandate 
-- COL 68.0.6 --
Draft Agreement
-- COL 68.0.7 --

-- COL 68.0.8 --

== ROW 68.1 ==
-- COL 68.1.0 --

-- COL 68.1.1 --

-- COL 68.1.2 --

-- COL 68.1.3 --

-- COL 68.1.4 --

-- COL 68.1.5 --

-- COL 68.1.6 --
acquired by an AI system in the  course of the use of such system as  well as the results and outputs of  the use linked to that authorisation.  It should not include input legally  acquired in accordance with  another national or Union law. In  any case, no decision producing an  adverse legal effect on a person  may be taken solely based on the  output of the remote biometric  identification system.
-- COL 68.1.7 --

-- COL 68.1.8 --

== ROW 68.2 ==
-- COL 68.2.0 --

-- COL 68.2.1 --

-- COL 68.2.2 --
Recital 21a
-- COL 68.2.3 --

-- COL 68.2.4 --

-- COL 68.2.5 --

-- COL 68.2.6 --

-- COL 68.2.7 --

-- COL 68.2.8 --

== ROW 68.3 ==
-- COL 68.3.0 --
G 
-- COL 68.3.1 --

-- COL 68.3.2 --
31a
-- COL 68.3.3 --

-- COL 68.3.4 --

-- COL 68.3.5 --

-- COL 68.3.6 --
(21a) In order to carry out their  tasks in accordance with the  requirements set out in this  
Regulation as well as in national  rules, the relevant market  
surveillance authority and the  national data protection authority  should be notified of each use of  the ‘real-time biometric  
identification system’. National  market surveillance authorities and  the national data protection  
authorities that have been notified  should submit to the Commission  an annual report on the use of  ‘real-time biometric identification  systems’. 
-- COL 68.3.7 --
G
-- COL 68.3.8 --

== ROW 68.4 ==
-- COL 68.4.0 --

-- COL 68.4.1 --

-- COL 68.4.2 --
Recital 22
-- COL 68.4.3 --

-- COL 68.4.4 --

-- COL 68.4.5 --

-- COL 68.4.6 --

-- COL 68.4.7 --

-- COL 68.4.8 --

== ROW 68.5 ==
-- COL 68.5.0 --
G 
-- COL 68.5.1 --

-- COL 68.5.2 --
32 
-- COL 68.5.3 --

-- COL 68.5.4 --

-- COL 68.5.5 --

-- COL 68.5.6 --

-- COL 68.5.7 --
G
-- COL 68.5.8 --


TTTXX TABLE: 69 XXTTT
== ROW 69.0 ==
-- COL 69.0.0 --

-- COL 69.0.1 --

-- COL 69.0.2 --

-- COL 69.0.3 --
Commission Proposal 
-- COL 69.0.4 --
EP Mandate 
-- COL 69.0.5 --
Council Mandate 
-- COL 69.0.6 --
Draft Agreement
-- COL 69.0.7 --

-- COL 69.0.8 --

== ROW 69.1 ==
-- COL 69.1.0 --

-- COL 69.1.1 --

-- COL 69.1.2 --

-- COL 69.1.3 --
(22) Furthermore, it is appropriate  to provide, within the exhaustive  framework set by this Regulation  that such use in the territory of a  Member State in accordance with  this Regulation should only be  possible where and in as far as the  Member State in question has  decided to expressly provide for the  possibility to authorise such use in  its detailed rules of national law.  Consequently, Member States  remain free under this Regulation  not to provide for such a possibility  at all or to only provide for such a  possibility in respect of some of the  objectives capable of justifying  authorised use identified in this  Regulation.
-- COL 69.1.4 --
deleted
-- COL 69.1.5 --
(22) Furthermore, it is appropriate  to provide, within the exhaustive  framework set by this Regulation  that such use in the territory of a  Member State in accordance with  this Regulation should only be  possible where and in as far as the  Member State in question has  decided to expressly provide for the  possibility to authorise such use in  its detailed rules of national law.  Consequently, Member States  remain free under this Regulation  not to provide for such a possibility  at all or to only provide for such a  possibility in respect of some of the  objectives capable of justifying  authorised use identified in this  Regulation.
-- COL 69.1.6 --
(22) Furthermore, it is appropriate  to provide, within the exhaustive  framework set by this Regulation  that such use in the territory of a  Member State in accordance with  this Regulation should only be  possible where and in as far as the  Member State in question has  decided to expressly provide for the  possibility to authorise such use in  its detailed rules of national law.  Consequently, Member States  remain free under this Regulation  not to provide for such a possibility  at all or to only provide for such a  possibility in respect of some of the  objectives capable of justifying  authorised use identified in this  Regulation. These national rules  should be notified to the  
Commission at the latest 30 days  following their adoption. 
-- COL 69.1.7 --

-- COL 69.1.8 --

== ROW 69.2 ==
-- COL 69.2.0 --

-- COL 69.2.1 --

-- COL 69.2.2 --
Recital 23
-- COL 69.2.3 --

-- COL 69.2.4 --

-- COL 69.2.5 --

-- COL 69.2.6 --

-- COL 69.2.7 --

-- COL 69.2.8 --

== ROW 69.3 ==
-- COL 69.3.0 --
G 
-- COL 69.3.1 --

-- COL 69.3.2 --
33
-- COL 69.3.3 --
(23) The use of AI systems for  ‘real-time’ remote biometric  
identification of natural persons in  publicly accessible spaces for the  purpose of law enforcement  
necessarily involves the processing  of biometric data. The rules of this  Regulation that prohibit, subject to  certain exceptions, such use, which  
are based on Article 16 TFEU,  should apply as lex specialis in 
-- COL 69.3.4 --
deleted
-- COL 69.3.5 --
(23) The use of AI systems for  ‘real-time’ remote biometric  
identification of natural persons in  publicly accessible spaces for the  purpose of law enforcement  
necessarily involves the processing  of biometric data. The rules of this  Regulation that prohibit, subject to  certain exceptions, such use, which  
are based on Article 16 TFEU,  should apply as lex specialis
-- COL 69.3.6 --
(23) The use of AI systems for  ‘real-time’ remote biometric  
identification of natural persons in  publicly accessible spaces for the  purpose of law enforcement  
necessarily involves the processing  of biometric data. The rules of this  Regulation that prohibit, subject to  certain exceptions, such use, which  
are based on Article 16 TFEU,  should apply as lex specialis in 
-- COL 69.3.7 --
G
-- COL 69.3.8 --


TTTXX TABLE: 70 XXTTT
== ROW 70.0 ==
-- COL 70.0.0 --

-- COL 70.0.1 --

-- COL 70.0.2 --

-- COL 70.0.3 --
Commission Proposal 
-- COL 70.0.4 --
EP Mandate 
-- COL 70.0.5 --
Council Mandate 
-- COL 70.0.6 --
Draft Agreement
-- COL 70.0.7 --

-- COL 70.0.8 --

== ROW 70.1 ==
-- COL 70.1.0 --

-- COL 70.1.1 --

-- COL 70.1.2 --

-- COL 70.1.3 --
respect of the rules on the processing  of biometric data contained in  Article 10 of Directive (EU)  
2016/680, thus regulating such use  and the processing of biometric data  involved in an exhaustive manner.  Therefore, such use and processing  should only be possible in as far as it  is compatible with the framework set  by this Regulation, without there  being scope, outside that framework,  for the competent authorities, where  they act for purpose of law  
enforcement, to use such systems  and process such data in connection  thereto on the grounds listed in  Article 10 of Directive (EU)  
2016/680. In this context, this  Regulation is not intended to provide  the legal basis for the processing of  personal data under Article 8 of  Directive 2016/680. However, the  use of ‘real-time’ remote biometric  identification systems in publicly  accessible spaces for purposes other  than law enforcement, including by  competent authorities, should not be  covered by the specific framework  regarding such use for the purpose of  law enforcement set by this  
Regulation. Such use for purposes  other than law enforcement should  therefore not be subject to the  requirement of an authorisation  under this Regulation and the  applicable detailed rules of national  law that may give effect to it.
-- COL 70.1.4 --

-- COL 70.1.5 --

Regulation. Such use for purposes  other than law enforcement should  therefore not be subject to the  requirement of an authorisation  under this Regulation and the  applicable detailed rules of national  law that may give effect to it.
-- COL 70.1.6 --
respect of the rules on the processing  of biometric data contained in  Article 10 of Directive (EU)  
2016/680, thus regulating such use  and the processing of biometric data  involved in an exhaustive manner.  Therefore, such use and processing  should only be possible in as far as it  is compatible with the framework set  by this Regulation, without there  being scope, outside that framework,  for the competent authorities, where  they act for purpose of law  
enforcement, to use such systems  and process such data in connection  thereto on the grounds listed in  Article 10 of Directive (EU)  
2016/680. In this context, this  Regulation is not intended to provide  the legal basis for the processing of  personal data under Article 8 of  Directive 2016/680. However, the  use of ‘real-time’ remote biometric  identification systems in publicly  accessible spaces for purposes other  than law enforcement, including by  competent authorities, should not be  covered by the specific framework  regarding such use for the purpose of  law enforcement set by this  
Regulation. Such use for purposes  other than law enforcement should  therefore not be subject to the  requirement of an authorisation  under this Regulation and the  applicable detailed rules of national  law that may give effect to it.
-- COL 70.1.7 --

-- COL 70.1.8 --


TTTXX TABLE: 71 XXTTT
== ROW 71.0 ==
-- COL 71.0.0 --

-- COL 71.0.1 --

-- COL 71.0.2 --

-- COL 71.0.3 --
Commission Proposal 
-- COL 71.0.4 --
EP Mandate 
-- COL 71.0.5 --
Council Mandate 
-- COL 71.0.6 --
Draft Agreement
-- COL 71.0.7 --

-- COL 71.0.8 --

== ROW 71.1 ==
-- COL 71.1.0 --

-- COL 71.1.1 --

-- COL 71.1.2 --

-- COL 71.1.3 --

-- COL 71.1.4 --

-- COL 71.1.5 --

-- COL 71.1.6 --

-- COL 71.1.7 --

-- COL 71.1.8 --

== ROW 71.2 ==
-- COL 71.2.0 --

-- COL 71.2.1 --

-- COL 71.2.2 --
Recital 24
-- COL 71.2.3 --

-- COL 71.2.4 --

-- COL 71.2.5 --

-- COL 71.2.6 --

-- COL 71.2.7 --

-- COL 71.2.8 --

== ROW 71.3 ==
-- COL 71.3.0 --
G 
-- COL 71.3.1 --

-- COL 71.3.2 --
34
-- COL 71.3.3 --
(24) Any processing of biometric  data and other personal data  
involved in the use of AI systems for  biometric identification, other than  in connection to the use of ‘real time’ remote biometric identification  systems in publicly accessible spaces  for the purpose of law enforcement  as regulated by this Regulation,  including where those systems are  used by competent authorities in  publicly accessible spaces for other  purposes than law enforcement,  should continue to comply with all  requirements resulting from Article  9(1) of Regulation (EU) 2016/679,  Article 10(1) of Regulation (EU)  2018/1725 and Article 10 of  
Directive (EU) 2016/680, as  
applicable.
-- COL 71.3.4 --
(24) Any processing of biometric  data and other personal data  
involved in the use of AI systems for  biometric identification, other than  in connection to the use of ‘real time’ remote biometric identification  systems in publicly accessible spaces  f as regulated by this Regulation,   p p should continue to comply with all  requirements resulting from Article  9(1) of Regulation (EU) 2016/679,  Article 10(1) of Regulation (EU)  2018/1725 and Article 10 of  
Directive (EU) 2016/680, as  
applicable.
-- COL 71.3.5 --
(24) Any processing of biometric  data and other personal data  
involved in the use of AI systems for  biometric identification, other than  in connection to the use of ‘real time’ remote biometric identification  systems in publicly accessible spaces  for the purpose of law enforcement  as regulated by this Regulation,    p should continue to comply with all  requirements resulting from Article  10 of Directive (EU) 2016/680. For  purposes other than law  
enforcement,   Article 9(1) of  Regulation (EU) 2016/679, and Article 10(1) of Regulation (EU)  2018/1725  
D 

-- COL 71.3.6 --
(24) Any processing of biometric  data and other personal data  
involved in the use of AI systems for  biometric identification, other than  in connection to the use of ‘real time’ remote biometric identification  systems in publicly accessible spaces  for the purpose of law enforcement  as regulated by this Regulation,    p should continue to comply with all  requirements resulting from Article  10 of Directive (EU) 2016/680.  For purposes other than law  
enforcement,   Article 9(1) of  Regulation (EU) 2016/679, and Article 10(1) of Regulation (EU)  2018/1725 rohibit the  
processing of biometric data subject  to limited exceptions as provided in  those articles. In application of Article  

enforcement has already been  subject to prohibition decisions by  national data protection authorities.
-- COL 71.3.7 --
G
-- COL 71.3.8 --


TTTXX TABLE: 72 XXTTT
== ROW 72.0 ==
-- COL 72.0.0 --

-- COL 72.0.1 --

-- COL 72.0.2 --

-- COL 72.0.3 --
Commission Proposal 
-- COL 72.0.4 --
EP Mandate 
-- COL 72.0.5 --
Council Mandate 
-- COL 72.0.6 --
Draft Agreement
-- COL 72.0.7 --

-- COL 72.0.8 --

== ROW 72.1 ==
-- COL 72.1.0 --

-- COL 72.1.1 --

-- COL 72.1.2 --

-- COL 72.1.3 --

-- COL 72.1.4 --

-- COL 72.1.5 --

-- COL 72.1.6 --

-- COL 72.1.7 --

-- COL 72.1.8 --

== ROW 72.2 ==
-- COL 72.2.0 --

-- COL 72.2.1 --

-- COL 72.2.2 --
Recital 25
-- COL 72.2.3 --

-- COL 72.2.4 --

-- COL 72.2.5 --

-- COL 72.2.6 --

-- COL 72.2.7 --

-- COL 72.2.8 --

== ROW 72.3 ==
-- COL 72.3.0 --
G 
-- COL 72.3.1 --

-- COL 72.3.2 --
35
-- COL 72.3.3 --
(25) In accordance with Article 6a  of Protocol No 21 on the position of  the United Kingdom and Ireland in  respect of the area of freedom,  security and justice, as annexed to  the TEU and to the TFEU, Ireland is  not bound by the rules laid down in  Article 5(1), point (d), (2) and (3) of  this Regulation adopted on the basis  of Article 16 of the TFEU which  relate to the processing of personal  data by the Member States when  carrying out activities falling within  the scope of Chapter 4 or Chapter 5  of Title V of Part Three of the  TFEU, where Ireland is not bound  by the rules governing the forms of  judicial cooperation in criminal  matters or police cooperation which  require compliance with the  
provisions laid down on the basis of  Article 16 of the TFEU.
-- COL 72.3.4 --
(25) In accordance with Article 6a  of Protocol No 21 on the position of  the United Kingdom and Ireland in  respect of the area of freedom,  security and justice, as annexed to  the TEU and to the TFEU, Ireland is  not bound by the rules laid down in  Article 5(1), point (d), of  this Regulation adopted on the basis  of Article 16 of the TFEU which  relate to the processing of personal  data by the Member States when  carrying out activities falling within  the scope of Chapter 4 or Chapter 5  of Title V of Part Three of the  TFEU, where Ireland is not bound  by the rules governing the forms of  judicial cooperation in criminal  matters or police cooperation which  require compliance with the  
provisions laid down on the basis of  Article 16 of the TFEU.
-- COL 72.3.5 --
(25) In accordance with Article 6a  of Protocol No 21 on the position of  the United Kingdom and Ireland in  respect of the area of freedom,  security and justice, as annexed to  the TEU and to the TFEU, Ireland is  not bound by the rules laid down in  Article 5(1), point (d), (2), (3) and  (4)  of this Regulation  adopted on the basis of Article 16 of  the TFEU which relate to the  
processing of personal data by the  Member States when carrying out  activities falling within the scope of  Chapter 4 or Chapter 5 of Title V of  Part Three of the TFEU, where  Ireland is not bound by the rules  governing the forms of judicial  cooperation in criminal matters or  police cooperation which require  compliance with the provisions laid  down on the basis of Article 16 of  the TFEU.
-- COL 72.3.6 --
(25) In accordance with Article 6a  of Protocol No 21 on the position of  the United Kingdom and Ireland in  respect of the area of freedom,  security and justice, as annexed to  the TEU and to the TFEU, Ireland is  not bound by the rules laid down in  Article 5(1), point (d), (2), (3), (3a),  (4) and (5), Article 5(1)(ba) to the  extent it applies to the use of  biometric categorisation systems for  activities in the field of police  cooperation and judicial  
cooperation in criminal matters,  Article 5(1)(da) to the extent it  applies to the use of AI systems  covered by that provision and  Article 29(6a)  of this  Regulation adopted on the basis of  Article 16 of the TFEU which relate  to the processing of personal data by  the Member States when carrying  out activities falling within the scope  of Chapter 4 or Chapter 5 of Title V  of Part Three of the TFEU, where  Ireland is not bound by the rules  governing the forms of judicial  cooperation in criminal matters or  police cooperation which require  compliance with the provisions laid  down on the basis of Article 16 of  the TFEU.
-- COL 72.3.7 --
G
-- COL 72.3.8 --


TTTXX TABLE: 73 XXTTT
== ROW 73.0 ==
-- COL 73.0.0 --

-- COL 73.0.1 --

-- COL 73.0.2 --

-- COL 73.0.3 --
Commission Proposal 
-- COL 73.0.4 --
EP Mandate 
-- COL 73.0.5 --
Council Mandate 
-- COL 73.0.6 --
Draft Agreement
-- COL 73.0.7 --

-- COL 73.0.8 --

== ROW 73.1 ==
-- COL 73.1.0 --

-- COL 73.1.1 --

-- COL 73.1.2 --
Recital 26
-- COL 73.1.3 --

-- COL 73.1.4 --

-- COL 73.1.5 --

-- COL 73.1.6 --

-- COL 73.1.7 --

-- COL 73.1.8 --

== ROW 73.2 ==
-- COL 73.2.0 --
G 
-- COL 73.2.1 --

-- COL 73.2.2 --
36
-- COL 73.2.3 --
(26) In accordance with Articles 2  and 2a of Protocol No 22 on the  position of Denmark, annexed to the  TEU and TFEU, Denmark is not  bound by rules laid down in Article  5(1), point (d), (2) and (3) of this  Regulation adopted on the basis of  Article 16 of the TFEU, or subject to  their application, which relate to the  processing of personal data by the  Member States when carrying out  activities falling within the scope of  Chapter 4 or Chapter 5 of Title V of  Part Three of the TFEU.
-- COL 73.2.4 --
(26) In accordance with Articles 2  and 2a of Protocol No 22 on the  position of Denmark, annexed to the  TEU and TFEU, Denmark is not  bound by rules laid down in Article  5(1), point (d), of this  Regulation adopted on the basis of  Article 16 of the TFEU, or subject to  their application, which relate to the  processing of personal data by the  Member States when carrying out  activities falling within the scope of  Chapter 4 or Chapter 5 of Title V of  Part Three of the TFEU.
-- COL 73.2.5 --
(26) In accordance with Articles 2  and 2a of Protocol No 22 on the  position of Denmark, annexed to the  TEU and TFEU, Denmark is not  bound by rules laid down in Article  5(1), point (d), (2), (3) and (4)   of this Regulation adopted on the  basis of Article 16 of the TFEU, or  subject to their application, which  relate to the processing of personal  data by the Member States when  carrying out activities falling within  the scope of Chapter 4 or Chapter 5  of Title V of Part Three of the  TFEU.
-- COL 73.2.6 --
(26) In accordance with Articles 2  and 2a of Protocol No 22 on the  position of Denmark, annexed to the  TEU and TFEU, Denmark is not  bound by rules laid down in Article  5(1), point (d), (2), (3), (3a), (4) and  (5), Article 5(1)(ba) to the extent it  applies to the use of biometric  categorisation systems for activities  in the field of police cooperation  and judicial cooperation in criminal  matters, Article 5(1)(da) to the  extent it applies to the use of AI  systems covered by that provision  and Article 29(6a) of this  Regulation adopted on the basis of  Article 16 of the TFEU, or subject to  their application, which relate to the  processing of personal data by the  Member States when carrying out  activities falling within the scope of  Chapter 4 or Chapter 5 of Title V of  Part Three of the TFEU.
-- COL 73.2.7 --
G
-- COL 73.2.8 --

== ROW 73.3 ==
-- COL 73.3.0 --

-- COL 73.3.1 --

-- COL 73.3.2 --
Recital 26a
-- COL 73.3.3 --

-- COL 73.3.4 --

-- COL 73.3.5 --

-- COL 73.3.6 --

-- COL 73.3.7 --

-- COL 73.3.8 --

== ROW 73.4 ==
-- COL 73.4.0 --
G 
-- COL 73.4.1 --

-- COL 73.4.2 --
36a
-- COL 73.4.3 --

-- COL 73.4.4 --
(26a) AI systems used by law  enforcement authorities or on their  behalf to make predictions, profiles  or risk assessments based on  profiling of natural persons or data  analysis based on personality traits  and characteristics, including the  person’s location, or past criminal 
-- COL 73.4.5 --

-- COL 73.4.6 --
(26a) In line with the presumption  of innocence, natural persons in the  EU should always be judged on  their actual behaviour. Natural  persons should never be judged on  AI-predicted behaviour based solely  on their profiling, personality traits  or characteristics, such as 
-- COL 73.4.7 --
G
-- COL 73.4.8 --


TTTXX TABLE: 74 XXTTT
== ROW 74.0 ==
-- COL 74.0.0 --

-- COL 74.0.1 --

-- COL 74.0.2 --

-- COL 74.0.3 --
Commission Proposal 
-- COL 74.0.4 --
EP Mandate 
-- COL 74.0.5 --
Council Mandate 
-- COL 74.0.6 --
Draft Agreement
-- COL 74.0.7 --

-- COL 74.0.8 --

== ROW 74.1 ==
-- COL 74.1.0 --

-- COL 74.1.1 --

-- COL 74.1.2 --

-- COL 74.1.3 --

-- COL 74.1.4 --
behaviour of natural persons or  groups of persons for the purpose  of predicting the occurrence or  reoccurrence of an actual or  potential criminal offence(s) or  other criminalised social behaviour  or administrative offences,  
including fraud-predicition systems,  hold a particular risk of  
discrimination against certain  persons or groups of persons, as  they violate human dignity as well  as the key legal principle of  
presumption of innocence. Such AI  systems should therefore be  
prohibited. 
-- COL 74.1.5 --

-- COL 74.1.6 --
nationality, place of birth, place of  residence, number of children, debt,  their type of car, without a  
reasonable suspicion of that person  being involved in a criminal activity  based on objective verifiable facts  and without human assessment  thereof. Therefore, risk assessments  of natural persons in order to assess  the risk of them offending or for  predicting the occurrence of an  actual or potential criminal offence  solely based on the profiling of a  natural person or on assessing their  personality traits and  
characteristics should be  
prohibited. In any case, this  
prohibition does not refer to nor  touch upon risk analytics that are  not based on the profiling of  individuals or on the personality  traits and characteristics of  
individuals, such as AI systems  using risk analytics to assess the  risk of financial fraud by  
undertakings based on suspicious  transactions or risk analytic tools to  predict the likelihood of localisation  of narcotics or illicit goods by  customs authorities, for example  based on known trafficking routes.
-- COL 74.1.7 --

-- COL 74.1.8 --

== ROW 74.2 ==
-- COL 74.2.0 --

-- COL 74.2.1 --

-- COL 74.2.2 --
Recital 26b
-- COL 74.2.3 --

-- COL 74.2.4 --

-- COL 74.2.5 --

-- COL 74.2.6 --

-- COL 74.2.7 --

-- COL 74.2.8 --

== ROW 74.3 ==
-- COL 74.3.0 --
G 
-- COL 74.3.1 --

-- COL 74.3.2 --
36b 
-- COL 74.3.3 --

-- COL 74.3.4 --
(26b) The indiscriminate and  untargeted scraping of biometric 
-- COL 74.3.5 --

-- COL 74.3.6 --
(26b) The placing on the market,  putting into service for this specific 
-- COL 74.3.7 --
G
-- COL 74.3.8 --


TTTXX TABLE: 75 XXTTT
== ROW 75.0 ==
-- COL 75.0.0 --

-- COL 75.0.1 --

-- COL 75.0.2 --

-- COL 75.0.3 --
Commission Proposal 
-- COL 75.0.4 --
EP Mandate 
-- COL 75.0.5 --
Council Mandate 
-- COL 75.0.6 --
Draft Agreement
-- COL 75.0.7 --

-- COL 75.0.8 --

== ROW 75.1 ==
-- COL 75.1.0 --

-- COL 75.1.1 --

-- COL 75.1.2 --

-- COL 75.1.3 --

-- COL 75.1.4 --
data from social media or CCTV  footage to create or expand facial  recognition databases add to the  feeling of mass surveillance and  
can lead to gross violations of  fundamental rights, including the  right to privacy. The use of AI  systems with this intended purpose  should therefore be prohibited. 
-- COL 75.1.5 --

-- COL 75.1.6 --
purpose, or use of AI systems that  create or expand facial recognition  databases through the untargeted  scraping of facial images from the  internet or CCTV footage should be  prohibited, as this practice adds to  the feeling of mass surveillance and  can lead to gross violations of  fundamental rights, including the  right to privacy.
-- COL 75.1.7 --

-- COL 75.1.8 --

== ROW 75.2 ==
-- COL 75.2.0 --

-- COL 75.2.1 --

-- COL 75.2.2 --
Recital 26c
-- COL 75.2.3 --

-- COL 75.2.4 --

-- COL 75.2.5 --

-- COL 75.2.6 --

-- COL 75.2.7 --

-- COL 75.2.8 --

== ROW 75.3 ==
-- COL 75.3.0 --
G 
-- COL 75.3.1 --

-- COL 75.3.2 --
36c
-- COL 75.3.3 --

-- COL 75.3.4 --
(26c) There are serious concerns  about the scientific basis of AI  systems aiming to detect emotions,  physical or physiological features  such as facial expressions,  
movements, pulse frequency or  voice. Emotions or expressions of  emotions and perceptions thereof  vary considerably across cultures  and situations, and even within a  single individual. Among the key  shortcomings of such technologies,  are the limited reliability (emotion  categories are neither reliably  expressed through, nor  
unequivocally associated with, a  common set of physical or  
physiological movements), the lack  of specificity (physical or  
physiological expressions do not  perfectly match emotion categories)  and the limited generalisability (the  effects of context and culture are 
-- COL 75.3.5 --

-- COL 75.3.6 --
(26c) There are serious concerns  about the scientific basis of AI  systems aiming to identify or infer  emotions, particularly as expression  of emotions vary considerably  across cultures and situations, and  even within a single individual.  Among the key shortcomings of  such systems are the limited  
reliability, the lack of specificity  and the limited generalizability.  Therefore, AI systems identifying or  inferring emotions or intentions of  natural persons on the basis of their  biometric data may lead to  
discriminatory outcomes and can be  intrusive to the rights and freedoms  of the concerned persons.  
Considering the imbalance of  power in the context of work or  education, combined with the  intrusive nature of these systems,  such systems could lead to 
-- COL 75.3.7 --
G
-- COL 75.3.8 --


TTTXX TABLE: 76 XXTTT
== ROW 76.0 ==
-- COL 76.0.0 --

-- COL 76.0.1 --

-- COL 76.0.2 --

-- COL 76.0.3 --
Commission Proposal 
-- COL 76.0.4 --
EP Mandate 
-- COL 76.0.5 --
Council Mandate 
-- COL 76.0.6 --
Draft Agreement
-- COL 76.0.7 --

-- COL 76.0.8 --

== ROW 76.1 ==
-- COL 76.1.0 --

-- COL 76.1.1 --

-- COL 76.1.2 --

-- COL 76.1.3 --

-- COL 76.1.4 --
not sufficiently considered).  
Reliability issues and consequently,  major risks for abuse, may  
especially arise when deploying the  system in real-life situations related  to law enforcement, border  
management, workplace and  education institutions. Therefore,  the placing on the market, putting  into service, or use of AI systems  intended to be used in these  
contexts to detect the emotional  state of individuals should be  prohibited. 
-- COL 76.1.5 --

-- COL 76.1.6 --
detrimental or unfavourable  treatment of certain natural persons  or whole groups thereof. Therefore,  the placing on the market, putting  into service, or use of AI systems  intended to be used to detect the  emotional state of individuals in  situations related to the workplace  and education should be prohibited.  This prohibition should not cover  AI systems placed on the market  strictly for medical or safety  
reasons, such as systems intended  for therapeutical use. 
-- COL 76.1.7 --

-- COL 76.1.8 --

== ROW 76.2 ==
-- COL 76.2.0 --

-- COL 76.2.1 --

-- COL 76.2.2 --
Recital 26d
-- COL 76.2.3 --

-- COL 76.2.4 --

-- COL 76.2.5 --

-- COL 76.2.6 --

-- COL 76.2.7 --

-- COL 76.2.8 --

== ROW 76.3 ==
-- COL 76.3.0 --
G 
-- COL 76.3.1 --

-- COL 76.3.2 --
36d
-- COL 76.3.3 --

-- COL 76.3.4 --
(26d) Practices that are prohibited  by Union legislation, including data  protection law, non-discrimination  law, consumer protection law, and  competition law, should not be  affected by this Regulation. 
-- COL 76.3.5 --

-- COL 76.3.6 --
(26d) Practices that are prohibited  by Union legislation, including data  protection law, non-discrimination  law, consumer protection law, and  competition law, should not be  affected by this Regulation.
-- COL 76.3.7 --
G
-- COL 76.3.8 --

== ROW 76.4 ==
-- COL 76.4.0 --

-- COL 76.4.1 --

-- COL 76.4.2 --
Recital 27
-- COL 76.4.3 --

-- COL 76.4.4 --

-- COL 76.4.5 --

-- COL 76.4.6 --

-- COL 76.4.7 --

-- COL 76.4.8 --

== ROW 76.5 ==
-- COL 76.5.0 --
G 
-- COL 76.5.1 --

-- COL 76.5.2 --
37
-- COL 76.5.3 --
(27) High-risk AI systems should  only be placed on the Union market  or put into service if they comply  with certain mandatory  
requirements. Those requirements  should ensure that high-risk AI  systems available in the Union or  whose output is otherwise used in  the Union do not pose unacceptable 
-- COL 76.5.4 --
(27) High-risk AI systems should  only be placed on the Union market  put into service or used if they  
comply with certain mandatory  requirements. Those requirements  should ensure that high-risk AI  systems available in the Union or  whose output is otherwise used in  the Union do not pose unacceptable 
-- COL 76.5.5 --
(27) High-risk AI systems should  only be placed on the Union market  or put into service if they comply  with certain mandatory  
requirements. Those requirements  should ensure that high-risk AI  systems available in the Union or  whose output is otherwise used in  the Union do not pose unacceptable 
-- COL 76.5.6 --
(27) High-risk AI systems should  only be placed on the Union market  put into service or used if they  
comply with certain mandatory  requirements. Those requirements  should ensure that high-risk AI  systems available in the Union or  whose output is otherwise used in  the Union do not pose unacceptable 
-- COL 76.5.7 --
G
-- COL 76.5.8 --


TTTXX TABLE: 77 XXTTT
== ROW 77.0 ==
-- COL 77.0.0 --

-- COL 77.0.1 --

-- COL 77.0.2 --

-- COL 77.0.3 --
Commission Proposal 
-- COL 77.0.4 --
EP Mandate 
-- COL 77.0.5 --
Council Mandate 
-- COL 77.0.6 --
Draft Agreement
-- COL 77.0.7 --

-- COL 77.0.8 --

== ROW 77.1 ==
-- COL 77.1.0 --

-- COL 77.1.1 --

-- COL 77.1.2 --

-- COL 77.1.3 --
risks to important Union public  interests as recognised and protected  by Union law. AI systems identified  as high-risk should be limited to  those that have a significant harmful  impact on the health, safety and  fundamental rights of persons in the  Union and such limitation minimises  any potential restriction to  
international trade, if any.
-- COL 77.1.4 --
risks to important Union public  interests as recognised and protected  by Union law, including  
fundamental rights, democracy, the  rule or law or the environment. In  order to ensure alignment with  sectoral legislation and avoid  duplications, requirements for  high-risk AI systems should take  into account sectoral legislation  laying down requirements for high risk AI systems included in the  scope of this Regulation, such as  Regulation (EU) 2017/745 on  Medical Devices and Regulation  (EU) 2017/746 on In Vitro  
Diagnostic Devices or Directive  2006/42/EC on Machinery. AI  systems identified as high-risk  should be limited to those that have  a significant harmful impact on the  health, safety and fundamental rights  of persons in the Union and such  limitation minimises any potential  restriction to international trade, if  any. Given the rapid pace of  
technological development, as well  as the potential changes in the use  of AI systems, the list of high-risk  
areas and use-cases in Annex III  should nonetheless be subject to  permanent review through the  exercise of regular assessment. 
-- COL 77.1.5 --
risks to important Union public  interests as recognised and protected  by Union law. AI systems identified  as high-risk should be limited to  those that have a significant harmful  impact on the health, safety and  fundamental rights of persons in the  Union and such limitation minimises  any potential restriction to  
international trade, if any.
-- COL 77.1.6 --
risks to important Union public  interests as recognised and protected  by Union law. Following the New  Legislative Framework approach,  as clarified in Commission notice  the ‘Blue Guide’ on the  
implementation of EU product rules  2022 (C/2022/3637) the general  rule is that several pieces of the EU  legislation, such as Regulation  (EU) 2017/745 on Medical Devices  and Regulation (EU) 2017/746 on  In Vitro Diagnostic Devices or  Directive 2006/42/EC on  
Machinery, may have to be taken  into consideration for one product,  since the making available or  putting into service can only take  place when the product complies  with all applicable Union  
harmonisation legislation. To  ensure consistency and avoid  unnecessary administrative burden  or costs, providers of a product that  contains one or more high-risk  artificial intelligence system, to  which the requirements of this  Regulation as well as requirements  of the Union harmonisation  
legislation listed in Annex II,  Section A apply, should have a  flexibility on operational decisions  on how to ensure compliance of a  product that contains one or more  artificial intelligence systems with  all applicable requirements of the  Union harmonised legislation in a 
-- COL 77.1.7 --

-- COL 77.1.8 --


TTTXX TABLE: 78 XXTTT
== ROW 78.0 ==
-- COL 78.0.0 --

-- COL 78.0.1 --

-- COL 78.0.2 --

-- COL 78.0.3 --
Commission Proposal 
-- COL 78.0.4 --
EP Mandate 
-- COL 78.0.5 --
Council Mandate 
-- COL 78.0.6 --
Draft Agreement
-- COL 78.0.7 --

-- COL 78.0.8 --

== ROW 78.1 ==
-- COL 78.1.0 --

-- COL 78.1.1 --

-- COL 78.1.2 --

-- COL 78.1.3 --

-- COL 78.1.4 --

-- COL 78.1.5 --

-- COL 78.1.6 --
best way. AI systems identified as  high-risk should be limited to those  that have a significant harmful  impact on the health, safety and  fundamental rights of persons in the  Union and such limitation minimises  any potential restriction to  
international trade, if any.
-- COL 78.1.7 --

-- COL 78.1.8 --

== ROW 78.2 ==
-- COL 78.2.0 --

-- COL 78.2.1 --

-- COL 78.2.2 --
Recital 28
-- COL 78.2.3 --

-- COL 78.2.4 --

-- COL 78.2.5 --

-- COL 78.2.6 --

-- COL 78.2.7 --

-- COL 78.2.8 --

== ROW 78.3 ==
-- COL 78.3.0 --
G 
-- COL 78.3.1 --

-- COL 78.3.2 --
38
-- COL 78.3.3 --
(28) AI systems could produce  adverse outcomes to health and  safety of persons, in particular when  such systems operate as components  of products. Consistently with the  objectives of Union harmonisation  legislation to facilitate the free  movement of products in the internal  market and to ensure that only safe  and otherwise compliant products  find their way into the market, it is  important that the safety risks that  may be generated by a product as a  whole due to its digital components,  including AI systems, are duly  prevented and mitigated. For  
instance, increasingly autonomous  robots, whether in the context of  manufacturing or personal assistance  and care should be able to safely  operate and performs their functions  in complex environments. Similarly,  in the health sector where the stakes  for life and health are particularly  high, increasingly sophisticated 
-- COL 78.3.4 --
(28) AI systems could pave  an adverse impact to health  and safety of persons, in particular  when such systems operate as safety components of products.  
Consistently with the objectives of  Union harmonisation legislation to  facilitate the free movement of  products in the internal market and  to ensure that only safe and  
otherwise compliant products find  their way into the market, it is  important that the safety risks that  may be generated by a product as a  whole due to its digital components,  including AI systems, are duly  prevented and mitigated. For  
instance, increasingly autonomous  robots, whether in the context of  manufacturing or personal assistance  and care should be able to safely  operate and performs their functions  in complex environments. Similarly,  in the health sector where the stakes  for life and health are particularly 
-- COL 78.3.5 --
(28) AI systems could produce  adverse outcomes to health and  safety of persons, in particular when  such systems operate as components  of products. Consistently with the  objectives of Union harmonisation  legislation to facilitate the free  movement of products in the internal  market and to ensure that only safe  and otherwise compliant products  find their way into the market, it is  important that the safety risks that  may be generated by a product as a  whole due to its digital components,  including AI systems, are duly  prevented and mitigated. For  
instance, increasingly autonomous  robots, whether in the context of  manufacturing or personal assistance  and care should be able to safely  operate and performs their functions  in complex environments. Similarly,  in the health sector where the stakes  for life and health are particularly  high, increasingly sophisticated 
-- COL 78.3.6 --
(28) AI systems could pave  an adverse impact to health  and safety of persons, in particular  when such systems operate as safety components of products.  
Consistently with the objectives of  Union harmonisation legislation to  facilitate the free movement of  products in the internal market and  to ensure that only safe and  
otherwise compliant products find  their way into the market, it is  important that the safety risks that  may be generated by a product as a  whole due to its digital components,  including AI systems, are duly  prevented and mitigated. For  
instance, increasingly autonomous  robots, whether in the context of  manufacturing or personal assistance  and care should be able to safely  operate and performs their functions  in complex environments. Similarly,  in the health sector where the stakes  for life and health are particularly 
-- COL 78.3.7 --
G
-- COL 78.3.8 --


TTTXX TABLE: 79 XXTTT
== ROW 79.0 ==
-- COL 79.0.0 --

-- COL 79.0.1 --

-- COL 79.0.2 --

-- COL 79.0.3 --
Commission Proposal 
-- COL 79.0.4 --
EP Mandate 
-- COL 79.0.5 --
Council Mandate 
-- COL 79.0.6 --
Draft Agreement
-- COL 79.0.7 --

-- COL 79.0.8 --

== ROW 79.1 ==
-- COL 79.1.0 --

-- COL 79.1.1 --

-- COL 79.1.2 --

-- COL 79.1.3 --
diagnostics systems and systems  supporting human decisions should  be reliable and accurate. The extent  of the adverse impact caused by the  AI system on the fundamental rights  protected by the Charter is of  particular relevance when  
classifying an AI system as high risk. Those rights include the right to  human dignity, respect for private  and family life, protection of  
personal data, freedom of expression  and information, freedom of  
assembly and of association, and  non-discrimination, consumer  protection, workers’ rights, rights of  persons with disabilities, right to an  effective remedy and to a fair trial,  right of defence and the presumption  of innocence, right to good  
administration. In addition to those  rights, it is important to highlight  that children have specific rights as  enshrined in Article 24 of the EU  Charter and in the United Nations  Convention on the Rights of the  Child (further elaborated in the  UNCRC General Comment No. 25  as regards the digital environment),  both of which require consideration  of the children’s vulnerabilities and  provision of such protection and care  as necessary for their well-being.  The fundamental right to a high level  of environmental protection  
enshrined in the Charter and  
implemented in Union policies 
-- COL 79.1.4 --
high, increasingly sophisticated  diagnostics systems and systems  supporting human decisions should  be reliable and accurate.   A p p 

p  
  p
    
p
-- COL 79.1.5 --
diagnostics systems and systems  supporting human decisions should  be reliable and accurate. The extent  of the adverse impact caused by the  AI system on the fundamental rights  protected by the Charter is of  particular relevance when  
classifying an AI system as high risk. Those rights include the right to  human dignity, respect for private  and family life, protection of  
personal data, freedom of expression  and information, freedom of  
assembly and of association, and  non-discrimination, consumer  protection, workers’ rights, rights of  persons with disabilities, right to an  effective remedy and to a fair trial,  right of defence and the presumption  of innocence, right to good  
administration. In addition to those  rights, it is important to highlight  that children have specific rights as  enshrined in Article 24 of the EU  Charter and in the United Nations  Convention on the Rights of the  Child (further elaborated in the  UNCRC General Comment No. 25  as regards the digital environment),  both of which require consideration  of the children’s vulnerabilities and  provision of such protection and care  as necessary for their well-being.  The fundamental right to a high level  of environmental protection  
enshrined in the Charter and  
implemented in Union policies 
-- COL 79.1.6 --
high, increasingly sophisticated  diagnostics systems and systems  supporting human decisions should  be reliable and accurate.   A p p 

p  
  p
    
p
-- COL 79.1.7 --

-- COL 79.1.8 --


TTTXX TABLE: 80 XXTTT
== ROW 80.0 ==
-- COL 80.0.0 --

-- COL 80.0.1 --

-- COL 80.0.2 --

-- COL 80.0.3 --
Commission Proposal 
-- COL 80.0.4 --
EP Mandate 
-- COL 80.0.5 --
Council Mandate 
-- COL 80.0.6 --
Draft Agreement
-- COL 80.0.7 --

-- COL 80.0.8 --

== ROW 80.1 ==
-- COL 80.1.0 --

-- COL 80.1.1 --

-- COL 80.1.2 --

-- COL 80.1.3 --
should also be considered when  assessing the severity of the harm  that an AI system can cause,  
including in relation to the health  and safety of persons.
-- COL 80.1.4 --

 
-- COL 80.1.5 --
should also be considered when  assessing the severity of the harm  that an AI system can cause,  
including in relation to the health  and safety of persons.
-- COL 80.1.6 --

 
-- COL 80.1.7 --

-- COL 80.1.8 --

== ROW 80.2 ==
-- COL 80.2.0 --

-- COL 80.2.1 --

-- COL 80.2.2 --
Recital 28a
-- COL 80.2.3 --

-- COL 80.2.4 --

-- COL 80.2.5 --

-- COL 80.2.6 --

-- COL 80.2.7 --

-- COL 80.2.8 --

== ROW 80.3 ==
-- COL 80.3.0 --
G 
-- COL 80.3.1 --

-- COL 80.3.2 --
38a
-- COL 80.3.3 --

-- COL 80.3.4 --
(28a) The extent of the adverse  impact caused by the AI system on  the fundamental rights protected by  the Charter is of particular  
relevance when classifying an AI  system as high-risk. Those rights  include the right to human dignity,  respect for private and family life,  protection of personal data,  
freedom of expression and  
information, freedom of assembly  and of association, and non 
discrimination, right to education  consumer protection, workers’  rights, rights of persons with  disabilities, gender equality,  
intellectual property rights, right to  an effective remedy and to a fair  trial, right of defence and the  presumption of innocence, right to  good administration. In addition to  those rights, it is important to  highlight that children have specific  rights as enshrined in Article 24 of  the EU Charter and in the United  Nations Convention on the Rights  of the Child (further elaborated in 
-- COL 80.3.5 --

-- COL 80.3.6 --
(28a) The extent of the adverse  impact caused by the AI system on  the fundamental rights protected by  the Charter is of particular  
relevance when classifying an AI  system as high-risk. Those rights  include the right to human dignity,  respect for private and family life,  protection of personal data,  
freedom of expression and  
information, freedom of assembly  and of association, and non 
discrimination, right to education  consumer protection, workers’  rights, rights of persons with  disabilities, gender equality,  
intellectual property rights, right to  an effective remedy and to a fair  trial, right of defence and the  presumption of innocence, right to  good administration. In addition to  those rights, it is important to  highlight that children have specific  rights as enshrined in Article 24 of  the EU Charter and in the United  Nations Convention on the Rights  of the Child (further elaborated in 
-- COL 80.3.7 --
G
-- COL 80.3.8 --
