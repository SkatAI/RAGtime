Amendment 310
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Citation 5 a (new)
Having regard to the opinion of the European Central Bank,

Amendment 311
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Dita Charanzová, Andrus Ansip, Morten
Citation 5 a (new)
Having regard to the opinion of the European Central Bank,

Amendment 312
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Citation 5 b (new)
Having regard to the joint opinion of the European Data Protection Board and the European Data Protection Supervisor,

Amendment 313
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 1
(1) The purpose of this Regulation is to improve the functioning of the internal market by laying down a uniform minimum legal framework in particular for the development, marketing and use of artificial intelligence in conformity with Union values. This Regulation pursues a number of overriding reasons of public interest, such as a high level of protection of health, safety and fundamental rights, as well as the environment, society, rule of law and democracy, economic interests and consumer protection. It also ensures the free movement of AI-based goods and services cross-border, thus preventing Member States from imposing restrictions on the development, marketing and use of AI systems, unless explicitly authorised by this Regulation, or justified by the need to ensure the protection of the rights and freedoms of natural persons, or the ethical principles advocated by this Regulation

Amendment 314
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 1
(1) The purpose of this Regulation is to ensure a high level of protection of fundamental rights, health, safety and the environment, as well as the Union values enshrined in Article 2 of the Treaty on European Union (TEU), from harmful effects of the use of artificial intelligence systems in the Union while enhancing innovation and improving the functioning of the internal market. This Regulation lays down a uniform legal framework in particular for the development, the placing on the market, the putting into service and the use of artificial intelligence in conformity with Union values and it ensures the free movement of AI-based goods and services cross-border, thus preventing Member States from imposing restrictions on the development, marketing and use of AI systems, unless explicitly authorised by this Regulation.

Amendment 315
ECR - European Conservatives and Reformists Group
Vincenzo Sofo, Kosma Złotowski
Recital 1
(1) The purpose of this Regulation is to improve the functioning of the internal market by laying down a uniform legal framework in particular for the development, marketing and use of artificial intelligence in conformity with Union values, the Universal Declaration of Human Rights, the European Convention on Human Rights and the Charter of Fundamental Rights of the EU. This Regulation pursues a number of overriding reasons of public interest, such as a high level of protection of health, safety and fundamental rights, and it ensures the free movement of AI-based goods and services cross-border, thus preventing Member States from imposing restrictions on the development, marketing and use of AI systems, unless explicitly authorised by this Regulation.

Amendment 316
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 1
(1) The purpose of this Regulation is to improve the functioning of the internal market by laying down a uniform legal framework in particular for the development, the placing on the market, the putting into service and the marketing and use of artificial intelligence in conformity with Union values. This Regulation pursues a number of overriding reasons of public interest, such as a high level of protection of health, safety, fundamental rights, the environment and the Union values enshrined in Article 2 of the Treaty on European Union (TEU), and it ensures the free movement of AI-based goods and services cross-border, thus preventing Member States from imposing restrictions on the development, marketing and use of AI systems, unless explicitly authorised by this Regulation.

Amendment 317
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 1
(1) The purpose of this Regulation is to improve the functioning of the internal market by laying down a uniform legal framework in particular for the development, marketing and use of artificial intelligence in conformity with Union values. This Regulation pursues a number of overriding reasons of public interest, such as a high level of protection of health, safety and fundamental rights, and it ensures the free movement of AI-based goods and services cross-border, thus preventing Member States from imposing restrictions on the development, marketing and use of AI systems, unless explicitly authorised by this Regulation and without prejudice to stricter national legislation governing the protection of fundamental rights.

Amendment 318
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 1
(1) The purpose of this Regulation is to improve the functioning of the internal market by laying down a uniform legal framework in particular for the development, marketing and use of artificial intelligence in conformity with Union values. This Regulation pursues a number of overriding reasons of public interest, such as a high level of protection of health, safety, environment and fundamental rights, as well as consumer protection and it ensures the free movement of AI-based goods and services cross-border, thus preventing Member States from imposing restrictions on the development, marketing and use of AI systems, unless explicitly authorised by this Regulation.

Amendment 319
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 1 a (new)
(1 a) The term “artificial intelligence” (AI) refers to systems developed by humans that can, using different techniques and approaches, generate outputs such as content, predictions, recommendations and decisions. The context they are used in is decisive for how much and what kind of influence they can have, and whether they are perceived by an observer as “intelligent”. The term “automated decision-making” (ADM) has been proposed as it could avoid the possible ambiguity of the term AI. ADM involves a user delegating initially a decision, partly or completely, to an entity by way of using a system or a service. That entity then uses automatically executed decision-making models to perform an action on behalf of a user, or to inform the user’s decisions in performing an action

Amendment 320
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 2
(2) Artificial intelligence systems (AI systems) can be easily deployed in multiple sectors of the economy and society, including cross border, and circulate throughout the Union. Certain Member States have already explored the adoption of national rules to ensure that artificial intelligence is safe and is developed and used in compliance with fundamental rights obligations. A consistent and high level of protection throughout the Union should therefore be ensured, while divergences hampering the free circulation of AI systems and related products and services within the internal market should be prevented, by laying down uniform obligations for operators and guaranteeing the uniform protection of overriding reasons of public interest and of rights of persons throughout the internal market based on Article 114 of the Treaty on the Functioning of the European Union (TFEU). To the extent that this Regulation contains specific rules on the protection of individuals with regard to the processing of personal data concerning restrictions of the use of AI systems biometric identification in publicly accessible spaces, it is appropriate to base this Regulation, in as far as those specific rules are concerned, on Article 16 of the TFEU. In light of those specific rules and the recourse to Article 16 TFEU, it is appropriate to consult the European Data Protection Board.

Amendment 321
ECR - European Conservatives and Reformists Group
Vincenzo Sofo, Kosma Złotowski
Recital 2
(2) Artificial intelligence systems (AI systems) can be easily deployed in multiple sectors of the economy and society, including cross border, and circulate throughout the Union. Certain Member States have already explored the adoption of national rules to ensure that artificial intelligence is safe and is developed and used in compliance with fundamental rights obligations. Differing national rules may lead to fragmentation of the internal market and decrease legal certainty for operators that develop or use AI systems. A consistent and high level of protection throughout the Union should therefore be ensured, while divergences hampering the free circulation of AI systems and related products and services within the internal market should be prevented, by laying down uniform obligations for operators and guaranteeing the uniform protection of overriding reasons of public interest and of rights of persons throughout the internal market based on Article 114 of the Treaty on the Functioning of the European Union (TFEU). To the extent that this Regulation contains specific rules on the protection of individuals with regard to the processing of personal data concerning restrictions of the use of AI systems for ‘real-time’ remote biometric identification in publicly accessible spaces for the purpose of law enforcement, it is appropriate to base this Regulation, in as far as those specific rules are concerned, on Article 16 of the TFEU and to align it with relevant EU legislation such as the GDPR and the EUDPR. In light of those specific rules and the recourse to Article 16 TFEU, it is appropriate to consult the European Data Protection Board and to take into consideration the EDPB-EDPS Joint Opinion 5/2021.

Amendment 322
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 2
(2) Artificial intelligence systems (AI systems) can be easily deployed in multiple sectors of the economy and society, including cross border, and circulate throughout the Union. Certain Member States have already explored the adoption of national rules to ensure that artificial intelligence is safe and is developed and used in compliance with fundamental rights obligations. Differing national rules may lead to fragmentation of the internal market and decrease legal certainty for operators that develop or use AI systems. A consistent and high level of protection throughout the Union should therefore be ensured, while divergences hampering the free circulation of AI systems and related products and services within the internal market should be prevented, by laying down uniform obligations for operators and guaranteeing the uniform protection of overriding reasons of public interest and of rights of persons throughout the internal market based on Article 114 of the Treaty on the Functioning of the European Union (TFEU). To the extent that this Regulation contains specific rules on the protection of individuals with regard to the processing of personal data concerning restrictions of the use of AI systems for ‘real-time’ remote biometric identification in publicly accessible and online spaces for the purpose of law enforcement, it is appropriate to base this Regulation, in as far as those specific rules are concerned, on Article 16 of the TFEU. In light of those specific rules and the recourse to Article 16 TFEU, it is appropriate to consult the European Data Protection Board.

Amendment 323
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 2
(2) Artificial intelligence systems (AI systems) can be easily deployed in multiple sectors of the economy and society, including cross border, and circulate throughout the Union. Certain Member States have already explored the adoption of national rules to ensure that artificial intelligence is safe and is developed and used in compliance with fundamental rights obligations. Differing national rules may lead to fragmentation of the internal market and decrease legal certainty for operators that develop or use AI systems. A minimum, consistent and high level of protection throughout the Union should therefore be ensured, while divergences hampering the free circulation of AI systems and related products and services within the internal market should be prevented, by laying down uniform obligations for operators and guaranteeing the uniform protection of overriding reasons of public interest and of rights of persons throughout the internal market based on Article 114 of the Treaty on the Functioning of the European Union (TFEU). To the extent that this Regulation contains specific rules on the protection of individuals with regard to the processing of personal data concerning restrictions of the use of AI systems for ‘real-time’ remote biometric identification in publicly accessible spaces for the purpose of law enforcement, it is appropriate to base this Regulation, in as far as those specific rules are concerned, on Article 16 of the TFEU. In light of those specific rules and the recourse to Article 16 TFEU, it is appropriate to consult the European Data Protection Board.

Amendment 324
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 2
(2) Artificial intelligence systems (AI systems) can be easily deployed in multiple sectors of the economy and society, including cross border, and circulate throughout the Union. Certain Member States have already explored the adoption of national rules to ensure that artificial intelligence is safe and is developed and used in compliance with fundamental rights obligations. Differing national rules may lead to fragmentation of the internal market and decrease legal certainty for operators that develop or use AI systems. A consistent and high level of protection throughout the Union should therefore be ensured, while divergences hampering the free circulation of AI systems and related products and services within the internal market should be prevented, by laying down uniform obligations for operators and guaranteeing the uniform protection of overriding reasons of public interest and of rights of persons throughout the internal market based on Article 114 of the Treaty on the Functioning of the European Union (TFEU). As AI systems rely on the processing of large volumes of data, including personal data, it is appropriate to base this Regulation on Article 16 of the TFEU, which enshrines the right of everyone to the protection of personal data concerning them and provides for the adoption of rules on the protection of individuals with regard to the processing of personal data. In light of the recourse to Article 16 TFEU, it is appropriate to consult the European Data Protection Board.

Amendment 325
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 2 a (new)
(2 a) However, in line with Article 114(2) TFEU, this Regulation does not affect the rights and interests of employed persons. This Regulation should therefore not affect Community law on social policy and national labour law and practice, that is any legal and contractual provision concerning employment conditions, working conditions, including health and safety at work and the relationship between employers and workers, including information, consultation and participation. This Regulation should not affect the exercise of fundamental rights as recognized in the Member States and at Union level, including the right or freedom to strike or to take other action covered by the specific industrial relations systems in Member States, in accordance with national law and/or practice. Nor should it affect concertation practices, the right to negotiate, to conclude and enforce collective agreement or to take collective action in accordance with national law and/or practice. It should in any case not prevent the Commission from proposing specific legislation on the rights and freedoms of workers affected by AI systems.

Amendment 326
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Maria-Manuel Leitão-Marques, Eva Kaili
Recital 2 a (new)
(2 a) The deployment of artificial intelligence applications across sectors will only accelerate in the years to come. The European Union should therefore consider, in separate legislation, the creation of an Artificial Intelligence Adjustment Fund, which could be beneficial for Member States to cover the accustoming of their labour markets to the new conditions arising from the rapid mass introduction of artificial intelligence systems that could affect specific job sectors.

Amendment 327
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 2 a (new)
(2 a) This Regulation should not affect the restrictions, prohibitions or enforcement that apply where an artificial intelligence practice infringes another EU law, including EU acquis on data protection, privacy, or the confidentiality of communications, on non discrimination, consumer protection or on competition.

Amendment 328
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Recital 3 a (new)
(3 a) The development of AI applications might bring down the costs and increase the volume of services available, e.g. health services, public transport, Farming 4.0, making them more affordable to a wider spectrum of society; that AI applications may also result in the rise of unemployment, pressure on social care systems, and an increase of poverty; in accordance with the values enshrined in Article 3 of the Treaty on European Union, there might be a need to adapt the Union AI transformation to socioeconomic capacities, to create adequate social shielding, support education and incentives to create alternative jobs; the establishment of a Union AI Adjustment Fund building upon the experience of The European Globalisation Adjustment Fund (EGF) or the currently developed Just Transition Fund should be considered;

Amendment 329
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Tomas Tobé, Arba Kokalari
Recital 3 a (new)
(3 a) The deployment of artificial intelligence is critical for European competitiveness and in particular for the success of small and medium-sized enterprises in industrial sectors. AI solutions can support European companies to optimise production processes, predict machinery failures and develop more efficient and smart services. The potential of AI can however only fully materialise if European industry, and in particular SMEs, are provided with a permissive legislative framework which avoids any overregulation that would funnel resources away from R&D towards unnecessary compliance costs.

Amendment 330
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 3 a (new)
(3 a) To ensure that Artificial Intelligence leads to socially and environmentally beneficial outcomes, Member States should support such measures through allocating sufficient resources, including public funding, and giving priority access to regulatory sandboxes to projects led by civil society and social stakeholders. Such projects should be based on the principle of interdisciplinary cooperation between AI developers, experts in equality and non-discrimination, accessibility, and consumer, environmental, and digital rights, and the academic community.

Amendment 331
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 3 a (new)
(3 a) In order for Member States to reach the carbon neutrality targets, European companies should seek to utilise all available technological advancements that can assist in realising this goal. AI is a well-developed and ready-to-use technology that can be used to process the ever-growing amount of data created during industrial, environmental, health and other processes. To facilitate investments in AI-based analysis and optimisation solutions, this Regulation should provide a predictable and proportionate environment for low-risk industrial solutions.

Amendment 332
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 3 a (new)
(3 a) To ensure that Artificial Intelligence leads to socially and environmentally beneficial outcomes, Member States should support such measures through allocating sufficient resources, including public funding, and giving priority access to regulatory sandboxes to projects led by civil society and social stakeholders. Such projects should be based on the principle of interdisciplinary cooperation between AI developers, experts in equality and non-discrimination, accessibility, and consumer, environmental, and digital rights, and the academic community.

Amendment 333
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 3 b (new)
(3 b) Furthermore, in order for Member States to fight against climate change, to achieve climate-neutrality and to meet the Sustainable Development Goals (SDGs), the European companies should ensure the sustainable design of AI systems to reduce resource usage and energy consumption, thereby limiting the risks to the environment; AI systems have the potential to automatically provide businesses with detailed insight into their emissions, including value chains, and forecast future emissions, thus helping to adjust and achieve the Union's emission targets.

Amendment 334
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 4
(4) At the same time, depending on the circumstances regarding its specific application and use, artificial intelligence may generate risks and cause harm to public interests and rights that are protected by Union law, whether individual, societal, environmental, economic, or to the rule of law and democracy. Such harm might be material or immaterial. Harm should be understood as injury or damage to the life, health, physical integrity and the property of a natural or legal person, economic harm to individuals, damage to their environment, security and other aspects defined in the scope of New Approach directives, complemented by collective harms such as harm to society, the democratic process and the environment, or going against core ethical principles. Immaterial harms should be understood as meaning harm as a result of which the affected person suffers considerable detriment, an objective and demonstrable impairment of his or her personal interests and an economic loss calculated having regard, for example, to annual average figures of past revenues and other relevant circumstances. Such immaterial harm can therefore consist of psychological harm, reputational harm or change in legal status. Harm can be caused (i) by single events and (ii) through exposure over time to harmful algorithmic practices, as well as (iii) through action distributed among a number of actors where the entity causing the harm is not necessarily that which uses the AI or (iv) through uses of AI which are different than intended for the given system.

Amendment 335
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 4
(4) At the same time, depending on the circumstances regarding its specific application and use, as well as the level of technological development, artificial intelligence may generate risks and cause harm to public interests and rights that are protected by Union law. Such harm might be material or immaterial, including physical, psychological, societal or economic harm.

Amendment 336
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 4
(4) At the same time, depending on the circumstances regarding its specific application and use, artificial intelligence may generate risks and cause harm to public interests and rights that are protected by Union law. Such harm might be material or immaterial and might affect one or more persons, a groups of persons or society as a whole, as well as the environment.

Amendment 337
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 4
(4) At the same time, depending on the circumstances regarding its specific application and use, artificial intelligence may generate risks and cause harm to public and private interests and rights that are protected by Union law. Such harm might be material or immaterial.

Amendment 338
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 4 a (new)
(4 a) In order to ensure the dual green and digital transition, and secure the technological resilience of the EU, to reduce the carbon footprint of artificial intelligence and achieve the objectives of the new European Green Deal, this Regulation should contribute to the promotion of a green and sustainable artificial intelligence and to the consideration of the environmental impact of AI systems throughout their lifecycle. Sustainability should be at the core at the European artificial intelligence framework to guarantee that the development of artificial intelligence is compatible with sustainable development of environmental resources for current and future generations, at all stages of the lifecycle of artificial intelligence products; sustainability of artificial intelligence should encompass sustainable data sources, data centres, resource use, power supplies and infrastructure;

Amendment 339
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Bettina Vollath
Recital 4 a (new)
(4 a) AI available in the Union market or otherwise affecting people in the Union should be designed human centered, so that people can trust that the technology is used in a way that is safe and compliant with the law, including the respect of fundamental rights what requires a shift towards a Human Centered AI Engineering, also in research and education.

Amendment 340
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 4 a (new)
(4 a) The concept of decision autonomy for machines is at its core in conflict with fundamental notions of our societies, such as human dignity, autonomy, and the rights to private life and the protection of personal data. This Regulation should reconcile the potential benefits to society offered by AI with the primacy of humans over machines;

Amendment 341
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 4 b (new)
(4 a) Given the major impact that artificial intelligence can have on society and the need to build trust, it is vital for artificial intelligence systems to respect the principles of fairness, accountability, transparency and accountability, privacy and security, and social benefit.

Amendment 342
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 4 b (new)
(4 b) Despite the high potential of solutions to the environmental and climate crisis offered by artificial intelligence, the design, training and execution of algorithms imply a high energy consumption and, consequently, high levels of carbon emissions. Artificial intelligence technologies and data centres have a high carbon footprint due to increased computational energy consumption, and high energy costs due to the volume of data stored and the amount of heat, electric and electronic waste generated, thus resulting in increased pollution. These environmental and carbon footprints are expected to increase overtime as the volume of data transferred and stored and the increasing development of artificial intelligence applications will continue to grow exponentially in the years to come. It is therefore important to minimise the climate and environmental footprint of artificial intelligence and related technologies and that AI systems and associated machinery are designed sustainably to reduce resource usage and energy consumption, thereby limiting the risks to the environment.

Amendment 343
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 4 c (new)
(4 c) To promote the sustainable development of AI systems and in particular to prioritise the need for sustainable, energy efficient data centres, requirements for efficient heating and cooling of data centres should be consistent with the long-term climate and environmental standards and priorities of the Union and comply with the principle of 'do no significant harm' within the meaning of Article 17 of Regulation (EU) 2020/852 on the establishment of a framework to facilitate sustainable investment, and should be fully decarbonised by January 2050. In this regard, Member States and telecommunications providers should collect and publish information relating to the energy performance and environmental footprint for artificial intelligence technologies and date centres including information on the energy efficiency of algorithms to establish a sustainability indicator for artificial intelligence technologies. A European code of conduct for datacentre energy efficiency can establish key sustainability indicators to measure four basic dimensions of a sustainable data centre, namely, how efficiently it uses energy, the proportion of energy generated from renewable energy sources, the reuse of any waste and heat, and the usage of fresh water.

Amendment 344
EPP - Group of the European Peoples Party (Christian Democrats)
Karlo Ressler
Recital 5
(5) A Union legal framework laying down harmonised rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time meets a high level of protection of public interests, such as health and safety and the protection of fundamental rights, as recognised and protected by Union law. To achieve that objective, rules regulating the placing on the market and putting into service of certain AI systems should be laid down, thus ensuring the smooth functioning of the internal market and allowing those systems to benefit from the principle of free movement of goods and services. These rules should be supportive to new innovative solutions and robust in protecting fundamental rights of all the actors. By laying down those rules, this Regulation supports the objective of the Union of being a global leader in the development of secure, trustworthy and ethical artificial intelligence, as stated by the European Council, and it ensures the protection of ethical principles, as specifically requested. One of the fundamental principles of this legislative framework is that there is no doubt between the protection of fundamental rights or the support of innovation, since this Regulation provides rules that adequately address both of mentioned priorities.

Amendment 345
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 5
(5) A Union legal framework laying down harmonised rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time meets a high level of protection of public interests, such as health and safety, the protection of fundamental rights, as recognised and protected by Union law, the environment and the Union values enshrined in Article 2 TEU. To achieve that objective, rules regulating the development, the placing on the market, and the putting into service and the use of certain AI systems should be laid down, thus ensuring the smooth functioning of the internal market and allowing those systems to benefit from the principle of free movement of goods and services. By laying down those rules, this Regulation supports the objective of the Union of being a global leader in the development of secure, trustworthy and ethical artificial intelligence, as stated by the European Council33, and it ensures the protection of ethical principles, as specifically requested by the European Parliament34.' '33 European Council, Special meeting of the European Council (1 and 2 October 2020) - Conclusions, EUCO 13/20, 2020, p. 6.', '34 European Parliament resolution of 20 October 2020 with recommendations to the Commission on a framework of ethical aspects of artificial intelligence, robotics and related technologies, 2020/2012(INL).

Amendment 346
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 5
(5) A Union legal framework laying down harmonised rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time meets a high level of protection of public interests, such as health and safety and the protection of fundamental rights, as recognised and protected by Union law. To achieve that objective, rules regulating the placing on the market and putting into service of certain AI systems should be laid down, thus ensuring the smooth functioning of the internal market and allowing those systems to benefit from the principle of free movement of goods and services. Furthermore, clear rules supporting the application and design of AI systems should be laid down, thus enabling a European ecosystem of public and private actors creating AI systems in line with European values. By laying down those rules, this Regulation supports the objective of the Union of being a global leader in the development of secure, trustworthy and ethical artificial intelligence, as stated by the European Council33, and it ensures the protection of ethical principles, as specifically requested by the European Parliament34.' '33 European Council, Special meeting of the European Council (1 and 2 October 2020) - Conclusions, EUCO 13/20, 2020, p. 6.', '34 European Parliament resolution of 20 October 2020 with recommendations to the Commission on a framework of ethical aspects of artificial intelligence, robotics and related technologies, 2020/2012(INL).

Amendment 347
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 5
(5) A Union legal framework laying down harmonised rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time guarantees a high level of protection of public interests, such as health and safety and the protection of fundamental rights, as recognised and protected by Union law as well as the environment, society, rule of law and democracy, economic interests and consumer protection. To achieve that objective, rules regulating the placing on the market and putting into service of certain AI systems should be laid down, thus ensuring the smooth functioning of the internal market and allowing those systems to benefit from the principle of free movement of goods and services. By laying down those rules, this Regulation supports the objective of the Union of being a global leader in the development of secure, trustworthy and ethical artificial intelligence, as stated by the European Council33 , and it ensures the protection of ethical principles, as specifically requested by the European Parliament34 .' '33 European Council, Special meeting of the European Council (1 and 2 October 2020) - Conclusions, EUCO 13/20, 2020, p. 6.', '34 European Parliament resolution of 20 October 2020 with recommendations to the Commission on a framework of ethical aspects of artificial intelligence, robotics and related technologies, 2020/2012(INL).

Amendment 348
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Dita Charanzová, Andrus Ansip, Morten
Recital 5
(5) A Union legal framework laying down harmonised rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time meets a high level of protection of public interests, such as health and safety and the protection of fundamental rights, as recognised and protected by Union law. To achieve that objective, rules regulating the placing on the market and putting into service of certain AI systems should be laid down, thus ensuring the smooth functioning of the internal market and allowing those systems to benefit from the principle of free movement of goods and services. By laying down those rules as well as measures in support of innovation with a particular focus on SMEs and start-ups, this Regulation supports the objective of the Union of being a global leader in the development of secure, trustworthy and ethical artificial intelligence, as stated by the European Council33 , and it ensures the protection of ethical principles, as specifically requested by the European Parliament34 .' '33 European Council, Special meeting of the European Council (1 and 2 October 2020) - Conclusions, EUCO 13/20, 2020, p. 6.', '34 European Parliament resolution of 20 October 2020 with recommendations to the Commission on a framework of ethical aspects of artificial intelligence, robotics and related technologies, 2020/2012(INL).

Amendment 349
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Recital 5
(5) A Union legal framework laying down harmonised rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time meets a high level of protection of public interests, such as health and safety and the protection of fundamental rights, as recognised and protected by Union law. To achieve that objective, rules regulating the placing on the market and putting into service of certain AI systems should be laid down, thus ensuring the smooth functioning of the internal market and allowing those systems to benefit from the principle of free movement of goods and services. By laying down those rules, this Regulation supports the objective of the Union of promoting the "AI made in Europe" and being a global leader in the development of secure, trustworthy and ethical artificial intelligence, as stated by the European Council33 , and it ensures the protection of ethical principles, as specifically requested by the European Parliament34 .' '33 European Council, Special meeting of the European Council (1 and 2 October 2020) - Conclusions, EUCO 13/20, 2020, p. 6.', '34 European Parliament resolution of 20 October 2020 with recommendations to the Commission on a framework of ethical aspects of artificial intelligence, robotics and related technologies, 2020/2012(INL).

Amendment 350
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Recital 5
(5) A Union legal framework laying down harmonised rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time meets a high level of protection of public interests, such as the protection of fundamental rights, health and safety, as recognised and protected by Union law. To achieve that objective, rules regulating the development, the placing on the market, putting into service and the use of certain AI systems should be laid down, thus ensuring the smooth functioning of the internal market and allowing those systems to benefit from the principle of free movement of goods and services. By laying down those rules, this Regulation supports the objective of the Union of being a global leader in the development of secure, trustworthy and ethical artificial intelligence, as stated by the European Council33 , and it ensures the protection of ethical principles, as specifically requested by the European Parliament34 .' '33 European Council, Special meeting of the European Council (1 and 2 October 2020) - Conclusions, EUCO 13/20, 2020, p. 6.', '34 European Parliament resolution of 20 October 2020 with recommendations to the Commission on a framework of ethical aspects of artificial intelligence, robotics and related technologies, 2020/2012(INL).

Amendment 351
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 5
(5) A Union legal framework laying down harmonised rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time meets a high level of protection of public interests, such as health and the environment and the protection of fundamental rights and values, as recognised and protected by Union law. To achieve that objective, rules regulating the placing on the market and putting into service of certain AI systems should be laid down, thus ensuring the smooth functioning of the internal market and allowing those systems to benefit from the principle of free movement of goods and services. By laying down those rules, this Regulation supports the objective of the Union of being a global leader in the development of secure, trustworthy and ethical artificial intelligence, as stated by the European Council33 , and it ensures the protection of ethical principles, as specifically requested by the European Parliament34 .' '33 European Council, Special meeting of the European Council (1 and 2 October 2020) - Conclusions, EUCO 13/20, 2020, p. 6.', '34 European Parliament resolution of 20 October 2020 with recommendations to the Commission on a framework of ethical aspects of artificial intelligence, robotics and related technologies, 2020/2012(INL).

Amendment 352
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 5 a (new)
(5) A Union legal framework laying down harmonised rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time meets a high level of protection of public and private interests, such as health and safety and the protection of fundamental rights, as recognised and protected by Union law. To achieve that objective, rules regulating the placing on the market and putting into service of certain AI systems should be laid down, thus ensuring the smooth functioning of the internal market and allowing those systems to benefit from the principle of free movement of goods and services. By laying down those rules, this Regulation supports the objective of the Union of being a global leader in the development of secure, trustworthy and ethical artificial intelligence, as stated by the European Council33 , and it ensures the protection of ethical principles, as specifically requested by the European Parliament34 .' '33 European Council, Special meeting of the European Council (1 and 2 October 2020) - Conclusions, EUCO 13/20, 2020, p. 6.', '34 European Parliament resolution of 20 October 2020 with recommendations to the Commission on a framework of ethical aspects of artificial intelligence, robotics and related technologies, 2020/2012(INL).

Amendment 353
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 5 a (new)
(5 a) Furthermore, in order to foster the development of artificial intelligence in line with Union values, the Union needs to address the main gaps and barriers blocking the potential of the digital transformation including the shortage of digitally skilled workers, cybersecurity concerns, lack of investment and access to investment, and existing and potential gaps between large companies, SME’s and start-ups. Special attention should be paid to ensuring that the benefits of AI and innovation in new technologies are felt across all regions of the Union and that sufficient investment and resources are provided especially to those regions that may be lagging behind in some digital indicators.

Amendment 354
ECR - European Conservatives and Reformists Group
Vincenzo Sofo, Kosma Złotowski
Recital 5 a (new)
(5 a) The regulatory framework addressing artificial intelligence should be without prejudice to existing and future Union laws concerning data protection, privacy, and protection of fundamental rights. In this regard, requirements of this Regulation should be consistent with the aims and objectives of, among others, the GDPR and the EUDPR. Where this Regulation addresses automated processing within the context of article 22 of the GDPR, the requirements contained in that article should continue to apply, ensuring the highest levels of protection for European citizens over the use of their personal data.

Amendment 355
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Recital 5 a (new)
(5 a) The Union legal framework for AI should respect existing sector specific legislations and create legal certainty by avoiding duplication and additional administrative burden;

Amendment 356
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 5 b (new)
(5 b) To ensure the development of secure, trustworthy and ethical AI, the European Commission established the High-Level Expert Group on Artificial Intelligence. In formulating both Ethics guidelines for Trustworthy AI and a corresponding Assessment List for Trustworthy Artificial Intelligence, this independent group solidified the foundational ambition for ‘Trustworthy AI’. As noted by the group, Trustworthiness is a prerequisite for people, societies and companies to develop, deploy and use AI systems. Without AI systems - and the human beings behind them - being demonstrably worthy of trust, serious and unwanted consequences may ensue and the uptake of AI might be hindered, preventing the realisation of the potentially vast social and economic benefits that trustworthy AI systems can bring. This approach should be seen as the basis of a European approach to both ensure and scale AI that is innovative and ethical.

Amendment 357
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 6
(6) The notion of AI system should be clearly defined to ensure legal certainty, while providing the flexibility to accommodate future technological developments. This definition should be in line with definitions that have found international acceptance. Moreover, it should be based on the key functional characteristics of artificial intelligence distinguishing it from more classic software systems and modelling approaches such as logistic regression and other techniques that are similarly transparent, explainable and interpretable. For the purposes of this Regulation, the definition should be based on the key functional characteristics of the AI system, in particular its ability, for a given set of human-defined objectives, to make predictions, recommendations, or decisions that influence real or virtual environments, whereby it uses machine and/or human-based data and inputs to (i) perceive real and/or virtual environments; (ii) abstract these perceptions into models through analysis in an automated manner (e.g. with machine learning), or manually; and (iii) use model inference to formulate options for outcomes. AI systems are designed to operate with varying levels of autonomy and can be used on a stand-alone software system, integrated into a physical product (embedded), used to serve the functionality of a physical product without being integrated therein (non-embedded) or used as a subsystem of a software/physical/hybrid system of systems. If an AI system is used as a subsystem of a system of systems, then all parts including their interfaces to other parts of the system of systems that would be obsolete if the AI functionality were turned off or removed are essential parts of the AI system thus fall directly under this regulation. Any parts of the system of systems to which this does not hold true are not covered by this regulation and the obligations listed in this regulation do not apply to them. This is to ensure that the integration of AI systems into existing systems is not blocked by this regulation.

Amendment 358
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Dita Charanzová, Andrus Ansip, Morten Løkkegaard, Vlad-
Recital 6
(6) The notion of AI system should be clearly defined to ensure legal certainty, while providing the flexibility to accommodate future technological developments. Therefore, the term AI system should be defined in line with internationally accepted definitions. The definition should be based on the key functional characteristics of AI systems, in particular the ability, for a given set of human-defined objectives, to generate outputs such as content, predictions, recommendations, or decisions which influence their physical or digital environment. AI systems can be designed to operate with varying levels of autonomy and be used on a stand-alone basis or as a component of a product, irrespective of whether the system is physically integrated into the product (embedded) or serve the functionality of the product without being integrated therein (non-embedded). The definition of AI system should be complemented by a list of specific techniques and approaches used for its development, which should be kept up-to-date in the light of market and technological developments through the adoption of delegated acts by the Commission to amend that list. In order to ensure alignment of definitions on an international level, the European Commission should engage in a dialogue with international organisations such as the Organisation for Economic Cooperation and Development (OECD), should their definitions of the term ‘AI system’ be adjusted.

Amendment 359
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Recital 6
(6) The notion of AI system should be clearly defined to ensure legal certainty, while providing the flexibility to accommodate future technological developments. The definition should be based on the key functional characteristics of the software, in particular the ability to perceive, reason and act on machine and/or human-based inputs, to generate outputs such as content, hypotheses, predictions, recommendations, or decisions which influence the environment with which the system interacts, be it in a physical or digital dimension. AI systems can be designed to operate with varying levels of autonomy and be used on a stand-alone basis or as a component of a product, irrespective of whether the system is physically integrated into the product (embedded) or serve the functionality of the product without being integrated therein (non-embedded).

Amendment 360
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 6
(6) The notion of AI system should be clearly defined to ensure legal certainty, while providing the flexibility to accommodate future technological developments. The definition should be based on the key functional characteristics of the software, in particular the ability to generate outputs such as content, predictions, recommendations, or decisions which influence the environment with which the system interacts, be it in a physical or digital dimension. AI systems can be designed to operate with varying levels of autonomy and be used on a stand-alone basis or as a component of a product, irrespective of whether the system is physically integrated into the product (embedded) or serve the functionality of the product without being integrated therein (non-embedded). AI systems can be developed through various techniques using learning, reasoning or modelling, such as: machine learning approaches, including supervised, unsupervised and reinforcement learning, using a wide variety of methods including deep learning; logic- and knowledge-based approaches, including knowledge representation, inductive (logic) programming, knowledge bases, inference and deductive engines, (symbolic) reasoning and expert systems; statistical approaches, Bayesian estimation, search and optimization methods.

Amendment 361
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 6
(6) The notion of AI system should be clearly defined to ensure legal certainty, while providing the flexibility to accommodate future technological developments. The definition should be based on the key functional characteristics of the software, in particular the ability, for a given set of objectives or parameters which have human control at their origin, to generate outputs such as content, predictions, recommendations, or decisions which influence the environment with which the system interacts, be it in a physical or digital dimension. AI systems can be designed to operate with varying levels of autonomy and be used on a stand-alone basis or as a component of a product, irrespective of whether the system is physically integrated into the product (embedded) or serve the functionality of the product without being integrated therein (non-embedded). The definition of AI system should be complemented by a list of specific techniques and approaches used for its development, which should be kept up-to-date in the light of market and technological developments through the adoption of delegated acts by the Commission to amend that list. These delegated acts should consist only of additions to the list of techniques used.

Amendment 362
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 6
(6) The notion of AI system should be clearly defined to ensure legal certainty, while providing the flexibility to accommodate future technological developments. The definition should be based on the key functional characteristics of the system, in particular the ability, for a given set of objectives, to generate outputs such as content, predictions, recommendations, or decisions. AI systems can be designed to operate with varying levels of autonomy and be used on a stand-alone basis or as a component of a product, irrespective of whether the system is physically integrated into the product (embedded) or serve the functionality of the product without being integrated therein (non-embedded). The definition of AI system should be complemented by a list of specific techniques and approaches used for its development, which should be kept up-to-date in the light of market and technological developments through the adoption of delegated acts by the Commission to amend that list.

Amendment 363
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Recital 6
(6) The notion of AI system should be clearly defined to ensure legal certainty, while providing the flexibility to accommodate existing harmless applications and future technological developments. The definition should be based on the key functional characteristics of the software, in particular the ability, for a given set of human-defined objectives, to generate outputs such as content, predictions, recommendations, or decisions which influence the environment with which the system interacts, be it in a physical or digital dimension. AI systems can be designed to operate with varying levels of autonomy and be used on a stand-alone basis or as a component of a product, irrespective of whether the system is physically integrated into the product (embedded) or serve the functionality of the product without being integrated therein (non-embedded). The definition of AI system should be complemented by a list of specific techniques and approaches used for its development, which should be kept up-to-date in the light of market and technological developments through the adoption of delegated acts by the Commission to amend that list.

Amendment 364
EPP - Group of the European Peoples Party (Christian Democrats)
Karlo Ressler
Recital 6
(6) The notion of AI system should be clearly defined to ensure legal certainty, while providing the flexibility to accommodate future technological developments. The definition should be aligned with internationally accepted approach. AI systems can be designed to operate with varying levels of autonomy and be used on a stand-alone basis or as a component of a product, irrespective of whether the system is physically integrated into the product (embedded) or serve the functionality of the product without being integrated therein (non-embedded). The definition of AI system should be complemented by a list of specific techniques and approaches used for its development, which should be kept up-to-date in the light of market and technological developments through the adoption of delegated acts by the Commission to amend that list. The Commission should engage in dialogue with key international organizations, so that the common international standards could be achieved to the highest possible extent.

Amendment 365
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 6 a (new)
(6 a) Defining AI systems is an ongoing process that should take into account the context in which AI operates, keep pace with societal developments in this field and not lose sight of the link between the ecosystem of excellence and the ecosystem of trust. The definition of AI system should be complemented by a list of specific techniques and approaches used for its development, which should be kept up-to-date in the light of market and technological developments through the adoption of delegated acts by the Commission to amend that list. In the drafting process of these delegated acts, the Commission shall insure the input of all relevant stakeholders including the technical experts and developers of AI systems. This consultation can take place through existing bodies such as the High Level Expert Group on AI or a newly established similar advisory body that is closely included in the work of the European Artificial Intelligence Board. Should the definition of ‘AI system’ from the OECD be adjusted in the coming years, the European Commission should engage in dialogue with these organisations to ensure alignment between the two definitions. Should the AI Act still be undergoing legislative procedure, the co-legislators should consider these latest developments during the legislative process, so as to ensure alignment, legal clarity and broad international acceptance of the AI Act Definition of ‘AI Systems’.

Amendment 366
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 6 b (new)
(6 b) Taking into account the work of International Standardisation Organisations, it is important to highlight the differences as well as the connection between Automation, Heteronomy and Autonomy. Experts speak of an automated system with different levels of automation instead of levels of autonomy. Autonomy is understood as the highest level of automation. An autonomous AI system would be capable to change its scope or its goals independently. However, today's AI technologies do not allow full autonomy yet and are not self-governing. Instead, they operate based on algorithms and otherwise obey the commands of operators. A fully autonomous AI system would be a genuine General or Super AI. Despite these restrictions, this Regulation will use the term “autonomy” as it is a key element of international accepted definitions.

Amendment 367
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 7
(7) The notion of biometric data used in this Regulation is in line with and should be interpreted consistently with the notion of biometric data as defined in Article 4(14) of Regulation (EU) 2016/679 of the European Parliament and of the Council35 , Article 3(18) of Regulation (EU) 2018/1725 of the European Parliament and of the Council36 and Article 3(13) of Directive (EU) 2016/680 of the European Parliament and of the Council37 . An additional definition has been added for ‘biometrics-based data’ to cover physical, physiological or behavioural data that may not meet the criteria to be defined as biometric data (i.e. would not allow or confirm the unique identification of a natural person) but which may be used for purposes such as emotion recognition or biometric categorisation. The addition of this definition does not narrow the scope of, nor exclude anything from, the definition of biometric data, but rather provides for a comprehensive scope for additional forms of data which may be used for purposes such as biometric categorisation but which would not allow or confirm unique identification.' '35 Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation) (OJ L 119, 4.5.2016, p. 1).', '36 Regulation (EU) 2018/1725 of the European Parliament and of the Council of 23 October 2018 on the protection of natural persons with regard to the processing of personal data by the Union institutions, bodies, offices and agencies and on the free movement of such data, and repealing Regulation (EC) No 45/2001 and Decision No 1247/2002/EC (OJ L 295, 21.11.2018, p. 39)', '37 Directive (EU) 2016/680 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data by competent authorities for the purposes of the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, and on the free movement of such data, and repealing Council Framework Decision 2008/977/JHA (Law Enforcement Directive) (OJ L 119, 4.5.2016, p. 89).

Amendment 368
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 7
(7) The notion of biometric data used in this Regulation is in line with and should be interpreted consistently with the notion of biometric data as defined in Article 4(14) of Regulation (EU) 2016/679 of the European Parliament and of the Council35 , Article 3(18) of Regulation (EU) 2018/1725 of the European Parliament and of the Council36 and Article 3(13) of Directive (EU) 2016/680 of the European Parliament and of the Council37 . An additional definition has been added for ‘biometrics-based data’ to cover physical, physiological or behavioural data that may not meet the criteria to be defined as biometric data (i.e. would not allow or confirm the unique identification of a natural person) but which may be used for purposes such as emotion recognition or biometric categorisation. The addition of this definition does not narrow the scope of, nor exclude anything from, the definition of biometric data, but rather provides for a comprehensive scope for additional forms of data which may be used for purposes such as biometric categorisation but which would not allow or confirm unique identification.' '35 Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation) (OJ L 119, 4.5.2016, p. 1).', '36 Regulation (EU) 2018/1725 of the European Parliament and of the Council of 23 October 2018 on the protection of natural persons with regard to the processing of personal data by the Union institutions, bodies, offices and agencies and on the free movement of such data, and repealing Regulation (EC) No 45/2001 and Decision No 1247/2002/EC (OJ L 295, 21.11.2018, p. 39)', '37 Directive (EU) 2016/680 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data by competent authorities for the purposes of the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, and on the free movement of such data, and repealing Council Framework Decision 2008/977/JHA (Law Enforcement Directive) (OJ L 119, 4.5.2016, p. 89).

Amendment 369
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 7
(7) The notion of biometric data used in this Regulation is the same as that defined in Article 4(14) of Regulation (EU) 2016/679 of the European Parliament and of the Council35.' '35 Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation) (OJ L 119, 4.5.2016, p. 1).

Amendment 370
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 7
(7) The notion of biometric data used in this Regulation is in line with and should be interpreted consistently with the notion of biometric data as defined in Article 4(14) of Regulation (EU) 2016/679 of the European Parliament and of the Council35 , Article 3(18) of Regulation (EU) 2018/1725 of the European Parliament and of the Council36 and Article 3(13) of Directive (EU) 2016/680 of the European Parliament and of the Council37 . The notion of “biometrics-based data” is broader, covering situations where the data in question may not, of itself, confirm the unique identification of an individual.' '35 Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation) (OJ L 119, 4.5.2016, p. 1).', '36 Regulation (EU) 2018/1725 of the European Parliament and of the Council of 23 October 2018 on the protection of natural persons with regard to the processing of personal data by the Union institutions, bodies, offices and agencies and on the free movement of such data, and repealing Regulation (EC) No 45/2001 and Decision No 1247/2002/EC (OJ L 295, 21.11.2018, p. 39)', '37 Directive (EU) 2016/680 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data by competent authorities for the purposes of the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, and on the free movement of such data, and repealing Council Framework Decision 2008/977/JHA (Law Enforcement Directive) (OJ L 119, 4.5.2016, p. 89).

Amendment 371
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 8
(8) The notion of biometric identification system as used in this Regulation should be defined functionally, as an AI system performing automated recognition of physical, physiological, behavioural, and psychological human features, for the purpose of identification of natural persons through the comparison of a person’s biometric data with the biometric data contained in a reference database, irrespectively of the particular technology, processes or types of biometric data used.

Amendment 372
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Recital 8
(8) The notion of remote biometric identification system as used in this Regulation should be defined functionally, as an AI system intended for the identification of natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database, and without prior knowledge whether the targeted person will be present and can be identified, irrespectively of the particular technology, processes or types of biometric data used.

Amendment 373
Greens/EFA - Group of the Greens/European Free Alliance
Patrick Breyer
Recital 8
(8) The notion of remote biometric identification system as used in this Regulation should be defined functionally, as an AI system intended for the identification of natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database, and without prior knowledge whether the targeted person will be present and can be identified, irrespectively of the particular technology, processes or types of biometric data used. Because remote biometric identification relates to how a system is designed and installed, and not solely to whether or not data subjects have consented, this definition applies even when warning notices are placed in the location that is under the surveillance of the remote biometric identification system, and is not de facto annulled by pre-enrolment.

Amendment 374
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,
Recital 8
(8) The notion of remote biometric identification system as used in this Regulation should be defined functionally, as an AI system intended for the identification of natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database, and without prior knowledge whether the targeted person will be present and can be identified, irrespectively of the particular technology, processes or types of biometric data used. Considering their different characteristics and manners in which they are used, as well as the different risks involved, a distinction should be made between ‘real-time’ and ‘post’ remote biometric identification systems. In the case of ‘real-time’ systems, the capturing of the biometric data, the comparison and the identification occur all instantaneously, near-instantaneously or in any event without a significant delay. In this regard, there should be no scope for circumventing the rules of this Regulation on the ‘real-time’ use of the AI systems in question by providing for minor delays. ‘Real-time’ systems involve the use of ‘live’ or ‘near-‘live’ material, such as video footage, generated by a camera or other device with similar functionality. In the case of ‘post’ systems, in contrast, the biometric data have already been captured and the comparison and identification occur only after a significant delay. This involves material, such as pictures or video footage generated by closed circuit television cameras or private devices, which has been generated before the use of the system in respect of the natural persons concerned. The notion of remote biometric identification system shall not include verification or authentification systems whose sole purpose is to confirm that a specific natural person is the person he or she claims to be, and systems that are used to confirm the identity of a natural person for the sole purpose of having access to a service, a device or premises.

Amendment 375
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 8
(8) The notion of remote biometric identification system as used in this Regulation should be defined functionally, as an AI system intended for the identification of natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database, and without prior knowledge whether the targeted person will be present and can be identified, irrespectively of the particular technology, processes or types of biometric data used. Considering their different characteristics and manners in which they are used, as well as the different risks involved, a distinction should be made between ‘real-time’ and ‘post’ remote biometric identification systems. In the case of ‘real-time’ systems, the capturing of the biometric data, the comparison and the identification occur all instantaneously, near-instantaneously or in any event without a significant delay. In this regard, there should be no scope for circumventing the rules of this Regulation on the ‘real-time’ use of the AI systems in question by providing for minor delays. ‘Real-time’ systems involve the use of ‘live’ or ‘near-‘live’ material, such as video footage, generated by a camera or other device with similar functionality. In the case of ‘post’ systems, in contrast, the biometric data have already been captured and the comparison and identification occur only after a significant delay. This involves material, such as pictures or video footage generated by closed circuit television cameras or private devices, which has been generated before the use of the system in respect of the natural persons concerned. The notion of remote biometric identification system shall not include authentification and verification systems whose purpose is to confirm, based on prior consent, that a specific natural person is the person he or she claims to be or to confirm the identity of a natural person for the purpose of having access to a service, a device or premises.

Amendment 376
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Recital 8
(8) The notion of biometric identification system, including remote biometric identification system as used in this Regulation, should be defined functionally, as an AI system intended for the identification of natural persons including at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference data repository, excluding verification/ authentication systems whose sole purpose is to confirm that a specific natural person is the person he or she claims to be, and systems that are used to confirm the identity of a natural person for the sole purpose of having access to a service, a device or premises, and without prior knowledge whether the targeted person will be present and can be identified, irrespectively of the particular technology, processes or types of biometric data used. Considering their different characteristics and manners in which they are used, as well as the different risks involved, a distinction should be made between ‘real-time’ and ‘post’ biometric identification systems. In the case of ‘real-time’ systems, the capturing of the biometric data, the comparison and the identification occur all instantaneously, near-instantaneously or in any event without a significant delay. In this regard, there should be no scope for circumventing the rules of this Regulation on the ‘real-time’ use of the AI systems in question by providing for minor delays. ‘Real-time’ systems involve the use of ‘live’ or ‘near-‘live’ material, such as video footage, generated by a camera or other device with similar functionality. In the case of ‘post’ systems, in contrast, the biometric data have already been captured and the comparison and identification occur only after a significant delay. This involves material, such as pictures or video footage generated by closed circuit television cameras or private devices, which has been generated before the use of the system in respect of the natural persons concerned.

Amendment 377
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Patryk Jaki, Eugen Jurzyca, Adam Bielan
Recital 8
(8) The notion of remote biometric identification system as used in this Regulation should be defined functionally, as an AI system intended for the identification of natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a database data repository, excluding verification/authentication systems whose sole purpose is to confirm that a specific natural person is the person he or she claims to be, and systems that are used to confirm the identity of a natural person for the sole purpose of having access to a service, a device or premises, and without prior knowledge whether the targeted person will be present and can be identified, irrespectively of the particular technology, processes or types of biometric data used. Considering their different characteristics and manners in which they are used, as well as the different risks involved, a distinction should be made between ‘real-time’ and ‘post’ remote biometric identification systems. In the case of ‘real-time’ systems, the capturing of the biometric data, the comparison and the identification occur all instantaneously, near-instantaneously or in any event without a significant delay. In this regard, there should be no scope for circumventing the rules of this Regulation on the ‘real-time’ use of the AI systems in question by providing for minor delays. ‘Real-time’ systems involve the use of ‘live’ or ‘near-‘live’ material, such as video footage, generated by a camera or other device with similar functionality. In the case of ‘post’ systems, in contrast, the biometric data have already been captured and the comparison and identification occur only after a significant delay. This involves material, such as pictures or video footage generated by closed circuit television cameras or private devices, which has been generated before the use of the system in respect of the natural persons concerned.

Amendment 378
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 8
(8) The notion of remote biometric identification system as used in this Regulation should be defined functionally, as an AI system intended for the identification of natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database, irrespectively of the particular technology, processes or types of biometric data used. The notion of ‘at a distance’ in Remote Biometric Identification (RBI) means the use of systems as described in Article 3(36), at a distance great enough that the system has the capacity to scan multiple persons in its field of view (or the equivalent generalised scanning of online / virtual spaces), which would mean that the identification could happen without one or more of the data subjects’ knowledge. Because RBI relates to how a system is designed and installed, and not solely to whether or not data subjects have consented, this definition applies even when warning notices are placed in the location that is under the surveillance of the RBI system, and is not de facto annulled by pre-enrolment.

Amendment 379
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Recital 8
(8) The notion of remote biometric identification system as used in this Regulation should be defined functionally, as an AI system intended for the identification of natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference data repository, and without prior knowledge whether the targeted person will be present and can be identified, irrespectively of the particular technology, processes or types of biometric data used. Considering their different characteristics and manners in which they are used, as well as the different risks involved, a distinction should be made between ‘real-time’ and ‘post’ remote biometric identification systems. In the case of ‘real-time’ systems, the capturing of the biometric data, the comparison and the identification occur all instantaneously, near-instantaneously or in any event without a significant delay. In this regard, there should be no scope for circumventing the rules of this Regulation on the ‘real-time’ use of the AI systems in question by providing for minor delays. ‘Real-time’ systems involve the use of ‘live’ or ‘near-‘live’ material, such as video footage, generated by a camera or other device with similar functionality. In the case of ‘post’ systems, in contrast, the biometric data have already been captured and the comparison and identification occur only after a significant delay. This involves material, such as pictures or video footage generated by closed circuit television cameras or private devices, which has been generated before the use of the system in respect of the natural persons concerned.

Amendment 380
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 9
(9) For the purposes of this Regulation the notion of publicly accessible physical or virtual space should be understood as referring to any physical or virtual place that is accessible to the public, on a temporary or permanent basis, irrespective of whether the place in question is privately or publicly owned. Therefore, the notion covers places that are both private in nature, used for private purposes only, accessed completely voluntarily and normally not freely accessible for third parties, including law enforcement authorities, unless those parties have been specifically invited or authorised, such as homes and private clubs. However, the mere fact that certain conditions for accessing a particular space may apply, such as admission tickets or age restrictions, does not mean that the space is not publicly accessible within the meaning of this Regulation. Consequently, in addition to public spaces such as streets, relevant parts of government buildings and most transport infrastructure, spaces such as cinemas, theatres, sports grounds, virtual gaming environments, schools, universities, hospitals, amusement parks, festivals, shops and shopping centres, offices, warehouses and factories are normally also publicly accessible. Whether a given space is accessible to the public should however be determined on a case-by-case basis, having regard to the specificities of the individual situation at hand.

Amendment 381
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 9
(9) For the purposes of this Regulation the notion of publicly accessible space should be understood as referring to any physical place that is accessible to the public, irrespective of whether the place in question is privately or publicly owned. Therefore, the notion does not cover places that are private in nature and normally not freely accessible for third parties, including law enforcement authorities, unless those parties have been specifically invited or authorised, such as homes, private clubs, offices, warehouses and factories. Online spaces are not covered either, as they are not physical spaces. However, the mere fact that certain conditions for accessing a particular space may apply, such as admission tickets or age restrictions, does not mean that the space is not publicly accessible within the meaning of this Regulation. Consequently, in addition to public spaces such as streets, relevant parts of government buildings and most transport infrastructure, spaces such as cinemas, theatres, shops and shopping centres are normally also publicly accessible. Whether a given space is accessible to the public should however be determined on a case-by-case basis by the competent judicial or administrative authority, having regard to the specificities of the individual situation at hand.

Amendment 382
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 9
(9) For the purposes of this Regulation the notion of publicly accessible space should be understood as referring to any physical place that is accessible to the public, irrespective of whether the place in question is privately or publicly owned. Therefore, the notion does not cover places that are private in nature and normally not freely accessible for third parties, including law enforcement authorities, unless those parties have been specifically invited or authorised, such as homes, private clubs, offices, warehouses and factories. However, the mere fact that certain conditions for accessing a particular space may apply, such as admission tickets or age restrictions, does not mean that the space is not publicly accessible within the meaning of this Regulation. Consequently, in addition to public spaces such as streets, relevant parts of government buildings and most transport infrastructure, spaces such as cinemas, theatres, shops and shopping centres are normally also publicly accessible. Whether a given space is accessible to the public should however be determined on a case-by-case basis, having regard to the specificities of the individual situation at hand.

Amendment 383
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Recital 9
(9) For the purposes of this Regulation the notion of publicly accessible space should be understood as referring to any physical place that is accessible to the public, irrespective of whether the place in question is privately or publicly owned. Therefore, the notion does not cover places that are private in nature and normally not freely accessible for third parties, including law enforcement authorities, unless those parties have been specifically invited or authorised, such as homes, private clubs, offices, warehouses and factories. However, the mere fact that certain conditions for accessing a particular space may apply, such as admission tickets or age restrictions, does not mean that the space is not publicly accessible within the meaning of this Regulation. Consequently, in addition to public spaces such as streets, relevant parts of government buildings and most transport infrastructure, spaces such as cinemas, theatres, shops and shopping centres are normally also publicly accessible. Whether a given space is accessible to the public should however be determined on a case-by-case basis, having regard to the specificities of the individual situation at hand.

Amendment 384
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 9
(9) For the purposes of this Regulation the notion of publicly accessible space should be understood as referring to any physical place that is accessible to the public, irrespective of whether the place in question is privately or publicly owned. Therefore, the notion does not cover places that are private in nature and normally not freely accessible for third parties, including law enforcement authorities, unless those parties have been specifically invited or authorised, such as homes, private clubs, offices, warehouses and factories. However, the mere fact that certain conditions for accessing a particular space may apply, such as admission tickets or age restrictions, does not mean that the space is not publicly accessible within the meaning of this Regulation. Consequently, in addition to online and public spaces such as streets, relevant parts of government buildings and most transport infrastructure, spaces such as cinemas, theatres, shops and shopping centres are normally also publicly accessible. Whether a given space is accessible to the public should however be determined on a case-by-case basis, having regard to the specificities of the individual situation at hand.

Amendment 385
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 9 a (new)
(9 a) In order to ensure the rights of individuals and groups, and the growth of trustworthy AI, certain principles should be guaranteed across all AI systems, such as transparency, the right to an explanation and the right to object to a decision. This requires that discrimination, and detrimental power and information imbalances be prevented, control and oversight guaranteed, and that compliance is demonstrable and subject to ongoing monitoring. Decision-making by, or supported by, AI systems, should be subject to specific transparency rules, as regards the logic and parameters on which decisions are made.

Amendment 386
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 9 b (new)
(9 b) Requirements on transparency and on the explicability of AI decision-making should contribute to countering the deterrent effects of digital asymmetry, power and information imbalance, and so-called ‘dark patterns’ targeting individuals and their informed consent.

Amendment 387
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 10
(10) In order to ensure a level playing field and an effective protection of rights and freedoms of individuals across the Union, the rules established by this Regulation should apply to providers of AI systems in a non-discriminatory manner, irrespective of whether they are established within the Union or in a third country, and to deployers of AI systems established within the Union. This Regulation and the rules it establishes should take into account different development and business models and the fact that standard implementations, or Free and Open Source software development and licensing models might entail less knowledge about and little to no control over further use, modification, and deployment within an AI system.

Amendment 388
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Recital 10
(10) In order to ensure a level playing field and an effective protection of rights and freedoms of individuals across the Union and on international level, the rules established by this Regulation should apply to providers of AI systems in a non-discriminatory manner, irrespective of whether they are established within the Union or in a third country, and to users of AI systems established within the Union.

Amendment 389
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte
Recital 11
(11) In light of their digital nature, certain AI systems should fall within the scope of this Regulation even when they are neither placed on the market, nor put into service, nor used in the Union. This is the case for example of an operator established in the Union that contracts certain services to an operator established outside the Union in relation to an activity to be performed by an AI system that would qualify as high-risk and whose effects impact natural persons located in the Union. In those circumstances, the AI system used by the operator outside the Union could process data lawfully collected in and transferred from the Union, and provide to the contracting operator in the Union the output of that AI system resulting from that processing, without that AI system being placed on the market, put into service or used in the Union. To prevent the circumvention of this Regulation and to ensure an effective protection of natural persons located in the Union, this Regulation should also apply to providers and users of AI systems that are established in a third country, to the extent the output produced by those systems is used in the Union.

Amendment 390
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 11
(11) In light of their digital nature, certain AI systems should fall within the scope of this Regulation even when they are neither placed on the market, nor put into service, nor used in the Union. This is the case for example of an operator established in the Union that contracts certain services to an operator established outside the Union in relation to an activity to be performed by an AI system that would qualify as high-risk and whose effects impact natural persons located in the Union. In those circumstances, the AI system used by the operator outside the Union could process data lawfully collected in and transferred from the Union, and provide to the contracting operator in the Union the output of that AI system resulting from that processing, without that AI system being placed on the market, put into service or used in the Union. To prevent the circumvention of this Regulation and to ensure an effective protection of natural persons located in the Union, this Regulation should also apply to providers and users of AI systems that are established in a third country, to the extent the output produced by those systems is used in the Union.

Amendment 391
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 11
(11) In light of their digital nature, certain AI systems should fall within the scope of this Regulation even when they are neither placed on the market, nor put into service, nor used in the Union. This is the case for example of an operator established in the Union that contracts certain services to an operator established outside the Union in relation to an activity to be performed by an AI system whose effects impact natural persons located in the Union. In those circumstances, the AI system used by the operator outside the Union could process data lawfully collected in and transferred from the Union, and provide to the contracting operator in the Union the output of that AI system resulting from that processing, without that AI system being placed on the market, put into service or used in the Union. To prevent the circumvention of this Regulation and to ensure an effective protection of natural persons located in the Union, this Regulation should also apply to providers and users of AI systems that are established in a third country, to the extent the output produced by those systems is used in the Union or it affects natural persons within the Union.

Amendment 392
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 11
(11) In light of their digital nature, certain AI systems should fall within the scope of this Regulation even when they are neither placed on the market, nor put into service, nor used in the Union. This is the case for example of an operator established in the Union that contracts certain services to an operator established outside the Union in relation to an activity to be performed by an AI system that would qualify as high-risk and whose effects impact natural persons located in the Union. In those circumstances, the AI system used by the operator outside the Union could process data lawfully collected in and transferred from the Union, and provide to the contracting operator in the Union the output of that AI system resulting from that processing, without that AI system being placed on the market, put into service or used in the Union. To prevent the circumvention of this Regulation and to ensure an effective protection of natural persons located in the Union, this Regulation should also apply to providers and deployers of AI systems that are established in a third country, to the extent the output produced by those systems is used in the Union or affects people in the Union.

Amendment 393
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 11
(11) In light of their digital nature, certain AI systems should fall within the scope of this Regulation even when they are neither placed on the market, nor put into service, nor used in the Union. This is the case for example of an operator established in the Union that contracts certain services to an operator established outside the Union in relation to an activity to be performed by an AI system that would qualify as high-risk and whose effects impact natural persons located in the Union. In those circumstances, the AI system used by the operator outside the Union could process data lawfully collected in and transferred from the Union, and provide to the contracting operator in the Union the output of that AI system resulting from that processing, without that AI system being placed on the market, put into service or used in the Union. To prevent the circumvention of this Regulation and to ensure an effective protection of natural persons located in the Union, this Regulation should also apply to providers and users of AI systems that are established in a third country, to the extent the output produced by those systems is used in the Union. Nonetheless, to take into account existing arrangements and special needs for cooperation with foreign partners with whom information and evidence is exchanged, this Regulation should not apply to public authorities of a third country and international organisations when acting in the framework of international agreements concluded at national or European level for law enforcement and judicial cooperation with the Union or with its Member States. Such agreements have been concluded bilaterally between Member States and third countries or between the European Union, Europol and other EU agencies and third countries and international organisations. This exception should nevertheless be limited to trusted countries and international organizations that share the Union’s values.

Amendment 394
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 11
(11) In light of their digital nature, certain AI systems should fall within the scope of this Regulation even when they are neither placed on the market, nor put into service, nor used in the Union. This is the case for example of an operator established in the Union that contracts certain services to an operator established outside the Union in relation to an activity to be performed by an AI system that would qualify as high-risk. In those circumstances, the AI system used by the operator outside the Union could process data lawfully collected in and transferred from the Union, and provide to the contracting operator in the Union the output of that AI system resulting from that processing, without that AI system being placed on the market, put into service or used in the Union. To prevent the circumvention of this Regulation and to ensure an effective protection of natural persons located in the Union, this Regulation should also apply to providers and users of AI systems that are established in a third country, to the extent the output produced by those systems is intended for use in the Union. Nonetheless, to take into account existing arrangements and special needs for future cooperation with foreign partners with whom information and evidence is exchanged, this Regulation should not apply to public authorities of a third country and international organisations when acting in the framework of international agreements concluded at national or European level for law enforcement and judicial cooperation with the Union or with its Member States. Such agreements have been concluded bilaterally between Member States and third countries or between the European Union, Europol and other EU agencies and third countries and international organisations.

Amendment 395
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 12
(12) This Regulation should also apply to Union institutions, offices, bodies and agencies when acting as a provider or user of an AI system. This Regulation should be without prejudice to the provisions regarding the liability of intermediary service providers set out in Directive 2000/31/EC of the European Parliament and of the Council [as amended by the Digital Services Act].

Amendment 396
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst
Recital 12
(12) This Regulation should also apply to Union institutions, offices, bodies and agencies when acting as a provider or user of an AI system. This Regulation should be without prejudice to the provisions regarding the liability of intermediary service providers set out in Directive 2000/31/EC of the European Parliament and of the Council [as amended by the Digital Services Act].

Amendment 397
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 12
(12) This Regulation should also apply to Union institutions, offices, bodies and agencies when acting as a provider or deployer of an AI system. This Regulation should be without prejudice to the provisions regarding the liability of intermediary service providers set out in Directive 2000/31/EC of the European Parliament and of the Council [as amended by the Digital Services Act].

Amendment 398
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul Garraud
Recital 12
(12) This Regulation should also apply to the institutions, bodies, offices and agencies of the Union. AI systems exclusively developed or used for military purposes should be excluded from the scope of this Regulation. This Regulation should be without prejudice to the provisions regarding the liability of intermediary service providers set out in Directive 2000/31/EC of the European Parliament and of the Council [as amended by the Digital Services Act].

Amendment 399
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Karen Melchior, Dita Charanzová, Andrus Ansip, Morten
Recital 12 a (new)
(12 a) This Regulation should not undermine research and development activity and should respect freedom of science. It is therefore necessary to exclude from its scope AI systems specifically developed and put into service for the sole purpose of scientific research and development and to ensure that the Regulation does not otherwise affect scientific research and development activity on AI systems. As regards product oriented research activity by providers, the provisions of this Regulation should apply insofar as such research leads to or entails placing of an AI system on the market or putting it into service. Under all circumstances, any research and development activity should be carried out in accordance with recognised ethical standards for scientific research.

Amendment 400
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Recital 12 a (new)
(12 a) This Regulation should also ensure harmonisation and consistency in definitions and terminology as biometric techniques can, in the light of their primary function, be divided into techniques of biometric identification, authentication and verification. Biometric authentication means the process of matching an identifier to a specific stored identifier in order to grant access to a device or service, whilst biometric verification refers to the process of confirming that an individual is who they claim to be. As they do not involve any “one-to-many” comparison of biometric data that is the distinctive trait of identification, both biometric verification and authentication should be excluded from the scope of this Regulation.

Amendment 401
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Recital 12 a (new)
(12 a) This Regulation should also ensure harmonisation consistency in definitions and terminology as biometric techniques can, in the light of their primary function, be divided into techniques of biometric identification, authentication and verification. Biometric authentication means the process of matching an identifier to a specific stored identifier in order to grant access to a device or service, whilst biometric verification refers to the process of confirming that an individual is who they claim to be. As they do not involve any “one-to-many” comparison of biometric data that is the distinctive trait of identification, both biometric verification and authentication should be excluded from the scope of this Regulation.

Amendment 402
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 12 a (new)
(12 a) AI systems developed or used exclusively for military purposes should be excluded from the scope of this Regulation where that use falls under the exclusive remit of the Common Foreign and Security Policy regulated under Title V TEU. However, AI systems which are developed or used for military purposes but can also be used for civil purposes, falling under the definition of “dual use items” pursuant to Regulation (EU) 2021/821 of the European Parliament and of the Council1ashould fall into the scope of this Regulation.' '1a Regulation (EU) 2021/821 of the European Parliament and of the Council of 20 May 2021 setting up a Union regime for the control of exports, brokering, technical assistance, transit and transfer of dual-use items (OJ L 206 11.6.2021, p. 1).

Amendment 403
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 12 a (new)
(12 a) In order to ensure a minimum level of transparency on the ecological sustainability aspects of an AI system, providers and users should document parameters including but not limited to resource consumption, resulting from the design, data management and training, the underlying infrastructures of the AI system, and of the methods to reduce such impact for any AI system.

Amendment 404
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Dita Charanzová, Andrus Ansip, Vlad-Marius Botoş, Moritz
Recital 12 b (new)
(12 b) Given the complexity of the value chain for AI systems, it is essential to clarify the role of persons who may contribute to the development of AI systems covered by this Regulation, without being providers and thus being obliged to comply with the obligations and requirements established herein. It is necessary to clarify that general purpose AI systems - understood as AI systems that are able to perform generally applicable functions such as image/speech recognition, audio/video generation, pattern detection, question answering, translation etc. - should not be considered as having an intended purpose within the meaning of this Regulation, unless those systems have been adapted to a specific intended purpose that falls within the scope of this Regulation. Initial providers of general purpose AI systems should therefore only have to comply with the provisions on accuracy, robustness and cybersecurity as laid down in Art. 15 of this Regulation. If a person adapts a general purpose AI application to a specific intended purpose and places it on the market or puts it into service, it shall be considered the provider and be subject to the obligations laid down in this Regulation. The initial provider of a general purpose AI application shall, after placing it on the market or putting it to service, and without compromising its own intellectual property rights or trade secrets, provide the new provider with all essential, relevant and reasonably expected information that is necessary to comply with the obligations set out in this Regulation.

Amendment 405
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 12 b (new)
(12 b) This Regulation should not affect the provisions aimed at improving working conditions in platform work set out in Directive 2021/762/EC.

Amendment 406
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 13
(13) In order to ensure a consistent and high level of protection of public interests as regards health, safety and fundamental rights, common normative standards for all high-risk AI systems should be established. Those standards should be consistent with the Charter of fundamental rights of the European Union (the Charter) and should be non-discriminatory and in line with the Union’s international trade commitments. In order to ensure a minimum level of transparency on the ecological sustainability aspects of an AI system, providers and users should document (i) parameters including, but not limited to, resource consumption resulting from the design, data management, training and from the underlying infrastructures of the AI system; as well as (ii) the methods to reduce such impact.

Amendment 407
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 13
(13) In order to ensure a consistent and high level of protection of public interests as regards health, safety, the environment and fundamental rights, and values, common normative standards for AI systems should be established. Those standards should be consistent with the Charter of fundamental rights of the European Union (the Charter), the European Green Deal (The Green Deal), the Joint Declaration on Digital Rights of the Union (the Declaration) and the Ethics Guidelines for Trustworthy Artificial Intelligence (AI) of the High-Level Expert Group on Artificial Intelligence (AI HLEG), and should be non-discriminatory and in line with the Union’s international commitments.

Amendment 408
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 13
(13) In order to ensure a consistent and high level of protection of public interests as regards health, safety, and fundamental rights, as well as the environment, society, rule of law and democracy, economic interests and consumer protection, common normative standards for all high-risk AI systems should be established. Those standards should be consistent with the Charter of Fundamental Rights of the European Union (the Charter) and should be non-discriminatory and in line with the Union’s international trade commitments.

Amendment 409
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 13
(13) In order to ensure a consistent and high level of protection of public interests as regards health, safety and fundamental rights, the environment and the Union values enshrined in Article 2 TEU, common normative standards for all high-risk AI systems should be established. Those standards should be consistent with the Charter of fundamental rights of the European Union (the Charter) and should be non-discriminatory and in line with the Union’s international trade commitments.

Amendment 410
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 13
(13) In order to ensure a consistent and high level of protection of public interests as regards health, safety and fundamental rights, minimum common normative standards for all high-risk AI systems should be established. Those standards should be consistent with the Charter of fundamental rights of the European Union (the Charter) and should be non-discriminatory and in line with the Union’s international commitments.

Amendment 411
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 13 a (new)
(13 a) AI systems and related ICT technology require significant natural resources, contribute to waste production, and have a significant overall impact on the environment. It is appropriate to design and develop in particular high-risk AI systems with methods and capabilities that measure, record, and reduce resource use and waste production, as well as energy use, and that increase their overall efficiency throughout their entire lifecycle. The Commission, the Member States and the European AI Board should contribute to these efforts by issuing guidelines and providing support to providers and deployers.

Amendment 412
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 14
(14) In order to introduce a proportionate and effective set of binding rules for AI systems, a clearly defined risk-based approach should be followed. That approach should tailor the type and content of such rules to the intensity and scope of the risks that AI systems can generate. It is therefore necessary to prohibit certain artificial intelligence practices, to lay down requirements for high-risk AI systems and obligations for the relevant operators, and to lay down transparency obligations for certain AI systems. It is also necessary to establish the criteria and conditions which determinine the category to which an AI system belongs.

Amendment 413
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Recital 14
(14) In order to introduce a proportionate and effective set of binding rules for AI systems, a clearly defined risk-based approach should be followed. That approach should tailor the type and content of such rules to the intensity and scope of the risks that AI systems can generate for individuals and society, rather than depend on the type of technology. It is therefore necessary to prohibit certain artificial intelligence practices, to lay down requirements for high-risk AI systems and obligations for the relevant operators, and to lay down transparency obligations for certain AI systems.

Amendment 414
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 14
(14) In order to introduce a proportionate and effective set of binding rules for AI systems, a clearly defined risk-based approach should be followed. That approach should tailor the type and content of such rules to the intensity and scope of the risks that AI systems can generate. It is therefore necessary to prohibit certain unacceptable artificial intelligence practices, to lay down requirements for high-risk AI systems and obligations for the relevant operators, and to lay down transparency obligations for certain AI systems.

Amendment 415
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 15
(15) AI systems can also be misused and provide novel and powerful tools for manipulative, exploitative and social control practices. Such practices are particularly harmful and should be prohibited because they contradict Union values of respect for human dignity, freedom, equality, democracy and the rule of law and Union fundamental rights, including the right to non-discrimination, data protection and privacy and the rights of the child. All uses of AI systems which interfere with the essence of the fundamental rights of individuals should in any case be prohibited. The prohibitions listed in this Regulation should apply notwithstanding existing Union law and do not provide a new legal basis for the development placing on the market, deployment or use of AI systems. To keep up with rapid technological development and to ensure future-proof regulation, the Commission should keep the list of prohibited and high-risk AI systems under constant review.

Amendment 416
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 15
(15) Aside from the many beneficial uses of artificial intelligence, that technology can also be misused and provide novel and powerful tools for manipulative, exploitative and social control practices. Such practices are particularly harmful and should be prohibited because they contradict the values of respect for human dignity, freedom, equality, democracy and the rule of law, which are protected values under EU law, and Union fundamental rights, including the right to non-discrimination, data protection and privacy and the rights of the child.

Amendment 417
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 15 a (new)
(15 a) As signatories to the United Nations Convention on the Rights of Persons with Disabilities (CRPD), the European Union and all Member States are legally obliged to protect persons with disabilities from discrimination and promote their equality, to ensure that persons with disabilities have access, on an equal basis with others, to information and communications technologies and systems, and to ensure respect for privacy of persons with disabilities. Given the growing importance and use of AI systems, the strict application of universal design principles to all new technologies and services should ensure full, equal, and unrestricted access for everyone potentially affected by or using AI technologies, including persons with disabilities, in a way that takes full account of their inherent dignity and diversity. It is essential to ensure that providers of AI systems design them, and users use them, in accordance with the accessibility requirements set out in Directive (EU) 2019/882.

Amendment 418
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 15 a (new)
(15 a) As signatories to the United Nations Convention on the Rights of Persons with Disabilities (CRPD), the European Union and all Member States are legally obliged to protect persons with disabilities from discrimination and promote their equality (Article 5). They are also obliged to ensure that persons with disabilities have access, on an equal basis with others, to information and communications technologies and systems. (Article 9). Finally, they are obliged to ensure respect for privacy of persons with disabilities (Article 22).

Amendment 419
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 15 a (new)
(15 a) As signatories to the United Nations Convention on the Rights of Persons with Disabilities (CRPD), the European Union and all Member States are legally obliged to protect persons with disabilities from discrimination and promote their equality (Article 5). They are also obliged to ensure that persons with disabilities have access, on an equal basis with others, to information and communications technologies and systems. (Article 9). Finally, they are obliged to ensure respect for privacy of persons with disabilities (Article 22).

Amendment 420
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Sylwia
Recital 15 a (new)
(15 a) The European Union and its Member States as signatories to the United Nations Convention on the Rights of Persons with Disabilities (CRPD) are obliged to protect persons with disabilities from discrimination and to promote their equality. They are obliged to ensure that persons with disabilities have access, on an equal basis with others, to information and communications technologies and systems and to ensure respect for the fundamental rights, including that of privacy, of persons with disabilities.

Amendment 421
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 15 a (new)
(15 a) As signatories to the United Nations Convention on the Rights of Persons with Disabilities (UNCRPD), the European Union and all Member States should protect persons with disabilities from discrimination and promote their equality, ensure that persons with disabilities have access, on an equal basis with others, to information and communications technologies and systems and ensure respect for privacy of persons with disabilities.

Amendment 422
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 15 b (new)
(15 b) Given the growing importance and use of AI systems, the strict application of universal design principles to all new technologies and services should ensure full, equal, and unrestricted access for everyone potentially affected by or using AI technologies, including persons with disabilities, in a way that takes full account of their inherent dignity and diversity. It is essential to ensure that providers of AI systems design them, and users use them, in accordance with the accessibility requirements set out in Directive (EU) 2019/882. Union law should be further developed, including through this Regulation, so that no one is left behind as result of digital innovation.

Amendment 423
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Sylwia
Recital 15 b (new)
(15 b) Providers of AI systems should ensure that these systems are designed in accordance with the accessibility requirements set out in Directive (EU) 2019/882 and guarantee full, equal, and unrestricted access for everyone potentially affected by or using AI systems, including persons with disabilities.

Amendment 424
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 16
(16) The placing on the market, putting into service or use of certain AI systems materially distorting human behaviour, whereby physical or psychological harms are likely to occur, should be forbidden. Such AI systems deploy subliminal components that persons cannot perceive or those systems otherwise exploit vulnerabilities of a specific group of persons due to their age, disability within the meaning of Directive (EU) 2019/882, or social or economic situation. Such systems can be placed on the market, put into service or used with the objective to or the effect of materially distorting the behaviour of a person and in a manner that causes or is reasonably likely to cause physical or psychological harm to that or another person or groups of persons, including harms that may be accumulated over time. The intention to distort the behaviour may not be presumed if the distortion results from factors external to the AI system which are outside of the control of the provider or the user meaning factors that may not be reasonably foreseen and mitigated by the provider or the user of the AI system. In any case, it is not necessary for the provider or the user to have the intention to cause the physical or psychological harm, as long as such harm results from the manipulative or exploitative AI-enabled practices. The prohibitions for such AI practices is complementary to the provisions contained in Directive [Unfair Commercial Practice Directive 2005/29/EC, as amended by Directive (EU) 2019/216], notably that unfair commercial practices leading to economic or financial harms to consumers are prohibited under all circumstances, irrespective of whether they are put in place through AI systems or otherwise.

Amendment 425
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 16
(16) The placing on the market, putting into service or use of certain AI systems with the effect or likely effect of distorting human behaviour, whereby physical, economic or psychological harms to individuals or society are likely to occur, should be forbidden. This includes AI systems that deploy subliminal components that individuals may not be able to perceive or understand, or exploit vulnerabilities of individuals. They materially distort the behaviour of a person, including in a manner that causes or is likely to cause physical, psychological or economic harm to that or another person, or to society, or lead them to make decisions they would not otherwise have taken. Manipulation may not be presumed if the distortion of human behaviour clearly results from factors external to the AI system which are outside of the control of the provider or the user and are not reasonably foreseeable at or during the deployment of the AI system. Research for legitimate purposes in relation to such AI systems should not be unduly limited by the prohibition, if such research does not amount to use of the AI system in non-supervised human-machine relations that exposes natural persons to harm and such research is carried out in accordance with recognised ethical standards for scientific research. If necessary, further flexibilities in order to foster research, and thereby European innovation capacities, should be introduced by Member States under controlled circumstances only and with all relevant safeguards to protect health and safety, fundamental rights, environment, society, rule of law and democracy.

Amendment 426
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 16
(16) The placing on the market, putting into service or use of certain AI systems intended to distort human behaviour should be forbidden. Such AI systems deploy subliminal components individuals cannot perceive or exploit vulnerabilities of people such as children or people who are vulnerable due to their age, physical or mental incapacities, or other traits. Research for legitimate purposes in relation to such AI systems should not be stifled by the prohibition, if such research does not amount to use of the AI system in human-machine relations with uninformed or non-consenting third parties that exposes natural persons to harm and such research is carried out in accordance with recognised ethical standards for scientific research.

Amendment 427
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Recital 16
(16) The placing on the market, putting into service or use of certain AI systems with the effect or likely effect of distorting human behaviour, whereby material or non-material harm, including physical, psychological or economic harms are likely to occur, should be forbidden. This limitation should be understood to include neuro-technologies assisted by AI systems that are used to monitor, use, or influence neural data gathered through brain-computer interfaces. Such AI systems deploy subliminal components individuals cannot perceive or exploit vulnerabilities of children and people due to their age, physical or mental incapacities. They do so with the effect of materially distorting the behaviour of a person and in a manner that causes or is likely to cause harm to that or another person. Research for legitimate purposes in relation to such AI systems should not be stifled by the prohibition, if such research does not amount to use of the AI system in human-machine relations that exposes natural persons to harm and such research is carried out in accordance with recognised ethical standards for scientific research.

Amendment 428
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 16
(16) The placing on the market, putting into service or use of certain AI systems intended to distort human behaviour, whereby physical or psychological harms are likely to occur, should be forbidden. In particular, AI systems that deploy subliminal components that natural persons cannot perceive, that exploit the vulnerabilities of any groups,or that use purposefully manipulative techniques with the intention to materially distort the behaviour of a person and in a manner that causes or is likely to cause harm to that or another person or to their rights or to the values of the Union should be prohibited. The intention may not be presumed if the distortion of human behaviour results from factors external to the AI system which are outside of the control of the provider or the user. Research for legitimate purposes in relation to such AI systems should not be stifled by the prohibition, if such research does not amount to use of the AI system inhuman-machine relations that exposes natural persons to harm and such research is carried out in accordance with recognised ethical standards for scientific research.

Amendment 429
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Maria-Manuel Leitão-Marques, Eva Kaili
Recital 16
(16) The placing on the market, putting into service or use of certain AI systems intended to distort human behaviour, whereby physical or psychological harms are likely to occur, should be forbidden. Such AI systems deploy subliminal components individuals cannot perceive, access brain or brain-generated data without consent, or exploit vulnerabilities of children and people due to their age, physical or mental incapacities. They do so with the intention to materially distort the behaviour of a person and in a manner that causes or is likely to cause harm to that or another person. The intention may not be presumed if the distortion of human behaviour results from factors external to the AI system which are outside of the control of the provider or the user. Research for legitimate purposes in relation to such AI systems should not be stifled by the prohibition, if such research does not amount to use of the AI system in human-machine relations that exposes natural persons to harm and such research is carried out in accordance with recognised ethical standards for scientific research.

Amendment 430
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Dita Charanzová, Andrus Ansip, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş, Abir Al-Sahlani, Moritz Körner, Ondřej Kovařík, Jan-Christoph Oetjen
Recital 16
(16) The placing on the market, putting into service or use of certain AI systems with the objective to or the effect of distorting human behaviour, whereby physical or psychological harms are reasonably likely to occur, should be forbidden. Such AI systems deploy subliminal components individuals cannot perceive or exploit vulnerabilities of specific groups of persons due to their age, disabilities, social or economic situation. They do so with the intention to materially distort the behaviour of a person and in a manner that causes or is likely to cause harm to that or another person. The intention may not be presumed if the distortion of human behaviour results from factors external to the AI system which are outside of the control of the provider or the user. Research for legitimate purposes in relation to such AI systems should not be stifled by the prohibition, if such research does not amount to use of the AI system inhuman-machine relations that exposes natural persons to harm and such research is carried out in accordance with recognised ethical standards for scientific research.

Amendment 431
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Recital 16
(16) The placing on the market, putting into service or use of certain AI systems intended to distort human behaviour, whereby with due diligence it could be predicted that physical or psychological harms are likely to occur, should be forbidden. Such AI systems deploy subliminal components individuals cannot perceive or exploit vulnerabilities of children and people due to their age, physical or mental incapacities. They do so with the intention to materially distort the behaviour of a person and in a manner that causes or is likely to cause harm to that or another person. The intention may not be presumed if the distortion of human behaviour results from factors external to the AI system which are outside of the control of the provider or the user. Research for legitimate purposes in relation to such AI systems should not be stifled by the prohibition, if such research does not amount to use of the AI system in human-machine relations that exposes natural persons to harm and such research is carried out in accordance with recognised ethical standards for scientific research.

Amendment 432
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 17
(17) AI systems providing social scoring of natural persons are, by definition, discriminatory.  They violate the right to dignity and non-discrimination and the values of equality and justice. Such AI systems evaluate or classify the trustworthiness of natural persons based on their social behaviour in multiple contexts or known or predicted personal or personality characteristics. The social score obtained from such AI systems leads to the detrimental or unfavourable treatment of natural persons or whole groups. Such AI systems should be therefore prohibited.

Amendment 433
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 17
(17) AI systems providing social scoring of natural persons for general purpose by private or public authorities or on their behalf may lead to discriminatory outcomes and the exclusion of certain groups. They may violate the right to dignity and non-discrimination and the values of equality and justice. Such AI systems evaluate or classify the trustworthiness of natural persons based on their social behaviour in multiple contexts or known or predicted personal or personality characteristics. Such AI systems should be therefore prohibited.

Amendment 434
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 17
(17) AI systems providing social scoring of natural persons for general purpose by public authorities or on their behalf may lead to discriminatory outcomes and the exclusion of certain groups. They may violate the right to dignity and non-discrimination and the values of equality and justice. Such AI systems evaluate or classify natural persons based on their social behaviour in multiple contexts or known or predicted personal or personality characteristics using trustworthiness, good citizenship, patriotism, deviancy, or any other such metric as a proxi. The social score obtained from such AI systems may lead to the detrimental or unfavourable treatment of natural persons or whole groups thereof in social contexts, which are unrelated to the context in which the data was originally generated or collected or to a detrimental treatment that is disproportionate or unjustified to the gravity of their social behaviour. This detrimental treatment can also be effected by providing undue and unjustified privileges to groups of people based on their social score. Such AI systems should be therefore prohibited.

Amendment 435
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 17
(17) AI systems that evaluate, classify, rate or score the trustworthiness or social standing of natural persons may lead to discriminatory outcomes and the exclusion of certain groups. They may violate the right to dignity and non-discrimination and the values of equality and justice. Such AI systems evaluate or classify the trustworthiness or social standing of natural persons based on multiple data points related to their social behaviour in multiple contexts or known, inferred or predicted personal or personality characteristics. The social score obtained from such AI systems may lead to the detrimental or unfavourable treatment of natural persons or whole groups thereof, which are unrelated to the context in which the data was originally generated or collected or to a detrimental treatment that is disproportionate or unjustified to the gravity of their social behaviour. Such AI systems should be therefore prohibited.

Amendment 436
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 17
(17) AI systems providing social scoring of natural persons for general purpose may lead to discriminatory outcomes and the exclusion of certain groups. They may violate the right to dignity and non-discrimination and the values of equality and justice. Such AI systems evaluate or classify the trustworthiness of natural persons based on their social behaviour in multiple contexts or known or predicted personal or personality characteristics. The social score obtained from such AI systems may lead to the detrimental or unfavourable treatment of natural persons or whole groups thereof in social contexts, which are unrelated to the context in which the data was originally generated or collected or to a detrimental treatment that is disproportionate or unjustified to the gravity of their social behaviour. Such AI systems should be therefore prohibited.

Amendment 437
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 17
(17) AI systems providing social scoring of natural persons for general purpose by public authorities or on their behalf may lead to discriminatory outcomes and the exclusion of certain groups. They violate the right to dignity and non-discrimination and the values of equality and justice. Such AI systems evaluate or classify natural persons based on their social behaviour in multiple contexts or known or predicted personal or personality characteristics. The social score obtained from such AI systems lead to the detrimental or unfavourable treatment of natural persons or whole groups thereof in social contexts, which are unrelated to the context in which the data was originally generated or collected or to a detrimental treatment that is disproportionate or unjustified to the gravity of their social behaviour. Such AI systems should be therefore prohibited.

Amendment 438
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 17 a (new)
(17 a) The placing on the market, putting into service or use of certain AI systems that can be used or foreseeably misused for intrusive monitoring and flagging to identify or deter rule-breaking or fraud should be forbidden. The use of such intrusive monitoring and flagging in a relationship of power, such as the use of e-proctoring software by education institutions to monitor students and pupils, or the use of surveillance- or monitoring software by employers on workers poses an unacceptable risk to the fundamental rights of workers, students and pupils, including minors. Notably, these practices affect the right to private life, data protection and human dignity of students and pupils, including minors.

Amendment 439
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 17 a (new)
(17 a) AI systems that are intended for use to protect consumers and prevent fraudulent activities should not necessarily be considered high-risk under this Regulation. As set by Article 94 of the Directive (EU) 2015/2366, payment systems and payment service providers should be allowed to process data to safeguard the prevention, investigation and detection of payment fraud. Therefore AI systems used to process data to safeguard the prevention, investigation and detection of fraud may not be considered as high-risk AI systems for the purpose of this Regulation.

Amendment 440
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 17 a (new)
(17 a) AI systems used by law enforcement authorities or on their behalf to make predictions, profiles or risk assessments based on data analysis or profiling of natural groups or locations, for the purpose of predicting the occurrence or reoccurrence of an actual or potential criminal offence(s) or other criminalised social behaviour, hold a particular risk of discrimination against certain persons or groups of persons, as they violate human dignity as well as the key legal principle of presumption of innocence. Such AI systems should therefore be prohibited.

Amendment 441
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Recital 17 a (new)
(17 a) AI systems used in law enforcement and criminal justice contexts based on predictive methods, profiling and risk assessment pose an unacceptable risk to fundamental rights and in particular to the right of non-discrimination, insofar as they contradict the fundamental right to be presumed innocent and are reflective of historical, systemic, institutional and societal discrimination and other discriminatory practices. These AI systems should therefore be prohibited;

Amendment 442
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 17 a (new)
(17 a) AI systems used by law enforcement authorities or on their behalf to predict the probability of a natural person to offend or to reoffend, based on profiling and individual or place-based risk-assessment hold a particular risk of discrimination against certain persons or groups of persons, as they violate human dignity as well as the key legal principle of presumption of innocence. Such AI systems should therefore be prohibited.

Amendment 443
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Sandro Gozi, Vlad-
Recital 17 a (new)
(17 a) AI systems used by law enforcement authorities or on their behalf to predict the probability of a natural person to offend or to reoffend, based on profiling and individual risk-assessment hold a particular risk of discrimination against certain persons or groups of persons, as they violate human dignity as well as the key legal principle of presumption of innocence. Such AI systems should therefore be prohibited.

Amendment 444
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 17 b (new)
(17 b) Insofar as such systems could ever function as intended, AI-based emotion recognition systems carry unacceptable risk for the essence of fundamental rights, such as human dignity and freedom of expression and must be prohibited. Exceptions for therapeutic tools or assistive technologies for personal use only could, nonetheless, be envisaged. However, this should only be permitted if the scientific basis and clinical validity of such systems have been demonstrated, where it can be shown that affected groups were active participants in the development process, and where the rights of everyone that is likely to be affected by the system, and not just the deployer , are clearly respected. Such systems should always be subject to careful oversight and transparency.

Amendment 445
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 17 c (new)
(17 c) Similarly, ostensible truth-detection technologies, such as polygraphs, have a long and unsuccessful history of abuse, misselling, miscarriages of justice and failure. The problems underlying these failures are exacerbated in the field of migration, which thusfar has been tarnished by new failings due to, inter alia to incorrect cultural assumptions. Such technologies therefore cannot be used while protecting the essence of all relevant fundamental rights.

Amendment 446
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 18
deleted

Amendment 447
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 18
(18) The use of AI systems for remote biometric identification of natural persons in publicly or privately accessible spaces, as well as online spaces, for the purpose of law enforcement is considered particularly intrusive in the rights and freedoms of the concerned persons, to the extent that it may affect the private life of a large part of the population, evoke a feeling of constant surveillance and indirectly dissuade the exercise of the freedom of assembly and other fundamental rights. Technical inaccuracies of AI systems intended for the remote biometric identification of natural persons can lead to biased results and entail discriminatory effects. This is particularly relevant when it comes to age, ethnicity, sex or disabilities. In addition, whether such systems are used in 'real-time' or post factum, there is little difference on the impact and the heightened risks for the rights and freedoms of the persons that are concerned by law enforcement activities. The placing or making available on the market, the putting into service or use of those systems should therefore be prohibited.

Amendment 448
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Recital 18
(18) The use of AI systems for remote biometric identification of natural persons in publicly or privately accessible spaces is particularly intrusive in the rights and freedoms of the concerned persons, to the extent that it may affect the private life of a large part of the population, evoke a feeling of constant surveillance and indirectly dissuade the exercise of the freedom of assembly and other fundamental rights. Such systems should therefore be prohibited.

Amendment 449
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Patrick
Recital 18
(18) The use of AI systems for biometric identification of natural persons in publicly accessible spaces is particularly corrosive to the rights and freedoms of the concerned persons and can ultimately affect the private life of a large part of the population, leave society with a justifiable feeling of constant surveillance, give parties deploying biometric identification in publicly accessible spaces a position of uncontrollable power and indirectly dissuade individuals from the exercise of their freedom of assembly and other fundamental rights  the core to the Rule of Law. Biometric identification not carried out in real time carries different but equally problematic risks. Due to the increase in pervasiveness, functionality and memory capacities of relevant devices, this would amount to a "surveillance time machine", which could be used to track movements and social interactions stretching back an indeterminate period into the past.

Amendment 450
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und Hohenstein, Vlad-Marius Botoş, Samira Rafaela, Monica Semedo, Salima Yenbou, Sophia in t Veld, Moritz Körner, Jan-Christoph Oetjen
Recital 18
(18) The use of AI systems for ‘real-time’ remote biometric identification of natural persons in publicly accessible spaces is considered particularly intrusive in the rights and freedoms of the concerned persons, to the extent that it may affect the private life of a large part of the population, evoke a feeling of constant surveillance and indirectly dissuade the exercise of the freedom of assembly and other fundamental rights. In addition, the immediacy of the impact and the limited opportunities for further checks or corrections in relation to the use of such systems operating in ‘real-time’ carry heightened risks for the rights and freedoms of the persons that are concerned by law enforcement activities. The use of those systems in publicly accessible places should therefore be prohibited.

Amendment 451
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 18
(18) The use of AI systems for ‘real-time’ remote biometric identification of natural persons in publicly accessible spaces is considered particularly intrusive in the rights and freedoms of the concerned persons, to the extent that it may affect the private life of a large part of the population, evoke a feeling of constant surveillance and indirectly dissuade the exercise of the freedom of assembly and other fundamental rights. In addition, the immediacy of the impact and the limited opportunities for further checks or corrections in relation to the use of such systems operating in ‘real-time’ carry heightened risks for the rights and freedoms of the persons that are concerned by law enforcement activities. The use of those systems in publicly accessible places should therefore be prohibited.

Amendment 452
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 18
(18) The use of AI systems for ‘real-time’ remote biometric identification of natural persons in publicly accessible spaces for the purpose of law enforcement is considered particularly intrusive in the rights and freedoms of the concerned persons, to the extent that it may affect the private life of a large part of the population, evoke a feeling of constant surveillance and indirectly dissuade the exercise of the freedom of assembly and other fundamental rights. In addition, the immediacy of the impact and the limited opportunities for further checks or corrections in relation to the use of such systems operating in ‘real-time’ carry heightened risks for the rights and freedoms of the persons that are concerned by law enforcement activities. Such AI systems should be therefore prohibited.

Amendment 453
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 18
(18) The use of AI systems for ‘real-time’ remote biometric identification of natural persons in publicly accessible or online spaces for the purpose of law enforcement is considered particularly intrusive in the rights and freedoms of the concerned persons, to the extent that it may affect the private life of a large part of the population, evoke a feeling of constant surveillance and indirectly dissuade the exercise of the freedom of assembly and other fundamental rights. In addition, the immediacy of the impact and the limited opportunities for further checks or corrections in relation to the use of such systems operating in ‘real-time’ carry heightened risks for the rights and freedoms of the persons that are concerned by law enforcement activities.

Amendment 454
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Recital 18
(18) The use of AI systems for ‘real-time’ remote biometric identification of natural persons in publicly accessible spaces is considered particularly intrusive in the rights and freedoms of the concerned persons, to the extent that it may affect the private life of a large part of the population, evoke a feeling of constant surveillance and indirectly dissuade the exercise of the freedom of assembly and other fundamental rights. In addition, the immediacy of the impact and the limited opportunities for further checks or corrections in relation to the use of such systems operating in ‘real-time’ carry heightened risks for the rights and freedoms of the persons that are concerned by law enforcement activities.

Amendment 455
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 18
(18) The use of AI systems for ‘real-time’ remote biometric identification of natural persons in publicly accessible spaces for the purpose of law enforcement is considered particularly intrusive in the rights and freedoms of the concerned persons, to the extent that it affects the private life of a large part of the population, constitutes constant surveillance and indirectly dissuades the exercise of the freedom of assembly and other fundamental rights. In addition, the immediacy of the impact and the limited opportunities for further checks or corrections in relation to the use of such systems operating in ‘real-time’ carry heightened risks for the rights and freedoms of the persons that are concerned by law enforcement activities.

Amendment 456
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 18 a (new)
(18 a) Despite progress regarding biometric identification technologies, the accuracy of the results still varies across technologies and depends on contextual factors. Even the relatively well-established fingerprint identification applications face challenges, in particular at the stage of the collection of biometric data (related to, for example, subject's age). The reliability of face recognition technologies in 'real world' settings is highly dependent on the quality of the images captured and on the quality of the algorithms used for biometric matching. During enrolment, poor quality images taken at e-gates or through a CCTV camera under variable environmental conditions may result in less accurate results. As in the case of automated fingerprint identification, changes in a person's physical characteristics over time may also affect the accuracy of facial recognition technologies. Research has found a considerable degradation in performance for face recognition algorithms on children as compared to the performance obtained on adults. In light of this, the placing or making available on the market, the putting into service or use of remote biometric identification systems should be prohibited.

Amendment 457
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 18 a (new)
(18 a) The notion of ‘at a distance’ in Remote Biometric Identification (RBI) means the use of systems as described in Article 3(36), at a distance great enough that the system has the capacity to scan multiple persons in its field of view (or the equivalent generalised scanning of online / virtual spaces), which would mean that the identification could happen without one or more of the data subjects’ knowledge. Because RBI relates to how a system is designed and installed, and not solely to whether or not data subjects have consented, this definition applies even when warning notices are placed in the location that is under the surveillance of the RBI system, and is not de facto annulled by pre-enrolment.

Amendment 458
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 18 a (new)
(18 a) The notion of ‘at a distance’ in Remote Biometric Identification (RBI) means the use of systems as described in Article 3(36), at a distance great enough that the system has the capacity to scanmultiple persons in its field of view (or the equivalent generalised scanning of online / virtual spaces), which would mean that the identification could happen without one or more of the data subjects’ knowledge. Because RBI relates to how a system is designed and installed, and not solely to whether or not data subjects have consented, this definition applies even when warning notices are placed in the location that is under the surveillance of the RBI system, and is not defacto annulled by pre-enrollment.

Amendment 459
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 18 a (new)
(18 a) The use of data collected or generated by practices prohibited under this Regulation should also be prohibited. Within the framework of judicial and administrative proceedings, the responsible authorities should establish that data collected or generated by practices prohibited under this regulation should not be admissible.

Amendment 460
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 18 b (new)
(18 b) There are serious concerns about the scientific basis of AI systems aiming to detect emotions from facial expressions. Facial expressions and perceptions thereof vary considerably across cultures and situations, and even within a single person. Among the key shortcomings of such technologies are the limited reliability (emotion categories are neither reliably expressed through, nor unequivocally associated with, a common set of facial movements), the lack of specificity (facial expressions do not perfectly match emotion categories) and the limited generalisability (the effects of context and culture are not sufficiently considered). Reliability issues may also arise when deploying the system in real-life situations, for example, when dealing with subjects who actively seek (and train themselves) to fool the system. Therefore, the placing on the market, putting into service, or use of AI systems intended to be used as polygraphs and similar tools to detect the emotional state, trustworthiness or related characteristics of a natural person, should be prohibited.

Amendment 461
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 18 b (new)
(18 b) ‘Biometric categorisation systems’ are defined as AI systems that assign natural persons to specific categories, or infer their characteristics or attributes. ‘Categorisation’ shall include any sorting of natural persons, whether into discrete categories (e.g. male/female, suspicious/not-suspicious), on a numerical scale (e.g. using the Fitzpatrick scale for skin type) or any other form of assigning labels or values to people. ‘Inferring an attribute or characteristic’ shall include any situation in which an AI system uses one type of data about a natural person (e.g. hair colour) to ascribe a different attribute or characteristic to that person (e.g. ethnic origin).

Amendment 462
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 19
deleted

Amendment 463
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 19
deleted

Amendment 464
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und
Recital 19
deleted

Amendment 465
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Recital 19
deleted

Amendment 466
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Recital 19
deleted

Amendment 467
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 19
deleted

Amendment 468
ECR - European Conservatives and Reformists Group
Jorge Buxadé Villalba
Recital 19
(19) The use of those systems for the purpose of law enforcement must therefore be prohibited, with the exception of border control and in the context of the fight against terrorism.

Amendment 469
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 19
(19) The use of those systems for the purpose of law enforcement should therefore be prohibited.

Amendment 470
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Patrick
Recital 19
(19) The use of AI systems for remote biometric identification of individuals should therefore be prohibited

Amendment 471
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte
Recital 19
(19) The use of those systems for the purpose of law enforcement should therefore be prohibited, except in three exhaustively listed and narrowly defined situations, where the use is ad hoc and strictly necessary to achieve a substantial public interest, the importance of which outweighs the risks. Those situations involve the search for potential victims of crime, including missing children; certain threats to the life or physical safety of natural persons or of a terrorist attack; and the detection, localisation, identification or prosecution of perpetrators or suspects of criminal offences if they are punishable by a custodial sentence or a detention order for a maximum period of at least ten years in the Member State concerned. Such threshold for the custodial sentence or detention order in accordance with national law contributes to ensure that the offence should be serious enough to potentially justify the use of ‘real-time’ remote biometric identification systems. The nature of the offences deemed sufficiently serious to justify a penalty up to this threshold is a matter for the national legislation of each Member State in accordance with its own criminal law.

Amendment 472
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Recital 20
deleted

Amendment 473
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 20
deleted

Amendment 474
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Recital 20
deleted

Amendment 475
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 20
deleted

Amendment 476
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Patrick
Recital 20
deleted

Amendment 477
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und
Recital 20
deleted

Amendment 478
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 20
deleted

Amendment 479
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 20
(20) In order to ensure that those systems are used in a responsible and proportionate manner, it is also important to establish that, in exhaustively listed and narrowly defined situations, certain elements should be taken into account, in particular as regards the nature of the situation giving rise to the request and the consequences of the use for the rights and freedoms of all persons concerned and the safeguards and conditions provided for with the use.

Amendment 480
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 20
(20) In order to ensure that those systems are used in a responsible and proportionate manner, it is also important to establish that, in each of those three exhaustively listed and narrowly defined situations, certain elements should be taken into account, in particular as regards the nature of the situation giving rise to the request and the consequences of the use for the rights and freedoms of all persons concerned and the safeguards and conditions provided for with the use. In addition, the use of ‘real-time’ remote biometric identification systems in publicly accessible or online spaces for the purpose of law enforcement should be subject to appropriate limits in time and space, having regard in particular to the evidence or indications regarding the threats, the victims or perpetrator. The reference database of persons should be appropriate for each use case in each of the three situations mentioned above.

Amendment 481
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Recital 21
deleted

Amendment 482
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 21
deleted

Amendment 483
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 21
deleted

Amendment 484
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Patrick
Recital 21
deleted

Amendment 485
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 21
deleted

Amendment 486
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und
Recital 21
deleted

Amendment 487
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Recital 21
deleted

Amendment 488
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 21
(21) Each use of a ‘real-time’ remote biometric identification system in publicly accessible or online spaces for the purpose of law enforcement should be subject to an express and specific authorisation by a judicial authority or by an independent administrative authority of a Member State. Such authorisation should in principle be obtained prior to the use, except in duly justified situations of urgency, that is, situations where the need to use the systems in question is such as to make it effectively and objectively impossible to obtain an authorisation before commencing the use. In such situations of urgency, the use should be restricted to the absolute minimum necessary and be subject to appropriate safeguards and conditions, as determined in national law and specified in the context of each individual urgent use case by the law enforcement authority itself. In addition, the law enforcement authority should in such situations seek to obtain an authorisation as soon as possible, whilst providing the reasons for not having been able to request it earlier.

Amendment 489
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 21
(21) Use of a ‘real-time’ remote biometric identification system in publicly accessible spaces for the purpose of law enforcement should be subject to authorisation by a judicial authority or by an independent administrative authority of a Member State. Such authorisation should in principle be obtained prior to the use, except in duly justified situations of urgency, that is, situations where the need to use the systems in question is such as to make it effectively and objectively impossible to obtain an authorisation before commencing the use. In such situations of urgency, the use should be restricted to the absolute minimum necessary and be subject to appropriate safeguards and conditions, as determined in national law and specified in the context of each individual urgent use case by the law enforcement authority itself. In addition, the law enforcement authority should in such situations seek to obtain an authorisation as soon as possible, whilst providing the reasons for not having been able to request it earlier.

Amendment 490
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 22
deleted

Amendment 491
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Recital 22
deleted

Amendment 492
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Patrick
Recital 22
deleted

Amendment 493
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 22
deleted

Amendment 494
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und
Recital 22
deleted

Amendment 495
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Recital 22
deleted

Amendment 496
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 22
(22) Furthermore, it is appropriate to provide that such use in the territory of a Member State in accordance with this Regulation should only be possible where and in as far as the Member State in question has decided to expressly provide for the possibility to authorise such use in its detailed rules of national law. Consequently, Member States remain free under this Regulation not to provide for such a possibility at all or to only provide limited possibilities in this regard.

Amendment 497
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und
Recital 23
deleted

Amendment 498
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Recital 23
deleted

Amendment 499
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 23
deleted

Amendment 500
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 23
deleted

Amendment 501
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Recital 23
deleted

Amendment 502
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Patrick
Recital 23
(23) The use of AI systems for biometric identification of natural persons in publicly accessible spaces necessarily involves the processing of biometric and biometrics-based data. The rules of this Regulation that prohibit, subject to certain exceptions, such use, which are based on Article 16 TFEU, should apply as lex specialis in respect of the rules on the processing of biometric data contained in Article 10 of Directive (EU) 2016/680 and Article 9 of Regulation 2016/679, thus regulating such use and the processing of biometric data involved in an exhaustive manner.

Amendment 503
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 23
(23) The use of AI systems for ‘real-time’ remote biometric identification of natural persons in publicly accessible spaces for the purpose of law enforcement necessarily involves the processing of biometric data. The rules of this Regulation that prohibit such use, which are based on Article 16 TFEU, should apply as lex specialis in respect of the rules on the processing of biometric data contained in Article 10 of Directive (EU) 2016/680. However, the use of ‘real-time’ remote biometric identification systems in publicly accessible spaces for purposes, including by competent authorities, should not be covered by the specific framework regarding such use for the purpose of law enforcement set by this Regulation. Such use for purposes other than law enforcement should therefore not be subject to the requirement of an authorisation under this Regulation and the applicable detailed rules of national law that may give effect to it. The lex specialis nature of the prohibition on RBI does not provide a legal basis for law enforcement uses of RBI, nor does it weaken existing protections of biometric data under the Data Protection Law Enforcement Directive (LED) or national implementations of the LED.

Amendment 504
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 23
(23) The use of AI systems for ‘real-time’ remote biometric identification of natural persons in publicly accessible or online spaces for the purpose of law enforcement necessarily involves the processing of biometric data. Therefore, such use and processing should only be possible in as far as it is compatible with the framework set by this Regulation, without there being scope, outside that framework, for the competent authorities, where they act for purpose of law enforcement, to use such systems and process such data in connection thereto on the grounds listed in Article 10 of Directive (EU) 2016/680. In this context, this Regulation is not intended to provide the legal basis for the processing of personal data under Article 8 of Directive 2016/680. However, the use of ‘real-time’ remote biometric identification systems in publicly accessible or online spaces for purposes other than law enforcement, including by competent authorities, should not be covered by the specific framework regarding such use for the purpose of law enforcement set by this Regulation. Such use for purposes other than law enforcement should therefore not be subject to the requirement of an authorisation under this Regulation and the applicable detailed rules of national law that may give effect to it.

Amendment 505
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte
Recital 23
(23) The use of AI systems for ‘real-time’ remote biometric identification of natural persons in publicly accessible spaces for the purpose of law enforcement necessarily involves the processing of biometric data. The rules of this Regulation that prohibit, subject to certain exceptions, such use, which are based on Article 16 TFEU, should apply as lex specialis in respect of the rules on the processing of biometric data contained in Article 10 of Directive (EU) 2016/680, thus regulating such use and the processing of biometric data involved in an exhaustive manner. Therefore, such use and processing should only be possible in as far as it is compatible with the framework set by this Regulation, without there being scope, outside that framework, for the competent authorities, where they act for purpose of law enforcement, to use such systems and process such data in connection thereto on the grounds listed in Article 10 of Directive (EU) 2016/680. In this context, this Regulation is not intended to provide the legal basis for the processing of personal data under Article 8 of Directive 2016/680. The use of biometric identification systems, including ‘real-time’ remote biometric identification systems in publicly accessible spaces for purposes other than law enforcement, including by competent authorities, should be covered by the framework set by this Regulation, with the exception of customs formalities and individual authentication.

Amendment 506
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 23
(23) The use of AI systems for ‘real-time’ remote biometric identification of natural persons in publicly accessible spaces for the purpose of law enforcement necessarily involves the processing of biometric data. The rules of this Regulation which are based on Article 16 TFEU, should apply as lex specialis in respect of the rules on the processing of biometric data contained in Article 10 of Directive (EU) 2016/680, thus regulating such use and the processing of biometric data involved in an exhaustive manner. Therefore, such use and processing should only be possible in as far as it is compatible with the framework set by this Regulation, without there being scope, outside that framework, for the competent authorities, where they act for purpose of law enforcement, to use such systems and process such data in connection thereto on the grounds listed in Article 10 of Directive (EU) 2016/680. In this context, this Regulation is not intended to provide the legal basis for the processing of personal data under Article 8 of Directive 2016/680. However, the use of ‘real-time’ remote biometric identification systems in publicly accessible spaces for purposes other than law enforcement, including by competent authorities, should not be covered by the specific framework regarding such use for the purpose of law enforcement set by this Regulation. Such use for purposes other than law enforcement should therefore not be subject to the requirement of an authorisation under this Regulation and the applicable detailed rules of national law that may give effect to it.

Amendment 507
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 23 a (new)
(23 a) ‘Biometric categorisation systems’ are defined as AI systems that assign natural persons to specific categories, or infer their characteristics or attributes. ‘Categorisation’ shall include any sorting of natural persons, whether into discrete categories (e.g. male/female, suspicious/not-suspicious), on a numerical scale (e.g. using the Fitzpatrick scale for skin type) or any other form of assigning labels or values to people. ‘Inferring an attribute or characteristic’ shall include any situation in which an AI system uses one type of data about a natural person (e.g. hair colour) to ascribe a different attribute or characteristic to that person (e.g. ethnic origin).

Amendment 508
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Recital 24
deleted

Amendment 509
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Recital 24
deleted

Amendment 510
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 24
(24) Any processing of biometric data and other personal data involved in the use of AI systems for biometric identification should continue to comply with all requirements resulting from Article 9(1) of Regulation (EU) 2016/679, Article 10(1) of Regulation (EU) 2018/1725 and Article 10 of Directive (EU) 2016/680, as applicable.

Amendment 511
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und
Recital 24
(24) Any processing of biometric data and other personal data involved in the use of AI systems for biometric identification, including where those systems are used by competent authorities in publicly accessible spaces for other purposes than law enforcement, should continue to comply with all requirements resulting from Article 9(1) of Regulation (EU) 2016/679, Article 10(1) of Regulation (EU) 2018/1725 and Article 10 of Directive (EU) 2016/680, as applicable.

Amendment 512
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 24
(24) Any processing of biometric data and other personal data involved in the use of AI systems for biometric identification, including where those systems are used by competent authorities in publicly accessible spaces for other purposes than law enforcement, should continue to comply with all requirements resulting from Article 9(1) of Regulation (EU) 2016/679, Article 10(1) of Regulation (EU) 2018/1725 and Article 10 of Directive (EU) 2016/680, as applicable.

Amendment 513
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Patrick
Recital 24
(24) Any processing of biometric data, biometrics-based data and other personal data involved in the use of AI systems for biometric identification, other than in connection to the use of biometric identification systems in publicly accessible spaces as regulated by this Regulation, should continue to comply with all requirements resulting from Article 9(1) of Regulation (EU) 2016/679, Article 10(1) of Regulation (EU) 2018/1725 and Article 10 of Directive (EU) 2016/680, as applicable.

Amendment 514
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 24
(24) Any processing of biometric data and other personal data involved in the use of AI systems for biometric identification, other than in connection to the use of ‘real-time’ remote biometric identification systems in publicly accessible or online spaces for the purpose of law enforcement as regulated by this Regulation, including where those systems are used by competent authorities in publicly accessible or online spaces for other purposes than law enforcement, should continue to comply with all requirements resulting from Article 9(1) of Regulation (EU) 2016/679, Article 10(1) of Regulation (EU) 2018/1725 and Article 10 of Directive (EU) 2016/680, as applicable.

Amendment 515
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Karen Melchior, Dita Charanzová, Andrus Ansip, Morten
Recital 24 a (new)
(24 a) Fundamental rights in the digital sphere have to be guaranteed to the same extent as in the offline world. The right to privacy needs to be ensured, amongst others through end-to-end encryption in private online communication and the protection of private content against any kind of general or targeted surveillance, be it by public or private actors. Therefore, the use of AI systems violating the right to privacy in online communication services should be prohibited.

Amendment 516
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Recital 25
(25) In accordance with Article 6a of Protocol No 21 on the position of the United Kingdom and Ireland in respect of the area of freedom, security and justice, as annexed to the TEU and to the TFEU, Ireland is not bound by the rules laid down in Article 5(1), point (d) of this Regulation adopted on the basis of Article 16 of the TFEU which relate to the processing of personal data by the Member States when carrying out activities falling within the scope of Chapter 4 or Chapter 5 of Title V of Part Three of the TFEU, where Ireland is not bound by the rules governing the forms of judicial cooperation in criminal matters or police cooperation which require compliance with the provisions laid down on the basis of Article 16 of the TFEU.

Amendment 517
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Recital 26
(26) In accordance with Articles 2 and 2a of Protocol No 22 on the position of Denmark, annexed to the TEU and TFEU, Denmark is not bound by rules laid down in Article 5(1), point (d) of this Regulation adopted on the basis of Article 16 of the TFEU, or subject to their application, which relate to the processing of personal data by the Member States when carrying out activities falling within the scope of Chapter 4 or Chapter 5 of Title V of Part Three of the TFEU.

Amendment 518
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 27
(26 a) AI systems capable of reading facial expressions to infer emotional states hold no scientific basis, while at the same time running a high risk of inaccuracy, in particular for certain groups of individuals whose facial traits are not easily readable by such systems, as several examples have shown. Therefore, due to the particular risk of discrimination, these systems should be prohibited.

Amendment 519
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 27
(27) High-risk AI systems should only be placed on the Union market or put into service if they comply with certain mandatory requirements. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as recognised and protected by Union law. AI systems identified as high-risk should be classified as such when they have a significant harmful impact on the health, safety, economic status and fundamental rights of individuals in the Union, and also on the environment, society, rule of law, democracy or consumer protection. Given the rapid path of technological development, but also given the potential changes in the use and the aim of authorised AI systems, regardless of whether they are high-risk or lower risk, the limited list of high-risk systems and areas of high risk systems in Annex III should nonetheless be subject to permanent review through the exercise of regular assessment as provided in Title III of this Regulation.

Amendment 520
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Recital 27
(27) High-risk AI systems should only be placed on the Union market or put into service if they comply with certain mandatory requirements. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as recognised and protected by Union law. AI systems identified as high-risk should be limited to those that have a significant harmful impact on the health, safety and fundamental rights of persons in the Union and such limitation minimises any potential restriction to international trade, if any. In particular, the classification as high-risk according to Article 6 should not apply to AI systems whose intended purpose demonstrates that the generated output is a recommendation, provided it is delivered with the information on its accuracy or other relevant methodical aspects necessary for the decision making. A human intervention is required to convert this recommendation into an action.

Amendment 521
EPP - Group of the European Peoples Party (Christian Democrats)
Deirdre Clune, Axel Voss, Andreas Schwab
Recital 27
(27) High-risk AI systems should only be placed on the Union market or put into service if they comply with certain mandatory requirements. To ensure alignment with sectoral legislation, requirements for certain high-risk AI systems and uses will take account of sectoral legislation which already lay out sufficient requirements for high-risk AI systems included within this Act, such as Regulation (EU) 2017/745 on Medical Devices and Regulation (EU) 2017/746 on In Vitro Diagnostic Devices and Directive 2006/42/EC on Machinery. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as recognised and protected by Union law. AI systems identified as high-risk should be limited to those that have a significant harmful impact on the health, safety and fundamental rights of persons in the Union and such limitation minimises any potential restriction to international trade, if any.

Amendment 522
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 27
(27) High-risk AI systems should only be placed on the Union market or put into service if they comply with certain mandatory requirements. To ensure alignment with sectoral legislation, requirements for certain high-risk AI systems and uses will take account of sectoral legislation which already lay out sufficient requirements for high-risk AI systems included within this Act, such as Regulation (EU) 2017/745 on Medical Devices and Regulation (EU) 2017/746 on In Vitro Diagnostic Devices and Directive 2006/42/EC on Machinery. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as recognised and protected by Union law. AI systems identified as high-risk should be limited to those that have a significant harmful impact on the health, safety and fundamental rights of persons in the Union and such limitation minimises any potential restriction to international trade, if any.

Amendment 523
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Recital 27
(27) High-risk AI systems should only be placed on the Union market or put into service if they comply with certain mandatory requirements. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as recognised and protected by Union law. AI systems identified as high-risk should be limited to those that have a significant harmful impact on the health, safety and fundamental rights of persons in the Union and such limitation minimises any potential restriction to international trade, if any. In particular, the classification as high-risk according to Article 6 should not apply to AI systems whose intended purpose demonstrates that the generated output is a recommendation and a human intervention is required to convert this recommendation into an action.

Amendment 524
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 27
(27) High-risk AI systems should only be placed on the Union market or put into service if they comply with certain mandatory requirements. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as recognised and protected by Union law and do not breach the Union values enshrined in Article 2 TEU or the principles applicable to all AI systems as per this Regulation. AI systems identified as high-risk should be limited to those that have a significant harmful impact on the fundamental rights of persons, their health and safety and such limitation minimises any potential restriction to international trade, if any.

Amendment 525
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina Penkova, René Repasi, Birgit Sippel, Maria Grapini, Adriana Maldonado López, Maria-Manuel Leitão-Marques, Marc Angel
Recital 27
(27) High-risk AI systems should only be placed on the Union market or put into service or used if they comply with certain mandatory requirements. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as recognised and protected by Union law and do not contravene the Union values enshrined in Article 2 TEU. AI systems identified as high-risk should be limited to those that have a significant harmful impact on the health, safety and the fundamental rights of persons in the Union or the environment and such limitation minimises any potential restriction to international trade, if any.

Amendment 526
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 27
(27) High-risk AI systems should only be placed on the Union market or put into service if they comply with certain mandatory requirements. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as recognised and protected by Union law. AI systems identified as high-risk should be limited to those that have a significant harmful impact on the health, safety and fundamental rights of persons in the Union, as well as the public order and national security of the Member States, and such limitation minimises any potential restriction to international trade, if any.

Amendment 527
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 27
(27) High-risk AI systems should only be placed on the Union market or put into service if they comply with certain mandatory requirements. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as recognised and protected by Union law. AI systems identified as high-risk should be limited to those that have a significant harmful impact on the health, safety and fundamental rights of persons in the Union or to Union values as enshrined in Article 2 TEU and such limitation minimises any potential restriction to international trade, if any.

Amendment 528
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 27
(27) High-risk AI systems should only be placed on the Union market or put into service if they comply with certain mandatory requirements. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as recognised and protected by Union law. AI systems identified as high-risk should be limited to those that have a harmful impact on the health, safety and fundamental rights of persons, but also on the environment, democracy and the rule of law in the Union..

Amendment 529
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 28
(28) AI systems could produce adverse outcomes to health and safety of persons, in particular when such systems operate as components of products. Consistently with the objectives of Union harmonisation legislation to facilitate the free movement of products in the internal market and to ensure that only safe and otherwise compliant products find their way into the market, it is important that the safety risks that may be generated by a product as a whole due to its digital components, including AI systems, are duly prevented and mitigated. For instance, increasingly autonomous robots, whether in the context of manufacturing or personal assistance and care should be able to safely operate and performs their functions in complex environments. Similarly, in the health sector where the stakes for life and health are particularly high, increasingly sophisticated diagnostics systems and systems supporting human decisions should be reliable and accurate. Conversely, industrial robots used in manufacturing processes that operate within a predefined and restricted area entail considerably lower safety risks and are already subject to harmonised safety legislation. The extent of the adverse impact caused by the AI system on the fundamental rights protected by the Charter is of particular relevance when classifying an AI system as high-risk. Those rights include the right to human dignity, respect for private and family life, protection of personal data, freedom of expression and information, freedom of assembly and of association, and non-discrimination, consumer protection, workers’ rights, rights of persons with disabilities, right to an effective remedy and to a fair trial, right of defence and the presumption of innocence, right to good administration. In addition to those rights, it is important to highlight that children have specific rights as enshrined in Article 24 of the EU Charter and in the United Nations Convention on the Rights of the Child (further elaborated in the UNCRC General Comment No. 25 as regards the digital environment), both of which require consideration of the children’s vulnerabilities and provision of such protection and care as necessary for their well-being. The fundamental right to a high level of environmental protection enshrined in the Charter and implemented in Union policies should also be considered when assessing the severity of the harm that an AI system can cause, including in relation to the health and safety of persons.

Amendment 530
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 28
(28) AI systems could have an adverse impact on persons, in particular when such systems operate as components of products. Consistently with the objectives of Union harmonisation legislation to facilitate the free movement of products in the internal market and to ensure that only safe and otherwise compliant products find their way into the market, it is important that the safety risks that may be generated by a product as a whole due to its digital components, including AI systems, are duly prevented and mitigated. For instance, increasingly autonomous robots, whether in the context of manufacturing or personal assistance and care should be able to safely operate and performs their functions in complex environments. Similarly, in the health sector where the stakes for life and health are particularly high, increasingly sophisticated diagnostics systems and systems supporting human decisions should be reliable and accurate. The extent of the adverse impact caused by the AI system on the fundamental rights protected by the Charter is of particular relevance when classifying an AI system as high-risk. Those rights include the right to human dignity, respect for private and family life, protection of personal data, freedom of expression and information, freedom of assembly and of association, and non-discrimination, consumer protection, workers’ rights, rights of persons with disabilities, right to an effective remedy and to a fair trial, right of defence and the presumption of innocence, right to good administration. In addition to those rights, it is important to highlight that children have specific rights as enshrined in Article 24 of the EU Charter and in the United Nations Convention on the Rights of the Child (further elaborated in the UNCRC General Comment No. 25 as regards the digital environment), both of which require consideration of the children’s vulnerabilities and provision of such protection and care as necessary for their well-being. The fundamental right to a high level of environmental protection enshrined in the Charter and implemented in Union policies should also be considered when assessing the severity of the harm that an AI system can cause.

Amendment 531
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 28 a (new)
(28 a) The risk-assessment of AI systems as regards their environmental impact and use of resources should not only focus on sectors related to the protection of the environment, but be common to all sectors, as environmental impacts can stem from any kind of AI systems, including those not originally directly related to the protection of the environment, in terms of energy production and distribution, waste management and emissions control.

Amendment 532
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 29
(29) As regards high-risk AI systems that are safety components of products or systems, or which are themselves products or systems falling within the scope of Regulation (EC) No 300/2008 of the European Parliament and of the Council39 , Regulation (EU) No 167/2013 of the European Parliament and of the Council40 , Regulation (EU) No 168/2013 of the European Parliament and of the Council41 , Directive 2014/90/EU of the European Parliament and of the Council42 , Directive (EU) 2016/797 of the European Parliament and of the Council43 , Regulation (EU) 2018/858 of the European Parliament and of the Council44 , Regulation (EU) 2018/1139 of the European Parliament and of the Council45 , and Regulation (EU) 2019/2144 of the European Parliament and of the Council46, Regulation (EU) 2017/745 of the European Parliament and of the Council, and Regulation (EU) 2017/746 of the European Parliament and of the Council, it is appropriate to amend those acts to ensure that the Commission takes into account, on the basis of the technical and regulatory specificities of each sector, and without interfering with existing governance, conformity assessment, market surveillance and enforcement mechanisms and authorities established therein, the mandatory requirements for high-risk AI systems laid down in this Regulation when adopting any relevant future delegated or implementing acts on the basis of those acts.' '39 Regulation (EC) No 300/2008 of the European Parliament and of the Council of 11 March 2008 on common rules in the field of civil aviation security and repealing Regulation (EC) No 2320/2002 (OJ L 97, 9.4.2008, p. 72).', '40 Regulation (EU) No 167/2013 of the European Parliament and of the Council of 5 February 2013 on the approval and market surveillance of agricultural and forestry vehicles (OJ L 60, 2.3.2013, p. 1).', '41 Regulation (EU) No 168/2013 of the European Parliament and of the Council of 15 January 2013 on the approval and market surveillance of two- or three-wheel vehicles and quadricycles (OJ L 60, 2.3.2013, p. 52).', '42 Directive 2014/90/EU of the European Parliament and of the Council of 23 July 2014 on marine equipment and repealing Council Directive 96/98/EC (OJ L 257, 28.8.2014, p. 146).', '43 Directive (EU) 2016/797 of the European Parliament and of the Council of 11 May 2016 on the interoperability of the rail system within the European Union (OJ L 138, 26.5.2016, p. 44).', '44 Regulation (EU) 2018/858 of the European Parliament and of the Council of 30 May 2018 on the approval and market surveillance of motor vehicles and their trailers, and of systems, components and separate technical units intended for such vehicles, amending Regulations (EC) No 715/2007 and (EC) No 595/2009 and repealing Directive 2007/46/EC (OJ L 151, 14.6.2018, p. 1).', '45 Regulation (EU) 2018/1139 of the European Parliament and of the Council of 4 July 2018 on common rules in the field of civil aviation and establishing a European Union Aviation Safety Agency, and amending Regulations (EC) No 2111/2005, (EC) No 1008/2008, (EU) No 996/2010, (EU) No 376/2014 and Directives 2014/30/EU and 2014/53/EU of the European Parliament and of the Council, and repealing Regulations (EC) No 552/2004 and (EC) No 216/2008 of the European Parliament and of the Council and Council Regulation (EEC) No 3922/91 (OJ L 212, 22.8.2018, p. 1).', '46 Regulation (EU) 2019/2144 of the European Parliament and of the Council of 27 November 2019 on type-approval requirements for motor vehicles and their trailers, and systems, components and separate technical units intended for such vehicles, as regards their general safety and the protection of vehicle occupants and vulnerable road users, amending Regulation (EU) 2018/858 of the European Parliament and of the Council and repealing Regulations (EC) No 78/2009, (EC) No 79/2009 and (EC) No 661/2009 of the European Parliament and of the Council and Commission Regulations (EC) No 631/2009, (EU) No 406/2010, (EU) No 672/2010, (EU) No 1003/2010, (EU) No 1005/2010, (EU) No 1008/2010, (EU) No 1009/2010, (EU) No 19/2011, (EU) No 109/2011, (EU) No 458/2011, (EU) No 65/2012, (EU) No 130/2012, (EU) No 347/2012, (EU) No 351/2012, (EU) No 1230/2012 and (EU) 2015/166 (OJ L 325, 16.12.2019, p. 1).

Amendment 533
EPP - Group of the European Peoples Party (Christian Democrats)
Deirdre Clune, Axel Voss, Andreas Schwab
Recital 29
(29) As regards high-risk AI systems that are safety components of products or systems, or which are themselves products or systems falling within the scope of Regulation (EC) No 300/2008 of the European Parliament and of the Council39 , Regulation (EU) No 167/2013 of the European Parliament and of the Council40 , Regulation (EU) No 168/2013 of the European Parliament and of the Council41 , Directive 2014/90/EU of the European Parliament and of the Council42 , Directive (EU) 2016/797 of the European Parliament and of the Council43 , Regulation (EU) 2018/858 of the European Parliament and of the Council44 , Regulation (EU) 2018/1139 of the European Parliament and of the Council45 , and Regulation (EU) 2019/2144 of the European Parliament and of the Council46 , Regulation (EU)2017/745 of the European Parliament and of the Council, and Regulation (EU)2017/746 of the European Parliament and of the Council, it is appropriate to amend those acts to ensure that the Commission takes into account, on the basis of the technical and regulatory specificities of each sector, and without interfering with existing governance, conformity assessment and enforcement mechanisms and authorities established therein, the mandatory requirements for high-risk AI systems laid down in this Regulation when adopting any relevant future delegated or implementing acts on the basis of those acts.' '39 Regulation (EC) No 300/2008 of the European Parliament and of the Council of 11 March 2008 on common rules in the field of civil aviation security and repealing Regulation (EC) No 2320/2002 (OJ L 97, 9.4.2008, p. 72).', '40 Regulation (EU) No 167/2013 of the European Parliament and of the Council of 5 February 2013 on the approval and market surveillance of agricultural and forestry vehicles (OJ L 60, 2.3.2013, p. 1).', '41 Regulation (EU) No 168/2013 of the European Parliament and of the Council of 15 January 2013 on the approval and market surveillance of two- or three-wheel vehicles and quadricycles (OJ L 60, 2.3.2013, p. 52).', '42 Directive 2014/90/EU of the European Parliament and of the Council of 23 July 2014 on marine equipment and repealing Council Directive 96/98/EC (OJ L 257, 28.8.2014, p. 146).', '43 Directive (EU) 2016/797 of the European Parliament and of the Council of 11 May 2016 on the interoperability of the rail system within the European Union (OJ L 138, 26.5.2016, p. 44).', '44 Regulation (EU) 2018/858 of the European Parliament and of the Council of 30 May 2018 on the approval and market surveillance of motor vehicles and their trailers, and of systems, components and separate technical units intended for such vehicles, amending Regulations (EC) No 715/2007 and (EC) No 595/2009 and repealing Directive 2007/46/EC (OJ L 151, 14.6.2018, p. 1).', '45 Regulation (EU) 2018/1139 of the European Parliament and of the Council of 4 July 2018 on common rules in the field of civil aviation and establishing a European Union Aviation Safety Agency, and amending Regulations (EC) No 2111/2005, (EC) No 1008/2008, (EU) No 996/2010, (EU) No 376/2014 and Directives 2014/30/EU and 2014/53/EU of the European Parliament and of the Council, and repealing Regulations (EC) No 552/2004 and (EC) No 216/2008 of the European Parliament and of the Council and Council Regulation (EEC) No 3922/91 (OJ L 212, 22.8.2018, p. 1).', '46 Regulation (EU) 2019/2144 of the European Parliament and of the Council of 27 November 2019 on type-approval requirements for motor vehicles and their trailers, and systems, components and separate technical units intended for such vehicles, as regards their general safety and the protection of vehicle occupants and vulnerable road users, amending Regulation (EU) 2018/858 of the European Parliament and of the Council and repealing Regulations (EC) No 78/2009, (EC) No 79/2009 and (EC) No 661/2009 of the European Parliament and of the Council and Commission Regulations (EC) No 631/2009, (EU) No 406/2010, (EU) No 672/2010, (EU) No 1003/2010, (EU) No 1005/2010, (EU) No 1008/2010, (EU) No 1009/2010, (EU) No 19/2011, (EU) No 109/2011, (EU) No 458/2011, (EU) No 65/2012, (EU) No 130/2012, (EU) No 347/2012, (EU) No 351/2012, (EU) No 1230/2012 and (EU) 2015/166 (OJ L 325, 16.12.2019, p. 1).

Amendment 534
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Dita Charanzová, Andrus Ansip, Morten Løkkegaard,
Recital 30
(30) As regards AI systems that are safety components of products, or which are themselves products, falling within the scope of certain Union harmonisation legislation, it is appropriate to classify them as high-risk under this Regulation if the product in question undergoes the conformity assessment procedure in order to ensure compliance with essential safety requirements with a third-party conformity assessment body pursuant to that relevant Union harmonisation legislation. In particular, such products are machinery, toys, lifts, equipment and protective systems intended for use in potentially explosive atmospheres, radio equipment, pressure equipment, recreational craft equipment, cableway installations, appliances burning gaseous fuels, medical devices, and in vitro diagnostic medical devices.

Amendment 535
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 30
(30) As regards AI systems that are safety components of products, or which are themselves products, falling within the scope of certain Union harmonisation legislation (as specified in Annex II), it is appropriate to classify them as high-risk under this Regulation if the product in question undergoes the conformity assessment procedure with a third-party conformity assessment body pursuant to that relevant Union harmonisation legislation. In particular, such products are machinery, toys, lifts, equipment and protective systems intended for use in potentially explosive atmospheres, radio equipment, pressure equipment, recreational craft equipment, cableway installations, appliances burning gaseous fuels, medical devices, and in vitro diagnostic medical devices.

Amendment 536
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 31
(31) The classification of an AI system as high-risk pursuant to this Regulation should not necessarily mean that the product whose safety component is the AI system, or the AI system itself as a product, is considered ‘high-risk’ under the criteria established in the relevant Union harmonisation legislation that applies to the product. This is notably the case for Regulation (EU) 2017/745 of the European Parliament and of the Council47 and Regulation (EU) 2017/746 of the European Parliament and of the Council48, where a third-party conformity assessment is provided for medium-risk and high-risk products. However, the classification of an AI system as high risk for the sole purpose of this Regulation will apply to all products which use that AI system or which are themselves AI systems, irrespective of their classification under the sector-specific harmonisation legislation of the Union under which they are otherwise covered.' '47 Regulation (EU) 2017/745 of the European Parliament and of the Council of 5 April 2017 on medical devices, amending Directive 2001/83/EC, Regulation (EC) No 178/2002 and Regulation (EC) No 1223/2009 and repealing Council Directives 90/385/EEC and 93/42/EEC (OJ L 117, 5.5.2017, p. 1).', '48 Regulation (EU) 2017/746 of the European Parliament and of the Council of 5 April 2017 on in vitro diagnostic medical devices and repealing Directive 98/79/EC and Commission Decision 2010/227/EU (OJ L 117, 5.5.2017, p. 176).

Amendment 537
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 31
(31) The classification of an AI system as high-risk pursuant to this Regulation shall not mean that the product whose safety component is the AI system, or the AI system itself as a product, is considered ‘high-risk’ under the criteria established in the relevant Union harmonisation legislation that applies to the product. This is notably the case for Regulation (EU) 2017/745 of the European Parliament and of the Council47 and Regulation (EU) 2017/746 of the European Parliament and of the Council48.' '47 Regulation (EU) 2017/745 of the European Parliament and of the Council of 5 April 2017 on medical devices, amending Directive 2001/83/EC, Regulation (EC) No 178/2002 and Regulation (EC) No 1223/2009 and repealing Council Directives 90/385/EEC and 93/42/EEC (OJ L 117, 5.5.2017, p. 1).', '48 Regulation (EU) 2017/746 of the European Parliament and of the Council of 5 April 2017 on in vitro diagnostic medical devices and repealing Directive 98/79/EC and Commission Decision 2010/227/EU (OJ L 117, 5.5.2017, p. 176).

Amendment 538
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 32
(32) As regards stand-alone AI systems, meaning high-risk AI systems other than those that are safety components of products, or which are themselves products, it is appropriate to classify them as high-risk if, in the light of their intended purpose, they pose a high risk of harm to the health, safety or the fundamental rights of persons or to Union values as enshrined in Article 2 TEU, taking into account both the severity of the possible harm and its probability of occurrence and they are used in a number of specifically pre-defined areas specified in the Regulation. The identification of those systems is based on the same methodology and criteria envisaged also for any future amendments of the list of high-risk AI systems. Such systems should be classified as high-risk only insofar as they are built and operated with biometric, biometrics-based, or personal data or they influence decisions of natural persons or make decisions or influence decisions affecting natural persons. This ensures that, when referencing AI systems in pre-defined areas of human activity, this Regulation does not inadvertently apply to AI systems that can have no impact on the health, safety, fundamental rights of natural persons or the values of the Union as enshrined in Article 2 TEU.

Amendment 539
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 32
(32) As regards stand-alone AI systems, meaning high-risk AI systems other than those that are safety components of products, or which are themselves products, it is appropriate to classify them as high-risk if, in the light of their intended purpose, they pose a significant risk of harm to the health and safety or the fundamental rights of persons, as well as the environment, society, rule of law, democracy, economic interests and consumer protection, taking into account both the severity of the possible harm and its probability of occurrence and they are used in a number of specifically pre-defined areas specified in the Regulation. The identification of those systems is based on the same methodology and criteria envisaged also for any future amendments of the list of high-risk AI systems. Such classification should take place before the placing onto the market but also during the life-cycle of an AI system.

Amendment 540
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 32
(32) As regards stand-alone AI systems, meaning high-risk AI systems other than those that are safety components of products, or which are themselves products, it is appropriate to classify them as high-risk if, in the light of their intended purpose or reasonably foreseeable uses, they pose a high risk of harm to the health and safety or the fundamental rights of persons, taking into account both the severity of the possible harm and its probability of occurrence and they are used in a number of specifically pre-defined areas specified in the Regulation. The identification of those systems is based on the same methodology and criteria envisaged also for any future amendments of the list of high-risk AI systems.', '(This amendment should apply throughout the text, i.e. any occurrence of "intended purpose" should be followed by "or reasonably foreseeable uses")

Amendment 541
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Patryk Jaki, Adam Bielan
Recital 32
(32) As regards stand-alone AI systems, meaning high-risk AI systems other than those that are safety components of products, or which are themselves products, it is appropriate to classify them as high-risk if, in the light of their intended purpose, they pose a high risk of harm to the health, natural environment, and safety or the fundamental rights of persons, taking into account both the severity of the possible harm and its probability of occurrence and they are used in a number of specifically pre-defined areas specified in the Regulation. The identification of those systems is based on the same methodology and criteria envisaged also for any future amendments of the list of high-risk AI systems.

Amendment 542
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 32
(32) As regards stand-alone AI systems, meaning high-risk AI systems other than those that are safety components of products, or which are themselves products, it is appropriate to classify them as high-risk if, in the light of their foreseeable uses, they pose a high risk of harm to the health and safety or the fundamental rights of persons, taking into account both the severity of the possible harm and its probability of occurrence and they are used in a number of specifically pre-defined areas specified in the Regulation. The identification of those systems is based on the same methodology and criteria envisaged also for any future amendments of the list of high-risk AI systems.

Amendment 543
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 32 a (new)
(32 a) In the light of the nature and complexity of the value chain for AI systems, it is essential to consider the foreseeable high-risks they can create when combined. Particular attention should be paid to the foreseeable uses and reasonably foreseeable misuses of AI systems with indeterminate uses.

Amendment 544
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 33
deleted

Amendment 545
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Recital 33
deleted

Amendment 546
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Dita Charanzová,
Recital 33
(33) Technical inaccuracies of AI systems intended for the remote biometric identification of natural persons can lead to biased results and entail discriminatory effects. This is particularly relevant when it comes to age, ethnicity, sex or disabilities. Therefore, ‘real-time’ and ‘post’ remote biometric identification systems should be classified as high-risk, except for verification or authentification systems whose sole purpose is to confirm that a specific natural person is the person he or she claims to be, and systems that are used to confirm the identity of a natural person for the sole purpose of having access to a service, a device or premises. In view of the risks that they pose, both types of remote biometric identification systems should be subject to specific requirements on logging capabilities and human oversight.

Amendment 547
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Recital 33
(33) Technical inaccuracies of AI systems intended for the remote biometric identification of natural persons can lead to biased results and entail discriminatory effects. This is particularly relevant when it comes to age, ethnicity, sex or disabilities. Therefore, ‘real-time’ and ‘post’ remote biometric identification systems should be classified as high-risk, except for the purpose of remote client on-boarding or verification of a user through a device. In view of the risks that they may pose, both types of remote biometric identification systems should be subject to specific requirements on logging capabilities and, when appropriate and justified by a proven added value to the protection of health, safety and fundamental rights, human oversight.

Amendment 548
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Recital 33
(33) Technical inaccuracies of AI systems intended for the remote biometric identification of natural persons can lead to biased results and entail discriminatory effects. This is particularly relevant when it comes to age, ethnicity, sex or disabilities. Therefore, ‘real-time’ and ‘post’ remote biometric identification systems should be classified as high-risk. In view of the risks that they may pose, both types of remote biometric identification systems should be subject to specific requirements on logging capabilities and, when appropriate and justified by a proven added value to the protection of health, safety and fundamental rights, human oversight.

Amendment 549
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Recital 33
(33) Technical inaccuracies of AI systems intended for the biometric identification of natural persons, including remote biometric identification, can lead to biased results and entail discriminatory effects. This is particularly relevant when it comes to age, ethnicity, sex or disabilities. Therefore, ‘real-time’ and ‘post’ remote biometric identification systems , including remote biometric identification, should be classified as high-risk. In view of the risks that they pose, both types of remote biometric identification systems should be subject to specific requirements on logging capabilities and human oversight.

Amendment 550
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 33
(33) Technical inaccuracies of AI systems intended for the remote biometric identification of natural persons can lead to biased results and entail discriminatory effects. This is particularly relevant when it comes to age, ethnicity, sex or disabilities. Therefore, ‘real-time’ and ‘post’ remote biometric identification systems should be classified as high-risk. In view of the risks that they pose, both types of remote biometric identification systems should be prohibited.

Amendment 551
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Patrick
Recital 33
(33) Technical inaccuracies, as well as conscious or subconscious design decisions, and the use of training data which codify and reinforce structural inequalities, mean that AI systems intended for the remote biometric identification of natural persons can lead to biased results and entail discriminatory effects. This is particularly relevant when it comes to age, ethnicity, sex or disabilities. As a result, ‘real-time’ and ‘post’ remote biometric identification systems undermine the essence of fundamental rights and therefore must be prohibited.

Amendment 552
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 33 a (new)
(33 a) Human oversight should target high-risk AI systems as a priority, with the aim of serving human-centric objectives. The individuals to whom human oversight is assigned shall be provided with adequate education and training on the functioning of the application, its capabilities to influence or make decisions, and to have harmful effects, notably on fundamental rights. The persons in charge of the assignment of these individuals shall provide them with relevant staff and psychological support.

Amendment 553
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 34
(34) As regards the management and operation of critical infrastructure, it is appropriate to classify as high-risk the AI systems intended to be used as safety or security components in the management and operation of road traffic and the supply of water, gas, heating and electricity, since their failure or malfunctioning may infringe the security and integrity of such critical infrastructure and thus put at risk the life and health of persons at large scale and lead to appreciable disruptions in the ordinary conduct of social and economic activities.

Amendment 554
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 34
(34) As regards the management and operation of critical infrastructure, it is appropriate to classify as high-risk the AI systems intended to be used as safety components in the management and operation of road traffic and the supply of water, gas, heating and electricity, and internet, since their failure or malfunctioning may put at risk the life and health of persons at large scale and lead to appreciable disruptions in the ordinary conduct of social and economic activities.

Amendment 555
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 34
(34) It is appropriate to classify as high-risk the AI systems intended to be used as safety components in the management and operation of critical infrastructure such as road traffic or the supply of water, gas, heating and electricity, since their failure or malfunctioning may put at risk the life and health of persons at large scale and lead to appreciable disruptions in the ordinary conduct of social and economic activities.

Amendment 556
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 35
(35) AI systems used in education or vocational training, notably for determining access or assigning persons to educational and vocational training institutions or to evaluate persons on tests as part of or as a precondition for their education should be considered high-risk, since they may determine the educational and professional course of a person’s life and therefore affect their ability to secure their livelihood. When improperly designed and used, such systems may violate the right to education and training as well as the right not to be discriminated against and perpetuate historical patterns of discrimination. Therefore, AI systems in education shall be prohibited to be used by public authorities in education of underaged children to meet the requirement in this regulation, to not exploit any of the vulnerabilities of the group of persons due to their age.

Amendment 557
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 35
(35) AI systems used in education or vocational training, notably for determining access or assigning persons to educational and vocational training institutions or to evaluate persons on tests as part of or as a precondition for their education should be considered high-risk, since they may determine the educational and professional course of a person’s life and therefore affect their ability to secure their livelihood. AI systems that are designed to constantly monitor individuals are particuarly intrusive and violate the right to education and training, the right not to be discriminated against and perpetuate historical patterns of discrimination and should therefore be prohibited.

Amendment 558
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 35
(35) AI systems used in education or vocational training, notably for determining access or assigning persons to educational and vocational training institutions or to evaluate persons on tests as part of or as a precondition for their education should be considered high-risk, since they may determine the educational and professional course of a person’s life and therefore affect their ability to secure their livelihood. When improperly designed and used, such systems may violate the right to education and training as well as the right not to be discriminated against.

Amendment 559
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 35
(35) AI systems used in education or vocational training, notably for determining access or assigning persons to educational and vocational training institutions or to evaluate or monitor persons on tests as part of or as a precondition for their education should be considered high-risk, since they may determine the educational and professional course of a person’s life and therefore affect their ability to secure their livelihood. When improperly designed and used, such systems may violate the right to education and training as well as the right not to be discriminated against and perpetuate historical patterns of discrimination.

Amendment 560
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 36
(36) AI systems used in employment, workers management and access to self-employment, notably affecting the initiation, establishment, implementation and termination of an employment relationship, including AI systems intended to support collective legal and regulatory matters should be high risk. Particularly AI affecting recruitment and selection of persons, for making decisions on promotion and for task allocation, for measuring and monitoring of performance or for evaluation of persons in work-related contractual relationships, should also be classified as high-risk, since those systems may appreciably impact future career prospects and livelihoods of these persons. AI systems used for constant monitoring of workers pose an unacceptable risk to their fundamental rights, and should be therefore prohibited. Relevant work-related contractual relationships should meaningfully involve employees and persons providing services through platforms as referred to in the Commission Work Programme 2021. Throughout the recruitment process and in the evaluation, promotion, or retention of persons in work-related contractual relationships, such systems may perpetuate historical patterns of discrimination, for example against women, certain age groups, persons with disabilities, or persons of certain racial or ethnic origins or sexual orientation. AI systems used to monitor the performance and behaviour of these persons may also undermine the essence of their fundamental rights to data protection and privacy. This Regulation applies without prejudice to Union and Member State competences to provide for more specific rules for the use of AI-systems in the employment context.

Amendment 561
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 36
(36) AI systems used in employment, workers management and access to self-employment, notably for the recruitment and selection of persons, for making decisions on promotion and termination and for personalised task allocation based on personal or biometric data, monitoring or evaluation of persons in work-related contractual relationships, should also be classified as high-risk, since those systems may appreciably impact future career prospects and livelihoods of these persons. Relevant work-related contractual relationships should involve employees and persons providing services through platforms as referred to in the Commission Work Programme 2021. Such persons should in principle not be considered users within the meaning of this Regulation. Throughout the recruitment process and in the evaluation, promotion, or retention of persons in work-related contractual relationships, such systems may perpetuate historical patterns of discrimination, for example against women, certain age groups, persons with disabilities, or persons of certain racial or ethnic origins or sexual orientation. AI systems used to monitor the performance and behaviour of these persons may also impact their rights to data protection and privacy.

Amendment 562
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 36
(36) AI systems used in employment, workers management and access to self-employment, notably for the recruitment and selection of persons, for making decisions on promotion and termination and for task allocation, monitoring or evaluation of persons in work-related contractual relationships, should also be classified as high-risk, in so far as such use does not correspond to practices prohibited by this Regulation, since those systems may appreciably impact future career prospects and livelihoods of these persons. Relevant work-related contractual relationships should involve employees and persons providing services through platforms as referred to in the Commission Work Programme 2021. Such persons should in principle not be considered users within the meaning of this Regulation. Throughout the recruitment process and in the evaluation, promotion, or retention of persons in work-related contractual relationships, such systems may lead to discrimination, for example against women, certain age groups, persons with disabilities, or persons of certain racial or ethnic origins or sexual orientation. AI systems used to monitor the performance and behaviour of these persons may also impact their rights to data protection and privacy.

Amendment 563
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Karen Melchior, Dita Charanzová, Andrus Ansip, Morten
Recital 36
(36) AI systems used for making autonomous decisions or materially influencing decisions in employment, workers management and access to self-employment, notably for the selection of persons, for making decisions on promotion and termination and for monitoring or evaluation of persons in work-related contractual relationships, should also be classified as high-risk, since those systems may appreciably impact future career prospects and livelihoods of these persons. Relevant work-related contractual relationships should involve employees and persons providing services through platforms as referred to in the Commission Work Programme 2021. Such persons should in principle not be considered users within the meaning of this Regulation. Throughout the recruitment process and in the evaluation, promotion, or retention of persons in work-related contractual relationships, such systems may perpetuate historical patterns of discrimination, for example against women, certain age groups, persons with disabilities, or persons of certain racial or ethnic origins or sexual orientation. AI systems used to monitor the performance and behaviour of these persons may also impact their rights to data protection and privacy.

Amendment 564
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst
Recital 36
(36) AI systems used in employment, workers management and access to self-employment, notably but not limited to, for the recruitment and selection of persons, for making decisions on promotion and termination and for task allocation, monitoring or evaluation of persons in work-related contractual relationships, should also be classified as high-risk, since those systems impact future career prospects, livelihoods of these persons and workers’ rights. Relevant work-related contractual relationships should involve employees and persons providing services through platforms as referred to in the Commission Work Programme 2021. Such persons should in principle not be considered users within the meaning of this Regulation. Throughout the recruitment process and in the evaluation, promotion, or retention of persons in work-related contractual relationships, such systems may perpetuate historical patterns of discrimination, for example against women, certain age groups, persons with disabilities, or persons of certain racial or ethnic origins or sexual orientation. AI systems used to monitor the performance and behaviour of these persons may also impact their rights to data protection and privacy.

Amendment 565
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 36 a (new)
(36) AI systems used in employment, workers management and access to self-employment, notably for the recruitment and selection of persons, for making decisions on promotion and termination, monitoring or evaluation of persons in work-related contractual relationships, should also be classified as high-risk, since those systems may appreciably impact future career prospects and livelihoods of these persons. Relevant work-related contractual relationships should involve employees and persons providing services through platforms as referred to in the Commission Work Programme 2021. Such persons should in principle not be considered users within the meaning of this Regulation. Throughout the recruitment process and in the evaluation, promotion, or retention of persons in work-related contractual relationships, such systems may perpetuate historical patterns of discrimination, for example against women, certain age groups, persons with disabilities, or persons of certain racial or ethnic origins or sexual orientation. AI systems used to monitor the performance and behaviour of these persons may also impact their rights to data protection and privacy.

Amendment 566
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Recital 36 a (new)
(36 a) In line with Article 114 (2) TFEU, this Regulation does not in any way affect the rights and interests of employed persons. This Regulation is without prejudice to Community law on social policy and national labour law and practice.

Amendment 567
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 36 b (new)
(36 b) Given the significance of Artificial Intelligence impact assessments according to the usage Artificial Intelligence applications in the workplace, the EU will consider a corresponding directive with specific provisions for an impact assessment to ensure the protection of the rights and freedoms of workers affected by AI systems through collective agreements of national legislation.

Amendment 568
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Recital 37
(37) Another area in which the use of AI systems deserves special consideration is the access to and enjoyment of certain essential private and public services and benefits necessary for people to fully participate in society or to improve one’s standard of living. In particular, AI systems that automatically generate models used to evaluate the credit score or creditworthiness of natural persons should be classified as high-risk AI systems, since they determine those persons’ access to financial resources or essential services such as housing, electricity, and telecommunication services. In contrast, ancillary applications to those systems determining whether an individual should be granted access to credit, such as AI applications used for the acceleration of the credit disbursement process, in the valuation of collateral, or for the internal process efficiency, as well as other subsequent applications based on the credit scoring which do not create high risks for individuals should be exempt from the scope. AI systems used to evaluate the credit score or creditworthiness may lead to discrimination of persons or groups and perpetuate historical patterns of discrimination, for example based on racial or ethnic origins, disabilities, age, sexual orientation, or create new forms of discriminatory impacts. Considering the very limited scale of the impact and the available alternatives on the market, it is appropriate to exempt AI systems for the purpose of creditworthiness assessment and credit scoring when put into service by small-scale providers for their own use. Natural persons applying for or receiving public assistance benefits and services from public authorities are typically dependent on those benefits and services and in a vulnerable position in relation to the responsible authorities. If AI systems are used for determining whether such benefits and services should be denied, reduced, revoked or reclaimed by authorities, they may have a significant impact on persons’ livelihood and may infringe their fundamental rights, such as the right to social protection, non-discrimination, human dignity or an effective remedy. Those systems should therefore be classified as high-risk. Infact, this Regulation should not hamper the development and use of innovative approaches in the public administration, which would stand to benefit from a wider use of compliant and safe AI systems, provided that those systems do not entail a high risk to legal and natural persons. Finally, AI systems used to dispatch or establish priority in the dispatching of emergency first response services should also be classified as high-risk since they make decisions in very critical situations for the life and health of persons and their property.

Amendment 569
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 37
(37) Another area in which the use of AI systems deserves special consideration is the access to and enjoyment of certain essential private and public services and benefits necessary for people to fully participate in society or to improve one’s standard of living. In particular, AI systems used to evaluate the credit score or creditworthiness of natural persons should be classified as high-risk AI systems, since they determine those persons’ access to financial resources or essential services such as housing, electricity, and telecommunication services. AI systems used for this purpose may lead to discrimination of persons or groups and perpetuate historical patterns of discrimination, for example based on racial or ethnic origins, disabilities, age, sexual orientation, or create new forms of discriminatory impacts. Natural persons applying for or receiving public assistance benefits and services from public authorities are typically dependent on those benefits and services and in a vulnerable position in relation to the responsible authorities. If AI systems are used for determining whether such benefits and services should be denied, reduced, revoked or reclaimed by authorities, they may have a significant impact on persons’ livelihood and may infringe their fundamental rights, such as the right to social protection, non-discrimination, human dignity or an effective remedy. Those systems should therefore be classified as high-risk. Finally, AI systems used to dispatch or establish priority in the dispatching of emergency first response services should also be classified as high-risk since they make decisions in very critical situations for the life and health of persons and their property.

Amendment 570
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 37
(37) Another area in which the use of AI systems deserves special consideration is the access to and enjoyment of certain essential private and public services and benefits necessary for people to fully participate in society or to improve one’s standard of living. In particular, AI systems used to evaluate the credit score or creditworthiness of natural persons should be prohibited, since they determine those persons’ access to financial resources or essential services such as housing, electricity, and telecommunication services. AI systems used for this purpose may lead to discrimination of persons or groups and perpetuate historical patterns of discrimination, for example based on racial or ethnic origins, disabilities, age, sexual orientation, or create new forms of discriminatory impacts. Considering the very limited scale of the impact and the available alternatives on the market, it is appropriate to exempt AI systems for the purpose of creditworthiness assessment and credit scoring when put into service by small-scale providers for their own use. Natural persons applying for or receiving public assistance benefits and services from public authorities are typically dependent on those benefits and services and in a vulnerable position in relation to the responsible authorities. If AI systems are used for determining whether such benefits and services should be denied, reduced, revoked or reclaimed by authorities, they may have a significant impact on persons’ livelihood and may infringe their fundamental rights, such as the right to social protection, non-discrimination, human dignity or an effective remedy. Finally, AI systems used to dispatch or establish priority in the dispatching of emergency first response services should also be classified as high-risk since they make decisions in very critical situations for the life and health of persons and their property.

Amendment 571
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 37
(37) Another area in which the use of AI systems deserves special consideration is the access to and enjoyment of certain essential private and public services and benefits necessary for people to fully participate in society or to improve one’s standard of living. In particular, AI systems used to evaluate the credit score or creditworthiness of natural persons should be prohibited, since they determine those persons’ access to financial resources or essential services such as housing, electricity, and telecommunication services. AI systems used for this purpose lead to an unacceptably high risk of discrimination against persons or groups and perpetuate historical patterns of discrimination, for example based on racial or ethnic origins, disabilities, age, sexual orientation, or create new forms of discriminatory impacts. Natural persons applying for or receiving public assistance benefits and services from public authorities are typically dependent on those benefits and services and in a vulnerable position in relation to the responsible authorities. If AI systems are used for determining whether such benefits and services should be denied, reduced, revoked or reclaimed by authorities, they have a significant impact on persons’ livelihood and infringe their fundamental rights, such as the right to social protection, non-discrimination, human dignity or an effective remedy. Those systems should therefore be prohibited. Nonetheless, this Regulation should not hamper the development and use of innovative approaches in the public administration, which would stand to benefit from a wider use of compliant and safe AI systems, provided that those systems do not entail a high risk to legal and natural persons. Finally, AI systems used to dispatch or establish priority in the dispatching of emergency first response services should also be classified as high-risk since they make decisions in very critical situations for the life and health of persons and their property.

Amendment 572
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Recital 37
(37) Another area in which the use of AI systems deserves special consideration is the access to and enjoyment of certain essential private and public services and benefits necessary for people to fully participate in society or to improve one’s standard of living. In particular, AI systems used to evaluate the credit score or creditworthiness of natural persons should be classified as high-risk AI systems, since they determine those persons’ access to financial resources or essential services such as housing, electricity, and telecommunication services. AI systems used for this purpose may lead to discrimination of persons or groups and perpetuate historical patterns of discrimination, for example based on racial or ethnic origins, disabilities, age, sexual orientation, or create new forms of discriminatory impacts. Considering the very limited scale of the impact and the available alternatives on the market, it is appropriate to exempt AI systems for the purpose of creditworthiness assessment and credit scoring when put into service by small-scale providers for their own use. Due to the fact that AI systems related to low-value credits for the purchase of movables do not cause high risk, it is proposed to exclude this category from the scope of high-risk AI category as well. . Natural persons applying for or receiving public assistance benefits and services from public authorities are typically dependent on those benefits and services and in a vulnerable position in relation to the responsible authorities. If AI systems are used for determining whether such benefits and services should be denied, reduced, revoked or reclaimed by authorities, they may have a significant impact on persons’ livelihood and may infringe their fundamental rights, such as the right to social protection, non-discrimination, human dignity or an effective remedy. Those systems should therefore be classified as high-risk. Nonetheless, this Regulation should not hamper the development and use of innovative approaches in the public administration, which would stand to benefit from a wider use of compliant and safe AI systems, provided that those systems do not entail a high risk to legal and natural persons. Finally, AI systems used to dispatch or establish priority in the dispatching of emergency first response services should also be classified as high-risk since they make decisions in very critical situations for the life and health of persons and their property.

Amendment 573
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Recital 37
(37) Another area in which the use of AI systems deserves special consideration is the access to and enjoyment of certain essential private and public services and benefits necessary for people to fully participate in society or to improve one’s standard of living. In particular, AI systems that automatically generate models used to evaluate the credit score or creditworthiness of natural persons should be classified as high-risk AI systems, since they determine those persons’ access to financial resources or essential services such as housing, electricity, and telecommunication services. In contrast, ancillary applications to those systems determining whether an individual should be granted access to credit, such as AI applications used for the acceleration of the credit disbursement process, in the valuation of collateral, or for the internal process efficiency, as well as other subsequent applications based on the credit scoring which do not create high risks for individuals should be exempt from the scope. AI systems used to evaluate the credit score or creditworthiness may lead to discrimination of persons or groups and perpetuate historical patterns of discrimination, for example based on racial or ethnic origins, disabilities, age, sexual orientation, or create new forms of discriminatory impacts. Natural persons applying for or receiving public assistance benefits and services from public authorities are typically dependent on those benefits and services and in a vulnerable position in relation to the responsible authorities. If AI systems are used for determining whether such benefits and services should be denied, reduced, revoked or reclaimed by authorities, they may have a significant impact on persons’ livelihood and may infringe their fundamental rights, such as the right to social protection, non-discrimination, human dignity or an effective remedy. Those systems should therefore be classified as high-risk. In fact, this Regulation should not hamper the development and use of innovative approaches in the public administration, which would stand to benefit from a wider use of compliant and safe AI systems, provided that those systems do not entail a high risk to legal and natural persons. Finally, AI systems used to dispatch or establish priority in the dispatching of emergency first response services should also be classified as high-risk since they make decisions in very critical situations for the life and health of persons and their property.

Amendment 574
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Patryk Jaki, Eugen Jurzyca
Recital 37
(37) Another area in which the use of AI systems deserves special consideration is the access to and enjoyment of certain essential private and public services and benefits necessary for people to fully participate in society or to improve one’s standard of living. In particular, AI systems used to evaluate the credit score or creditworthiness of natural persons should be classified as high-risk AI systems, since they determine those persons’ access to financial resources or essential services such as housing, electricity, and telecommunication services. AI systems used for this purpose may lead to discrimination of persons or groups and perpetuate historical patterns of discrimination, for example based on racial or ethnic origins, disabilities, age, sexual orientation, or create new forms of discriminatory impacts. Considering the very limited scale of the impact and the available alternatives on the market, it is appropriate to exempt AI systems for the purpose of creditworthiness assessment and credit scoring when put into service by small-scale providers for their own use. Due to the fact that AI systems related to low-value credits for the purchase of moveables does not cause high risk, it is proposed to exclude this category from the scope of high-risk AI category as well. Natural persons applying for or receiving public assistance benefits and services from public authorities are typically dependent on those benefits and services and in a vulnerable position in relation to the responsible authorities. If AI systems are used for determining whether such benefits and services should be denied, reduced, revoked or reclaimed by authorities, they may have a significant impact on persons’ livelihood and may infringe their fundamental rights, such as the right to social protection, non-discrimination, human dignity or an effective remedy. Those systems should therefore be classified as high-risk. Nonetheless, this Regulation should not hamper the development and use of innovative approaches in the public administration, which would stand to benefit from a wider use of compliant and safe AI systems, provided that those systems do not entail a high risk to legal and natural persons. Finally, AI systems used to dispatch or establish priority in the dispatching of emergency first response services should also be classified as high-risk since they make decisions in very critical situations for the life and health of persons and their property.

Amendment 575
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Markus Buchheit, Hélène Laporte
Recital 37
(37) Another area in which the use of AI systems deserves special consideration is the access to and enjoyment of certain essential private and public services and benefits necessary for people to fully participate in society or to improve one’s standard of living. In particular, AI systems used to evaluate the credit score or creditworthiness of natural persons should be classified as high-risk AI systems, in so far as such use does not correspond to practices prohibited by this Regulation, since they determine those persons’ access to financial resources or essential services such as housing, electricity, and telecommunication services. AI systems used for this purpose may lead to discrimination of persons or groups, for example based on racial or ethnic origins, disabilities, age, sexual orientation, or create new forms of discriminatory impacts. Considering the very limited scale of the impact and the available alternatives on the market, it is appropriate to exempt AI systems for the purpose of creditworthiness assessment and credit scoring when put into service by small-scale providers for their own use. Natural persons applying for or receiving public assistance benefits and services from public authorities are typically dependent on those benefits and services and in a vulnerable position in relation to the responsible authorities. If AI systems are used for determining whether such benefits and services should be denied, reduced, revoked or reclaimed by authorities, they will have a significant impact on persons’ livelihood and will infringe their fundamental rights, such as the right to social protection, non-discrimination, human dignity or an effective remedy. Those systems should therefore be classified as high-risk. Nonetheless, this Regulation should allow for experimentation in the public administration, in a regulatory sandbox, with innovative approaches which would stand to benefit from a wider use of compliant and safe AI systems, in accordance with the established rules.  Finally, AI systems used to dispatch or establish priority in the dispatching of emergency first response services should be prohibited as they make decisions in very critical situations for the life and health of persons and their property, and such ethical choices should not be given over to computer systems.

Amendment 576
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Dita Charanzová, Andrus Ansip, Morten
Recital 37
(37) Another area in which the use of AI systems deserves special consideration is the access to and enjoyment of certain essential private and public services and benefits necessary for people to fully participate in society or to improve one’s standard of living. In particular, AI systems used to evaluate the credit score or creditworthiness of natural persons should be classified as high-risk AI systems, since they determine those persons’ access to financial resources or essential services such as housing, electricity, and telecommunication services. AI systems used for this purpose may lead to discrimination of persons or groups and perpetuate historical patterns of discrimination, for example based on racial or ethnic origins, disabilities, age, sexual orientation, or create new forms of discriminatory impacts. Considering the very limited scale of the impact and the available alternatives on the market, it is appropriate to exempt AI systems for the purpose of creditworthiness assessment and credit scoring when put into service by SMEs and start-ups for their own use. Natural persons applying for or receiving public assistance benefits and services from public authorities are typically dependent on those benefits and services and in a vulnerable position in relation to the responsible authorities. If AI systems are used for determining whether such benefits and services should be denied, reduced, revoked or reclaimed by authorities, they may have a significant impact on persons’ livelihood and may infringe their fundamental rights, such as the right to social protection, non-discrimination, human dignity or an effective remedy. Those systems should therefore be classified as high-risk. Nonetheless, this Regulation should not hamper the development and use of innovative approaches in the public administration, which would stand to benefit from a wider use of compliant and safe AI systems, provided that those systems do not entail a high risk to legal and natural persons. Finally, AI systems used to dispatch or establish priority in the dispatching of emergency first response services should also be classified as high-risk since they make decisions in very critical situations for the life and health of persons and their property.

Amendment 577
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 37 a (new)
(37 a) Given the speed at which AI applications are being developed around the world, it is not feasible to compile an exhaustive listing of applications that should be prohibited or considered high-risk. What is needed is a clear and coherent governance model guaranteeing both the fundamental rights of individuals and legal clarity for operators, considering the continuous evolution of technology. Nevertheless, given the role and responsibility of police and judicial authorities, and the impact of decisions they take for the purposes of the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, the use of AI applications has to be categorised as high-risk in instances where there is the potential to significantly affect the lives of individuals.

Amendment 578
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 38
(38) Actions by law enforcement authorities involving certain uses of AI systems are characterised by a significant degree of power imbalance and may lead to surveillance, arrest or deprivation of a natural person’s liberty as well as other adverse impacts on fundamental rights guaranteed in the Charter. In particular, if the AI system is not trained with high quality data, does not meet adequate requirements in terms of its accuracy or robustness, or is not properly designed and tested before being put on the market or otherwise put into service, it may single out people in a discriminatory or otherwise incorrect or unjust manner. In addition, some applications, such as to make predictions, profiles, or risk assessments based on data analysis or profiling of groups or individuals for the purpose of predicting the occurrence or recurrence of actual or potential offences or rule-breaking undermine the essence of fundamental rights and should be prohibited. Furthermore, the exercise of important procedural fundamental rights, such as the right to an effective remedy and to a fair trial as well as the right of defence and the presumption of innocence, could be hampered, in particular, where such AI systems are not sufficiently transparent, explainable and documented. It is therefore appropriate to classify as prohibited a number of AI systems intended to be used in the law enforcement context as well as for crime analytics regarding natural persons.

Amendment 579
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 38
(38) Actions by law enforcement authorities involving certain uses of AI systems are characterised by a significant degree of power imbalance and may lead to surveillance, arrest or deprivation of a natural person’s liberty as well as other adverse impacts on fundamental rights guaranteed in the Charter. In particular, if the AI system is not trained with high quality data, does not meet adequate requirements in terms of its performance, including its accuracy or robustness, or is not properly designed and tested before being put on the market or otherwise put into service, it may single out people in a discriminatory or otherwise incorrect or unjust manner. Furthermore, the exercise of important procedural fundamental rights, such as the right to an effective remedy and to a fair trial as well as the right of defence and the presumption of innocence, could be hampered, in particular, where such AI systems are not sufficiently transparent, explainable and documented. It is therefore appropriate to classify as high-risk a number of AI systems intended to be used in the law enforcement context where accuracy, reliability and transparency is particularly important to avoid adverse impacts, retain public trust and ensure accountability and effective redress. AI systems specifically intended to be used for administrative proceedings by tax and customs authorities should not be considered high-risk AI systems used by law enforcement authorities for the purposes of prevention, detection, investigation and prosecution of criminal offences.

Amendment 580
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Markus Buchheit, Hélène Laporte
Recital 38
(38) Actions by law enforcement authorities involving certain uses of AI systems are characterised by a significant degree of power imbalance and may lead to surveillance, arrest or deprivation of a natural person’s liberty as well as other adverse impacts on fundamental rights guaranteed in the Charter. In particular, if the AI system is not trained with high quality data, does not meet adequate requirements in terms of its accuracy or robustness, or is not properly designed and tested before being put on the market or otherwise put into service, it may single out people in a discriminatory or otherwise incorrect or unjust manner. Furthermore, the exercise of important procedural fundamental rights, such as the right to an effective remedy and to a fair trial as well as the right of defence and the presumption of innocence, could be hampered, in particular, where such AI systems are not sufficiently transparent, explainable and documented. AI systems intended to assess or rank the reliability of natural persons, to identify natural persons based on biometric data, to serve as polygraphs or similar tools, to detect the emotional state of natural persons, to predict the occurrence or reoccurrence of an actual or potential criminal offence based on profiling of natural persons or to assess personality traits of natural persons or groups for profiling in the course of detection, investigation or prosecution of criminal offences, shall be prohibited except in the three specific cases provided for in this Regulation. AI systems other than the aforementioned and intended to be used in a law enforcement context where accuracy, reliability and transparency is particularly important shall be classed as high-risk AI systems to avoid adverse impacts, retain public trust and ensure accountability and effective redress. In view of the nature of the activities in question and the risks relating thereto, those high-risk AI systems should include in particular AI systems intended to be used by law enforcement authorities for individual risk assessments, to detect ‘deep fakes’, for the evaluation of the reliability of evidence in criminal proceedings, or assessing characteristics or past criminal behaviour of natural persons or groups for profiling in the course of detection, investigation or prosecution of criminal offences, as well as for crime analytics regarding natural persons. AI systems specifically intended to be used for administrative proceedings by tax and customs authorities should not be considered high-risk AI systems used by law enforcement authorities for the purposes of prevention, detection, investigation and prosecution of criminal offences.

Amendment 581
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 38
(38) Actions by law enforcement authorities involving certain uses of AI systems are characterised by a significant degree of power imbalance and may lead to surveillance, arrest or deprivation of a natural person’s liberty as well as other adverse impacts on fundamental rights guaranteed in the Charter. In particular, if the AI system is not trained with high quality data, does not meet adequate requirements in terms of its accuracy or robustness, or is not properly designed and tested before being put on the market or otherwise put into service, it may single out people in a discriminatory or otherwise incorrect or unjust manner. Furthermore, the exercise of important procedural fundamental rights, such as the right to an effective remedy and to a fair trial as well as the right of defence and the presumption of innocence, could be hampered, in particular, where such AI systems are not sufficiently transparent, explainable and documented. It is therefore appropriate to classify as high-risk a number of AI systems intended to be used in the law enforcement context where accuracy, reliability and transparency is particularly important to avoid adverse impacts, retain public trust and ensure accountability and effective redress. In view of the nature of the activities in question and the risks relating thereto, those high-risk AI systems should include in particular AI systems intended to be used by law enforcement authorities or on their behalf to detect ‘deep fakes’, for the evaluation of the reliability of evidence in criminal proceedings, as well as for crime analytics regarding natural persons. AI systems specifically intended to be used for administrative proceedings by tax and customs authorities should not be considered high-risk AI systems used by law enforcement authorities for the purposes of prevention, detection, investigation and prosecution of criminal offences.

Amendment 582
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,
Recital 38
(38) Actions by law enforcement authorities involving certain uses of AI systems are characterised by a significant degree of power imbalance and may lead to surveillance, arrest or deprivation of a natural person’s liberty as well as other adverse impacts on fundamental rights guaranteed in the Charter. In particular, if the AI system is not trained with high quality data, does not meet adequate requirements in terms of its accuracy or robustness, or is not properly designed and tested before being put on the market or otherwise put into service, it may single out people in a discriminatory or otherwise incorrect or unjust manner. Furthermore, the exercise of important procedural fundamental rights, such as the right to an effective remedy and to a fair trial as well as the right of defence and the presumption of innocence, could be hampered, in particular, where such AI systems are not sufficiently transparent, explainable and documented. It is therefore appropriate to classify as high-risk a number of AI systems intended to be used in the law enforcement context where accuracy, reliability and transparency is particularly important to avoid adverse impacts, retain public trust and ensure accountability and effective redress. In view of the nature of the activities in question and the risks relating thereto, those high-risk AI systems should include in particular AI systems intended to be used by law enforcement authorities for individual risk assessments, polygraphs and similar tools or to detect the emotional state of natural person, to detect ‘deep fakes’, for the evaluation of the reliability of evidence in criminal proceedings, for profiling in the course of detection, investigation or prosecution of criminal offences, as well as for crime analytics regarding natural persons. AI systems specifically intended to be used for administrative proceedings by tax and customs authorities should not be considered high-risk AI systems used by law enforcement authorities for the purposes of prevention, detection, investigation and prosecution of criminal offences.

Amendment 583
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 38
(38) Actions by law enforcement authorities involving certain uses of AI systems are characterised by a significant degree of power imbalance and may lead to surveillance, arrest or deprivation of a natural person’s liberty as well as other adverse impacts on fundamental rights guaranteed in the Charter. In particular, if the AI system is not trained with high quality data, does not meet adequate requirements in terms of its accuracy or robustness, or is not properly designed and tested before being put on the market or otherwise put into service, it may single out people in a discriminatory or otherwise incorrect or unjust manner. Furthermore, the exercise of important procedural fundamental rights, such as the right to an effective remedy and to a fair trial as well as the right of defence and the presumption of innocence, could be hampered, in particular, where such AI systems are not sufficiently transparent, explainable and documented. It is therefore appropriate to classify as high-risk a number of AI systems intended to be used in the law enforcement context where accuracy, reliability and transparency is particularly important to avoid adverse impacts, retain public trust and ensure accountability and effective redress. In view of the nature of the activities in question and the risks relating thereto, those high-risk AI systems should include in particular AI systems intended to be used by law enforcement authorities for individual risk assessments, polygraphs and similar tools or to detect the emotional state of natural person, to detect ‘deep fakes’, for the evaluation of the reliability of evidence in criminal proceedings, for profiling in the course of detection, investigation or prosecution of criminal offences, as well as for crime analytics regarding natural persons. AI systems specifically intended to be used for administrative proceedings by tax and customs authorities should not be considered high-risk AI systems used by law enforcement authorities for the purposes of prevention, detection, investigation and prosecution of criminal offences.

Amendment 584
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 38
(38) Actions by law enforcement authorities involving certain uses of AI systems are characterised by a significant degree of power imbalance and may lead to surveillance, arrest or deprivation of a natural person’s liberty as well as other adverse impacts on fundamental rights guaranteed in the Charter. In particular, if the AI system is not trained with high quality data, does not meet adequate requirements in terms of its accuracy or robustness, or is not properly designed and tested before being put on the market or otherwise put into service, it may single out people in a discriminatory or otherwise incorrect or unjust manner. Furthermore, the exercise of important procedural fundamental rights, such as the right to an effective remedy and to a fair trial as well as the right of defence and the presumption of innocence, could be hampered, in particular, where such AI systems are not sufficiently transparent, explainable and documented and where a redress procedure is not foreseen. It is therefore appropriate to prohibit some AI systems intended to be used in the law enforcement context where accuracy, reliability and transparency is particularly important to avoid adverse impacts, retain public trust and ensure accountability and effective redress, including the availability of redress-by-design mechanisms and procedures. In view of the nature of the activities in question and the risks relating thereto, those prohibited systems should include in particular AI systems intended to be used by law enforcement authorities for individual risk assessments, polygraphs and similar tools or to detect the emotional state of natural person, for predicting the occurrence or reoccurrence of an actual or potential criminal offence based on profiling of natural persons, or assessing personality traits and characteristics or past criminal behaviour of natural persons or groups, for profiling in the course of detection, investigation or prosecution of criminal offences. AI systems specifically intended to be used for administrative proceedings by tax and customs authorities should not be included in such a ban.

Amendment 585
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 38 a (new)
(38 a) The use of AI tools by law enforcement and judicial authorities should not become a factor of inequality, social fracture or exclusion. The impact of the use of AI tools on the defence rights of suspects should not be ignored, notably the difficulty in obtaining meaningful information on their functioning and the consequent difficulty in challenging their results in court, in particular by individuals under investigation.

Amendment 586
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 39
(39) AI systems used in migration, asylum and border control management affect people who are often in particularly vulnerable position and who are dependent on the outcome of the actions of the competent public authorities. The accuracy, non-discriminatory nature and transparency of the AI systems used in those contexts are therefore particularly important to guarantee the respect of the fundamental rights of the affected persons, notably their rights to free movement, non-discrimination, protection of private life and personal data, international protection and good administration. AI systems in the area of migration, asylum and border control management covered by this Regulation should comply with the relevant procedural requirements set by the Directive 2013/32/EU of the European Parliament and of the Council49 , the Regulation (EC) No 810/2009 of the European Parliament and of the Council50 and other relevant legislation.' '49 Directive 2013/32/EU of the European Parliament and of the Council of 26 June 2013 on common procedures for granting and withdrawing international protection (OJ L 180, 29.6.2013, p. 60).', '50 Regulation (EC) No 810/2009 of the European Parliament and of the Council of 13 July 2009 establishing a Community Code on Visas (Visa Code) (OJ L 243, 15.9.2009, p. 1).

Amendment 587
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 39
(39) AI systems used in migration, asylum and border control management affect people who are often in particularly vulnerable position and who are dependent on the outcome of the actions of the competent public authorities. The accuracy, non-discriminatory nature and transparency of the AI systems used in those contexts are therefore particularly important to guarantee the respect of the fundamental rights of the affected persons, notably their rights to free movement, non-discrimination, protection of private life and personal data, international protection and good administration. It is therefore appropriate to classify as high-risk AI systems intended to be used by the competent public authorities charged with tasks in the fields of migration, asylum and border control management. AI systems in the area of migration, asylum and border control management covered by this Regulation should comply with the relevant procedural requirements set by the Directive 2013/32/EU of the European Parliament and of the Council49 , the Regulation (EC) No 810/2009 of the European Parliament and of the Council50 and other relevant legislation.' '49 Directive 2013/32/EU of the European Parliament and of the Council of 26 June 2013 on common procedures for granting and withdrawing international protection (OJ L 180, 29.6.2013, p. 60).', '50 Regulation (EC) No 810/2009 of the European Parliament and of the Council of 13 July 2009 establishing a Community Code on Visas (Visa Code) (OJ L 243, 15.9.2009, p. 1).

Amendment 588
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 39
(39) AI systems used in migration, asylum and border control management affect people who are often in particularly vulnerable position and who are dependent on the outcome of the actions of the competent public authorities. The accuracy, non-discriminatory nature and transparency of the AI systems used in those contexts are therefore particularly important to guarantee the respect of the fundamental rights of the affected persons, notably their rights to free movement, non-discrimination, protection of private life and personal data, international protection and good administration. It is therefore appropriate to classify as high-risk AI systems intended to be used by the competent public authorities charged with tasks in the fields of migration, asylum and border control management; for verifying the authenticity of the relevant documents of natural persons; AI systems in the area of migration, asylum and border control management covered by this Regulation should comply with the relevant procedural requirements set by the Directive 2013/32/EU of the European Parliament and of the Council, the Regulation (EC) No 810/2009 of the European Parliament and of the Council and other relevant legislation.

Amendment 589
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Tineke
Recital 39
(39) AI systems used in migration, asylum and border control management affect people who are often in a particularly vulnerable position and who are dependent on the outcome of the actions of the competent public authorities. The accuracy, non-discriminatory nature and transparency of the AI systems used in those contexts are therefore particularly important to guarantee the respect of the fundamental rights of the affected persons, notably their rights to free movement, non-discrimination, protection of private life and personal data, international protection and good administration. It is therefore appropriate to classify as high-risk AI systems intended to be used by the competent public authorities charged with tasks in the fields of migration, asylum and border control management as applying for visa or asylum; for verifying the authenticity of the relevant documents of natural persons; for assisting competent public authorities for the examination of applications for asylum, visa and residence permits and associated complaints with regard to the objective to establish the eligibility of the natural persons applying for a status. AI systems in the area of migration, asylum and border control management covered by this Regulation should comply with the relevant procedural requirements set by the Directive 2013/32/EU of the European Parliament and of the Council, the Regulation (EC) No 810/2009 of the European Parliament and of the Council and other relevant legislation

Amendment 590
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte
Recital 39
(39) AI systems used in migration, asylum and border control management affect people who are sometimes in a vulnerable position and who are dependent on the outcome of the actions of the competent public authorities. The accuracy, non-discriminatory nature and transparency of the AI systems used in those contexts are therefore particularly important to guarantee the respect of the fundamental rights of the affected persons, notably, and where applicable, their rights to free movement, non-discrimination, protection of private life and personal data, international protection and good administration. It is therefore appropriate to classify as high-risk AI systems intended to be used by the competent public authorities charged with tasks in the fields of migration, asylum and border control management as polygraphs and similar tools or to detect the emotional state of a natural person; for assessing certain risks posed by natural persons entering the territory of a Member State or applying for visa or asylum; for verifying the authenticity of the relevant documents of natural persons; for assisting competent public authorities for the examination of applications for asylum, visa and residence permits and associated complaints with regard to the objective to establish the eligibility of the natural persons applying for a status. AI systems in the area of migration, asylum and border control management covered by this Regulation should comply with the relevant procedural requirements set by the Directive 2013/32/EU of the European Parliament and of the Council49, the Regulation (EC) No 810/2009 of the European Parliament and of the Council50 and other relevant legislation.' '49 Directive 2013/32/EU of the European Parliament and of the Council of 26 June 2013 on common procedures for granting and withdrawing international protection (OJ L 180, 29.6.2013, p. 60).', '50 Regulation (EC) No 810/2009 of the European Parliament and of the Council of 13 July 2009 establishing a Community Code on Visas (Visa Code) (OJ L 243, 15.9.2009, p. 1).

Amendment 591
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Tineke
Recital 39 a (new)
(39 a) The use of AI systems in migration, asylum and border control management should in no circumstances be used by Member States or European Union institutions as a means to circumvent their international obligations under the Convention of 28 July 1951 relating to the Status of Refugees as amended by the Protocol of 31 January 1967, nor should they be used to in any way infringe on the principle of non-refoulement, or or deny safe and effective legal avenues into the territory of the Union, including the right to international protection;

Amendment 592
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Recital 39 a (new)
(39 a) The use of AI systems in migration, asylum and border control management should in no circumstances be used by Member States or European Union institutions as a means to circumvent their international obligations under the Convention of 28 July 1951 relating to the Status of Refugees as amended by the Protocol of 31 January 1967, nor should they be used to in any way infringe on the principle of non-refoulement, or deny safe and effective legal avenues into the territory of the Union, including the right to international protection;

Amendment 593
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 39 a (new)
(39 a) The use of AI systems in migration, asylum and border control management should in no circumstances be used by Member States or European Union institutions as a means to circumvent their international obligations under the Convention of 28 July 1951 relating to the Status of Refugees as amended by the Protocol of 31 January 1967, nor should they be used to in any way infringe on the principle of non-refoulement, or deny safe and effective legal avenues into the territory of the Union, including the right to international protection;

Amendment 594
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 39 a (new)
(39 a) The use of AI systems in migration, asylum and border control management should in no circumstances be used by Member States or European Union institutions as a means to circumvent their international obligations under the Convention of 28 July 1951 relating to the Status of Refugees as amended by the Protocol of 31 January1967, nor should they be used to in any way infringe on the principle of non-refoulement, or deny safe and effective legal avenues into the territory of the Union, including the right to international protection;

Amendment 595
Renew - Renew Europe Group
Abir Al-Sahlani, Svenja Hahn, Samira Rafaela, Monica Semedo
Recital 39 a (new)
(39 a) The use of AI systems in migration, asylum and border management should however not, at any point, be used by Member States or by the institutions or agencies of the Union to infringe on the principle of non-refoulement, the right to asylum or to circumvent international obligations under the Convention of 28 July 1951 relating to the Status of Refugees as amended by the Protocol of 31 January 1967.

Amendment 596
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 40
(40) Certain AI systems intended for the administration of justice and democratic processes should be classified as high-risk, considering their potentially significant impact on democracy, rule of law, individual freedoms as well as the right to an effective remedy and to a fair trial. The use of Artificial Intelligence tools can support, but should not interfere with the decision-making power of judges or judicial independence, as the final decision-making must remain a human-driven activity and decision. In particular, to address the risks of potential biases, errors and opacity, it is appropriate to qualify as high-risk AI systems intended to assist judicial authorities in researching and interpreting facts and the law and in applying the law. Such qualification should not extend, however, to AI systems intended for purely ancillary administrative activities that do not affect the actual administration of justice in individual cases, such as anonymisation or pseudonymisation of judicial decisions, documents or data, communication between personnel, administrative tasks or allocation of resources

Amendment 597
ECR - European Conservatives and Reformists Group
Vincenzo Sofo, Kosma Złotowski
Recital 40
(40) Certain AI systems intended for the administration of justice and democratic processes should be classified as high-risk, considering their potentially significant impact on democracy, rule of law, individual freedoms as well as the right to an effective remedy and to a fair trial. In particular, to address the risks of potential biases, errors and opacity, it is appropriate to qualify as high-risk AI systems intended to assist judicial authorities in researching facts and the law. Such qualification should not extend, however, to AI systems intended for purely ancillary administrative activities that do not affect the actual administration of justice in individual cases, such as anonymisation or pseudonymisation of judicial decisions, documents or data, communication between personnel, administrative tasks or allocation of resources.

Amendment 598
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte
Recital 40
(40) Certain AI systems intended for the administration of justice and democratic processes should be prohibited, considering their potentially significant impact on democracy, rule of law, individual freedoms as well as the right to an effective remedy and to a fair trial. In particular, to address the risks of potential biases, errors and opacity, it is appropriate to prohibit the use of AI systems intended to assist judicial authorities in researching and interpreting facts and the law and in applying the law to a concrete set of facts. Such qualification should not extend, however, to AI systems intended for purely ancillary administrative activities that do not affect the actual administration of justice in individual cases, such as anonymisation or pseudonymisation of judicial decisions, documents or data, communication between personnel, administrative tasks or allocation of resources.

Amendment 599
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Dita Charanzová, Andrus Ansip, Morten Løkkegaard, Vlad-
Recital 40
(40) Certain AI systems intended for the administration of justice and democratic processes should be classified as high-risk, considering their potentially significant impact on democracy, rule of law, individual freedoms as well as the right to an effective remedy and to a fair trial. In particular, to address the risks of potential biases, errors and opacity, it is appropriate to qualify as high-risk AI systems intended to assist judicial authorities in interpreting facts or the law for applying the law to a concrete set of facts. Such qualification should not extend, however, to AI systems intended for purely ancillary administrative activities that do not affect the actual administration of justice in individual cases, such as anonymisation or pseudonymisation of judicial decisions, documents or data, communication between personnel, administrative tasks or allocation of resources.

Amendment 600
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 40 a (new)
(40 a) Another area in which the use of AI systems deserves special consideration is the use for health-related purposes, including healthcare. Next to medical devices (as per EU regulation 2017/745), other health-related AI systems also bring about risks which should be regulated. These include systems that influence individual’s health outcomes but do not meet the criteria for a medical device, systems that influence population health outcomes or health equality, systems that impact the distribution of healthcare resources and systems used by pharmaceutical and medical technology companies in research and development, pharmacovigilance, market optimisation and pharmaceutical marketing. Bias and errors in health-related AI systems can have major and immediate consequences for individuals’ and populations’ health and wellbeing. Further, many systems will use sensitive and personal data, which needs to be justified, and about which patients need to be properly informed. What is more, systems that work on hospital, health system, or population level may have a major effect on societal health because they influence the distribution of healthcare resources and health policy design. For these reasons, there is a need for trustworthy AI in healthcare, meaning people must be able to trust that systems used in healthcare are scientifically, technically and clinically valid, safe and accountable, and safeguard individuals’ autonomy and privacy.

Amendment 601
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 40 a (new)
(40 a) Certain AI systems should at the same time be subject to transparency requirements and be classified as high-risk AI systems, given their potential to deceive and cause both individual and societal harm. In particular, AI systems that generate deep fakes representing existing persons have the potential to both manipulate the natural persons that are exposed to those deep fakes and harm the persons they are representing or misrepresenting, while AI systems that, based on limited human input, generate complex text such as news articles, opinion articles, novels, scripts and scientific articles have the potential to manipulate, to deceive, or to expose natural persons to built-in biases or inaccuracies. These should not include AI systems intended to translate text, or cases where the content forms part of an evidently artistic, creative or fictional cinematographic and analogous work.

Amendment 602
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 40 a (new)
(40 a) When the “deep fake” content forms part of an evidently artistic, creative, or fictional cinematographic and analogous work, or when the “AI authors” generate content that undergoes human review and for the publication of which a natural or legal person established in the Union is liable or holds editorial responsibility, the AI systems should not be considered high-risk but should nevertheless be subject to adequate transparency requirements, where appropriate.

Amendment 603
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 40 a (new)
(40 a) Certain AI-systems used in the area of healthcare that are not covered by Regulation (EU) 2017/745 (Regulation on Medical Devices) should be high-risk. Uses such as software impacting diagnostics, treatments or medical prescriptions and access to health insurance can clearly impact health and safety, but also can also obstruct access to health services, impact the right to health care and cause physical harm in the long run.

Amendment 604
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Recital 40 a (new)
(40 a) Transparency requirements shall not apply where the content forms part of an evidently artistic, creative, satirical, fictional or analogous work or programme.

Amendment 605
Renew - Renew Europe Group
Morten Løkkegaard
Recital 40 a (new)
(40 a) Transparency requirements shall not apply where the content forms part of an evidently artistic, creative, satirical, fictional and analogous work or programme.

Amendment 606
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 40 b (new)
(40 b) Subliminal techniques are techniques that expose natural persons to sensorial stimuli that the natural persons cannot consciously perceive but that are assumed to register in the brain unconsciously, such as flashing images or text for fractions of a second or playing sounds outside the range of perceptible hearing. AI systems deploying such techniques should be prohibited, because these techniques are by their very nature intended to be manipulative. Nevertheless, exceptions are warranted for AI systems using subliminal techniques for research and therapeutical purposes, based on the consent of the natural persons that are being exposed to them. In such limited cases, the AI systems should be considered high-risk and comply with the requirements for high-risk AI systems as set forth in this Regulation.

Amendment 607
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 40 b (new)
(40 b) Certain AI-systems used in the area of media, particularly in the area of social media, due to their potentially large reach and the specific risk of large scale spread of disinformation and exacerbation of societal polarisation should be high-risk due to their potential impact on individuals’ rights, but also on society and democracy at large.

Amendment 608
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 41
(41) The fact that an AI system is classified as high risk under this Regulation should not be interpreted as indicating that the use of the system is necessarily lawful under other acts of Union law or under national law compatible with Union law, such as on the protection of personal data. Any such use should continue to occur solely in accordance with the applicable requirements resulting from the Charter and from the applicable acts of secondary Union law and national law. This Regulation should not be understood as providing for the legal ground for processing of personal data, including special categories of personal data.

Amendment 609
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 41
(41) The fact that an AI system is classified as high risk under this Regulation should not be interpreted as indicating that the use of the system is necessarily lawful under other acts of Union law or under national law compatible with Union law, such as on the protection of personal data. Any such use should continue to occur solely in accordance with the applicable requirements resulting from the Charter and from the applicable acts of secondary Union law and national law. This Regulation should not be understood as providing for the legal ground for processing of personal data, including special categories of personal data, where relevant.

Amendment 610
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 41
(41) The fact that an AI system is classified as high risk under this Regulation should not be interpreted as indicating that the use of the system is necessarily lawful under other acts of Union law or under national law compatible with Union law, such as on the protection of personal data. Any such use should continue to occur solely in accordance with the applicable requirements resulting from the Charter and from the applicable acts of secondary Union law and national law. This Regulation should not be understood as providing for the legal ground for processing of personal data, including special categories of personal data, where relevant.

Amendment 611
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 41
(41) The fact that an AI system is compliant with the requirements for high-risk AI under this Regulation should not be interpreted as indicating that the use of the system is necessarily unlawful under other acts of Union law or under national law compatible with Union law, such as on the protection of personal data, on the use of polygraphs and similar tools or other systems to detect the emotional state of natural persons. Any such use should continue to occur solely in accordance with the applicable requirements resulting from the Charter and from the applicable acts of secondary Union law and national law. As far as is applicable and proportionate, this Regulation may, where duly justified, be understood as providing for the legal ground for processing of personal data where relevant.

Amendment 612
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 41 a (new)
(41 a) AI systems do not operate in a lawless world. A number of legally binding rules at European, national and international level already apply or are relevant to AI systems today. Legal sources include, but are not limited to EU primary law (the Treaties of the European Union and its Charter of Fundamental Rights), EU secondary law (such as the General Data Protection Regulation, the Product Liability Directive, the Regulation on the Free Flow of Non-Personal Data, anti-discrimination Directives, consumer law and Safety and Health at Work Directives), the UN Human Rights treaties and the Council of Europe conventions (such as the European Convention on Human Rights), and numerous EU Member State laws. Besides horizontally applicable rules, various domain-specific rules exist that apply to particular AI applications (such as for instance the Medical Device Regulation in the healthcare sector).

Amendment 613
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 42
(42) To mitigate the risks from high-risk AI systems placed or otherwise put into service on the Union market for users and affected persons, certain mandatory requirements should apply, taking into account the intended purpose of the use of the system and according to the risk management system to be established by the provider. These requirements should be objective-driven, fit to purpose, reasonable and effective, without adding undue regulatory burdens or costs on operators.

Amendment 614
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 42
(42) To mitigate the risks from high-risk AI systems placed or otherwise put into service on the Union market for users and affected persons, certain mandatory requirements should apply, taking into account the intended purpose of the use of the system, level of reliance of the user or business user on the output of the AI system for the final decision or outcome and according to the risk management system to be established by the provider.

Amendment 615
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 42
(42) To mitigate the risks from high-risk AI systems placed or otherwise put into service on the Union market for deployers and AI subjects, certain mandatory requirements should apply, taking into account the intended purpose, the potential or reasonably foreseeable use or misuse of the system, and should be in accordance with the risk management system to be established by the provider.

Amendment 616
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 42
(42) To mitigate the risks from high-risk AI systems placed or otherwise put into service on the Union market for users and affected persons, certain mandatory requirements should apply, taking into account the intended purpose or reasonably foreseeable use of the system and according to the risk management system to be established by the provider.

Amendment 617
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 42
(42) To mitigate the risks from high-risk AI systems placed or otherwise put into service on the Union market for users and affected persons, certain mandatory requirements should apply, taking into account the foreseeable uses of the system and according to the risk management system to be established by the provider.

Amendment 618
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 43
(43) Requirements should apply to high-risk AI systems as regards the quality and relevance of data sets used, technical documentation and record-keeping, transparency and the provision of information to users, human oversight, and robustness, accuracy and security. Those requirements are necessary to effectively mitigate the risks for health, safety and fundamental rights, as well as the environment, society, rule of law, democracy, economic interests and consumer protection, as applicable in the light of the intended purpose, the potential or reasonably foreseeable use or misuse of the system, and no other less trade restrictive measures are reasonably available, thus avoiding unjustified restrictions to trade.

Amendment 619
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 43
(43) Requirements should apply to high-risk AI systems as regards the quality of data sets used, technical documentation and record-keeping, transparency and the provision of information to users, human oversight, and robustness, accuracy and cybersecurity. Those requirements are necessary to effectively mitigate the risks for health, safety, fundamental rights, the environment and the Union values enshrined in Article 2 TEU, as applicable in the light of the intended purpose or reasonably foreseeable use of the system, and no other less trade restrictive measures are reasonably available, thus avoiding unjustified restrictions to trade.

Amendment 620
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 43
(43) Requirements should apply to high-risk AI systems as regards the quality of data sets used, technical documentation and record-keeping, transparency and the provision of information to users, human oversight, and robustness, accuracy and cybersecurity. Those requirements are necessary to effectively mitigate the risks for health, safety and fundamental rights, as applicable in the light of the intended purpose or reasonably foreseeable use of the system, and no other less trade restrictive measures are reasonably available, thus avoiding unjustified restrictions to trade.

Amendment 621
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 43
(43) Requirements should apply to high-risk AI systems as regards the quality of data sets used, technical documentation and record-keeping, transparency and the provision of information to users, human oversight, and robustness, accuracy and cybersecurity. Those requirements are necessary to effectively mitigate the risks for health, safety and fundamental rights, as applicable in the light of the foreseeable uses of the system, and no other less trade restrictive measures are reasonably available, thus avoiding unjustified restrictions to trade.

Amendment 622
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Andrzej Halicki, Adam Jarubas, Jerzy Buzek, Janusz Lewandowski,
Recital 43 a (new)
(43 a) Fundamental rights impact assessments for high-risk AI systems may include a clear outline of the intended purpose for which the system will be used, a clear outline of the intended geographic and temporal scope of the system’s use, categories of natural persons and groups likely to be affected by the use of the system or any specific risk of harm likely to impact marginalised persons or groups at risk of discrimination, or increase societal inequalities;

Amendment 623
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 44
(44) High data quality and having simple and accessible data plays a vital role in providing structure and ground truth for AI and are essential for purpose-ready data analytics and the performance of many AI systems, especially when techniques involving the training of models are used, with a view to ensure that the high-risk AI system performs as intended and safely and it does not become the source of discrimination prohibited by Union law. To achieve simple access to and usability of high quality data for AI, the Commission should examine ways to facilitate the lawful processing of personal data to train legitimate AI systems by appropriate amendments to applicable laws. High quality training, validation and testing data sets require the implementation of appropriate data governance and management practices. Training, machine learning validation and testing data sets should be sufficiently relevant and representative in view of the intended purpose of the system. They should also have the appropriate statistical properties, including as regards the persons or groups of persons on which the high-risk AI system is intended to be used. In particular, training, machine learning validation and testing data sets should take into account, to the extent required in the light of their intended purpose, the features, characteristics or elements that are particular to the specific geographical, behavioural or functional setting or context within which the AI system is intended to be used. If it is necessary for the aforementioned purpose to use existing sets of data that includes personal data originally collected and stored for a different purpose, their use for the aforementioned purpose should be deemed compatible with the original purpose so long as the personal data is not transferred to any third party. In order to protect the right of others from the discrimination that might result from the bias in AI systems, the providers should be able to process also special categories of personal data, as a matter of substantial public interest, in order to ensure the bias monitoring, detection and correction in relation to high-risk AI systems.

Amendment 624
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 44
(44) High data quality is essential for the performance of many AI systems, especially when techniques involving the training of models are used, with a view to ensure that the high-risk AI system performs as intended and safely and it does not become the source of discrimination prohibited by Union law. High quality training, validation and testing data sets require the implementation of appropriate data governance and management practices. Training, validation and testing data sets should be sufficiently relevant, representative and free of errors and complete in view of the intended purpose of the system. They should also have the appropriate statistical properties, including as regards the persons or groups of persons on which the high-risk AI system is intended to be used. In particular, training, validation and testing data sets should take into account, to the extent required in the light of their intended purpose, the features, characteristics or elements that are particular to the specific geographical, behavioural or functional setting or context within which the AI system is intended to be used.

Amendment 625
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Recital 44
(44) High data quality is essential for the performance of many AI systems, especially when techniques involving the training of models are used, with a view to ensure that the high-risk AI system performs as intended and safely and it does not become the source of discrimination prohibited by Union law. High quality training, validation and testing data sets require the implementation of appropriate data governance and management practices. Training, validation and testing data sets should be sufficiently relevant, representative as complete and close to zero error as possible. A procedure to check data and completeness in view of the intended purpose of the system should be implemented. They should also have the appropriate statistical properties, including as regards the persons or groups of persons on which the high-risk AI system is intended to be used. In particular, training, validation and testing data sets should take into account, to the extent required in the light of their intended purpose, the features, characteristics or elements that are particular to the specific geographical, behavioural or functional setting or context within which the AI system is intended to be used. In order to protect the right of others from the discrimination that might result from the unfair bias in AI systems, the providers shouldbe able to process also special categories of personal data, as a matter of substantial public interest, in order to ensure the unfair bias monitoring, detection and correction in relation to high-risk AI systems.

Amendment 626
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 44
(44) High data quality is essential for the performance of many AI systems, especially when techniques involving the training of models are used, with a view to ensure that the high-risk AI system performs as intended and safely and it does not become the source of discrimination prohibited by Union law. High quality training, validation and testing data sets require the implementation of appropriate data governance and management practices. Training, validation and testing data sets should be sufficiently relevant, representative and free of errors and complete in view of the foreseeable uses of the system. They should also have the appropriate statistical properties, including as regards the persons or groups of persons on which the high-risk AI system is intended to be used. In particular, training, validation and testing data sets should take into account, to the extent required in the light of their foreseeable uses, the features, characteristics or elements that are particular to the specific geographical, behavioural or functional setting or context within which the AI system is intended to be used. In order to protect the right of others from the discrimination that might result from the bias in AI systems, the providers should ensure the bias monitoring, detection and correction in relation to high-risk AI systems.

Amendment 627
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 44
(44) High data quality is essential for the performance of many AI systems, especially when techniques involving the training of models are used, with a view to ensure that the high-risk AI system performs as intended and safely and it does not become the source of discrimination prohibited by Union law. High quality training, validation and testing data sets require the implementation of appropriate data governance and management practices. Training, validation and testing data sets should be sufficiently relevant, representative and free of errors and complete in view of the intended purpose or reasonably foreseeable use of the system. They should also have the appropriate statistical properties, including as regards the persons or groups of persons on which the high-risk AI system is intended to be used. In particular, training, validation and testing data sets should take into account, to the extent required in the light of their intended purpose or reasonably foreseeable use , the features, characteristics or elements that are particular to the specific geographical, behavioural or functional setting or context within which the AI system is intended or foreseeable to be used. In order to protect the right of others from the discrimination that might result from the bias in AI systems, the providers should be able to process also special categories of personal data, as a matter of substantial public interest, in order to ensure the bias monitoring, detection and correction in relation to high-risk AI systems.

Amendment 628
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 44
(44) High data quality is essential for the performance of many AI systems, especially when techniques involving the training of models are used, with a view to ensure that the high-risk AI system performs as intended and safely and it does not become a source of discrimination prohibited by Union law. High quality training, validation and testing data sets require the implementation of appropriate data governance and management practices. Training, validation and testing data sets should be sufficiently relevant, representative and free of errors, statistically complete and relevant in view of the intended purpose of the system and the context of its use. They should also have the appropriate statistical properties, including as regards the persons or groups of persons in relation to whom the high-risk AI system is intended to be used. In particular, training, validation and testing data sets should take into account, to the extent necessary in the light of their intended purpose, the features, characteristics or elements that are particular to the specific geographical, behavioural or functional setting or context within which the AI system is intended to be used. Solely in order to protect the right of others from the discrimination that might result from the bias in AI systems, the providers should be able to process special categories of personal data, as a matter of substantial public interest, in order to ensure bias monitoring, detection and correction in relation to high-risk AI systems.

Amendment 629
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 44
(44) High data quality is essential for the performance of many AI systems, especially when techniques involving the training of models are used, with a view to ensure that the high-risk AI system performs as intended and safely and it does not become the source of discrimination prohibited by Union law. High quality training, validation and testing data sets require the implementation of appropriate data governance and management practices. Training datasets, and where applicable, validation and testing datasets, including the labels, shall be relevant, representative, up-to-date, and to the best extent possible, free of errors and complete. They should also have the appropriate statistical properties, including as regards the persons or groups of persons on which the high-risk AI system is intended to be used. In particular, data sets should take into account, to the extent required by the intended purpose, the foreseeable uses and reasonably foreseeable misuses of AI systems with indeterminate uses, the features, characteristics or elements that are particular to the specific geographical, behavioural or functional setting or context within which the AI system is intended to be used.

Amendment 630
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Recital 44
(44) High data quality is essential for the performance of many AI systems, especially when techniques involving the training of models are used, with a view to ensure that the high-risk AI system performs as intended and safely and it does not become the source of discrimination prohibited by Union law. High quality training, validation and testing data sets require the implementation of appropriate data governance and management practices. Training, validation and testing data sets should be sufficiently relevant, representative in view of the intended purpose of the system. They should also have the appropriate statistical properties, including as regards the persons or groups of persons on which the high-risk AI system is intended to be used. In particular, training, validation and testing data sets should take into account, to the extent required in the light of their intended purpose, the features, characteristics or elements that are particular to the specific geographical, behavioural or functional setting or context within which the AI system is intended to be used. In order to protect the right of others from the discrimination that might result from the bias in AI systems, the providers shouldbe able to process also special categories of personal data, as a matter of substantial public interest, in order to ensure the bias monitoring, detection and correction in relation to high-risk AI systems.

Amendment 631
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 44 a (new)
(44 a) Biases can be inherent in underlying datasets, especially when historical data is being used, introduced by the developers of the algorithms, or generated when the systems are implemented in real world settings. Any result provided by an AI system is necessarily influenced by the quality of the data used, and such inherent biases are inclined to gradually increase and thereby perpetuate and amplify existing discrimination, in particular for persons belonging to certain ethnic groups or racialised communities.

Amendment 632
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 45
(45) For the development of high-risk AI systems, certain actors, such as providers, notified bodies and other relevant entities, such as digital innovation hubs, testing experimentation facilities and researchers, should be able to access and use high quality datasets within their respective fields of activities which are related to this Regulation. European common data spaces established by the Commission, developed and operated by European actors and which do not transfer any data outside the territory or legal jurisdiction of the European Union, and the facilitation of data sharing between businesses and with government in the public interest will be instrumental to provide trustful, accountable and non-discriminatory access to high quality data for the training, validation and testing of AI systems. For example, in health, the European health data space will facilitate non-discriminatory access to health data and the training of artificial intelligence algorithms on those datasets, in a privacy-preserving, secure, timely, transparent and trustworthy manner, and with an appropriate institutional governance. Relevant competent authorities, including sectoral ones, providing or supporting the access to data may also support the provision of high-quality data for the training, validation and testing of AI systems.

Amendment 633
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 46
(45) For the development and assessment of high-risk AI systems, certain actors, such as providers, notified bodies and other relevant entities, such as digital innovation hubs, testing experimentation facilities and researchers, should be able to access and use high quality datasets within their respective fields of activities which are related to this Regulation. European common data spaces established by the Commission and the facilitation of data sharing between businesses and with government in the public interest will be instrumental to provide trustful, accountable and non-discriminatory access to high quality data for the training, validation and testing of AI systems. For example, in health, the European health data space will facilitate non-discriminatory access to health data and the training of artificial intelligence algorithms on those datasets, in a privacy-preserving, secure, timely, transparent and trustworthy manner, and with an appropriate institutional governance. Relevant competent authorities, including sectoral ones, providing or supporting the access to data may also support the provision of high-quality data for the training, validation and testing of AI systems.

Amendment 634
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 46
(46) Having information on how high-risk AI systems have been developed and how they perform throughout their lifecycle is essential to verify compliance with the requirements under this Regulation. This requires keeping records and the availability of a technical documentation, containing information which is necessary to assess the compliance of the AI system with the relevant requirements. Such information should include the general characteristics, capabilities and limitations of the system, algorithms, data, training, testing and validation processes used as well as documentation on the relevant risk management system. The technical documentation should be kept up to date. The required technical documentation may contain trade secrets in accordance with Directive (EU) 2016/943 of the European Parliament and of the Council of 8 June 2016 on the protection of undisclosed know-how and business information (trade secrets) against their unlawful acquisition, use and disclosure. Possible trade secrets in the required documentation must be treated and kept in accordance with national legislation put in place in accordance with mentioned directive.

Amendment 635
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 46
(46) Having information on how high-risk AI systems have been developed and how they perform throughout their lifecycle is essential to verify compliance with the requirements under this Regulation. This requires keeping records and the availability of a technical documentation, containing information which is necessary to assess the compliance of the AI system with the relevant requirements. Such information should include the general characteristics, capabilities and limitations of the system, algorithms, data, training, testing and validation processes used as well as documentation on the relevant risk management system. The technical documentation should be kept up to date throughout the entire lifecycle of the AI system.

Amendment 636
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 46
(46) Having information on how high-risk AI systems have been developed and how they perform throughout their lifetime is essential to verify compliance with the requirements under this Regulation. This requires keeping records and the availability of a technical documentation, containing information which is necessary to assess the compliance of the AI system with the relevant requirements, while preserving trade secrets. Such information should include the general characteristics, capabilities and limitations of the system, algorithms, data, training, testing and validation processes used as well as documentation on the relevant risk management system. The technical documentation should be kept up to date.

Amendment 637
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 47
(47) To address the opacity that may make certain AI systems incomprehensible to or too complex for natural persons, a certain degree of transparency should be required for high-risk AI systems. Deployers should be able to interpret the system’s goals, priorities and output and use it appropriately. High-risk AI systems should therefore be accompanied by relevant documentation and instructions of use and include concise and clear information, including in relation to possible risks to fundamental rights and discrimination, where appropriate. Where individuals are passively subject to AI systems (AI subjects), information to ensure an appropriate type and degree of transparency should be made publicly available, with full respect to the privacy, personality, and related rights of subjects.

Amendment 638
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 47 a (new)
(47 a) It is vital to ensure that the development, deployment and use of AI systems for the judiciary and law enforcement comply with fundamental rights, and are trusted by citizens, as well as in order to ensure that results generated by AI algorithms can be rendered intelligible to users and to those subject to these systems, and that there is transparency on the source data and how the system arrived at a certain conclusion. To this aim, law enforcement or judiciary authorities in the Union should use only such AI systems whose algorithms and logic are auditable and accessible at least to the police and the judiciary, as well as independent auditors, to allow for their evaluation, auditing and vetting, and such systems should not be closed or labelled as proprietary by the vendors.

Amendment 639
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 48
(48) High-risk AI systems should be designed and developed in such a way that natural persons may, when appropriate, oversee their functioning. For this purpose, when it brings proven added value to the protection of health, safety and fundamental rights, appropriate human oversight measures should be identified by the provider of the system before its placing on the market or putting into service. In particular, where appropriate, such measures should guarantee that the system is subject to in-built operational constraints and are responsive to the human operator during the expected lifetime of the device where necessary to reduce risks as far as possible and achieve performance in consideration of the generally acknowledged state-of-the-art and technological and scientific progress, and that the natural persons to whom human oversight has been assigned have the necessary competence, training and authority to carry out that role. By way of derogation regarding high-risk AI systems within the scope of Regulation (EU) 2017/745 and Regulation (EU) 2017/746 of the European Parliament and of the Council, the established benefit-risk ratio requirements under the sectoral medical device legislation should apply.

Amendment 640
EPP - Group of the European Peoples Party (Christian Democrats)
Deirdre Clune, Axel Voss, Andreas Schwab
Recital 48
(48) High-risk AI systems should be designed and developed in such a way that natural persons may, when appropriate, oversee their functioning. For this purpose, when it brings proven added value to the protection of health, safety and fundamental rights, appropriate human oversight measures should be identified by the provider of the system before its placing on the market or putting into service. In particular, where appropriate, such measures should guarantee that the system is subject to in-built operational constraints and are responsive to the human operator during the expected lifetime of the device where necessary to reduce risks as far as possible and achieve performance in consideration of the generally acknowledged state-of-the-art technological and scientific progress, and that the natural persons to whom human oversight has been assigned have the necessary competence, training and authority to carry out that role. By way of derogation regarding high-risk AI systems within the scope of Regulation (EU) 2017/745 and Regulation (EU) 2017/746 of the European Parliament and of the Council, the established benefit-risk ratio requirements under the sectoral medical device legislation should apply.

Amendment 641
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki
Recital 48
(48) High-risk AI systems should be designed and developed in such a way that natural persons may, when appropriate, oversee their functioning. For this purpose, when it brings a proven added value to the protection of health, safety and fundamental rights, appropriate human oversight measures should be identified by the provider of the system before its placing on the market or putting into service. In particular, where appropriate, such measures should guarantee that the system is subject to in-built operational constraints that cannot be overridden by the system itself and is responsive to the human operator, and that the natural persons to whom human oversight has been assigned have the necessary competence, training and authority to carry out that role.

Amendment 642
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 48
(48) High-risk AI systems should be designed and developed in such a way that natural persons can actually oversee their functioning. For this purpose, appropriate human oversight measures should be identified by the provider of the system before its placing on the market or putting into service. In particular, where appropriate, such measures should guarantee that the system is subject to in-built operational constraints that cannot be overridden by the system itself, that it cannot make decisions without approval by the human operator, that it is responsive to the human operator, and that the natural persons to whom human oversight has been assigned have the necessary competence, training and authority to carry out that role.

Amendment 643
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 48
(48) High-risk AI systems should be designed and developed in such a way that natural persons can meaningfully oversee and regulate their functioning or investigate in case of an accident. For this purpose, appropriate human oversight measures should be ensured by the provider of the system before its placing on the market or putting into service. In particular, where appropriate, such measures should guarantee that the system is subject to in-built operational constraints that cannot be overridden by the system itself and is responsive to the human operator, and that the natural persons to whom human oversight has been assigned have the necessary competence, training and authority to carry out that role.

Amendment 644
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 48 a (new)
(48 a) In order to protect natural persons that are developers or users of AI systems against retaliation from their employers and colleagues, and to prevent misconduct or breaches of this Regulation and other relevant Union law, they should have the right to rely on the whistleblower protections set in Directive (EU) 2019/1937 of the European Parliament and of the Council.

Amendment 645
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 49
(49) High-risk AI systems should perform consistently throughout their lifetime and meet an appropriate level of accuracy, robustness and cybersecurity in accordance with the generally acknowledged state of the art. The level of accuracy and accuracy metrics should be communicated to the users. While standardisation organisations exist to establish standards, coordination on benchmarking is needed to establish how these standards should be met and measured. The European Artificial Intelligence Board should bring together national metrology and benchmarking authorities and provide guidance to address the technical aspects of how to measure the appropriate levels of accuracy and robustness. Their work should not be seen as a replacement of the standardisation organisations, but as a complementary function to provide specific technical expertise on measurement.

Amendment 646
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 49
(49) High-risk AI systems should perform consistently throughout their lifecycle and meet an appropriate level of accuracy, robustness and cybersecurity in accordance with the generally acknowledged state of the art. The level of accuracy and accuracy metrics should be defined by standards or common technical specifications and communicated to the users. The European Commission should be able to decide on such standards or common technical specifications or to adopt existing ones developed by third parties such as suppliers, stakeholders or standardisation bodies.

Amendment 647
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 49
(49) High-risk AI systems should perform consistently throughout their lifecycle and meet an appropriate level of accuracy, robustness, reliability and security in accordance with the generally acknowledged state of the art. The level of accuracy and accuracy metrics should be communicated to the deployers.

Amendment 648
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 50
(50) Technical robustness is a key requirement for high-risk AI systems. They should be resilient against risks connected to the limitations of the system (e.g. errors, faults, inconsistencies, unexpected situations) as well as adequately protected against malicious actions that may compromise the security of the AI system and result in harmful or otherwise undesirable behaviour. Failure to protect against these risks could lead to safety impacts or negatively affect fundamental rights, for example due to erroneous decisions or wrong or biased outputs generated by the AI system.

Amendment 649
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 51
(51) Cybersecurity plays a crucial role in ensuring that AI systems are resilient against attempts to alter their use, behaviour, performance or compromise their security properties by malicious third parties exploiting the system’s vulnerabilities. Cyberattacks against AI systems can leverage AI specific assets, such as training data sets (e.g. data poisoning) or trained models (e.g. adversarial attacks), or exploit vulnerabilities in the AI system’s digital assets or the underlying ICT infrastructure. To ensure a level of cybersecurity appropriate to the risks, state-of-the-art measures should therefore be taken into account by the providers of high-risk AI systems but also by the national competent authorities, market surveillance authorities and notified bodies that are accessing the data of providers of high-risk AI systems, next to appropriate underlying ICT infrastructure. It should be further taken into account that AI in the form of machine learning is a critical defence against malware representing a legitimate interest of the AI user.

Amendment 650
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan, Vincenzo Sofo
Recital 51
(51) Cybersecurity plays a crucial role in ensuring that AI systems are resilient against attempts to alter their use, behaviour, performance or compromise their security properties by malicious third parties exploiting the system’s vulnerabilities. Cyberattacks against AI systems can leverage AI specific assets, such as training data sets (e.g. data poisoning) or trained models (e.g. adversarial attacks), or exploit vulnerabilities in the AI system’s digital assets or the underlying ICT infrastructure. To ensure a level of cybersecurity appropriate to the risks, suitable measures should therefore be taken by the providers of high-risk AI systems, as well as the notified bodies, competent national authorities and market surveillance authorities accessing the data of providers of high-risk AI systems, also taking into account as appropriate the underlying ICT infrastructure.

Amendment 651
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 51
(51) Cybersecurity plays a crucial role in ensuring that AI systems are resilient against attempts to alter their use, behaviour, performance or compromise their security properties by malicious third parties exploiting the system’s vulnerabilities. Cyberattacks against AI systems can leverage AI specific assets, such as training data sets (e.g. data poisoning) or trained models (e.g. adversarial attacks), or exploit vulnerabilities in the AI system’s digital assets or the underlying ICT infrastructure. To ensure a level of cybersecurity appropriate to the risks, suitable measures should therefore be taken by the providers of high-risk AI systems, as well as the notified bodies, competent national authorities and market surveillance authorities, also taking into account as appropriate the underlying ICT infrastructure.

Amendment 652
EPP - Group of the European Peoples Party (Christian Democrats)
Karlo Ressler
Recital 51
(51) Cybersecurity plays a crucial role in ensuring that AI systems are resilient against attempts to alter their use, behaviour, performance or compromise their security properties by malicious third parties exploiting the system’s vulnerabilities. Cyberattacks against AI systems can leverage AI specific assets, such as training data sets (e.g. data poisoning) or trained models (e.g. adversarial attacks), or exploit vulnerabilities in the AI system’s digital assets or the underlying ICT infrastructure. To ensure a level of cybersecurity appropriate to the risks, suitable measures should therefore be taken by the providers of high-risk AI systems, as well as the competent public authorities accessing the data of providers of high-risk AI systems, also taking into account as appropriate the underlying ICT infrastructure.

Amendment 653
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 51
(51) Cybersecurity plays a crucial role in ensuring that AI systems are resilient against attempts to alter their use, behaviour, performance or compromise their security properties by malicious third parties exploiting the system’s vulnerabilities. Cyberattacks against AI systems can target AI specific assets, such as training data sets (e.g. data poisoning) or trained models (e.g. adversarial attacks), or exploit vulnerabilities in the AI system’s digital assets or the underlying ICT infrastructure. To ensure a level of cybersecurity appropriate to the risks, suitable measures should therefore be taken by the providers of high-risk AI systems, also taking into account as appropriate the underlying ICT infrastructure.

Amendment 654
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 51
(51) Cybersecurity plays a crucial role in ensuring that AI systems are resilient against attempts to alter their use, behaviour, performance or compromise their security properties by malicious third parties exploiting the system’s vulnerabilities. Cyberattacks against AI systems can leverage AI specific assets, such as training data sets (e.g. data poisoning) or trained models (e.g. adversarial attacks), or exploit vulnerabilities in the AI system’s digital assets or the underlying ICT infrastructure. To ensure a level of cybersecurity appropriate to the risks, suitable measures should therefore be taken by the providers of high-risk AI systems, also taking into account the underlying ICT infrastructure.

Amendment 655
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 53
(53) It is appropriate that a specific natural or legal person, defined as the provider, takes the responsibility for the placing on the market or putting into service of a high-risk AI system, regardless of whether that natural or legal person is the person who designed or developed the system, without prejudice to the right of a provider to take action against the manufacturer of that system.

Amendment 656
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 53
(53) It is appropriate that a specific natural or legal person, defined as the provider, takes the responsibility for the placing on the market, putting into service or deploying of a high-risk AI system, regardless of whether that natural or legal person is the person who designed or developed the system.

Amendment 657
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 54
(54) The provider and, where applicable, deployer should establish a sound quality management system, ensure the accomplishment of the required conformity assessment procedure, draw up the relevant documentation and establish a robust post-market monitoring system. Public authorities which put into service high-risk AI systems for their own use may adopt and implement the rules for the quality management system as part of the quality management system adopted at a national or regional level, as appropriate, taking into account the specificities of the sector and the competences and organisation of the public authority in question. Deployers should have strategies in place to ensure that the data management, including data acquisition, data collection, data analysis, data labelling, data storage, data filtration, data mining, data aggregation, data retention and any other operation regarding the data during the deployment lifetime of high-risk AI systems, complies with applicable rules and ensure regulatory compliance, in particular regarding modifications to the high-risk AI systems.

Amendment 658
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Recital 54
(54) The provider should establish a sound quality management system, ensure the accomplishment of the required conformity assessment procedure, draw up the relevant documentation in the language of the Member State concerned and establish a robust post-market monitoring system. All elements, from design to future development, must be transparent for the user. Public authorities which put into service high-risk AI systems for their own use may adopt and implement the rules for the quality management system as part of the quality management system adopted at a national or regional level, as appropriate, taking into account the specificities of the sector and the competences and organisation of the public authority in question.

Amendment 659
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Recital 54
(54) Unless the provider has already implemented a risk management system warranting quality and conformity, the provider should establish a sound quality management system, ensure the accomplishment of the required conformity assessment procedure, draw up the relevant documentation and establish a robust post-market monitoring system. Public authorities which put into service high-risk AI systems for their own use may adopt and implement the rules for the quality management system as part of the quality management system adopted at a national or regional level, as appropriate, taking into account the specificities of the sector and the competences and organisation of the public authority in question.

Amendment 660
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Recital 54
(54) In case there are no risk management systems already in place, the provider should establish a sound quality management system, ensure the accomplishment of the required conformity assessment procedure, draw up the relevant documentation and establish a robust post-market monitoring system. Public authorities which put into service high-risk AI systems for their own use may adopt and implement the rules for the quality management system as part of the quality management system adopted at a national or regional level, as appropriate, taking into account the specificities of the sector and the competences and organisation of the public authority in question.

Amendment 661
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 56
(56) To enable enforcement of this Regulation and create a level-playing field for operators, and taking into account the different forms of making available of digital products, it is important to ensure that, under all circumstances, a person established in the Union can provide authorities with all the necessary information on the compliance of an AI system. Therefore, prior to placing any AI system on the Union market, putting it into service or using it, where an importer cannot be identified, operators established outside the Union should, by written mandate, appoint a legal representative established in the Union. The legal representative should act on behalf of the operator and may be addressed by any competent authorities for the purpose of this Regulation. The designation of such a legal representative does not affect the responsibility or liability of the operator under this Regulation. Such a legal representative should perform its tasks according to the mandate received from the operator, including cooperating with the national supervisory authorities with regard to any action taken to ensure compliance with this Regulation. The designated legal representative should be subject to enforcement proceedings in the event of non-compliance by the operator.

Amendment 662
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz
Recital 56
(56) To enable enforcement of this Regulation and create a level-playing field for operators, and taking into account the different forms of making available of digital products, it is important to ensure that, under all circumstances, a person established in the Union can provide authorities with all the necessary information on the compliance of an AI system. Therefore, prior to making their AI systems available in the Union, providers established outside the Union shall, by written mandate, appoint an authorised representative established in the Union.

Amendment 663
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 58
(58) Given the nature of AI systems and the risks to safety and fundamental rights possibly associated with their use, including as regard the need to ensure proper monitoring of the performance of an AI system in a real-life setting, it is appropriate to set specific responsibilities for users. Users should in particular use high-risk AI systems in accordance with the instructions of use and certain other obligations should be provided for with regard to monitoring of the functioning of the AI systems and with regard to record-keeping, as appropriate. Given the potential impact and the need for democratic oversight and scrutiny, users of high-risk AI systems that are public authorities or Union institutions, bodies, offices and agencies should be required to conduct a fundamental rights impact assessment prior to commencing the use of a high-risk AI system should be required to register the use of any high-risk AI systems in a public database.

Amendment 664
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 58
(58) Given the nature of AI systems and the risks to safety and fundamental rights possibly associated with their use, including as regard the need to ensure proper monitoring of the performance of an AI system in a real-life setting, it is appropriate to set specific responsibilities for users. Users should in particular use high-risk AI systems for the purpose for which they were intended and in accordance with the instructions of use, to that end high-risk AI systems should structurally limit, to the greatest extent possible, the technical possibility for a user to use these AI systems in another way, and certain other obligations should be provided for with regard to monitoring of the functioning of the AI systems and with regard to record-keeping, as appropriate.

Amendment 665
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 58
(58) Given the nature of AI systems and the risks to safety and fundamental rights possibly associated with their use, including as regards the need to ensure proper monitoring of the performance of an AI system in a real-life setting, it is appropriate to set specific responsibilities for deployers. Deployers should in particular use high-risk AI systems in accordance with the instructions of use and certain other obligations should be provided for with regard to monitoring of the functioning of the AI systems and with regard to record-keeping and quality management, as appropriate.

Amendment 666
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 58 a (new)
(58 a) Whilst risks related to AI systems can generate from the way such systems are designed, risks can as well stem from how such AI systems are used. Users of high-risk AI system therefore play a critical role in ensuring that fundamental rights are protected, complementing the obligations of the provider when developing the AI system. Users are best placed to understand how the high-risk AI system will be used concretely and can therefore identify potential risks that were not foreseen in the development phase, thanks to a more precise knowledge of the context of use, the people or groups of people likely to be affected, including marginalised and vulnerable groups. In order to efficiently ensure that fundamental rights are protected, the user of high-risk AI systems should therefore carry out a fundamental rights impact assessment on how it intends to use such AI systems, and prior to putting it into use. The impact assessment should be accompanied by a detailed plan describing the measures or tools that will help mitigating the risks to fundamental rights identified. When performing this impact assessment, the user should notify the national supervisory authority, the market surveillance authority as well as relevant stakeholders. It should also involve representatives of groups of persons likely to be affected by the AI system in order to collect relevant information which is deemed necessary to perform the impact assessment.

Amendment 667
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 58 a (new)
(58 a) To ensure that fundamental rights, the environment and the public interest are effectively protected where an AI-system is classified as high-risk under Annex III, both producers and deployers before each deployment should perform a fundamental rights impact assessment of the systems’ impact in the context of use throughout the entire lifecycle and include measures to mitigate any impact on fundamental rights, the environment or the public interest. The fundamental rights impact assessment should be registered in the public EU database for stand-alone high-risk AI systems and be publicly accessible. The supervisory authority should have the power to review these fundamental rights impact assessments.

Amendment 668
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 58 a (new)
(58 a) Risks for people affected by AI systems often arise from uses of an AI system in a specific context and with respect to a specific group of people, and might not always be foreseeable for the provider. Therefore, prior to putting a high-risk AI system into use, the user should conduct an assessment of the system’s impact on the fundamental rights in particular, within the context of use, and publish the results.

Amendment 669
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 59
(59) It is appropriate to envisage that the user of the AI system should be the natural or legal person, public authority, agency or other body under whose authority the AI system is operated.

Amendment 670
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 59
(59) It is appropriate to envisage that the deployer of the AI system should be the natural or legal person, public authority, agency or other body under whose authority the AI system is operated except where the use is made in the course of a personal non-professional activity.

Amendment 671
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Recital 60
(60) In the light of the complexity of the artificial intelligence value chain, relevant third parties, notably the ones involved in the sale and the supply of software, software tools and components, pre-trained models and data, or providers of network services, should cooperate, as appropriate, with providers and users to enable their compliance with the obligations under this Regulation and with competent authorities established under this Regulation. This provision shall qualify as a legal obligation in the context of the processing of personal data where necessary for the cooperation between the relevant providers.

Amendment 672
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 60
(60) In the light of the complexity of the artificial intelligence value chain, relevant third parties, notably the ones involved in the sale and the supply of software, software tools and components, pre-trained models and data, or providers of network services, should cooperate, as appropriate, with providers and deployers to enable their compliance with the obligations under this Regulation and with competent authorities established under this Regulation.

Amendment 673
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul Garraud
Recital 61
(61) Standardisation should play a key role to provide technical solutions to providers to ensure compliance with this Regulation, in particular as regards the levels and metrics of accuracy and robustness for high-risk AI systems. The Commission should be able to adopt common technical specifications in areas where no harmonised standards exist or where they are insufficient. The Commission should also be able to adopt standards or common technical specifications developed by third parties such as suppliers, stakeholders or standardisation bodies. Compliance with the common technical specifications adopted by the Commission should be a means for suppliers to demonstrate compliance with the requirements of this Regulation. Compliance with other harmonised standards set out in Regulation (EU) No 1025/2012 of the European Parliament and of the Council54 should also help to demonstrate suppliers’ compliance with the requirements of this Regulation, without having the same probative value as the common technical specifications adopted by the Commission.' '54 Regulation (EU) No 1025/2012 of the European Parliament and of the Council of 25 October 2012 on European standardisation, amending Council Directives 89/686/EEC and 93/15/EEC and Directives 94/9/EC, 94/25/EC, 95/16/EC, 97/23/EC, 98/34/EC, 2004/22/EC, 2007/23/EC, 2009/23/EC and 2009/105/EC of the European Parliament and of the Council and repealing Council Decision 87/95/EEC and Decision No 1673/2006/EC of the European Parliament and of the Council (OJ L 316, 14.11.2012, p. 12).

Amendment 674
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Recital 61
(61) Standardisation should play a key role to provide technical solutions to providers to ensure compliance with this Regulation. Compliance with harmonised standards as defined in Regulation (EU) No 1025/2012 of the European Parliament and of the Council54 should be a means for providers to demonstrate conformity with the requirements of this Regulation. However, the Commission could adopt common technical specifications in areas where no harmonised standards exist and are not expected to be published within a reasonable period or where they are insufficient, only after consulting the Artificial Intelligence Board, the European standardisation organisations as well as the relevant stakeholders. The Commission should duly justify why it decided not to use harmonised standards.' '54 Regulation (EU) No 1025/2012 of the European Parliament and of the Council of 25 October 2012 on European standardisation, amending Council Directives 89/686/EEC and 93/15/EEC and Directives 94/9/EC, 94/25/EC, 95/16/EC, 97/23/EC, 98/34/EC, 2004/22/EC, 2007/23/EC, 2009/23/EC and 2009/105/EC of the European Parliament and of the Council and repealing Council Decision 87/95/EEC and Decision No 1673/2006/EC of the European Parliament and of the Council (OJ L 316, 14.11.2012, p. 12).

Amendment 675
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 61
(61) Standardisation should play a key role to provide technical solutions to providers to ensure compliance with this Regulation. Compliance with harmonised standards as defined in Regulation (EU) No 1025/2012 of the European Parliament and of the Council54 should be a means for providers to demonstrate conformity with the requirements of this Regulation. However, in exceptional cases, where industry and technical experts consider that pressing and specific safety or fundamental rights concerns cannot be addressed by established standardisation processes, the Commission may adopt common technical specifications in areas where no harmonised standards exist or where they are evidently insufficient.' '54 Regulation (EU) No 1025/2012 of the European Parliament and of the Council of 25 October 2012 on European standardisation, amending Council Directives 89/686/EEC and 93/15/EEC and Directives 94/9/EC, 94/25/EC, 95/16/EC, 97/23/EC, 98/34/EC, 2004/22/EC, 2007/23/EC, 2009/23/EC and 2009/105/EC of the European Parliament and of the Council and repealing Council Decision 87/95/EEC and Decision No 1673/2006/EC of the European Parliament and of the Council (OJ L 316, 14.11.2012, p. 12).

Amendment 676
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 61 a (new)
(61 a) As part of the new legal framework on corporate sustainable reporting and due diligence, minimum common standards for the reporting of businesses on the societal and environmental impacts of the AI systems that they develop, sell or distribute should be established and used at an early stage of the development and life-cycle of AI systems. Such common standard obligations should notably consist of mandatory human rights due diligence rules, thus enabling a level-playing field among European businesses and non-European businesses operating in the EU.

Amendment 677
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Tomas Tobé, Arba Kokalari
Recital 61 a (new)
(61 a) Striving for regulatory alignment on AI with likeminded global partners is key to fostering mutual innovation and cross-border partnerships within the field of AI. Coordination with international standardisation bodies is therefore of great importance.

Amendment 678
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 62
(62) In order to ensure a high level of trustworthiness of high-risk AI systems, those systems should be subject to a conformity assessment prior to their placing on the market or putting into service. AI systems, including general purpose AI systems, that may not necessarily be high-risk, are frequently used as components of other AI or non-AI software systems. In order to increase trust in the value chain and to give certainty to businesses about the performance of their systems, providers may voluntarily apply for a third-party conformity assessment.

Amendment 679
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 62
(62) In order to ensure a high level of trustworthiness of high-risk AI systems, those systems should be subject to a third party conformity assessment prior to their placing on the market or putting into service.

Amendment 680
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 63
(63) It is appropriate that, in order to minimise the burden on operators and avoid any possible duplication, for high-risk AI systems related to products which are covered by existing Union harmonisation legislation following the New Legislative Framework approach, the compliance of those AI systems with the requirements of this Regulation should be assessed as part of the conformity assessment already foreseen under that legislation. The applicability of the requirements of this Regulation should thus not affect the specific logic, methodology or general structure of conformity assessment under the relevant specific New Legislative Framework legislation. This approach is fully reflected in the interplay between this Regulation and the [Machinery Regulation]. While safety risks of AI systems ensuring safety functions in machinery are addressed by the requirements of this Regulation, certain specific requirements in the [Machinery Regulation] will ensure the safe integration of the AI system into the overall machinery, so as not to compromise the safety of the machinery as a whole. The [Machinery Regulation] applies the same definition of AI system as this Regulation. However, should this Regulation and another legislative act of the European Union both cover the same product or component of a product and provide diverging definitions or impose different safety requirements, the applicable text shall be the one with the definition or safety requirements offering the best protection for people, Member States, society and fundamental rights.

Amendment 681
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 64
deleted

Amendment 682
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul Garraud
Recital 64
(64) Given the more extensive experience of professional pre-market certifiers in the field of product safety and the different nature of risks involved, it is appropriate to allow them to carry out a conformity assessment for AI systems, including high-risk AI systems, as qualified bodies, to the extent that these systems are not prohibited.

Amendment 683
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,
Recital 64
(64) Given the more extensive experience of professional pre-market certifiers in the field of product safety and the different nature of risks involved, it is appropriate to limit, at least in an initial phase of application of this Regulation, the scope of application of third-party conformity assessment for high-risk AI systems other than those related to products. Therefore, the conformity assessment of such systems should be carried out as a general rule by the provider under its own responsibility, with the exception of AI systems intended to be used for the remote biometric identification of persons and AI systems intended to be used to make inferences on the basis of biometric data that produce legal effects or affect the rights and freedoms of natural persons. For those types of AI systems the involvement of a notified body in the conformity assessment should be foreseen, to the extent they are not prohibited..

Amendment 684
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 64
(64) Given the more extensive experience of professional pre-market certifiers in the field of product safety and the different nature of risks involved, it is essential to ensure, particularly in the period before application of this Regulation, the development of adequate capacity for the application of third-party conformity assessment for high-risk AI systems other than those related to products. Therefore, the conformity assessment of such systems should be carried out as a general rule by the provider under its own responsibility.

Amendment 685
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 64
(64) Given the more extensive experience of professional pre-market certifiers in the field of product safety and the different nature of risks involved, it is appropriate to limit, at least in an initial phase of application of this Regulation, the scope of application of third-party conformity assessment for high-risk AI systems other than those related to products. Therefore, the conformity assessment of such systems should be carried out as a general rule by the provider under its own responsibility, with the only exception of AI systems intended to be used for the remote biometric identification of persons, for which the involvement of a notified body in the conformity assessment should be foreseen.

Amendment 686
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 65
deleted

Amendment 687
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Recital 65
(65) In order to carry out third-party conformity assessment for AI systems intended to be used for the remote biometric identification of persons, notified bodies should be designated under this Regulation by the national competent authorities, provided they are compliant with a set of requirements, notably on independence, competence, absence of conflicts of interests and minimum cybersecurity requirements.

Amendment 688
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 65
(65) In order to carry out third-party conformity assessments when so required, notified bodies should be designated under this Regulation by the national competent authorities, provided they are compliant with a set of requirements, notably on independence, competence and absence of conflicts of interests.

Amendment 689
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 65
(65) In order to carry out third-party conformity assessment for AI systems intended to be used for any of the use-cases listed in Annex III, notified bodies should be designated under this Regulation by the national competent authorities, provided they are compliant with a set of requirements, notably on independence, competence and absence of conflicts of interests.

Amendment 690
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 65 a (new)
(65 a) Third party conformity assessments for products listed in Annex III are essential as a precautionary measure and to ensure that trust is not lost in AI products, to the detriment of innovation, competition and growth. Due to the particularly sensitive nature of the tasks at hand, third party conformity assessments in the fields of law enforcement, asylum and immigration should be carried out by the market surveillance authority.

Amendment 691
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 66
(66) In line with the commonly established notion of substantial modification for products regulated by Union harmonisation legislation, it is appropriate that an AI system undergoes a new conformity assessment whenever a change occurs which may create a new or increased risk and significantly affect the compliance of the system with this Regulation or when the intended purpose of the system changes. If such a case materialises, the provider should follow a clear procedure with fixed deadlines, transparency requirements and reporting duties involving, where appropriate and applicable, external oversight by notified bodies or, where it is covered already under the relevant sectoral legislation, post market monitoring if that is needed. In addition, as regards AI systems which continue to ‘learn’ after being placed on the market or put into service (i.e. they automatically adapt how functions are carried out), it is necessary to provide rules establishing that changes to the algorithm and its performance that have been considered by the provider and assessed at the moment of the conformity assessment should not constitute a substantial modification. In addition, it should not be considered a substantial modification if the user trains an AI system. In this situation, the user should clearly delimit the effects that the learning can have for the AI system. The notion of substantial modification should be assessed in light of the essential requirements set in this Regulation and be left to the manufacturer to determine if a modification is deemed to be substantial.

Amendment 692
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 66
(66) In line with the commonly established notion of substantial modification for products regulated by Union harmonisation legislation, it is appropriate that an AI system undergoes a new conformity assessment whenever a change occurs which may affect the compliance of the system with this Regulation or when the intended purpose of the system changes.  In addition, as regards AI systems which continue to ‘learn’ after being placed on the market or put into service (i.e. they automatically adapt how functions are carried out), it is necessary that changes to the algorithm and its performance that constitute substantial modifications are subject to new conformity assessments, including in cases where the substantial modifications have been pre-determined by the provider and assessed at the moment of the initial conformity assessment.

Amendment 693
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 66
(66) In line with the commonly established notion of substantial modification for products regulated by Union harmonisation legislation, it is appropriate that an AI system undergoes a new conformity assessment whenever a change occurs which may affect the compliance of the system with this Regulation or when the intended purpose or reasonably foreseeable use of the system changes. In addition, as regards AI systems which continue to ‘learn’ after being placed on the market or put into service (i.e. they automatically adapt how functions are carried out), it is necessary to provide rules establishing that changes to the algorithm and its performance that have been pre-determined by the provider and assessed at the moment of the conformity assessment should not constitute a substantial modification.

Amendment 694
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Recital 66
(66) In line with the commonly established notion of substantial modification for products regulated by Union harmonisation legislation, it is appropriate that an AI system undergoes a new third party conformity assessment whenever a change occurs which may affect the compliance of the system with this Regulation or when the intended purpose of the system changes. In addition, as regards AI systems which continue to ‘learn’ after being placed on the market or put into service (i.e. they automatically adapt how functions are carried out), it is necessary to provide rules establishing that changes to the algorithm and its performance that have been pre-determined by the provider and assessed at the moment of the conformity assessment should not constitute a substantial modification.

Amendment 695
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 66
(66) In line with the commonly established notion of substantial modification for products regulated by Union harmonisation legislation, it is appropriate that an AI system undergoes a new conformity assessment whenever a change occurs which may affect the compliance of the system with this Regulation or when the foreseeable uses of the system changes. In addition, as regards AI systems which continue to ‘learn’ after being placed on the market or put into service (i.e. they automatically adapt how functions are carried out), it is necessary to provide rules establishing that changes to the algorithm and its performance that have been pre-determined by the provider and assessed at the moment of the conformity assessment should not constitute a substantial modification.

Amendment 696
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 66 a (new)
(66 a) To prevent any deterioration in the expected safety of the algorithm subject to significant changes independent of the providers control, a clearly developed plan to address such significant changes should be subject to oversight by the relevant competent authorities or notified bodies when it is already addressed in principle in the respective sectoral Union harmonisation legislation regarding post-market monitoring

Amendment 697
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 67
(67) High-risk AI systems should bear the CE marking to indicate their conformity with this Regulation so that they can move freely within the internal market. Member States should not create obstacles to the placing on the market or putting into service of high-risk AI systems that comply with the requirements laid down in this Regulation and bear the CE marking.

Amendment 698
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 68
deleted

Amendment 699
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 68
deleted

Amendment 700
ECR - European Conservatives and Reformists Group
Vincenzo Sofo, Kosma Złotowski
Recital 68
deleted

Amendment 701
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 68
deleted

Amendment 702
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 69
(69) In order to facilitate the work of the Commission and the Member States in the artificial intelligence field as well as to increase the transparency towards the public, providers and users of high-risk AI systems other than those related to products falling within the scope of relevant existing Union harmonisation legislation, should be required to register their high-risk AI system or the use thereof in a EU database, to be established and managed by the Commission. Certain AI systems listed in Article 52 (1b) and (2) and uses thereof shall be registered in the EU database. In order to facilitate this, users shall request information listed in Annex VIII point 2(g) from providers of AI systems. Any uses of AI systems by public authorities or on their behalf shall also be registered in the EU database. In order to facilitate this, public authorities shall request information listed in Annex VIII point 3(g) from providers of AI systems. The Commission should be the controller of that database, in accordance with Regulation (EU) 2018/1725 of the European Parliament and of the Council. In order to ensure the full functionality of the database, when deployed, the procedure for setting the database should include the elaboration of functional specifications by the Commission and an independent audit report. In order to maximise the availability and use of the database by the public, the database, including the information made available through it, should comply with requirements under the European Accessibility Act.

Amendment 703
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 69
(69) In order to facilitate the work of the Commission and the Member States in the artificial intelligence field as well as to increase the transparency towards the public, providers and users of high-risk AI systems other than those related to products falling within the scope of relevant existing Union harmonisation legislation, should be required to register their high-risk AI system or the use thereof in a EU database, to be established and managed by the Commission. The Commission should be the controller of that database, in accordance with Regulation (EU) 2018/1725 of the European Parliament and of the Council55 . In order to ensure the full functionality of the database, when deployed, the procedure for setting the database should include the elaboration of functional specifications by the Commission and an independent audit report. In order to maximise the availability and use of the database by the public, the database, including the information made available through it, should comply with requirements under the European Accessibility Act.' '55 Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation) (OJ L 119, 4.5.2016, p. 1).

Amendment 704
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 69
(69) In order to facilitate the work of the Commission and the Member States in the artificial intelligence field as well as to increase the transparency towards the public, both providers and users of high-risk AI systems other than those related to products falling within the scope of relevant existing Union harmonisation legislation, should be required to register their high-risk AI system in a EU database, to be established and managed by the Commission. Users who are public authorities or European Union institutions, bodies, offices and agencies or users acting on their behalf should also register in the EU database before putting into service or using any AI system. The Commission should be the controller of that database, in accordance with Regulation (EU) 2018/1725 of the European Parliament and of the Council55 . In order to ensure the full functionality of the database, when deployed, the procedure for setting the database should include the elaboration of functional specifications by the Commission and an independent audit report.' '55 Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation) (OJ L 119, 4.5.2016, p. 1).

Amendment 705
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 69
(69) In order to facilitate the work of the Commission and the Member States in the artificial intelligence field as well as to increase the transparency towards the public, providers and deployers of high-risk AI systems should be required to register their high-risk AI system in a EU database, to be established and managed by the Commission. The Commission should be the controller of that database, in accordance with Regulation (EU) 2018/1725 of the European Parliament and of the Council55 . In order to ensure the full functionality of the database, when deployed, the procedure for setting the database should include the elaboration of functional specifications by the Commission and an independent audit report.' '55 Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation) (OJ L 119, 4.5.2016, p. 1).

Amendment 706
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Recital 69
(69) In order to facilitate the work of the Commission and the Member States in the artificial intelligence field as well as to increase the transparency towards regulators, providers of high-risk AI systems other than those related to products falling within the scope of relevant existing Union harmonisation legislation, should be required to register their high-risk AI system in a EU database, to be established and managed by the Commission. The Commission should be the controller of that database, in accordance with Regulation (EU) 2018/1725 of the European Parliament and of the Council55 . In order to ensure the full functionality of the database, when deployed, the procedure for setting the database should include the elaboration of functional specifications by the Commission and an independent audit report.' '55 Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation) (OJ L 119, 4.5.2016, p. 1).

Amendment 707
EPP - Group of the European Peoples Party (Christian Democrats)
Geoffroy Didier
Recital 70
(70) Certain AI systems intended to interact with natural persons or to generate content may pose specific risks of impersonation, deception or EU principles and values irrespective of whether they qualify as high-risk or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems. In particular, natural persons should be notified that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use. Moreover, natural persons should be notified when they are exposed to an emotion recognition system or a biometric categorisation system. Such information and notifications should be provided in accessible formats for persons with disabilities. Further, users, who use an AI system to generate or manipulate image, audio, text, script, or video content that appreciably resembles existing persons, places or events and would falsely appear to a person to be authentic, should disclose that the content has been artificially created or manipulated by labelling the artificial intelligence output accordingly and disclosing its artificial origin. Besides, recommendation systems, in particular automated decision-making algorithms that disseminate and order cultural and creative content displayed to users, should be designed in such a way that their personalised suggestions are explainable and non-discriminatory. A clear explanation of the parameters used for the personalised suggestions should be easily accessible and understandable to the users. Natural persons should have a right to opt out of recommended and personalised services without affecting their right to use the core service.

Amendment 708
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Recital 70
(70) Certain AI systems intended to interact with natural persons or to generate content may pose specific risks of impersonation or deception irrespective of whether they qualify as high-risk or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems. In particular, natural persons should be notified that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use. Moreover, natural persons should be notified when they are exposed to an emotion recognition system or a biometric categorisation system. Such information and notifications should be provided in accessible formats for persons with disabilities. Further, users, who use an AI system to generate or manipulate image, audio or video content that appreciably resembles existing persons, places or events and would falsely appear to a person to be authentic, should disclose that the content has been artificially created or manipulated by labelling the artificial intelligence output accordingly and disclosing its artificial origin. Images generated through the use of AI in the creation of audio-visual content such as films and video game visuals should not be considered “deep fakes” as defined in Article 52 (3), which must be consistent with the principle of artistic freedom under the Charter of Fundamental Rights.

Amendment 709
Renew - Renew Europe Group
Morten Løkkegaard
Recital 70
(70) Certain AI systems intended to interact with natural persons or to generate content may pose specific risks of impersonation or deception irrespective of whether they qualify as high-risk or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems. In particular, natural persons should be notified that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use. Moreover, natural persons should be notified when they are exposed to an emotion recognition system or a biometric categorisation system. Such information and notifications should be provided in accessible formats for persons with disabilities. Further, users, who use an AI system to generate or manipulate image, audio or video content that appreciably resembles existing persons, places or events and would falsely appear to a person to be authentic, should disclose that the content has been artificially created or manipulated by labelling the artificial intelligence output accordingly and disclosing its artificial origin. Images generated through the use of AI in the creation of audiovisual content such as films and video game visuals should not be considered “deep fakes” as defined in Article 52 (3), which must be consistent with the principle of artistic freedom under the Charter of Fundamental Rights.

Amendment 710
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 70
(70) Certain AI systems intended to interact with natural persons or to generate content may pose specific risks of impersonation or deception irrespective of whether they qualify as high-risk or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems. In particular, natural persons should be notified that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use or where the content forms part of an evidently creative, satirical, artistic or fictional cinematographic, video game visuals or analogous work. Moreover, natural persons should be notified when they are exposed to an emotion recognition system or a biometric categorisation system. Such information and notifications should be provided in accessible formats for persons with disabilities. Further, users, who use an AI system to generate or manipulate image, audio or video content that appreciably resembles existing persons, places or events and would falsely appear to a person to be authentic, should disclose in an appropriate, clear and visible manner that the content has been artificially created or manipulated by labelling the artificial intelligence output accordingly and disclosing its artificial origin.

Amendment 711
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 70
(70) Certain AI systems intended to interact with natural persons or to generate content may pose specific risks of impersonation or deception irrespective of whether they qualify as high-risk or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems. In particular, natural persons should be notified that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use. Such information and notifications should be provided in accessible formats for persons with disabilities. Further, deployers, who use an AI system to generate or manipulate image, audio or video content that appreciably resembles existing persons, places or events and would falsely appear to a person to be authentic, should disclose that the content has been artificially created or manipulated by labelling the artificial intelligence output accordingly and disclosing its artificial origin. Additionally, the use of an AI system to generate or manipulate image, audio or video content that appreciably resembles a natural person should be permitted only when used for freedom of expression and artistic purposes and while respecting the limits of these purposes, or with the explicit consent of that person.

Amendment 712
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 70
(70) Certain AI systems intended to interact with natural persons or to generate content may pose specific risks of impersonation or deception irrespective of whether they qualify as high-risk or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems. In particular, natural persons should be notified that they are interacting with an AI system. Such information and notifications should be provided in accessible formats for persons with disabilities. Further, users, who use an AI system to generate or manipulate image, audio or video content that appreciably resembles existing persons, places or events and would falsely appear to a person to be authentic, should disclose that the content has been artificially created or manipulated by labelling the artificial intelligence output accordingly and disclosing its artificial origin.

Amendment 713
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Dita Charanzová, Andrus Ansip, Morten
Recital 70
(70) Certain AI systems intended to interact with natural persons or to generate content may pose specific risks of impersonation or deception irrespective of whether they qualify as high-risk or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems. In particular, natural persons should be notified that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use or where the content is part of an obviously artistic, creative or fictional cinematographic work. Moreover, natural persons should be notified when they are exposed to an emotion recognition system or a biometric categorisation system. Such information and notifications should be provided in accessible formats for persons with disabilities. Further, users, who use an AI system to generate or manipulate image, audio or video content that appreciably resembles existing persons, places or events and would falsely appear to a person to be authentic, should disclose, in an appropriate, clear and visible manner, that the content has been artificially created or manipulated by labelling the artificial intelligence output accordingly and disclosing its artificial origin.

Amendment 714
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Recital 70
(70) Certain AI systems intended to interact with natural persons or to generate content may pose specific risks of impersonation or deception irrespective of whether they qualify as high-risk or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems. In particular, natural persons should be notified that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use. Such information and notifications should be provided in accessible formats for persons with disabilities. Further, users, who use an AI system to generate or manipulate image, audio or video content that appreciably resembles existing persons, places or events and would falsely appear to a person to be authentic, should disclose that the content has been artificially created or manipulated by labelling the artificial intelligence output accordingly and disclosing its artificial origin.

Amendment 715
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 70
(70) Certain AI systems intended to interact with natural persons or to generate content may pose specific risks of impersonation or deception irrespective of whether they qualify as high-risk or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems. In particular, natural persons should be notified that they are interacting with an AI system. Moreover, natural persons should be notified when they are exposed to an emotion recognition system or a biometric categorisation system. Such information and notifications should be provided in accessible formats for persons with disabilities. Further, AI systems used to generate or manipulate image, audio or video content that appreciably resembles existing persons, places or events and would falsely appear to a person to be authentic, should systematically contain an indication on the content generated that the content has been artificially created or manipulated, and users who use such AI systems or reuse the content generated should not be allowed to remove or conceal that indication.

Amendment 716
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 70 a (new)
(70 a) In light of the nature and complexity of the value chain for AI systems, it is essential to clarify the role of humans who may contribute to the development of AI systems covered by this Regulation, without being providers, no longer being providers or when other natural or legal persons have also become providers. Therefore, it is particularly important to clarify the legal situation when it comes to general purpose AI systems. Those AI system are able to perform generally applicable functions such as image/speech recognition, audio/video generation, pattern detection, question answering or translation in a plurality of contexts. Every natural or legal person can become a new provider by adapting a general purpose AI system, already placed on the market or put into service, to a specific intended purpose. Due to their peculiar nature and in order to ensure a fair sharing of responsibilities along the AI value chain, such general purpose AI system should however already be subject to proportionate and tailored requirements and obligations under this Regulation even before placing it on the Union market or putting it into service. The original provider of a general purpose AI system should furthermore cooperate, as appropriate, with the new provider to enable its compliance with the relevant obligations under this Regulation.

Amendment 717
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Recital 70 a (new)
(70 a) Suppliers of general purpose AI systems and, as relevant, other third parties that may supply other software tools and components, including pre-trained models and data, should cooperate, as appropriate, with providers that use such systems or components for an intended purpose under this Regulation in order to enable their compliance with applicable obligations under this Regulation and their cooperation, as appropriate, with the competent authorities established under this Regulation. In such cases, the provider may, by written agreement, specify the information or other assistance that such supplier will furnish in order to enable the provider to comply with its obligations herein.

Amendment 718
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 71
(71) Artificial intelligence is a rapidly developing family of technologies that requires novel forms of regulatory oversight and a safe and fully controlled space for experimentation, while ensuring responsible innovation and integration of appropriate ethical safeguards and risk mitigation measures. To ensure a legal framework that is innovation-friendly, future-proof and resilient to disruption, national competent authorities from one or more Member States should be encouraged to establish artificial intelligence regulatory sandboxes to facilitate the development and testing of innovative AI systems under strict regulatory oversight before these systems are placed on the market or otherwise put into service. Regulatory sandboxes involving activities that may impact health, safety and fundamental rights, democracy and the rule of law or the environment should be developed in accordance with redress-by-design principles. Any significant risks identified during the development and testing of such systems should result in immediate mitigation and, failing that, in the suspension of the development and testing process until such mitigation takes place. The legal basis of such sandboxes should comply with the requirements established in the existing data protection framework and should be consistent with the Charter of fundamental rights of the European Union.

Amendment 719
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 71
(71) Artificial intelligence is a rapidly developing family of technologies that benefits from clear rules and legal certainty, and requires regulatory oversight. In order to fulfill its potential to benefit society, a safe space for controlled experimentation, ensuring respect for Union law and the protection of fundamental rights, can help foster responsible innovation and integration of appropriate safeguards and risk mitigation measures. To ensure a legal framework that promotes sustainable innovation, is future-proof and resilient to disruption, national competent authorities from one or more Member States should be encouraged to cooperate in establishing artificial intelligence regulatory sandboxes to facilitate the development and testing of AI systems under strict regulatory oversight before these systems are placed on the market or otherwise put into service.

Amendment 720
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 71
(71) Artificial intelligence is a rapidly developing family of technologies that requires novel forms of regulatory oversight and a safe space for experimentation, while ensuring responsible innovation and integration of appropriate safeguards and risk mitigation measures. To ensure a legal framework that is innovation-friendly, future-proof and resilient to disruption, Member States should establish artificial intelligence regulatory sandboxes to facilitate the development and testing of innovative AI systems under strict regulatory oversight before these systems are placed on the market or otherwise put into service. Member States should ensure that the regulatory sandboxes have the adequate financial and human resources for their proper functioning.

Amendment 721
EPP - Group of the European Peoples Party (Christian Democrats)
Karlo Ressler
Recital 71
(71) Artificial intelligence is a rapidly developing family of technologies that requires novel forms of regulatory oversight and a safe space for experimentation, while ensuring responsible innovation and integration of appropriate safeguards and risk mitigation measures. To ensure a legal framework that is innovation-friendly, future-proof and resilient to disruption, national competent authorities from one or more Member States should establish artificial intelligence regulatory sandboxes to facilitate the development and testing of innovative AI systems under strict regulatory oversight before these systems are placed on the market or otherwise put into service. All other relevant actors should be encouraged to do so as well.

Amendment 722
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 71
(71) Artificial intelligence is a rapidly developing family of technologies that requires novel forms of regulatory oversight and a safe space for experimentation, while ensuring responsible innovation and integration of appropriate safeguards and risk mitigation measures. To ensure a legal framework that safeguards fundamental rights and is innovation-friendly, future-proof and resilient to disruption, national supervisory authorities from one or more Member States could establish artificial intelligence regulatory sandboxes to facilitate the development and testing of innovative AI systems under strict regulatory oversight before these systems are placed on the market or otherwise put into service.

Amendment 723
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 71
(71) Artificial intelligence is a rapidly developing family of technologies that requires novel forms of regulatory oversight and a safe space for experimentation, while ensuring responsible innovation and integration of appropriate safeguards and risk mitigation measures. To ensure a legal framework that is innovation-friendly, future-proof and resilient to disruption, national competent authorities from one or more Member States should establish artificial intelligence regulatory sandboxes to facilitate the development and testing of innovative AI systems under strict regulatory oversight before these systems are placed on the market or otherwise put into service.

Amendment 724
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 72
(72) The objectives of the regulatory sandboxes should be to foster AI innovation for the benefit of society by establishing a controlled experimentation and testing environment in the development and pre-marketing phase with a view to ensuring respect for and protection of fundamental rights, compliance of the innovative AI systems with this Regulation and other relevant Union and Member States legislation; to enhance legal certainty for innovators and the competent authorities’ oversight and understanding of the opportunities, emerging risks and the impacts of AI use, and to accelerate access to markets, including by removing barriers for small and medium enterprises (SMEs) and start-ups. To ensure uniform implementation across the Union and economies of scale, it is appropriate to establish common rules for the regulatory sandboxes’ implementation and a framework for cooperation between the relevant authorities involved in the supervision of the sandboxes. Personal data that had originally been collected for different purposes should be processed in a sandbox only under specified conditions and within the limits of Regulation (EU) 2016/679. Such further processing should be considered as for statistical purposes in the meaning of Article 5(1)(b) of that Regulation. Participants in the sandbox should ensure appropriate safeguards and cooperate with the competent authorities, including by following their guidance and acting expeditiously and in good faith to mitigate any risks to safety and fundamental rights that may arise during the development and experimentation in the sandbox. The conduct of the participants in the sandbox should be taken into account when competent authorities decide over the suspending or banning them from participating in the sandbox, or whether to impose an administrative fine under Article 83(2) of Regulation 2016/679 and Article 57 of Directive 2016/680. This Regulation should also provide the legal basis for the use of data protected by intellectual property or trade-secrets for developing certain AI systems in the public interest within the AI regulatory sandbox, without prejudice to Directive (EU) 2019/790 and to Directive (EU) 2016/943. The authorised use of data protected by intellectual property or trade-secrets under Article 54 of this Regulation should be covered by Article 4 of Directive (EU) 2019/790.

Amendment 725
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 72
(72) The objectives of the regulatory sandboxes should be to foster AI innovation by establishing a strictly controlled experimentation and testing environment in the development and pre-marketing phase with a view to ensuring compliance of the innovative AI systems with this Regulation and other relevant Union and Member States legislation, as well as with the Charter of Fundamental Rights of the European Union and the General Data Protection Regulation; to enhance legal certainty for innovators and the competent authorities’ oversight and understanding of the opportunities, emerging risks and the impacts of AI use, to provide safeguards needed to build trust and reliance on AI systems, to accelerate access to markets, including by removing barriers for the public sector, small and medium enterprises (SMEs) and start-ups; and to contribute to the development of ethical, socially responsible and environmentally sustainable AI systems. To ensure uniform implementation across the Union and economies of scale, it is appropriate to establish common rules for the regulatory sandboxes’ implementation and a framework for cooperation between the relevant authorities involved in the supervision of the sandboxes. This Regulation should provide the legal basis for the use of personal data collected for other purposes for developing certain AI systems in the public interest within the AI regulatory sandbox, in line with Article 6(4) of Regulation (EU) 2016/679, and Article 6 of Regulation (EU) 2018/1725, and without prejudice to Article 4(2) of Directive (EU) 2016/680. Participants in the sandbox should ensure appropriate safeguards and cooperate with the competent authorities, including by following their guidance and acting expeditiously and in good faith to mitigate any high-risks to safety and fundamental rights that may arise during the development and experimentation in the sandbox. The conduct of the participants in the sandbox should be taken into account when competent authorities decide whether to impose an administrative fine under Article 83(2) of Regulation 2016/679 and Article 57 of Directive 2016/680.

Amendment 726
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 72
(72) The objectives of the regulatory sandboxes should be to foster AI innovation by establishing a controlled experimentation and testing environment in the development and pre-marketing phase with a view to ensuring compliance of the innovative AI systems with this Regulation and other relevant Union and Member States legislation; to enhance legal certainty for innovators and the competent authorities’ oversight and understanding of the opportunities, emerging risks and the impacts of AI use, and to accelerate access to markets, including by removing barriers for small and medium enterprises (SMEs) and start-ups. To ensure uniform implementation across the Union and economies of scale, it is appropriate to establish common rules for the regulatory sandboxes’ implementation and a framework for cooperation between the relevant authorities involved in the supervision of the sandboxes. Participants in the sandbox should ensure appropriate safeguards and cooperate with the competent authorities, including by following their guidance and acting expeditiously and in good faith to mitigate any high-risks to safety and fundamental rights that may arise during the development and experimentation in the sandbox. The conduct of the participants in the sandbox should be taken into account when competent authorities decide whether to impose an administrative fine under Article 83(2) of Regulation 2016/679 and Article 57 of Directive 2016/680.

Amendment 727
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 72
(72) The objectives of the regulatory sandboxes should be to foster AI innovation, while safeguarding fundamental rights and the values enshrined in Article 2 TFEU, by establishing a controlled experimentation and testing environment in the development and pre-marketing phase with a view to ensuring compliance of the innovative AI systems with this Regulation and other relevant Union and Member States legislation; to enhance legal certainty for innovators and the national supervisory authorities’ oversight and understanding of the opportunities, emerging risks and the impacts of AI use, and to accelerate access to markets, including by removing barriers for small and medium enterprises (SMEs) and start-ups. To ensure uniform implementation across the Union and economies of scale, it is appropriate to establish common rules for the regulatory sandboxes’ implementation and a framework for cooperation between the national supervisory authorities involved in the supervision of the sandboxes. Participants in the sandbox should ensure appropriate safeguards and cooperate with the national supervisory authorities, including by following their guidance and acting expeditiously and in good faith to mitigate any high-risks to safety and fundamental rights that may arise during the development and experimentation in the sandbox. The conduct of the participants in the sandbox should be taken into account when competent authorities decide whether to impose an administrative fine under Article 83(2) of Regulation 2016/679 and Article 57 of Directive 2016/680.

Amendment 728
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 72 a (new)
(72 a) To ensure that Artificial Intelligence leads to socially and environmentally beneficial outcomes, Member States should support and promote research and development of AI in support of socially and environmentally beneficial outcomes by allocating sufficient resources, including public and Union funding, and giving priority access to regulatory sandboxes to projects led by civil society. Such projects should be based on the principle of interdisciplinary cooperation between AI developers, experts on inequality and non-discrimination, accessibility, consumer, environmental, and digital rights, as well as academics.

Amendment 729
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 73
(73) In order to promote and protect innovation, it is important that the interests of SME providers and users of AI systems are taken into particular account. To this objective, AI solutions and services designed to combat fraud and protect consumers against fraudulent activities should not be considered high-risk, nor be prohibited. As a matter of substantial public interest, it is vital that this Regulation does not undermine the incentive of industry to create and roll out solutions designed to combat fraud across the Union. Furthermore, Member States should develop initiatives, which are targeted at those operators, including on awareness raising and information communication. Moreover, the specific interests and needs of SME providers shall be taken into account when Notified Bodies set conformity assessment fees. Translation costs related to mandatory documentation and communication with authorities may constitute a significant cost for providers and other operators, notably those of a smaller scale. Member States should possibly ensure that one of the languages determined and accepted by them for relevant providers’ documentation and for communication with operators is one which is broadly understood by the largest possible number of cross-border users. Member States should also be encouraged to do the same for small and medium enterprises, which may sometimes lack the requisite administrative and legal resources to ensure proper understanding and compliance with the provisions under this act. In the event that Member States request it, the Commission may also provide assistance in this regard.

Amendment 730
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Recital 73
(73) In order to promote and protect innovation, it is important that the interests of small-scale providers, like SMEs, micro-enterprises and users of AI systems are taken into particular account. SMEs are the backbone of the European economy and they face more challenges adapting to new legislations therefore measures should be foreseen to support them to cope with the new obligations or to exclude them from certain requirements. To this objective, Member States should develop initiatives, which are targeted at those operators, including on awareness raising and information communication. Moreover, the specific interests and needs of small-scale providers shall be taken into account when Notified Bodies set conformity assessment fees. Translation costs related to mandatory documentation and communication with authorities may constitute a significant cost for providers and other operators, notably those of a smaller scale. Member States should ensure that one of the languages determined and accepted by them for relevant providers’ documentation and for communication with operators is one which is broadly understood by the largest possible number of cross-border users.

Amendment 731
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 73
(73) In order to promote and protect innovation, it is important that the interests of small-scale providers and users of AI systems are taken into particular account. To this objective, Member States should develop initiatives, which are targeted at those operators, including on awareness raising and information communication. Moreover, the specific interests and needs of small-scale providers shall be taken into account when Notified Bodies set conformity assessment fees. Translation costs related to mandatory documentation and communication with authorities may constitute a significant cost for providers and other operators, notably those of a smaller scale.

Amendment 732
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 73
(73) In order to promote and protect innovation, it is important that the interests of small-scale providers and deployers of AI systems are taken into particular account. To this objective, Member States should develop initiatives, which are targeted at those operators, including on awareness raising and information communication, and including the cooperation across borders. Moreover, the specific interests and needs of small-scale providers shall be taken into account when Notified Bodies set conformity assessment fees. Translation costs related to mandatory documentation and communication with authorities may constitute a significant cost for providers and other operators, notably those of a smaller scale. Member States should ensure that one of the languages determined and accepted by them for relevant providers’ documentation and for communication with operators is one which is broadly understood by the largest possible number of cross-border deployers.

Amendment 733
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Dita Charanzová, Andrus Ansip, Morten
Recital 73
(73) In order to promote and protect innovation, it is important that the interests of start-ups and SME providers and users of AI systems are taken into particular account. To this objective, Member States should develop initiatives, which are targeted at those operators, including on awareness raising and information communication. Moreover, the specific interests and needs of SMEs and start-ups shall be taken into account when Notified Bodies set conformity assessment fees. Translation costs related to mandatory documentation and communication with authorities may constitute a significant cost for providers and other operators, notably those of a smaller scale. Member States should possibly ensure that one of the languages determined and accepted by them for relevant providers’ documentation and for communication with operators is one which is broadly understood by the largest possible number of cross-border users.

Amendment 734
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Patryk Jaki, Adam Bielan
Recital 73 a (new)
(73 a) AI solutions and services designed to combat fraud and protect consumers against fraudulent activities should not be considered high risk, nor prohibited. As a matter of substantial public interest, it is vital that this Regulation does not undermine the incentive of the industry to create and roll out solutions designed to combat fraud across the European Union.

Amendment 735
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 74
(74) In order to minimise the risks to implementation resulting from lack of knowledge and expertise in the market as well as to facilitate compliance of providers and notified bodies with their obligations under this Regulation, Member States should utilise existing dedicated channels for communication with SMEs and start-ups. Such existing channels could include but are not limited to ENISA’s Computer Security Incident Response Teams, National data protection agencies, the AI-on demand platform, the European Digital Innovation Hubs and the Testing and Experimentation Facilities established by the Commission and the Member States at national or EU level. Within their respective mission and fields of competence, they may provide in particular technical and scientific support to providers and notified bodies.

Amendment 736
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 74
(74) In order to minimise the risks to implementation resulting from lack of knowledge and expertise in the market as well as to facilitate compliance of providers and notified bodies with their obligations under this Regulation, the AI-on demand platform, the European Digital Innovation Hubs and the Testing and Experimentation Facilities established by the Commission and the Member States at national or EU level, as well as the ENISA, the EU Agency for Fundamental Rights, EIGE, and the European Data Protection Supervisor should constantly contribute to the implementation of this Regulation. Within their respective mission and fields of competence, they may provide in particular technical and scientific support to providers and notified bodies.

Amendment 737
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 74
(74) In order to minimise the risks to implementation resulting from lack of knowledge and expertise in the market as well as to facilitate compliance of providers and notified bodies with their obligations under this Regulation, the AI-on demand platform, the European Digital Innovation Hubs and the Testing and Experimentation Facilities established by the Commission and the Member States at national or EU level should contribute to the implementation of this Regulation. Within their respective mission and fields of competence, they may provide in particular technical and scientific support to providers and notified bodies.

Amendment 738
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 76
(76) In order to facilitate a smooth, effective and consistent implementation of this Regulation an independent European Artificial Intelligence Board should be established. The Board should be responsible for a number of tasks, including issuing opinions, recommendations, advice or guidance on matters related to the implementation of this Regulation, including on technical specifications or existing standards regarding the requirements established in this Regulation and providing advice to and assisting the Commission on specific questions related to artificial intelligence, including on possible amendments of the annexes, in particular the annex listing high-risk AI systems. To contribute to the effective and harmonised enforcement of this Regulation, the Board should also be able to adopt binding decisions for the settlement of cases involving two or more Member States in which the national supervisory authorities are in disagreement or when it is not clear who the lead national supervisory authority is. The Board should also be able to adopt a binding decision in those cases when a national supervisory authority of a Member State finds that although an AI system is in compliance with this Regulation, it presents a risk to the compliance with obligations under Union or national law intended to protect fundamental rights, the principles of Article 4a, the values as enshrined in Article 2 TEU, the environment, or to other aspects of public interest protection.

Amendment 739
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona Strugariu, Dragoş Pîslaru, Lucia Ďuriš Nicholsonová, Irena Joveva, Karen Melchior, Alin Mituța
Recital 76
(76) In order to ensure an effective and harmonised implementation of this Regulation, to achieve a high level of trustworthiness and of protection of health, safety, fundamental rights and the Union values enshrined in Article 2 TEU across the Union with regards to artificial intelligence systems, to actively support Member States, Union institutions, bodies, offices and agencies in matters pertaining to this Regulation, to reduce the fragmentation of the internal market, and to increase the uptake of artificial intelligence throughout the Union, an European Union Artificial Intelligence Office should be established. The AI Office should have legal personality, should act in full independence, and should be adequately funded and staffed. Member States should provide the strategic direction and control of the AI Office through the management board of the AI Office, alongside the Commission, the EDPS, and the FRA. An executive director should be responsible for the coordination of the AI Office’s operations and for the implementation of its work programme. Industry,start-ups and SMEs, and civil society should formally participate in the work of the AI Office through an advisory forum that should ensure varied stakeholder representation and should advise the AI Office on matters pertaining to this Regulation.

Amendment 740
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 76
(76) In order to facilitate a smooth, effective and harmonised implementation of this Regulation a European Artificial Intelligence Board should be established. The Board should be independent and responsible for a number of advisory and enforcement tasks, including issuing decisions, opinions, recommendations, advice or guidance on matters related to the implementation of this Regulation, including on technical specifications or existing standards regarding the requirements established in this Regulation and providing advice to and assisting the Commission on specific questions related to artificial intelligence. In order to ensure a consistent and appropriate enforcement vis-à-vis very large undertakings, the Board should be the supervisory authority for undertakings that meet the criteria of 'community dimension' as defined in Article 1(3) of Regulation 139/200 (Merger Regulation). The Board should have a secretariat with sufficient resources and expertise to be able to fulfil its role. In this respect, the secretariat should establish a European Centre of Excellence for Artificial Intelligence (ECE-AI).

Amendment 741
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,
Recital 76 a (new)
(76) In order to facilitate a smooth, effective and harmonised implementation of this Regulation a European Artificial Intelligence Board should be established as a body of the Union and should have legal personality. The Board should be responsible for a number of advisory tasks, including issuing opinions, recommendations, advice or guidance on matters related to the implementation of this Regulation, including on technical specifications or existing standards regarding the requirements established in this Regulation and providing advice to and assisting the Commission and the national competent authorities on specific questions related to artificial intelligence.

Amendment 742
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Radosław Sikorski,
Recital 76 a (new)
(76 a) An AI advisory council(‘the Advisory Council’) should be established as a sub-group of the Board consisting of relevant representatives from industry, research, academia, civil society, standardisation organisations, relevant common European data spaces, and other relevant stakeholders, including social partners, where appropriate depending on the subject matter discussed, representing all Member States to maintain geographical balance. The Advisory Council should support the work of the Board by providing advice relating to the tasks of the Board. The Advisory Council should nominate a representative to attend meetings of the Board and to participate in its work.

Amendment 743
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 76 a (new)
(76 a) The Commission should re-establish the High Level Expert Group or a similar body with a new and balanced membership comprising an equal number of experts from SMEs and start-ups, large enterprises, academia and Research, and civil society. This new High Level Expert Group should not only act as advisory body to the Commission but also to the Board. At least every quarter, the new High Level Expert Group must have the chance to share its practical and technical expertise in a special meeting with the Board.

Amendment 744
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 77
(77) Member States hold a key role in the application and enforcement of this Regulation. In this respect, each Member State should designate one or more national competent authorities for the purpose of supervising the application and implementation of this Regulation. In order to increase organisation efficiency on the side of Member States and to set an official point of contact vis-à-vis the public and other counterparts at Member State and Union levels, in each Member State one national authority should be designated as national supervisory authority. In order to avoid duplication and combine expertise and competences, this should be a supervisory authority established under Regulation (EU) 2016/679 (General Data Protection Regulation). The supervisory authorities should have sufficient investigative and corrective powers.

Amendment 745
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 77
(77) Each Member State should establish or designate a single national supervisory authority to act as the lead authority and be responsible for ensuring the effective coordination between the national competent authorities regarding the implementation of this Regulation. It should also represent its Member State on the Board. Each national supervisory authority should act with complete independence in performing its tasks and exercising its powers in accordance with this Regulation.

Amendment 746
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 77 a (new)
(77 a) The national supervisory authorities should monitor the application of the provisions pursuant to this Regulation and contribute to its consistent application throughout the Union. For that purpose, the national supervisory authorities should cooperate with each other, with the market surveillance authorities and with the Commission, without the need for any agreement between Member States on the provision of mutual assistance or on such cooperation.

Amendment 747
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 78
(78) In order to ensure that providers of high-risk AI systems can take into account the experience on the use of high-risk AI systems for improving their systems and the design and development process or can take any possible corrective action in a timely manner, all providers should have a post-market monitoring system in place. In view of the sensitive nature of high-risk AI systems, this post-market monitoring system should not be able to automatically send data or error reports to the supplier via the AI system. This system is also key to ensure that the possible risks emerging from AI systems which continue to ‘learn’ after being placed on the market or put into service can be more efficiently and timely addressed. In this context, providers should also be required to have a system in place to report to the relevant authorities any serious incidents or any breaches to national and Union law protecting fundamental rights resulting from the use of their AI systems.

Amendment 748
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 78
(78) In order to ensure that providers of high-risk AI systems can take into account the experience on the use of high-risk AI systems for improving their systems and the design and development process or can take any possible corrective action in a timely manner, all providers should have a post-market monitoring system in place. This system is also key to ensure that the possible risks emerging from AI systems which continue to ‘learn’ after being placed on the market or put into service can be more efficiently and timely addressed. In this context, providers should also be required to have a system in place to report to the relevant authorities any serious incidents or any breaches to national and Union law, including those protecting fundamental rights and consumer rights, resulting from the use of their AI systems.

Amendment 749
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 78
(78) In order to ensure that providers of high-risk AI systems can take into account the experience on the use of high-risk AI systems for improving their systems and the design and development process or can take any possible corrective action in a timely manner, all providers should have a post-market monitoring system in place. This system is also key to ensure that the possible risks emerging from AI systems which continue to ‘learn’ after being placed on the market or put into service can be more efficiently and timely addressed. In this context, providers should also be required to report to the relevant authorities any serious incidents or any breaches to national and Union law protecting fundamental rights resulting from the use of their AI systems.

Amendment 750
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 79
(79) In order to ensure an appropriate and effective enforcement of the requirements and obligations set out by this Regulation, which is Union harmonisation legislation, the system of market surveillance and compliance of products established by Regulation (EU) 2019/1020 should apply in its entirety. Where necessary for their mandate, national public authorities or bodies, which supervise the application of Union law protecting fundamental rights, including equality bodies, should also have access to any documentation created under this Regulation. A reasonable suspicion of breach of fundamental rights, which may arise from a complaint from an individual or a notification of a breach submitted by a civil society organisation, should be deemed as a sufficient reason for the commencement of an evaluation of an AI system at national level.

Amendment 751
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 79 a (new)
(79 a) As the rights and freedoms of individuals can be seriously undermined by AI systems, it is essential that affected individuals have meaningful access to reporting and redress mechanisms. They should be able to report infringements of this Regulation to their national supervisory authority and have the right to be heard and to be informed about the outcome of their complaint and the right to a timely decision. In addition, they should have the right to an effective remedy against competent authorities who fail to enforce these rights and the right to redress. Where applicable, deployers should provide internal complaints mechanisms to be used by affected individuals and should be liable for pecuniary and non-pecuniary damages in cases of breaches of individuals’ or groups’ rights. Collective representation of affected individuals must be possible.

Amendment 752
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Recital 80
(80) Union legislation on financial services includes internal governance and risk management rules and requirements which are applicable to regulated financial institutions in the course of provision of those services, including when they make use of AI systems. In order to ensure coherent application and enforcement of the obligations under this Regulation and relevant rules and requirements of the Union financial services legislation, the authorities responsible for the supervision and enforcement of the financial services legislation, including where applicable the European Central Bank, should be designated as competent authorities for the purpose of supervising the implementation of this Regulation, including for market surveillance activities, as regards AI systems provided or used by regulated and supervised financial institutions. To further enhance the consistency between this Regulation and the rules applicable to credit institutions regulated under Directive 2013/36/EU of the European Parliament and of the Council56 , it is also appropriate to integrate the conformity assessment procedure and some of the providers’ procedural obligations in relation to risk management, post marketing monitoring and documentation into the existing obligations and procedures under Directive 2013/36/EU. In order to avoid overlaps, limited derogations should also be envisaged in relation to the quality management system of providers and the monitoring obligation placed on users of high-risk AI systems to the extent that these apply to credit institutions regulated by Directive 2013/36/EU. With regard to use case 5(b) in Annex III, areas covered by this Regulation relate to those outlined in Article 1(a). All other procedures relating to creditworthiness assessment are covered by the Directive of the European Parliament and of the Council on consumer credits .' '56 Directive 2013/36/EU of the European Parliament and of the Council of 26 June 2013 on access to the activity of credit institutions and the prudential supervision of credit institutions and investment firms, amending Directive 2002/87/EC and repealing Directives 2006/48/EC and 2006/49/EC (OJ L 176, 27.6.2013, p. 338).

Amendment 753
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Recital 80
(80) Union legislation on financial services includes internal governance and risk management rules and requirements which are applicable to regulated financial institutions in the course of provision of those services, including when they make use of AI systems. In order to ensure coherent application and enforcement of the obligations under this Regulation and relevant rules and requirements of the Union financial services legislation, the authorities responsible for the supervision and enforcement of the financial services legislation, including where applicable the European Central Bank, should be designated as competent authorities for the purpose of supervising the implementation of this Regulation, including for market surveillance activities, as regards AI systems provided or used by regulated and supervised financial institutions. To further enhance the consistency between this Regulation and the rules applicable to credit institutions regulated under Directive 2013/36/EU of the European Parliament and of the Council56 , it is also appropriate to integrate the conformity assessment procedure and some of the providers’ procedural obligations in relation to risk management, post marketing monitoring and documentation into the existing obligations and procedures under Directive 2013/36/EU. In order to avoid overlaps, limited derogations should also be envisaged in relation to the quality management system of providers and the monitoring obligation placed on users of high-risk AI systems to the extent that these apply to credit institutions regulated by Directive 2013/36/EU. With regard to use case 5(b) in Annex III, areas covered by this Regulation relate to those outlined in Article 1(a). All other procedures relating to creditworthiness assessment are covered by the Directive of the European Parliament and of the Council on consumer credits.' '56 Directive 2013/36/EU of the European Parliament and of the Council of 26 June 2013 on access to the activity of credit institutions and the prudential supervision of credit institutions and investment firms, amending Directive 2002/87/EC and repealing Directives 2006/48/EC and 2006/49/EC (OJ L 176, 27.6.2013, p. 338).

Amendment 754
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 80
(80) Union legislation on financial services includes internal governance and risk management rules and requirements which are applicable to regulated financial institutions in the course of provision of those services, including when they make use of AI systems. In order to ensure coherent application and enforcement of the obligations under this Regulation and relevant rules and requirements of the Union financial services legislation, the authorities responsible for the supervision and enforcement of the financial services legislation, including where applicable the European Central Bank, should be designated as competent authorities for the purpose of supervising the implementation of this Regulation, including for market surveillance activities, as regards AI systems provided or used by regulated and supervised financial institutions. To further enhance the consistency between this Regulation and the rules applicable to credit institutions regulated under Directive 2013/36/EU of the European Parliament and of the Council56 , it is also appropriate to integrate the conformity assessment procedure and some of the providers’ procedural obligations in relation to risk management, post marketing monitoring and documentation into the existing obligations and procedures under Directive 2013/36/EU.' '56 Directive 2013/36/EU of the European Parliament and of the Council of 26 June 2013 on access to the activity of credit institutions and the prudential supervision of credit institutions and investment firms, amending Directive 2002/87/EC and repealing Directives 2006/48/EC and 2006/49/EC (OJ L 176, 27.6.2013, p. 338).

Amendment 755
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 80
(80) Union legislation on financial services includes internal governance and risk management rules and requirements which are applicable to regulated financial institutions in the course of provision of those services, including when they make use of AI systems. In order to ensure coherent application and enforcement of the obligations under this Regulation and relevant rules and requirements of the Union financial services legislation, the competent authorities responsible for the supervision and enforcement of the financial services legislation, including where applicable the competent authorities as defined in Directive 2013/36/EU of the European Parliament and of the Council, should be designated as competent authorities for the purpose of supervising the implementation of this Regulation, excluding market surveillance activities, as regards AI systems provided or used by regulated and supervised financial institutions. To further enhance the consistency between this Regulation and the rules applicable to credit institutions regulated under Directive 2013/36/EU of the European Parliament and of the Council56, it is also appropriate to integrate certain aspects of the conformity assessment procedure and some of the providers’ procedural obligations in relation to risk management, post marketing monitoring and documentation into the existing obligations and procedures under Directive 2013/36/EU. In order to avoid overlaps, limited derogations should also be envisaged in relation to the quality management system of providers and the monitoring obligation placed on users of high-risk AI systems to the extent that these apply to credit institutions regulated by Directive 2013/36/EU.' '56 Directive 2013/36/EU of the European Parliament and of the Council of 26 June 2013 on access to the activity of credit institutions and the prudential supervision of credit institutions and investment firms, amending Directive 2002/87/EC and repealing Directives 2006/48/EC and 2006/49/EC (OJ L 176, 27.6.2013, p. 338).

Amendment 756
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 80 a (new)
(80 a) Where the national market surveillance authority has not taken measures against an infringement to this Regulation, the Commission should be in possession of all the necessary resources, in terms of staffing, expertise, and financial means, for the performance of its tasks instead of the national market surveillance authority under this Regulation. In order to ensure the availability of the resources necessary for the adequate investigation and enforcement measures that the Commission could undertake under this Regulation, the Commission should charge fees on national market surveillance authorities, the level of which should be established on a case-by-case basis. The overall amount of fees charged should be established on the basis of the overall amount of the costs incurred by the Commission to exercise its investigation and enforcement powers under this Regulation. Such an amount should include costs relating to the exercise of the specific powers and tasks connected to Chapter 4 of Title VIII of this Regulation. The external assigned revenues resulting from the fees could be used to finance additional human resources, such as contractual agents and seconded national experts, and other expenditure related to the fulfilment of these tasks entrusted to the Commission by this Regulation.

Amendment 757
Renew - Renew Europe Group
Morten Løkkegaard
Recital 81
(81) The development of AI systems other than high-risk AI systems in a safe, trustworthy, and ethical manner may lead to a larger uptake of trustworthy artificial intelligence in the Union. Providers of non-high-risk AI systems should be encouraged to create voluntary market-based codes of conduct based on the requirements applicable to high-risk AI systems, adapted in light of the intended purpose of the systems and the lower risk involved. Providers should also be encouraged to apply on a voluntary basis additional requirements related, for example, to environmental sustainability, accessibility to persons with disability, stakeholders’ participation in the design and development of AI systems, and diversity of the development teams. Compliance with the codes of conduct can be signaled through a label, where relevant. The Digital Europe Programme should support the development and uptake of these codes of conduct. The Commission may develop initiatives, including of a sectorial nature, to facilitate the lowering of technical barriers hindering cross-border exchange of data for AI development, including on data access infrastructure, semantic and technical interoperability of different types of data.

Amendment 758
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Christel Schaldemose
Recital 81
(81) The development of AI systems other than high-risk AI systems in a safe, trustworthy and ethical manner may lead to a larger uptake of trustworthy artificial intelligence in the Union. Providers of non-high-risk AI systems should be encouraged to create voluntary market-based codes of conduct based on the requirements applicable to high-risk AI systems, adapted in light of the intended purpose of the systems and the lower risk involved. Providers should also be encouraged to apply on a voluntary basis additional requirements related, for example, to environmental sustainability, accessibility to persons with disability, stakeholders’ participation in the design and development of AI systems, and diversity of the development teams. Compliance with the codes of conduct can be signaled through a label, where relevant. The Digital Europe Programme should support the development and uptake of these codes of conduct. The Commission may develop initiatives, including of a sectorial nature, to facilitate the lowering of technical barriers hindering cross-border exchange of data for AI development, including on data access infrastructure, semantic and technical interoperability of different types of data.

Amendment 759
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 81
(81) The development of AI systems other than high-risk AI systems in accordance with the requirements of this Regulation may lead to a larger uptake of trustworthy artificial intelligence in the Union. Providers of non-high-risk AI systems should be encouraged to create codes of conduct intended to foster the voluntary application of the mandatory requirements applicable to high-risk AI systems or risk-appropriate codes of conduct that sufficiently increase trust in the underlying technology that is not high-risk. Providers should also be encouraged to apply on a voluntary basis additional requirements related, for example, to environmental sustainability, accessibility to persons with disability, stakeholders’ participation in the design and development of AI systems, and diversity of the development teams. The Commission may develop initiatives, including of a sectorial nature, to facilitate the lowering of technical barriers hindering cross-border exchange of data for AI development, including on data access infrastructure, semantic and technical interoperability of different types of data.

Amendment 760
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 81
(81) The development of AI systems other than high-risk AI systems in accordance with the requirements of this Regulation may lead to a larger uptake of trustworthy artificial intelligence in the Union. Providers of non-high-risk AI systems should be encouraged to create codes of conduct intended to foster the voluntary application of the mandatory requirements applicable to high-risk AI systems. Providers should also be encouraged to apply on a voluntary basis additional requirements related, for example, to energy efficiency, resource use and waste production, and environmental sustainability, accessibility to persons with disability, stakeholders’ participation in the design and development of AI systems, and diversity, equal representation and gender-balance of the development teams. The Commission may develop initiatives, including of a sectorial nature, to facilitate the lowering of technical barriers hindering cross-border exchange of data for AI development, including on data access infrastructure, semantic and technical interoperability of different types of data.

Amendment 761
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 82
(82) It is important that AI systems related to products that are not high-risk in accordance with this Regulation and thus are not required to comply with the requirements set out for high-risk AI systems are nevertheless safe when placed on the market or put into service. To contribute to this objective, the Directive 2001/95/EC of the European Parliament and of the Council57 would apply as a safety net.' '57 Directive 2001/95/EC of the European Parliament and of the Council of 3 December 2001 on general product safety (OJ L 11, 15.1.2002, p. 4).

Amendment 762
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 83
(83) In order to ensure trustful and constructive cooperation of competent authorities on Union and national level, all parties involved in the application of this Regulation should aim for transparency and openness. Where necessary for individual cases and internal deliberations, they should also respect the confidentiality of information and data obtained in carrying out their tasks.

Amendment 763
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Recital 84
(84) Member States should take all necessary measures to ensure that the provisions of this Regulation are implemented, including by laying down effective, proportionate and dissuasive penalties for their infringement. For certain specific infringements, Member States should take into account the margins and criteria set out in this Regulation. The European Data Protection Supervisor should have the power to impose fines on Union institutions, agencies and bodies falling within the scope of this Regulation. The penalties and litigation costs under this Regulation should not be subject to contractual clauses or any other arrangements.

Amendment 764
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 84 a (new)
(84 a) In order to strengthen and harmonise administrative penalties for infringements of this Regulation, each national supervisory authority should have the power to impose administrative fines. This Regulation should indicate infringements and the upper limit for setting the related administrative fines, which should be determined by the national supervisory authority in each individual case, taking into account all relevant circumstances of the specific situation, with due regard in particular to the nature, gravity and duration of the infringement and of its consequences and the measures taken to ensure compliance with the obligations under this Regulation and to prevent or mitigate the consequences of the infringement.

Amendment 765
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 84 a (new)
(84 a) An affected person should also have the right to mandate a not-for-profit body, organisation or association that has been properly constituted in accordance with the law of a Member State, to lodge the complaint on their behalf. To this end, Directive 2020/1828/EC on Representative Actions for the Protection of the Collective Interests of Consumers should be amended to include this Regulation among the provisions of Union law falling under its scope.

Amendment 766
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 84 a (new)
(84 a) Union legislation on the protection of whistleblowers (Directive (EU) 2019/1937) has full application to academics, designers, developers, project contributors, auditors, product managers, engineers and economic operators acquiring information on breaches of Union law by a provider of AI system or its AI system, even if they are not explicitly mentioned in Article 4(1)a-4(1)d of that Directive.

Amendment 767
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 84 b (new)
(84 b) Natural persons, affected by an AI system falling within the scope of this Regulation, should have the right to lodge a complaint against the providers or users of such AI system with a national supervisory authority, if they consider that their fundamental rights, health or safety have been breached. An affected person should also have the right to mandate a not-for-profit body, organisation or association that has been properly constituted in accordance with the law of a Member State, to lodge the complaint on their behalf.

Amendment 768
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 84 b (new)
(84 b) Union legislation on consumer protection(notably Directives (EU) 2019/2161, 2005/29/EC,2011/83/EU) applies to AI systems to the extent determined in these legislations, regardless of whether these systems are categorized as high-risk.

Amendment 769
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 85
(85) In order to ensure that the regulatory framework can be adapted where necessary, the power to adopt acts in accordance with Article 290 TFEU should be delegated to the Commission to amend the techniques and approaches referred to in Annex I to define AI systems, the Union harmonisation legislation listed in Annex II, the high-risk AI systems listed in Annex III, the provisions regarding technical documentation listed in Annex IV, the content of the EU declaration of conformity in Annex V, the provisions regarding the conformity assessment procedures in Annex VI and VII and the provisions establishing the high-risk AI systems to which the conformity assessment procedure based on assessment of the quality management system and assessment of the technical documentation should apply. As the purpose of delegating that power is to allow this Regulation to be adapted to technical advancements, the Commission should only be able to adopt such delegated acts to include non-restrictive additions or clarifications in the lists in those Annexes, whereas deletions, restrictive clarifications or amendments to the definitions of the items in those Annexes should only result from the adoption of amending regulations. It is of particular importance that the Commission carry out appropriate consultations during its preparatory work, including at expert level, and that those consultations be conducted in accordance with the principles laid down in the Interinstitutional Agreement of 13 April 2016 on Better Law-Making58. In particular, to ensure equal participation in the preparation of delegated acts, the European Parliament and the Council receive all documents at the same time as Member States’ experts, and their experts systematically have access to meetings of Commission expert groups dealing with the preparation of delegated acts.' '58 OJ L 123, 12.5.2016 p.1.

Amendment 770
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 85
(85) In order to ensure that the regulatory framework can be adapted where necessary, the power to adopt acts in accordance with Article 290 TFEU should be delegated to the Commission to amend the techniques and approaches referred to in Annex I to define AI systems, the Union harmonisation legislation listed in Annex II and the content of the EU declaration of conformity in Annex V. It is of particular importance that the Commission carry out appropriate consultations during its preparatory work, including at expert level, and that those consultations be conducted in accordance with the principles laid down in the Interinstitutional Agreement of 13 April 2016 on Better Law-Making58 . In particular, to ensure equal participation in the preparation of delegated acts, the European Parliament and the Council receive all documents at the same time as Member States’ experts, and their experts systematically have access to meetings of Commission expert groups dealing with the preparation of delegated acts.' '58 OJ L 123, 12.5.2016, p. 1.

Amendment 771
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 85
(85) In order to ensure that the regulatory framework can be adapted where necessary, the power to adopt acts in accordance with Article 290 TFEU should be delegated to the Commission to amend the techniques and approaches referred to in Annex I to define AI systems, the Union harmonisation legislation listed in Annex II, the high-risk AI systems listed in Annex III, the provisions regarding technical documentation listed in Annex IV, the content of the EU declaration of conformity in Annex V, the provisions regarding the conformity assessment procedures in Annex VI and VII and the provisions establishing the high-risk AI systems to which the conformity assessment procedure based on assessment of the quality management system and assessment of the technical documentation should apply. It is of particular importance that the Commission carry out appropriate consultations during its preparatory work, including at expert level, and that those consultations be conducted in accordance with the principles laid down in the Interinstitutional Agreement of 13 April 2016 on Better Law-Making58 . These consultations should involve the participation of a balanced selection of stakeholders, including consumer organisations, associations representing affected persons, businesses representatives from different sectors and sizes, as well as researchers and scientists. In particular, to ensure equal participation in the preparation of delegated acts, the European Parliament and the Council receive all documents at the same time as Member States’ experts, and their experts systematically have access to meetings of Commission expert groups dealing with the preparation of delegated acts.' '58 OJ L 123, 12.5.2016, p. 1.

Amendment 772
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 85
(85) In order to ensure that the regulatory framework can be adapted where necessary, the power to adopt acts in accordance with Article 290 TFEU should be delegated to the Commission to amend the Union harmonisation legislation listed in Annex II, the high-risk AI systems listed in Annex III, the provisions regarding technical documentation listed in Annex IV, the content of the EU declaration of conformity in Annex V and the provisions regarding the conformity assessment procedures in Annex VI and VII. It is of particular importance that the Commission carry out appropriate consultations during its preparatory work, including at expert level, and that those consultations be conducted in accordance with the principles laid down in the Interinstitutional Agreement of 13 April 2016 on Better Law-Making58 . In particular, to ensure equal participation in the preparation of delegated acts, the European Parliament and the Council receive all documents at the same time as Member States’ experts, and their experts systematically have access to meetings of Commission expert groups dealing with the preparation of delegated acts.' '58 OJ L 123, 12.5.2016, p. 1.

Amendment 773
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 85
(85) In order to ensure that the regulatory framework can be adapted where necessary, the power to adopt acts in accordance with Article 290 TFEU should be delegated to the Commission to amend the techniques and approaches referred to in Annex I to define AI systems, the Union harmonisation legislation listed in Annex II, the high-risk AI systems listed in Annex III, the provisions regarding technical documentation listed in Annex IV, the content of the EU declaration of conformity in Annex V, the provisions regarding the conformity assessment procedures in Annex VI and VII and the provisions establishing the high-risk AI systems to which the conformity assessment procedure based on assessment of the quality management system and assessment of the technical documentation should apply. It is of particular importance that the Commission carry out appropriate consultations during its preparatory work, including with industry, civil society, other stakeholders, and at expert level, and that those consultations be conducted in accordance with the principles laid down in the Interinstitutional Agreement of 13 April 2016 on Better Law-Making58 . In particular, to ensure equal participation in the preparation of delegated acts, the European Parliament and the Council receive all documents at the same time as Member States’ experts, and their experts systematically have access to meetings of Commission expert groups dealing with the preparation of delegated acts.' '58 OJ L 123, 12.5.2016, p. 1.

Amendment 774
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 86 a (new)
(86 a) Given the rapid technological developments and the required technical expertise in conducting the assessment of high-risk AI systems, the Commission should regularly review Annex III, at least every six months, while consulting with the relevant stakeholders, including ethics experts and anthropologists, sociologists, mental health specialists and any relevant scientists and researchers.

Amendment 775
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Recital 86 a (new)
(86 a) In order to ensure uniform conditions for the implementation of this Regulation, it should be accompanied by the publication of guidelines to help all stakeholders to interpret key concepts covered by the Regulation, such as prohibited or high-risk AI cases and the precise means and implementation rules of the Regulation by national competent authorities;

Amendment 776
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 86 b (new)
(86 b) When adopting delegated or implementing acts concerning high-risk sectors of AI development, notably those raising concerns with respect to ethical principles or entailing risks to the health or safety of humans, animals or plants, or the protection of the environment, Member States should also assume greater responsibility in the decision-making process. In particular, the abstentions of Member States representatives’ should be counted within a qualified majority, each Member State representative should give substantive reasons for votes and abstentions, each of their vote and abstention should be accompanied by a detailed justification, on the basis of Regulation XX/XX amending Regulation (EU) No 182/2011.

Amendment 777
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 87 a (new)
(87 a) As reliable information on the resource and energy use, waste production and other environmental impact of AI systems and related ICT technology, including software, hardware and in particular data centres, is limited, the Commission should evaluate the impact and effectiveness of this Regulation regarding these criteria and further evaluate bringing legislation for the sector to contribute to EU climate strategy and targets.

Amendment 778
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 89
(89) The European Data Protection Supervisor and the European Data Protection Board were consulted in accordance with Article 42(2) of Regulation (EU) 2018/1725 and delivered an opinion on 18.6.2021”.

Amendment 779
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 1 - title
1 Aim and subject matter

Amendment 780
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 1 - paragraph -1 (new)
-1 The purpose of this Regulation is to ensure a high level of protection of health, safety, fundamental rights, the environment and the Union values enshrined in Article 2 TEU from harmful effects of artificial intelligence systems in the Union while promoting innovation.

Amendment 781
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 1 - paragraph -1 (new)
-1 The purpose of this Regulation is to ensure a high level of protection of health, safety, fundamental rights and the environment, from harmful effects of artificial intelligence systems ("AI systems") in the Union, while enhancing innovation.

Amendment 782
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 1 - paragraph -1 (new)
-1 The purpose of this Regulation is to ensure a high level of protection of health, safety, and fundamental rights from harmful effects of artificial intelligence systems ("AI systems") in the Union, while enhancing innovation.

Amendment 783
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 1 - paragraph 1 - introductory part
1.The purpose of this Regulation is to ensure a high level of protection of public interests, such as health, safety, fundamental rights, the environment and democracy from harmful effects of artificial intelligence systems ("AI systems") in the Union, whether individual, societal or environmental, while enhancing innovation.Its provisions are underpinned by the precautionary principle.', 'This Regulation lays down:

Amendment 784
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 1 - paragraph 1 - introductory part
The purpose of this Regulation is to ensure a high level of protection of fundamental rights, health, safety and the environment from harmful effects of the use of artificial intelligence systems in the Union while enhancing innovation. This Regulation lays down:

Amendment 785
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article premier - paragraph 1 - point a
(a) harmonised minimum rules for the development of human-centric AI in the Union through the placing on the market, putting into service and use of artificial intelligence systems (‘AI systems’);

Amendment 786
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 1 - paragraph 1 - point a
(a) harmonised rules for the placing on the market, the development, the putting into service, the deployment and the use of human-centric and trustworthy artificial intelligence systems (‘AI systems’) in the Union;

Amendment 787
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Article 1 - paragraph 1 - point a
(a) harmonised rules for the placing on the market, the putting into service and the use of safe and trustworthy artificial intelligence systems (‘AI systems’) in the Union;

Amendment 788
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 1 - paragraph 1 - point a
(a) harmonised rules for the development, placing on the market, the putting into service and the use of artificial intelligence systems (‘AI systems’) in the Union;

Amendment 789
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 1 - paragraph 1 - point a
(a) harmonised rules for the development, placing on the market, the putting into service and the use of artificial intelligence systems (‘AI systems’) in the Union;

Amendment 790
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 1 - paragraph 1 - point a a (new)
(a a) principles applicable to all AI systems;

Amendment 791
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 1 - paragraph 1 - point c
(c) specific requirements for high-risk AI systems and obligations for operators of such systems, unless these systems are already covered by sector-specific regulation;

Amendment 792
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 1 - paragraph 1 - point c a (new)
(c a) harmonised rules on high-risk AI systems to ensure a high level of trustworthiness and protection of fundamental rights, health and safety, the Union values enshrined in Article 2 TEU and the environment;

Amendment 793
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 1 - paragraph 1 - point c a (new)
(c a) harmonised rules on high-risk AI systems to ensure a high level of trustworthiness and protection of fundamental rights, health and safety

Amendment 794
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 1 - paragraph 1 - point d
(d) harmonised transparency rules for AI systems;

Amendment 795
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 1 - paragraph 1 - point d
(d) harmonised transparency rules for AI systems;

Amendment 796
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Vlad-Marius Botoş, Moritz Körner,
Article 1 - paragraph 1 - point d
(d) harmonised transparency rules for certain AI systems;

Amendment 797
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 1 - paragraph 1 - point e
(e) rules on market monitoring, market surveillance and governance;', '.

Amendment 798
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 1 - paragraph 1 - point e
(e) rules on market monitoring, market surveillance and enforcement.

Amendment 799
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 1 - paragraph 1 - point e
(e) rules on market monitoring, market surveillance and governance;

Amendment 800
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 1 - paragraph 1 - point e a (new)
(e a) measures in support of innovation with a particular focus on SMEs and start-ups, including but not limited to setting up regulatory sandboxes and targeted measures to reduce the compliance burden on SME’s and start-ups;

Amendment 801
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Article 1 - paragraph 1 - point e a (new)
(e a) measures to support innovation and provide for a level playing field for European providers of AI systems on international level, in particular for small-scale providers like SMEs.

Amendment 802
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Dita Charanzová, Andrus Ansip, Morten
Article 1 - paragraph 1 - point e a (new)
(e a) measures in support of innovation with a particular focus on SMEs and start-ups, including the setting up of regulatory sandboxes and the reduction of regulatory burdens.

Amendment 803
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 1 - paragraph 1 - point e a (new)
(e a) rules for the establishment and functioning of the European Union Artificial Intelligence Office;

Amendment 804
EPP - Group of the European Peoples Party (Christian Democrats)
Karlo Ressler
Article 1 - paragraph 1 - point e a (new)
(e a) measures in support of innovation particularly focusing on SMEs and start-ups.

Amendment 805
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 1 - paragraph 1 - point e b (new)
(e b) measures in support of innovation, including the setting up of regulatory sandboxes, and measures to reduce the regulatory burden on SMEs and start-ups.

Amendment 806
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 1 - paragraph 1 a (new)
(e b) the establishment of an independent ‘European Artificial Intelligence Board’ and its activities supporting the enforcement of this Regulation.

Amendment 807
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 1 - paragraph 1 a (new)
This Regulation is based on the principle that it is for developers, importers, distributors and users to ensure that they develop, place on the market or use AI systems that do not adversely affect health, safety, or fundamental rights. Its provisions are underpinned by the precautionary principle.

Amendment 808
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 1 - paragraph 1 a (new)
When justified by significant risks to fundamental rights of persons, including the protection of consumer rights, Member States may introduce regulatory solutions ensuring a higher level of protection of persons than offered in this Regulation.

Amendment 809
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 1 - paragraph 1 a (new)
The purpose of this Regulation is to ensure protection of health, safety, fundamental rights and the environment, from harmful effects of artificial intelligence systems in the Union, while supporting innovation.

Amendment 810
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 1 - paragraph 1 a (new)
These provisions shall apply to AI systems as a product, service or practice, or as part of a product, service or practice.

Amendment 811
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 1 - paragraph 1 b (new)
This Regulation shall be applied taking due account of the precautionary principle.

Amendment 812
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 1 - paragraph 1 b (new)
This Regulation is based on the principle that it is for developers, importers, distributors and downstream users to ensure that they develop, place on the market or use artificial intelligence that does not adversely affect health, safety, fundamental rights, and the environment. Its provisions are underpinned by the precautionary principle.

Amendment 813
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 1 - paragraph 1 b (new)
This Regulation is based on the principle that it is for developers, importers, distributors and downstream users to ensure that they develop, place on the market or use artificial intelligence that does not adversely affect health, safety, fundamental rights, or the environment. Its provisions are underpinned by the precautionary principle.

Amendment 814
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 1 - paragraph 1 c (new)
Any processing of personal data for the purposes of this Regulation shall take place in accordance with Union legislation for the protection of personal data, in particular Regulation 2016/679, Directive 2016/680, Regulation 2018/1725 and Directive 2002/58.

Amendment 815
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 2 - paragraph 1 - point a
(a) providers placing on the market, developing, putting into service or deploying AI systems in the Union, irrespective of whether those providers are established within the Union or in a third country;

Amendment 816
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 2 - paragraph 1 - point a a (new)
(a) operators placing on the market or putting into service AI systems in the Union, irrespective of whether those operators are established within the Union or in a third country;

Amendment 817
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 2 - paragraph 1 - point a a (new)
(a a) providers of AI systems that have their main establishment in the EU;

Amendment 818
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 2 - paragraph 1 - point b
(b) users of AI systems who are physically present or established within the Union;

Amendment 819
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 2 - paragraph 1 - point b
(b) deployers of AI systems located or established within the Union;

Amendment 820
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz Körner, Jan-
Article 2 - paragraph 1 - point b
(b) users of AI systems who are established within the Union;

Amendment 821
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 2 - paragraph 1 - point b
(b) users of AI systems that are located within the Union;

Amendment 822
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Article 2 - paragraph 1 - point b a (new)
(b) users of AI systems using the AI system in the Union;

Amendment 823
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 2 - paragraph 1 - point b a (new)
(b a) natural persons affected by the use of AI systems;

Amendment 824
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 2 - paragraph 1 - point c
(c) providers and users of AI systems that are located in a third country, where the output, meaning predictions, recommendations or decisions, produced by the AI system and influencing the environment it interacts with, is intended for use in the Union and puts at risk the health, safety or fundamental rights of natural persons physically present in the Union, insofar as the provider has permitted, is aware or can reasonably expect such use;

Amendment 825
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 2 - paragraph 1 - point c
(c) providers and users of AI systems that are located in a third country, where the output produced by the system is used in the Union or affects natural persons within the Union;

Amendment 826
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 2 - paragraph 1 - point c
(c) providers and users of AI systems that are located in a third country, where the output produced by the system is used in the Union or has effects in the Union;

Amendment 827
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz
Article 2 - paragraph 1 - point c
(c) providers and users of AI systems who are established in a third country, where the output produced by the system is used in the Union;

Amendment 828
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 2 - paragraph 1 - point c a (new)
(c a) public authorities in a third country or to international organisations where those authorities or organisations use AI systems in the framework of international agreements for law enforcement and judicial cooperation with the Union or with one or more Member States.

Amendment 829
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 2 - paragraph 1 - point c a (new)
(c a) importers, distributors, and authorised representatives of providers of AI systems;

Amendment 830
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 2 - paragraph 1 - point c a (new)
(c a) importers, distributors and authorised representatives of providers of AI-systems.

Amendment 831
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 2 - paragraph 1 - point c a (new)
(c a) natural persons, affected by the use of an AI system, who are in the Union;

Amendment 832
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 2 - paragraph 1 - point c a (new)
(c a) natural persons, affected by the use of an AI system, who are in the Union;

Amendment 833
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 2 - paragraph 1 - point c a (new)
(c a) importers and distributors of AI systems;

Amendment 834
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 2 - paragraph 1 - point c b (new)
(c b) product placing on the market or putting into service an AI system together with their product and under their own name or trademark;

Amendment 835
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 2 - paragraph 1 - point c b (new)
(c b) providers placing on the market or putting into service AI systems outside the Union where the provider is located within the Union;

Amendment 836
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 2 - paragraph 1 - point c b (new)
(c b) AI systems as a product, service or practice, or as part of a product, service or practice.

Amendment 837
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 2 - paragraph 1 - point c c (new)
(c c) authorised representatives of providers, which are established in the Union.

Amendment 838
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 2 - paragraph 1 a (new)
1 a. providers placing on the market or putting into service AI systems in a third country where the provider or distributor of such AI systems originates from the Union;

Amendment 839
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 2 - paragraph 1 a (new)
1 a. This Regulation shall also apply to Union institutions, offices and agencies where they develop, deploy or otherwise make use of AI systems.

Amendment 840
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 2 - paragraph 1 a (new)
1 a. This Regulation shall apply to Union institutions, offices, bodies and agencies when acting as an operator of an AI system.

Amendment 841
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 2 - paragraph 2
deleted

Amendment 842
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Article 2 - paragraph 2 - introductory part
2. In order to ensure legal certainty, preserve the existing legislation and avoid duplication, only Article 84 of this Regulation shall apply for high-risk AI systems that are safety components of products or systems, or which are themselves products or systems, falling within the scope of the following acts:

Amendment 843
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 2 - paragraph 2 - introductory part
2. For high-risk AI systems that are safety components of products or systems, or which are themselves products or Systems and that fall within the scope of the listed Acts in Annex II - Section B, only Article 84 of this Regulation shall apply.

Amendment 844
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz
Article 2 - paragraph 2 - introductory part
2. For AI systems classified as high-risk AI in accordance with Article 6 related to products covered by Union harmonisation legislation listed in Annex II, section B only Article 84 of this Regulation shall apply.

Amendment 845
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz
Article 2 - paragraph 2 - point a
deleted

Amendment 846
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 2 - paragraph 2 - point b
deleted

Amendment 847
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz
Article 2 - paragraph 2 - point b
deleted

Amendment 848
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 2 - paragraph 2 - point b
deleted

Amendment 849
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz
Article 2 - paragraph 2 - point c
deleted

Amendment 850
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 2 - paragraph 2 - point c
deleted

Amendment 851
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz
Article 2 - paragraph 2 - point d
deleted

Amendment 852
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 2 - paragraph 2 - point d
deleted

Amendment 853
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz
Article 2 - paragraph 2 - point e
deleted

Amendment 854
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 2 - paragraph 2 - point e
deleted

Amendment 855
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 2 - paragraph 2 - point f
deleted

Amendment 856
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz
Article 2 - paragraph 2 - point f
deleted

Amendment 857
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz
Article 2 - paragraph 2 - point g
deleted

Amendment 858
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 2 - paragraph 2 - point g
deleted

Amendment 859
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 2 - paragraph 2 - point h
deleted

Amendment 860
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz
Article 2 - paragraph 2 a (new)
deleted

Amendment 861
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 2 - paragraph 2 a (new)
2 a. This Regulation shall not apply to AI systems, including their output, specifically developed and put into service for the sole purpose of scientific research and development.

Amendment 862
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Milan Brglez, Hilde Vautmans, Catharina Rinzema
Article 2 - paragraph 2 a (new)
2 a. AI systems likely to interact with or impact on children shall be considered high-risk for this group;

Amendment 863
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 2 - paragraph 3
2 b. This Regulation shall not apply to any research and development activity regarding AI systems in so far as such activity does not lead to or entail placing an AI system on the market or putting it into service.

Amendment 864
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 2 - paragraph 3
deleted

Amendment 865
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 2 - paragraph 3
deleted

Amendment 866
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 2 - paragraph 3
deleted

Amendment 867
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 2 - paragraph 3
3. This Regulation shall not apply to AI systems developed or used exclusively for military purposes.', 'However, this Regulation shall apply to AI systems which are developed or used as dual-use items, as defined in Article 2, point (1) of Regulation (EU) 2021/821 of the European Parliament and of the Council1a.' '1a Regulation (EU) 2021/821 of the European Parliament and of the Council of 20 May 2021 setting up a Union regime for the control of exports, brokering, technical assistance, transit and transfer of dual-use items (OJ L 206, 11.6.2021, p. 1).

Amendment 868
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 2 - paragraph 3
3. This Regulation shall not apply to AI systems developed or used exclusively for military purposes, unless the AI system is subsequently used for non-military purposes.

Amendment 869
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 2 - paragraph 3
3. This Regulation shall not apply to AI systems developed or used exclusively for military or national security purposes

Amendment 870
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan, Vincenzo Sofo
Article 2 - paragraph 3
3. This Regulation shall not apply to AI systems designed, modified, developed or used exclusively for military purposes.

Amendment 871
ECR - European Conservatives and Reformists Group
Rob Rooken
Article 2 - paragraph 3
3. This Regulation shall not apply to AI systems developed or used for military purposes.

Amendment 872
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 2 - paragraph 3 a (new)
3 a. Union law on the protection of personal data, privacy and the confidentiality of communications applies to personal data processed in connection with the rights and obligations laid down in this Regulation. This Regulation shall not affect Regulations (EU) 2016/679, (EU) 2018/1725 or Directives 2002/58/EC and (EU) 2016/680.

Amendment 873
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 2 - paragraph 3 a (new)
3 a. Any exemptions from the application of this Act to AI systems used exclusively by Member States for national security purposes will be without prejudice to the application of Union law to any activity carried out by the Union or by a Member State that is subject to Union law.

Amendment 874
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 2 - paragraph 3 a (new)
3 a. This Regulation shall not apply to AI systems, including their output, specifically developed and put into service for the sole purpose of research and development.

Amendment 875
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 2 - paragraph 3 a (new)
3 a. Title III of this Regulation shall not apply to AI systems that are used in a business-to-business environment and do not directly impact natural persons.

Amendment 876
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 2 - paragraph 4
3 a. This Regulation shall apply to Union institutions, offices, bodies and agencies when acting as an operator of an AI system.

Amendment 877
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte
Article 2 - paragraph 4
deleted

Amendment 878
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 2 - paragraph 4
deleted

Amendment 879
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 2 - paragraph 4
deleted

Amendment 880
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 2 - paragraph 4
deleted

Amendment 881
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 2 - paragraph 4
deleted

Amendment 882
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 2 - paragraph 4
deleted

Amendment 883
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 2 - paragraph 4
4. This Regulation shall not apply to public authorities in a third country nor to international organisations falling within the scope of this Regulation pursuant to paragraph 1, where those authorities or organisations use AI systems in the framework of international agreements for law enforcement and judicial cooperation with the Union or with one or more Member States and are subject of a decision of the Commission adopted in accordance with Article 36 of Directive (EU)2016/680 or Article 45 of Regulation 2016/679 (‘adequacy decision’) or are part of an international agreement concluded between the Union and that third country or international organisation pursuant to Article 218 TFEU adducing adequate safeguards with respect to the protection of privacy and fundamental rights and freedoms of individuals;

Amendment 884
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Patryk Jaki
Article 2 - paragraph 5 a (new)
4. This Regulation shall not apply to public authorities in a third country nor to international organisations falling within the scope of this Regulation pursuant to paragraph 1, where those authorities or organisations use AI systems in the framework of international cooperation or agreements for law enforcement and judicial cooperation or in the context of border checks, asylum and immigration related activities with the Union or with one or more Member States.

Amendment 885
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 2 - paragraph 5 a (new)
5 a. The use of any AI-system that is in line with this Regulation, should also continue to comply with the European Charter on Fundamental Rights, secondary Union law and national law. This Regulation shall not provide the legal ground for unlawful AI development, deployment or use.

Amendment 886
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 2 - paragraph 5 a (new)
5 a. An AI-system or practice that is in line with this Regulation, should also continue to comply with the European Charter on Fundamental Rights, existing and new secondary Union law and national law.

Amendment 887
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Vincenzo Sofo, Adam Bielan
Article 2 - paragraph 5 a (new)
5 a. This Regulation shall not apply to AI systems, including their output, specifically developed or used exclusively for scientific research and development purposes.

Amendment 888
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 2 - paragraph 5 a (new)
5 a. This Regulation shall not affect any research, testing and development activity regarding an AI system prior to this system being placed on the market or put into service.

Amendment 889
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 2 - paragraph 5 a (new)
5 a. This Regulation shall not provide a legal basis for the development, deployment or use of AI systems that is unlawful under Union or national law;

Amendment 890
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 2 - paragraph 5 a (new)
5 a. This Regulation shall not affect community law on social policy.

Amendment 891
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 2 - paragraph 5 b (new)
5 b. This Regulation shall not affect national labour law and practice or collective agreements, and it shall not preclude national legislation to ensure the protection of workers’ rights in respect of the use of AI systems by employers, including where this implies introducing more stringent obligations than those laid down in this Regulation.

Amendment 892
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 2 - paragraph 5 b (new)
5 b. This Regulation shall not apply to AI systems, including their output, specifically developed and put into service for the sole purpose of scientific research, testing and development. The Commission may adopt delegated acts that clarify this exemption.

Amendment 893
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 2 - paragraph 5 b (new)
5 b. This Regulation is without prejudice to the rules laid down by other Union legal acts regulating the protection of personal data, in particular Regulation (EU) 2016/679, Directive (EU) 2016/680, Regulation (EU) 2018/1725, and Directive 2002/57/EC;

Amendment 894
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 2 - paragraph 5 b (new)
5 b. Member States may adopt or maintain in force more stringent provisions, compatible with the Treaty in the field covered by this Directive, to ensure a higher level of protection of health, safety and fundamental rights.

Amendment 895
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 2 - paragraph 5 b (new)
5 b. This Regulation shall not affect any research and development activity regarding AI systems in so far as such activity does not lead to placing an AI system on the market or putting it into service.

Amendment 896
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 2 - paragraph 5 b (new)
5 b. This Regulation shall be without prejudice to Regulation (EU) 2016/679.

Amendment 897
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina Penkova, Petar Vitanov, René Repasi, Birgit Sippel, Maria Grapini, Adriana Maldonado López, Maria-Manuel Leitão-Marques
Article 2 - paragraph 5 c (new)
5 c. This Regulation is without prejudice to the rules laid down by other Union legal acts regulating other aspects of AI systems as well as the national rules aimed at enforcing or, as the case may be, implementing these acts, in particular Union law on consumer protection and product safety, including Regulation (EU)2017/2394, Regulation (EU) 2019/1020, Directive 2001/95/EC on general product safety and Directive 2013/11/EU.

Amendment 898
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 2 - paragraph 5 c (new)
5 c. This Regulation is without prejudice to the rules laid down by other Union legal acts relating to consumer protection and product safety, including Regulation (EU) 2017/2394, Regulation (EU) 2019/1020 and Directive 2001/95/EC on general product safety and Directive 2013/11/EU.

Amendment 899
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 2 - paragraph 5 c (new)
5 c. This Regulation shall be without prejudice to Community law on social policy.

Amendment 900
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 2 - paragraph 5 d (new)
5 d. This Regulation shall be without prejudice to national labour law and practice, that is any legal or contractual provision concerning employment conditions, working conditions, including health and safety at work and the relationship between employers and workers, including information, consultation and participation

Amendment 901
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 2 - paragraph 5 e (new)
5 e. This Regulation shall not in any way affect the exercise of fundamental rights as recognised in the Member States and at Union level, including the right or freedom to strike or to take other action covered by the specific industrial relations systems in Member States, in accordance with national law and/or practice. Nor does it affect the right to negotiate, to conclude and enforce collective agreements, or to take collective action in accordance with national law and/or practice.

Amendment 902
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 2 a (new)
Article 2 a', 'Metaverse environments', '1. This regulation shall apply, mutatis mutandis, to operators of AI systems operating in virtual environments that can be accessed by natural persons in the Union that fulfil all the following criteria (‘metaverse environments’):', '(i) they require natural persons to have a uniquely identifiable and permanent representation within the virtual environment that is legally and economically connected to them via an official identity document, a digital identity, a digital wallet, or equivalent;', '(ii) they are built for social and economic interaction on a large scale;', '(iii) they allow natural persons to behave and interact virtually in manners that are consistent with their real-world behaviours and interactions and that can be analysed to infer real-world characteristics, including personal data;', '(iv) they allow natural persons to engage in real-world financial transactions, including through blockchain-backed digital currencies and non-fungible tokens;', '(v) they allow for such interactions between natural persons as to make possible risks to the health, safety, or fundamental rights of natural persons or to bring prejudice to the values of the Union as enshrined in Article 2 TEU.

Amendment 903
ECR - European Conservatives and Reformists Group
Rob Rooken
Article 3 - paragraph 1 - point 1
(1) ‘artificial intelligence system’ (AI system) refers to systems designed by humans that, given a complex goal, act in the physical or digital world by perceiving their environment, interpreting the collected structured or unstructured data, reasoning on the knowledge derived from this data and deciding the best action(s) to take (according to pre-defined parameters) to achieve the given goal. AI systems can also be designed to learn to adapt theirbehaviour by analysing how the environment is affected by their previous actions. As a scientific discipline, AI includes several approaches and techniques, such as machine learning (of which deep learning and reinforcement learning are specific examples), machine reasoning (which includes planning, scheduling, knowledge representation and reasoning, search, and optimization), and robotics(which includes control, perception, sensors and actuators, as well as the integration of all other techniques into cyber-physical systems);

Amendment 904
EPP - Group of the European Peoples Party (Christian Democrats)
Geoffroy Didier
Article 3 - paragraph 1 - point 1
(1) ‘artificial intelligence system’ (AI system) means a system that combines these three criteria:', '(i) receives machine and/or human-based data and inputs,', '(ii) infers how to achieve a given set of human-defined objectives using learning, reasoning or modelling implemented with the techniques and approaches listed in Annex I, and', '(iii) generates outputs in the form of content (generative AI systems), predictions, recommendations or decisions, which influence the environments it interacts with;

Amendment 905
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar
Article 3 - paragraph 1 - point 1
(1) ‘artificial intelligence system’ (AI system) means software that display intelligent behaviour by analysing their environment and taking actions - with some degree of autonomy - to achieve specific goals, which:', '(a) receives machine and/or human-based data and inputs;', '(b) infers how to achieve a given set of human-defined objectives using data-driven models created through learning or reasoning implemented with the techniques and approaches listed in Annex I, and', '(c) generates outputs in the form of content (generative AI systems), predictions, recommendations or decisions, which influence the environments it interacts with;

Amendment 906
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 1
(1) ‘artificial intelligence system’ (AI system) means a machine-based system that is developed with one or more of the techniques and approaches listed in Annex I and is capable of influencing the environment by producing an output(predictions, recommendations, or decisions) for a given set of objectives. It uses machine and/or human-based data and inputs to (i) perceive real and/or virtual environments; (ii) abstract these perceptions into models through analysis in an automated manner (e.g. with machine learning), or manually; and (iii) use model inference to formulate options for outcomes. AI systems are designed to operate with varying levels of autonomy;

Amendment 907
Renew - Renew Europe Group
Morten Løkkegaard
Article 3 - paragraph 1 - point 1
(1) 'artificial intelligence' (AI) systems are software (and also hardware) systems designed by humans that, given a complex goal, act in the physical or digital dimension by perceiving their environment through data acquisition, interpreting the collected structured or unstructured data, reasoning on the knowledge, or processing the information, derived from this data and deciding the best action(s) to take to achieve the given goal. AI systems can either use symbolic rules or learn a numeric model, and they can also adapt their behaviour by analysing how the environment is affected by their previous actions;

Amendment 908
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 3 - paragraph 1 - point 1
(1) ‘artificial intelligence system’ (AI system) means a system that', '(I) receives machine and/or human-based data and inputs,', '(II) infers how to achieve a given set of human-defined objectives using learning, reasoning or modelling implemented with the techniques and approaches listed in Annex I, and', '(III) generates outputs in the form of content, predictions, recommendations or decisions, which influence the environments it interacts with;

Amendment 909
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 3 - paragraph 1 - point 1
(1) ‘artificial intelligence (AI)' means computer systems that act in the physical or digital world and that, in an automated manner:", '(i) decide on action(s) to take according to predefined parameters by perceiving their environment and analysing the collected structured or unstructured information from that environment;and/or', '(ii) can adapt their decisions by analysing how the environment is affected by their previous actions.

Amendment 910
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Article 3 - paragraph 1 - point 1
(1) ‘artificial intelligence system’ (AI system) means a system that operates with varying degrees of autonomy, uses one or more of the techniques and approaches listed in Annex I and can, for human-defined objectives, generate outputs such as content, predictions, recommendations, or decisions influencing the environments they interact with and that cannot be fully predicted by the natural person developing the system;

Amendment 911
ECR - European Conservatives and Reformists Group
Carlo Fidanza
Article 3 - paragraph 1 - point 1
(1) ‘artificial intelligence system’ (AI system) means a machine-based system that can, for a given set of human-defined objectives, make predictions, recommendations, or decisions real or virtual environments

Amendment 912
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Vlad-Marius Botoş, Moritz Körner, Ondřej Kovařík, Jan-
Article 3 - paragraph 1 - point 1
(1) ‘artificial intelligence system’ (AI system) means software that can, for a given set of human-defined objectives, generate outputs such as predictions, recommendations, or decisions influencing real or virtual environments; AI systems can be designed to operate with varying levels of autonomy and can be developed with one or more of the techniques and approaches listed in Annex I;

Amendment 913
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Article 3 - paragraph 1 - point 1
(1) ‘artificial intelligence system’ (AI system) means a system based on machine or human-based data and input that infers how to achieve a given set of human-defined objectives using one or more of the techniques and approaches listed in Annex I and generates outputs such as content, predictions, recommendations, or decisions influencing the environments they interact with;

Amendment 914
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Article 3 - paragraph 1 - point 1
(1) ‘artificial intelligence system’ (AI system) means software that is developed with one or more of the techniques and approaches listed in Annex I and can, for a given set of human-defined objectives, indispensably with some degree of autonomy, generate outputs such as content, predictions, recommendations, or decisions influencing the environments they interact with;

Amendment 915
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 3 - paragraph 1 - point 1
(1) ‘artificial intelligence system’ (AI system) means software that is developed with one or more of the techniques and approaches listed in Annex I and can, for a given set of objectives or parameters subject to human command, generate outputs such as content, predictions, recommendations, or decisions influencing the environments they interact with;

Amendment 916
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Article 3 - paragraph 1 - point 1
(1) ‘artificial intelligence system’ (AI system) means software that is developed with one or more of the techniques and approaches listed in Annex I and can, for a given set of human-defined objectives and with varying levels of autonomy, generate outputs such as content, predictions, recommendations, or decisions influencing the environments they interact with;

Amendment 917
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 3 - paragraph 1 - point 1
(1) ‘artificial intelligence system’ (AI system) means software that is developed with one or more of the techniques and approaches listed in Annex I and can, for a given set of inputs and objectives, generate outputs such as content, predictions, recommendations, or decisions;

Amendment 918
EPP - Group of the European Peoples Party (Christian Democrats)
Karlo Ressler
Article 3 - paragraph 1 - point 1
(1) ‘artificial intelligence system’ (AI system) means a machine-based system that can, for a given set of human-defined objectives, make predictions, recommendations, or decisions influencing real or virtual environments and is designed to operate with varying levels of autonomy;

Amendment 919
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 1
(1) ‘artificial intelligence system’ (AI system) means software that is developed with one or more of the techniques and approaches listed in Annex I and can generate outputs such as content, predictions, recommendations, or decisions influencing the environments they interact with;

Amendment 920
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 3 - paragraph 1 - point 1
(1) ‘artificial intelligence system’(AI system) means software that can perceive, learn, reason or model based on machine and/or human based inputs, to generate outputs such as content, hypotheses, predictions, recommendations, or decisions influencing the real or virtual environments they interact with;

Amendment 921
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 3 - paragraph 1 - point 1 a (new)
(1) 'artificial intelligence system’ (AI system) means software that can for example perceive, learn, reason or model based on machine and/or human based inputs, to generate outputs such as content, hypotheses, predictions, recommendations, or decisions influencing the real or virtual environments they interact with;

Amendment 922
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 3 - paragraph 1 - point 1 a (new)
(1a) ‘human-centric AI’ means an approach which strives to ensure that human values are central to the development, deployment, use and monitoring of AI systems, by ensuring respect for fundamental rights, including those set out in the Treaties of the European Union and the Charter of Fundamental Rights of the European Union, all of which are united by reference to a common foundation rooted in respect for human dignity, in which every human being enjoys a unique and inalienable moral status, which also entails consideration of the natural environment and of other living beings that are part of the human ecosystem, as well as a sustainable approach enabling the flourishing of future generations;

Amendment 923
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Vlad-Marius Botoş, Moritz Körner, Jan-Christoph Oetjen
Article 3 - paragraph 1 - point 1 a (new)
(1 a) 'autonomy' means that to some degree an AI system operates by interpreting certain input and by using a set of pre-determined objectives, without being limited to such instructions, even when the system’s behaviour was initially constrained by, and targeted at, fulfilling the goal it was given and other relevant design choices made by its developer;

Amendment 924
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 1 a (new)
(1 a) ‘machine learning’ means an AI system that gives computers the ability to find patterns in data without being explicitly programmed for a given task;

Amendment 925
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 1 b (new)
(1 b) 'general purpose AI system' means an AI system that - irrespective of the modality in which it is placed on the market or put into service including as open source software - is able to perform generally applicable functions such as image or speech recognition, audio or video generation, pattern detection, question answering, translation or others; a general purpose AI system may be used in a plurality of contexts and may be integrated in a plurality of other AI systems;

Amendment 926
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Vlad-Marius Botoş, Sophia in t Veld, Moritz Körner, Jan-
Article 3 - paragraph 1 - point 1 b (new)
(1 b) 'general purpose AI system’ means an AI system that is able to perform generally applicable functions for multiple potential purposes, such as image or speech recognition, audio or video generation, pattern detection, question answering, and translation, is largely customizable and often open source software;

Amendment 927
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 1 d (new)
(1 c) ‘autonomous’ means an AI-system that operates by interpreting certain input and results and by using a set of pre-determined objectives, without being limited to such instructions, despite the system’s behaviour being constrained by, and targeted at, fulfilling the goal it was given and other relevant design choices made by its provider;

Amendment 928
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 1 d (new)
(1 d) ‘risk’ means the combination of the probability of occurrence of a harm and the severity of that harm;

Amendment 929
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 1 e (new)
(1 e) ‘harm’ means an adverse impact affecting the health, safety or fundamental rights of a natural person;

Amendment 930
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 3 - paragraph 1 - point 2
(2) 'developer' means a natural or legal person, public authority, agency or other body that develops an AI system or that has an AI system developed and places it on the market or puts it into service under its own name or trademark, whether for payment or free of charge or that adapts general purpose AI systems to a specific intended purpose;

Amendment 931
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 2
(2) ‘provider’ means a natural or legal person, public authority, agency or other body that places an AI system on the market or puts it into service under its own name or trademark, whether for payment or free of charge or that adapts general purpose AI systems to an intended purpose;

Amendment 932
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 3 - paragraph 1 - point 2
(2) ‘provider’ means a natural or legal person, public authority, agency or other body that develops an AI system or that has an AI system developed and places that system on the market or puts it into service under its own name or trademark, whether for payment or free of charge;

Amendment 933
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Article 3 - paragraph 1 - point 2
(2) ‘provider’ means a natural or legal person, public authority, agency or other body that develops an AI system or that has an AI system developed and places that system on the market or puts it into service under its own name or trademark, whether for payment or free of charge;

Amendment 934
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 2 a (new)
(2 a) ‘new provider’ means a natural or legal person that becames provider for the purposes of this Regulation due to one of the circumstances referred to in Art 23a(1).

Amendment 935
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 2 b (new)
(2 b) ‘former provider’ means a provider that initially placed the AI system on the market or put it into service but is according to Art 23a(2) no longer considered a provider for the purposes of this Regulation;

Amendment 936
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 2 c (new)
(2 c) ‘original provider’ means a provider of a general purpose AI system, who has made available the AI system to a natural or legal person that itself became a provider by giving an intended purpose to the general purpose AI system;

Amendment 937
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz Körner, Jan-Christoph Oetjen
Article 3 - paragraph 1 - point 3
deleted

Amendment 938
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 3
deleted

Amendment 939
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Samira Rafaela,
Article 3 - paragraph 1 - point 3 a (new)
(3 a) ‘risk’ means the combination of the probability of occurrence of a harm and the severity of that harm;

Amendment 940
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş,
Article 3 - paragraph 1 - point 3 b (new)
(3 b) ‘significant harm‘ means a material harm to a person's life, health and safety or fundamental rights or entities or society at large whose severity is exceptional. The severity is in particular exceptional when the harm is hardly reversible, the outcome has a material adverse impact on health or safety of a person or the impacted person is dependent on the outcome;

Amendment 941
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 3 - paragraph 1 - point 4
(4) ‘user’ means any natural or legal person, public authority, agency or other body using an AI system under its authority;

Amendment 942
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Article 3 - paragraph 1 - point 4
(4) ‘user’ means any natural or legal person, public authority, agency or other body using an AI system under its authority;

Amendment 943
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 4
(4) ‘user’ means any natural or legal person, data subject, public authority, agency or other body using an AI system under its authority and on its own responsibility, except where the AI system is used in the course of a personal non-professional activity;

Amendment 944
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Patryk Jaki, Adam Bielan
Article 3 - paragraph 1 - point 4
(4) ‘deployer’ means any natural or legal person, public authority, agency or other body using an AI system under its authority, except where the AI system is used in the course of a personal non-professional activity;

Amendment 945
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 4
(4) ‘deployer’ means any natural or legal person, public authority, agency or other body using an AI system under its authority, except where the AI system is used in the course of a personal non-professional activity;

Amendment 946
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 3 - paragraph 1 - point 4
(4) ‘deployer’ means any natural or legal person, public authority, agency or other body using an AI system under its authority, except where the AI system is used in the course of a personal non-professional activity;

Amendment 947
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 3 - paragraph 1 - point 4
(4) ‘deployer’ means any natural or legal person, public authority, agency or other body using an AI system under its authority, except where the AI system is used in the course of a personal non-professional activity;

Amendment 948
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 3 - paragraph 1 - point 4 a (new)
(4 a) ‘AI subject’ means any natural or legal person that is subject to a decision based on or assisted by an AI system, or subject to interaction with an AI system or treatment of data relating to them by an AI system, or otherwise subjected to analysis by an AI or otherwise impacted or affected by an AI system;

Amendment 949
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Article 3 - paragraph 1 - point 4 a (new)
(4 a) ‘end user’ means any natural person who, in the context of employment or contractual agreement with the user, uses or deploys the AI system under the authority of the user;

Amendment 950
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 3 - paragraph 1 - point 4 a (new)
(4 a) 'End-user' means any natural person who, in the framework of employment, contract or agreement with the deployer, uses the AI system under the authority of the deployer;

Amendment 951
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
René Repasi, Marc Angel, Andreas Schieder, Maria-Manuel Leitão-Marques
Article 3 - paragraph 1 - point 5
(4 a) ‘affected person’ means the natural or legal person who is ultimately directly or indirectly affected by the deployment of an AI system.

Amendment 952
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 5
(5) ‘authorised representative’ means any natural or legal person physically present or established in the Union who has received and accepted a written mandate from a provider of an AI system to, respectively, perform and carry out on its behalf the obligations and procedures established by this Regulation;

Amendment 953
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 3 - paragraph 1 - point 5
(5) ‘legal representative’ means any natural or legal person established in the Union who has received a written mandate from a provider of an AI system to, respectively, perform and carry out on its behalf any of the obligations and procedures established by this Regulation;

Amendment 954
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 5 a (new)
(5 a) ‘product manufacturer’ means a manufacturer within the meaning of any of the Union harmonisation legislation listed in Annex II;

Amendment 955
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 6
(6) ‘importer’ means any natural or legal person physically present or established in the Union that places on the market an AI system that bears the name or trademark of a natural or legal person established outside the Union;

Amendment 956
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 8
(7 a) ‘economic operator’ means the provider, the authorised representative, the importer and the distributor;

Amendment 957
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 8
(8) ‘operator’ means the economic operator and the user;

Amendment 958
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 3 - paragraph 1 - point 8
(8) ‘operator’ means the provider, the deployer, the authorised representative, the importer and the distributor;

Amendment 959
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 3 - paragraph 1 - point 8 a (new)
(8) ‘operator’ means the provider, the user, the legal representative, the importer and the distributor;

Amendment 960
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 3 - paragraph 1 - point 8 a (new)
(8 a) ‘affected person’ means any natural person or a group of persons who are subjects to or affected by an AI system

Amendment 961
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 3 - paragraph 1 - point 8 a (new)
(8 a) ‘affected person’ means any natural person or group of persons who are subject to or affected by an AI system;

Amendment 962
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 3 - paragraph 1 - point 11
(11) ‘putting into service’ means the supply of an AI system for first use directly to the user or for own use on the Union market for its intended purpose or reasonably foreseeable use ;

Amendment 963
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 3 - paragraph 1 - point 11
(11) ‘putting into service’ means the supply of an AI system for first use directly to the deployer or for own use on the Union market for its intended purpose;

Amendment 964
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 3 - paragraph 1 - point 11
(11) ‘putting into service’ means the supply of an AI system for first use directly to the user or for own use on the Union market for its foreseeable uses;

Amendment 965
EPP - Group of the European Peoples Party (Christian Democrats)
Nathalie Colin-Oesterlé
Article 3 - paragraph 1 - point 11 a (new)
(11a) ‘testing’ means making the AI system available to a limited and restricted group of users before it is placed on the market or put into service;

Amendment 966
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Patryk Jaki, Adam Bielan
Article 3 - paragraph 1 - point 12
(12) ‘intended purpose’ means the specific use for which an AI system is intended by the provider, including the specific context and conditions of use, as specified in the information supplied by the provider in the instructions for use, promotional or sales materials and statements, as well as in the technical documentation; general purpose AI systems shall not be considered as having an intended purpose within the meaning of this Regulation;

Amendment 967
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 3 - paragraph 1 - point 12
(12) ‘foreseeable uses’ means uses that can reasonably be expected to be made of an AI system, including but not limited to the use for which the AI system is intended for consumers or the likely use by consumers under reasonably foreseeable conditions;

Amendment 968
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
René Repasi, Marc Angel, Andreas Schieder, Maria-Manuel Leitão-Marques
Article 3 - paragraph 1 - point 12
(12) ‘reasonably foreseeable purpose’ means the use for which an AI system is intended by the provider, including the specific context and conditions of use, as specified in the information supplied by the provider in the instructions for use, promotional or sales materials and statements, as well as in the technical documentation;

Amendment 969
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 3 - paragraph 1 - point 12 - point i (new)
i) 'Reasonably foreseeable use' means the use of an AI system in a way that is or should be reasonably foreseeable and that addresses the risks to health, safety and fundamental rights that it can cause.

Amendment 970
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 12 a (new)
(12 a) ‘foreseeable uses’ means uses that can reasonably be expected to be made of an AI system, including but not limited to the use for which the AI system is intended for consumers or the likely use by consumers under reasonably foreseeable conditions;

Amendment 971
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 12 a (new)
(12 a) 'reasonably foreseeable use' means the use of an AI system in a way that is or should be reasonably foreseeable;

Amendment 972
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Article 3 - paragraph 1 - point 13
deleted

Amendment 973
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 13
(13) ‘reasonably foreseeable misuse’ means the use of an AI system in a way that is not in accordance with its intended purpose and with the specific context and conditions of use established by the provider, but which may result from reasonably foreseeable human behaviour or interaction with other systems;

Amendment 974
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Article 3 - paragraph 1 - point 13
(13) ‘reasonably foreseeable misuse’ means the use of an AI system within its intended purpose, but not in accordance with the specific context and conditions of use established by the provider and in a way which may result from reasonably foreseeable human behaviour or interaction with other systems;

Amendment 975
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 3 - paragraph 1 - point 13
(13) ‘reasonably foreseeable misuse’ means the use of an AI system in a way that is not in accordance with its purpose as indicated in instruction for use or technical specification, but which may result from reasonably foreseeable human behaviour or interaction with other systems;

Amendment 976
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 3 - paragraph 1 - point 13
(13) ‘reasonably foreseeable misuse’ means the use of an AI system in a way that is not in accordance with its intended purpose, but which may result from reasonably foreseeable human behaviour or interaction with other systems, including other AI systems;

Amendment 977
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 3 - paragraph 1 - point 13
(13) ‘reasonably foreseeable misuse’ means the use of an AI system in a way that is not in accordance with its intended purpose, but which may result from reasonably foreseeable human behaviour or interaction with other systems, and with other AI systems;;

Amendment 978
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 3 - paragraph 1 - point 13
(13) ‘reasonably foreseeable misuse’ means the use of an AI system in a way that is not in accordance with its intended purpose, but which may result from reasonably foreseeable human behaviour or interaction with other systems, and with other AI systems;

Amendment 979
EPP - Group of the European Peoples Party (Christian Democrats)
Nathalie Colin-Oesterlé
Article 3 - paragraph 1 - point 13
(13) ‘reasonably foreseeable misuse’ means the use of an AI system in a way that is not in accordance with its intended purpose, but which may result from known and reasonably foreseeable human behaviour;

Amendment 980
EPP - Group of the European Peoples Party (Christian Democrats)
Karlo Ressler
Article 3 - paragraph 1 - point 13 a (new)
(13 a) ‘harmful subliminal technique’ means a measure whose existence and operation are entirely imperceptible by those on whom it is used, and which has the purpose and direct effect to induce actions leading to that person’s physical or psychological harm.

Amendment 981
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Article 3 - paragraph 1 - point 14
(14) ‘safety component of a product or system’ means a component of a product or of a system which fulfils a safety function for that product or system or the failure or malfunctioning of which endangers the health and safety of persons or property, but which is not necessary in order for the product or system to function;

Amendment 982
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 14
(14) ‘safety component of a product or system’ means, in line with the relevant Union harmonisation legislation listed in Annex II, a component of a product or of a system which fulfils a direct and critical safety function for that product or system so that its malfunction endagers the health and safety of persons;

Amendment 983
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 3 - paragraph 1 - point 14
(14) ‘safety component of a product or system’ means a component of a product or of a system which fulfils a safety or security function for that product or system or the failure or malfunctioning of which endangers the fundamental rights, health or safety of persons, or which damages property or the environment;

Amendment 984
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 3 - paragraph 1 - point 14
(14) ‘safety component of a product or system’ means a component of a product or of a system which fulfils a safety or security function for that product or system or the failure or malfunctioning of which endangers the health, safety, fundamental rights of persons or which damages property, or the environment;

Amendment 985
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 14
(14) ‘safety component of a product or system’ means a component of a product or of a system which fulfils a direct or indirect safety function for that product or system or the failure or malfunctioning of which endangers the health and safety of persons or property;

Amendment 986
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Article 3 - paragraph 1 - point 14
(14) ‘safety component of a product or system’ means a component of a product or of a system which fulfils a safety function for that product or system so that its malfunctioning endangers the health and safety of persons or property;

Amendment 987
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 15
(15) ‘instructions for use’ means the information provided by the provider to inform the user of in particular an AI system’s intended purpose and proper use,

Amendment 988
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 3 - paragraph 1 - point 15
(15) ‘instructions for use’ means the information provided by the provider to inform the user of in particular an AI system’s intended purpose or reasonably foreseeable use and proper use, inclusive of the specific geographical, behavioural or functional setting within which the high-risk AI system is intended or foreseeable to be used;

Amendment 989
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 3 - paragraph 1 - point 15
(15) ‘instructions for use’ means the information provided by the provider to inform the deployer of in particular an AI system’s intended purpose and proper use, inclusive of the specific geographical, behavioural or functional setting within which the high-risk AI system is intended to be used;

Amendment 990
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 3 - paragraph 1 - point 15
(15) ‘instructions for use’ means the information provided by the provider to inform the user of in particular an AI system’s foreseeable uses and proper use, inclusive of the specific geographical, behavioural or functional setting within which the high-risk AI system is intended to be used;

Amendment 991
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 16
(16) ‘recall of an AI system’ means any measure aimed at achieving the return to the provider or taking it out of service or disable the use of an AI system made available to users;

Amendment 992
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 3 - paragraph 1 - point 16
(16) ‘recall of an AI system’ means any measure aimed at achieving the return to the provider of an AI system made available to deployers;

Amendment 993
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 17
(17) ‘withdrawal of an AI system’ means any measure aimed at preventing an AI system in the supply chain being made available on the market;

Amendment 994
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 3 - paragraph 1 - point 18
(18) ‘performance of an AI system’ means the ability of an AI system to achieve its intended purpose or reasonably foreseeable use ;

Amendment 995
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 3 - paragraph 1 - point 18
(18) ‘performance of an AI system’ means the ability of an AI system to achieve its foreseeable uses;

Amendment 996
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 3 - paragraph 1 - point 18 a (new)
(18a) ‘lifecycle of AI’ means the process of developing, deploying and using an AI system, including the research, design, data supply, training, limited-scale deployment, implementation and withdrawal stages;

Amendment 997
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 3 - paragraph 1 - point 20
(20) ‘conformity assessment’ means the process of verification by an independent third party whether the principles and requirements set out in Title III, Chapter 2 of this Regulation relating to an AI system have been fulfilled;

Amendment 998
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 20
(20) ‘conformity assessment’ means the process of demonstrating whether the requirements set out in Title III, Chapter 2 of this Regulation relating to an AI system have been fulfilled;

Amendment 999
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 3 - paragraph 1 - point 20
(20) ‘conformity assessment’ means the process of demonstrating whether the requirements set out in Title III, Chapter 2 of this Regulation relating to an AI system have been fulfilled;

Amendment 1000
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 22
(22) ‘notified body’ means a conformity assessment body notified in accordance with Art 32 of this Regulation and with other relevant Union harmonisation legislation;

Amendment 1001
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Article 3 - paragraph 1 - point 23
(23) ‘substantial modification’ means a change to a high-risk AI system following its placing on the market or putting into service which affects the compliance of the AI system with the requirements set out in Title III, Chapter 2 of this Regulation such as a new training with a completely different dataset with respect to the one used to begin with or the addition of a further AI module into the AI system or results in a modification to the intended purpose for which the AI system has been assessed; Supplementary and periodic training of an AI algorithm by the AI user or provider using their own data to ensure that the system remains accurate and/or is working as intended does not amount to a ‘substantial modification’ under this Regulation. The periodic retraining of models due to new data with same structure shall not constitute a substantial modification. For high-risk AI systems that continue to learn after being placed on the market or put into service, changes to the high-risk AI system and its performance that have been predetermined by the provider at the moment of the initial conformity assessment and are part of the information contained in the technical documentation referred to in point 2(f) of Annex IV, shall not constitute a substantial modification;

Amendment 1002
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 3 - paragraph 1 - point 23
(23) ‘substantial modification’ means a change to the AI system following its placing on the market or putting into service, which is not foreseen or planned by the provider and as a result of which the compliance of the AI system with the requirements set out in Title III, Chapter 2 of this Regulation is affected or which results in a modification to the intended purpose for which the AI system has been assessed. A substantial modification is given if the remaining risk is increased by the modification of the AI system under the application of all necessary protective measures;

Amendment 1003
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 3 - paragraph 1 - point 23
(23) ‘substantial modification’ means a change to the AI system following its placing on the market or putting into service which affects the compliance of the AI system with the requirements set out in Title III, Chapter 2 of this Regulation or results in a modification to the intended purpose for which the AI system has been assessed or to its performance, including modifications of the intended purpose of an AI system which is not classified as high-risk and is already placed on the market or put into service;

Amendment 1004
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
René Repasi, Marc Angel, Andreas Schieder, Maria-Manuel Leitão-Marques
Article 3 - paragraph 1 - point 23
(23) ‘substantial modification’ means a change to the AI system following its placing on the market or putting into service which affects the compliance of the AI system with the requirements set out in Title III, Chapter 2 of this Regulation or results in a modification to the intended purpose for which the AI system has been assessed including the use of an AI system beyond its reasonably foreseeable purpose;

Amendment 1005
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 3 - paragraph 1 - point 23
(23) ‘substantial modification’ means a change to the AI system following its placing on the market or putting into service which affects the compliance of the AI system with the requirements set out in Title III, Chapter 2 of this Regulation or results in a modification to the foreseeable uses for which the AI system has been assessed, health and safety requirements are to be covered;

Amendment 1006
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 3 - paragraph 1 - point 23
(23) ‘substantial modification’ means a change, including a change based on ‘learning’, to the AI system following its placing on the market or putting into service which affects the compliance of the AI system with the requirements set out in Title III, Chapter 2 of this Regulation or results in a modification to the intended purpose for which the AI system has been assessed;

Amendment 1007
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 23
(23) ‘substantial modification’ means a change to the AI system following its placing on the market or putting into service, not foreseen by the provider, which affects the compliance of the AI system with the requirements set out in Title III, Chapter 2 of this Regulation or results in a modification to the intended purpose for which the AI system has been assessed;

Amendment 1008
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 3 - paragraph 1 - point 23
(23) ‘substantial modification’ means a change to the AI system following its placing on the market or putting into service which affects the compliance of the AI system with the requirements set out in Title III, Chapter 2 of this Regulation or results in a modification to the intended purpose or reasonably foreseeable use for which the AI system has been assessed;

Amendment 1009
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 3 - paragraph 1 - point 24
(24) ‘CE marking of conformity’ (CE marking) means a physical or digital marking by which a provider indicates that an AI system or a product with an embedded AI system is in conformity with the requirements set out in Title III, Chapter 2 of this Regulation and other applicable Union legislation harmonising the conditions for the marketing of products (‘Union harmonisation legislation’) providing for its affixing;

Amendment 1010
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 24
(24) ‘CE marking of conformity’ (CE marking) means a physical or electronic marking by which a provider indicates that an AI system is in conformity with the requirements set out in Title III, Chapter 2 of this Regulation and other applicable Union legislation harmonising the conditions for the marketing of products (‘Union harmonisation legislation’) providing for its affixing as well as the GDPR;

Amendment 1011
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 3 - paragraph 1 - point 25
(25) ‘post-market monitoring’ means all activities carried out by providers of AI systems to proactively collect and review experience gained from the use of AI systems they place on the market or put into service for the purpose of identifying any need to immediately apply any necessary corrective or preventive actions, whereby such activities may not consist in the AI system automatically sending data or error reports to the provider;

Amendment 1012
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 28
(28) ‘common specifications’ means a document comprising a set of technical specifications, other than a standard, providing a means to comply with certain requirements and obligations established under this Regulation;

Amendment 1013
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 3 - paragraph 1 - point 28 a (new)
(28a) ‘sandbox’, in connection with the development of AI systems, means an isolated operating and experimental environment enabling certain actions to be carried out using an AI system while protecting the user from any harm resulting from computer bias, damage or compromise;

Amendment 1014
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 29
(29) ‘training data’ means data used for training an AI system to fit its learnable parameters;

Amendment 1015
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 3 - paragraph 1 - point 30
(29) ‘training data’ means data used for training an AI system through fitting its learnable parameters;

Amendment 1016
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 30
(30) ‘validation data’ means data used for providing an evaluation of the trained AI system. The process evaluates whether the model is under-fitted or overfitted; The validation dataset should be a separate dataset of the training set for the evaluation to be unbiased. If there is only one available dataset, this is divided into two parts, a training set and a validation set. Both sets should still comply with Article 10(3) to ensure appropriate data governance and management practices.

Amendment 1017
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 3 - paragraph 1 - point 30
(30) ‘validation data’ means data used for providing an evaluation of the trained AI system and for tuning its non-learnable parameters and its learning process, whereas the validation dataset can be a separate dataset or part of the training dataset, either as a fixed or variable split;

Amendment 1018
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 30
(30) ‘machine learning validation data’ means data used for providing an evaluation of the trained AI system and for tuning its non-learnable parameters and its learning process, among other things, in order to prevent overfitting; whereas the validation dataset can be a separate dataset or part of the training dataset, either as a fixed or variable split;

Amendment 1019
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 3 - paragraph 1 - point 30
(30) ‘validation data’ means data used for providing an evaluation of the trained AI system and for tuning its non-learnable parameters and its learning process, among other things, in order to prevent underfitting or overfitting; whereas the validation dataset is a separate dataset or part of the training dataset, either as a fixed or variable split;

Amendment 1020
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 31
(31) ‘testing data’ means data used for providing an independent evaluation of the trained and validated AI system to confirm the expected performance of that system before its placing on the market or putting into service. Similar to Article 3(30), the testing dataset should be a separate dataset from the training set and validation set. This set should also comply with Article 10(3) to ensure appropriate data governance and management practices.

Amendment 1021
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 31
(31) ‘testing data’ means data used for providing an independent evaluation of the trained and validated AI system in order to confirm the expected performance of that system before its placing on the market or putting into service. The testing data must be a separate dataset;

Amendment 1022
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 3 - paragraph 1 - point 33
(33) ‘biometric data’ means personal data as defined in Article 4, point (14) of Regulation (EU) 2016/679;

Amendment 1023
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 3 - paragraph 1 - point 33
(33) ‘biometric data’ means personal data resulting from specific technical processing relating to the physical, physiological or behavioural characteristics of a natural person, such as facial images or dactyloscopic data;

Amendment 1024
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte
Article 3 - paragraph 1 - point 33 a (new)
(33) ‘biometric data’ means personal data resulting from specific technical processing relating to the physical or physiological characteristics of a natural person, which allow or confirm the unique identification of that natural person, such as facial images or dactyloscopic data;

Amendment 1025
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 33 a (new)
(33 a) ‘biometrics-based data’ means data resulting from specific technical processing relating to physical, physiological or behavioural signals of a natural person which may or may not allow or confirm the unique identification of a natural person;

Amendment 1026
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 33 a (new)
(33 a) ‘biometrics-based data’ means data resulting from specific technical processing relating to physical, physiological or behavioural signals of a natural person which may or may not allow or confirm the unique identification of a natural person

Amendment 1027
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 3 - paragraph 1 - point 33 a (new)
(33 a) ‘biometrics-based data’ means data resulting from specific technical processing relating to physical, physiological, or behavioural features, signals, or characteristics of a natural person;

Amendment 1028
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 3 - paragraph 1 - point 33 a (new)
(33 a) ‘subliminal techniques’ means techniques that use sensorial stimuli such as images, text, or sounds, that are below the limits of conscious human sensorial perception;

Amendment 1029
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar, Paul Tang, Maria Grapini
Article 3 - paragraph 1 - point 33 a (new)
(33 a) “special categories of personal data” means the categories of personal data referred to in Article 9(1) of Regulation (EU)2016/679;

Amendment 1030
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 3 - paragraph 1 - point 33 b (new)
(33 b) ‘biometric identification’ means the use of AI-systems for the purpose of the automated recognition of physical, physiological, behavioural, and psychological human features such as the face, eye movement, facial expressions, body shape, voice, speech, gait, posture, heart rate, blood pressure, odour, keystrokes, psychological reactions (anger, distress, grief, etc.) for the purpose of verification of an individual’s identity by comparing biometric data of that individual to stored biometric data of individuals in a database (one-to-many identification);

Amendment 1031
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 34
(34) ‘emotion recognition system’ means an AI system for the purpose of identifying or inferring emotions, thoughts, states of mind (such as ‘deception’, ‘trustworthiness’ or ‘truthfulness’) or intentions of natural persons on the basis of their biometric data or other biometrics-based data;

Amendment 1032
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 34
(34) ‘emotion recognition system’ means an AI system for the purpose of identifying or inferring emotions, thoughts, states of mind (such as ‘deception’, ‘trustworthiness’ or ‘truthfulness’)or intentions of natural persons on the basis of their biometric data or biometrics-based data;

Amendment 1033
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 3 - paragraph 1 - point 34
(34) ‘emotion recognition system’ means an AI system capable of identifying, categorizing or inferring emotions, thoughts, states of mind (such as 'deception', 'trustworthiness', or 'trustfulness') or intentions of natural persons on the basis of their biometric data;

Amendment 1034
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 3 - paragraph 1 - point 34
(34) ‘emotion recognition system’ means an AI system for the purpose of identifying or inferring emotions or intentions of natural persons on the basis of their biometric or behavioural data or by means of biological or brain implants;

Amendment 1035
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Article 3 - paragraph 1 - point 34
(34) ‘emotion recognition system’ means an AI system for the purpose of identifying or inferring emotions or intentions of natural persons on the basis of their biometric or other data obtained, read or interpreted from an individual;

Amendment 1036
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina Penkova, Paul Tang, Petar Vitanov, René Repasi, Birgit Sippel, Maria Grapini, Adriana Maldonado López, Maria-Manuel Leitão-Marques, Marc Angel
Article 3 - paragraph 1 - point 34
(34) ‘emotion recognition system’ means an AI system for the purpose of identifying or inferring emotions thoughts, states of mind or intentions of individuals or groups on the basis of their biometric and biometric-based data;

Amendment 1037
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,
Article 3 - paragraph 1 - point 34
(34) ‘emotion recognition system’ means an AI system for the purpose of identifying or inferring emotions, thoughts or intentions of natural persons on the basis of their biometric or biometrics-based data;

Amendment 1038
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 3 - paragraph 1 - point 35
(34) ‘emotion recognition system’ means an AI system for the purpose of identifying or inferring emotions, thoughts, states of mind or intentions of natural persons;

Amendment 1039
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 3 - paragraph 1 - point 35
(35) ‘biometric categorisation system’ means an AI system for the purpose of assigning natural persons to specific categories, such as gender, sex, age, hair colour, eye colour, tattoos, ethnic or social origin, health, mental or physical ability, behavioural or personality traits, language, religion, or membership of a national minority, or sexual or political orientation, on the basis of their biometric or biometric-based data, or which can be reasonably inferred from such data.

Amendment 1040
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 3 - paragraph 1 - point 35
(35) ‘biometric categorisation system’ means an AI system for the purpose of assigning natural persons to specific categories, such as gender, sex, age, hair colour, eye colour, tattoos, ethnic or social origin, health, mental or physical ability,behavioural or personality traits, language, religion, or membership of a national minority, or sexual or political orientation, on the basis of their biometric or biometric-based data, or which can be reasonably inferred from such data;

Amendment 1041
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 3 - paragraph 1 - point 35
(35) ‘biometric categorisation system’ means an AI system for the purpose of assigning natural persons to specific categories, such as sex, age, hair colour, eye colour, health, mental ability, personality traits, tattoos, ethnic origin or sexual or political orientation, on the basis of their biometric data or biometrics-based data;

Amendment 1042
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte
Article 3 - paragraph 1 - point 35
(35) ‘biometric categorisation system’ means an AI system for the purpose of assigning natural persons to specific categories, such as sex, age, hair colour, eye colour, tattoos, health, ethnic origin or sexual or political orientation, on the basis of their biometric data;

Amendment 1043
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 35
(35) ‘biometric categorisation system’ means an AI system that uses biometric or biometrics-based data for the purpose of assigning natural persons to specific categories, or inferring their characteristics and attributes ;

Amendment 1044
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,
Article 3 - paragraph 1 - point 35
(35) ‘biometric categorisation system’ means an AI system for the purpose of assigning natural persons to specific categories or inferring their characteristics and attributes on the basis of their biometric or biometrics-based data;

Amendment 1045
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 35
(35) ‘biometric categorisation system’ means an AI system for the purpose of assigning natural persons to specific categories or inferring their characteristics and attributes on the basis of their biometric data or biometrics-based data;

Amendment 1046
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka, Róża Thun und Hohenstein
Article 3 - paragraph 1 - point 35
(35) ‘biometric categorisation system’ means an AI system that uses biometric data, or other physical, physiological or behavioral data, capable of assigning natural persons to specific categories or inferring their characteristics and attributes;

Amendment 1047
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 3 - paragraph 1 - point 36
(35 a) ‘remote biometric categorisation system’ means a biometric categorisation system capable of categorising natural persons at a distance;

Amendment 1048
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Article 3 - paragraph 1 - point 36
(36) ‘remote biometric identification system’ means an AI system for the purpose of identifying natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database, and without prior knowledge of the user of the AI system whether the person will be present and can be identified; this does not include biometric identification systems used for remote customer onboarding as proscribed under Article 13(1) of Directive (EU) 2018/843 of the European Parliament and of the Council, nor the use for authentication as defined under Articles 4(29) & 4(30) of Directive (EU) 2015/2366 of the European Parliament and of the Council;

Amendment 1049
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Article 3 - paragraph 1 - point 36
(36) ‘biometric identification system’ means an AI system, including remote biometric identification, for the purpose of identifying natural persons including at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference data repository, excluding verification/authentication systems whose sole purpose is to confirm that a specific natural person is the person he or she claims to be, and systems that are used to confirm the identity of a natural person for the sole purpose of having access to a service, a device or premises; , and without prior knowledge of the user of the AI system whether the person will be present and can be identified;

Amendment 1050
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Patryk Jaki, Eugen Jurzyca
Article 3 - paragraph 1 - point 36
(36) ‘remote biometric identification system’ means an AI system for the purpose of identifying natural persons, at a physical distance through the comparison of a person’s biometric data with the biometric data contained in a reference data repository, excluding verification/authentication systems whose sole purpose is to confirm that a specific natural person is the person he or she claims to be, and systems that are used to confirm the identity of a natural person for the sole purpose of having access to a service, a device or premises; and without prior knowledge of the user of the AI system whether the person will be present and can be identified;

Amendment 1051
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 3 - paragraph 1 - point 36
(36) ‘remote biometric identification system’ means an AI system for the purpose of identifying natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database, and without prior knowledge of the user of the AI system whether the person will be present and can be identified, , excluding authentification and verification systems whose sole purpose is to confirm, based on prior consent, that a specific natural person is the person he or she claims to be or to confirm the identity of a natural person for the sole purpose of having access to a service, a device or premises;

Amendment 1052
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,
Article 3 - paragraph 1 - point 36
(36) ‘remote biometric identification system’ means an AI system for the purpose of identifying natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database, and without prior knowledge of the user of the AI system whether the person will be present and can be identified, excluding verification/authentification systems whose sole purpose is to confirm that a specific natural person is the person he or she claims to be, and systems that are used to confirm the identity of a natural person for the sole purpose of having access to a service, a device or premises;

Amendment 1053
ECR - European Conservatives and Reformists Group
Jorge Buxadé Villalba
Article 3 - paragraph 1 - point 36
(36) ‘remote biometric identification system’ means an AI system for the purpose of identifying natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database.

Amendment 1054
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 36
(36) ‘remote biometric identification system’ means an AI system capable of identifying natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database;

Amendment 1055
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 3 - paragraph 1 - point 36
(36) ‘remote biometric identification system’ means an AI system capable of identifying natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database;

Amendment 1056
ECR - European Conservatives and Reformists Group
Rob Rooken
Article 3 - paragraph 1 - point 36
(36) ‘remote biometric identification system’ means an AI system for the purpose of identifying natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database;

Amendment 1057
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 3 - paragraph 1 - point 36
(36) ‘remote biometric identification system’ means an AI system for the purpose of identifying natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database;

Amendment 1058
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 36
(36) ‘remote biometric identification system’ means an AI system capable of identifying natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database or data repository;

Amendment 1059
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Article 3 - paragraph 1 - point 36
(36) ‘remote biometric identification system’ means an AI system for the purpose of identifying natural persons at a physical distance through a “one to many” comparison where the persons identified do not claim to have a particular identity but where the identity is otherwise established - without the conscious cooperation of these persons - by matching live templates with templates stored in a template database;

Amendment 1060
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 3 - paragraph 1 - point 36
(36) ‘remote biometric identification system’ means an AI system for the purpose, after a unique process, of identifying natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database;

Amendment 1061
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka, Róża Thun und Hohenstein
Article 3 - paragraph 1 - point 36
(36) ‘remote biometric identification system’ means an AI system capable of categorizing natural persons at a distance through the comparison of a person’s biometric data or other physical, physiological or behavioral data, with this data contained in a reference database;

Amendment 1062
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Article 3 - paragraph 1 - point 36 a (new)
(36 a) ‘at a distance’ means the process of identification, verification or authentication in physical distance with indirect interaction with the data subject or without;

Amendment 1063
Greens/EFA - Group of the Greens/European Free Alliance
Patrick Breyer
Article 3 - paragraph 1 - point 37
deleted

Amendment 1064
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 3 - paragraph 1 - point 37
(37) biometric identification system’ means a remote biometric identification system whereby the capturing of biometric data, the comparison and the identification occur on a continuous or large-scale basis over a period of time and without limitation to a particular past incident.

Amendment 1065
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 3 - paragraph 1 - point 38
deleted

Amendment 1066
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 3 - paragraph 1 - point 38
(38) ‘‘post’ remote biometric identification system’ means a remote biometric identification system other than a ‘real-time’ remote biometric identification system, regardless of whether the acquired data is hosted in a separate system prior to the comparison and identification;

Amendment 1067
ECR - European Conservatives and Reformists Group
Rob Rooken
Article 3 - paragraph 1 - point 38 a (new)
(38 a) 'deepfakes' means manipulated or synthetic audio or video which appears to be authentic, and which feature people, without their consent/awareness, or events that are false and/or misleading, produced using artificial intelligence techniques, including machine learning and deep learning;

Amendment 1068
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Article 3 - paragraph 1 - point 39
(39) ‘publicly accessible space’ means any publicly or privately owned physical place accessible to an undetermined number of natural persons, regardless of whether certain conditions or circumstances for access have been predetermined, and regardless of the potential capacity restrictions;

Amendment 1069
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 3 - paragraph 1 - point 39
(39) ‘publicly accessible space’ means any place accessible to the public, or fulfilling a public function, regardless of whether certain conditions for access may apply;

Amendment 1070
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 3 - paragraph 1 - point 40 - introductory part
(40) ‘law enforcement authority’ means any public authority competent for the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, including the safeguarding against and the prevention of threats to public security;

Amendment 1071
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 3 - paragraph 1 - point 40 - point a
deleted

Amendment 1072
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 40 - point a a (new)
(a a) any other authority competent for law enforcement, including courts and the judiciary;

Amendment 1073
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte
Article 3 - paragraph 1 - point 40 - point b
deleted

Amendment 1074
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 41
(41) ‘law enforcement’ means', 'i) activities carried out by law enforcement authorities for the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, including the safeguarding against and the prevention of threats to public security; and', 'ii) activities carried out by any other authority that is part of the criminal justice system, including the judiciary;

Amendment 1075
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Article 3 - paragraph 1 - point 41
(41) ‘law enforcement’ means activities carried out by law enforcement authorities or on their behalf for the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, including the safeguarding against and the prevention of threats to public security;

Amendment 1076
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 3 - paragraph 1 - point 41
(41) ‘law enforcement’ means activities carried out by law enforcement authorities solely for the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, including the safeguarding against and the prevention of threats to public security;

Amendment 1077
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 3 - paragraph 1 - point 42
(42) ‘national supervisory authority’ means an independent public authority to which a Member State assigns the responsibility for the implementation and application of this Regulation, for coordinating the activities entrusted to that Member State, for acting as the single contact point for the Commission, and for representing the Member State at the European Artificial Intelligence Board;

Amendment 1078
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 3 - paragraph 1 - point 42
(42) ‘national supervisory authority’ means the authority to which a Member State assigns the responsibility for the implementation and application of this Regulation, for coordinating the activities entrusted to that Member State, for acting as the single contact point for the Commission, and for representing the Member State in the management board of the AI Office;

Amendment 1079
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 43
deleted

Amendment 1080
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 3 - paragraph 1 - point 43
(43) ‘national competent authority’ means the notifying authority and the market surveillance authority;

Amendment 1081
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 3 - paragraph 1 - point 43
(43) ‘competent authority’ means the EDPS, the national supervisory authority, the notifying authority and the market surveillance authority;

Amendment 1082
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 3 - paragraph 1 - point 44 - introductory part
(44) ‘serious incident’ means any incident or malfunctioning that directly or indirectly leads, might have led or might lead to any of the following:

Amendment 1083
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 44 - introductory part
(44) ‘serious incident’ means any incident that directly or indirectly leads to any of the following:

Amendment 1084
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Article 3 - paragraph 1 - point 44 - introductory part
(44) ‘serious incident’ means any incident that directly or indirectly leads to any of the following:

Amendment 1085
ECR - European Conservatives and Reformists Group
Rob Rooken
Article 3 - paragraph 1 - point 44 - point a
(a) the death of a person or serious damage to a person’s physical health, mental health or wellbeing, to property or the environment,

Amendment 1086
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 44 - point a
(a) the death of a person or serious damage to a person’s physical health, mental health or wellbeing, to property or the environment

Amendment 1087
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 3 - paragraph 1 - point 44 - point a
(a) the death of a person or damage to a person’s health or wealth, to property or the environment,

Amendment 1088
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 44 - point a
(a) the death of a person or serious damage to a person’s health,

Amendment 1089
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 3 - paragraph 1 - point 44 - point a
(a) the death of a person or damage to a person’s health, to property or the environment,

Amendment 1090
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 44 - point a b (new)
(a a) a breach of fundamental rights defined by The Charter of Fundamental Rights of the European Union;

Amendment 1091
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 44 - point a b (new)
(a b) systematic, mass or serious breach of other rights;

Amendment 1092
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 44 - point a c (new)
(a c) damage to democracy, the rule of law or the environment

Amendment 1093
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 3 - paragraph 1 - point 44 - point b
(b) a serious disruption of the management and operation of critical infrastructure,

Amendment 1094
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 3 - paragraph 1 - point 44 - point b a (new)
(ba) a breach of obligations under national law or Union law intended to protect fundamental rights.

Amendment 1095
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 3 - paragraph 1 - point 44 - point b a (new)
(b a) a breach of obligations under Union law intended to protect fundamental rights;

Amendment 1096
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 44 - point b a (new)
(b a) breach of obligations under Union law intended to protect personal data

Amendment 1097
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 3 - paragraph 1 - point 44 - point b a (new)
(b a) a serious violation of an individual’s fundamental rights;

Amendment 1098
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 3 - paragraph 1 - point 44 a (new)
(44 a) ‘AI systems presenting a risk’ means an AI system having the potential to affect adversely fundamental rights, health and safety of persons in general, including in the workplace, protection of consumers, the environment, public security, the values enshrined in Article 2 TEU and other public interests, that are protected by the applicable Union harmonisation legislation, to a degree which goes beyond that considered reasonable and acceptable in relation to its intended purpose or under the normal or reasonably foreseeable conditions of use of the system concerned, including the duration of use and, where applicable, its putting into service, installation and maintenance requirements.

Amendment 1099
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 44 a (new)
(44 a) ‘regulatory sandbox’ means a framework which, by providing a structured context for experimentation, enable where appropriate in a real-world or digital environment the testing of innovative technologies, products, services or approaches for a limited time and in a limited part of a sector or area under regulatory supervision ensuring that appropriate safeguards are in place;

Amendment 1100
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 3 - paragraph 1 - point 44 a (new)
(44 a) ‘Recommender system’ means a fully or partially automated system used by an online platform to suggest or prioritise in its online interface specific information to recipients of the service, including as a result of a search initiated by the recipient of the service or otherwise determining the relative order or prominence of information displayed.

Amendment 1101
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 3 - paragraph 1 - point 44 a (new)
(44 a) 'critical infrastructure' means an asset, system or part thereof which is necessary for the delivery of a service that is essential for the maintenance of vital societal functions or economic activities within the meaning of Article 2(4) and (5) of Directive (…) on the resilience of critical entities;

Amendment 1102
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte
Article 3 - paragraph 1 - point 44 a (new)
(44a) ‘bias’ means any inclination of prejudice towards or against a person, object or position, whether voluntary or involuntary, that may arise as a result of the design, data supply, interactions, personalisation or configuration of an IA system;

Amendment 1103
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 3 - paragraph 1 - point 44 a (new)
(44 a) ‘regulatory sandbox’ means a facility that provides a controlled environment that facilitates the safe development, testing and validation of innovative AI systems for a limited time before their placement on the market or putting into service pursuant to a specific plan;

Amendment 1104
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Article 3 - paragraph 1 - point 44 a (new)
(44 a) ‘unfair bias’ means an inclination of prejudice towards or against a natural person that can result in discriminatory and/or unfair treatment of some natural persons with respect to others;

Amendment 1105
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 44 a (new)
(44 a) ´scientific research and development´ means any scientific development, experimentation, analysis, testing or validation carried out under controlled conditions.

Amendment 1106
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 44 a (new)
(44 a) scientific research and development means: any scientific development, experimentation, analysis, testing or validation carried out under controlled conditions.

Amendment 1107
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 3 - paragraph 1 - point 44 a (new)
(44 a) 'near miss' means any incident that, if the circumstances were slightly different, would have resulted in a 'serious incident';

Amendment 1108
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 44 b (new)
(44 b) ‘social scoring’ means the evaluation or categorisation of EU citizens based on their behavior or (personality) characteristics, where one or more of the following conditions apply:', '(i) the information is not reasonably relevant for the evaluation or categorisation;', '(ii) the information is generated or collected in another domain than that of the evaluation or categorisation;', '(iii) the information is not necessary for or proportionate to the evaluation or categorisation;', '(iv) the information contains or reveals special categories of personal data.

Amendment 1109
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 44 b (new)
(44 b) ‘social scoring’ means the evaluation or categorisation of persons based on their behaviour or (personality) characteristics, where one or more of the following conditions apply:', '(i) the information is not reasonably relevant for the evaluation or categorisation;', '(ii) the information is generated or collected in another domain than that of the evaluation or categorisation;', '(iii) the information is not necessary for or proportionate to the evaluation or categorisation;', '(iv) the information contains or reveals special categories of personal data.

Amendment 1110
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 44 b (new)
(44 b) ‘deep fake’ means manipulated or synthetic audio, image or video content that would falsely appear to be authentic or truthful, and which features depictions of persons appearing to say or do things they did not say or do, without their consent, produced using AI techniques, including machine learning and deep learning;

Amendment 1111
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 3 - paragraph 1 - point 44 b (new)
(44 b) ‘deep fake’ means an AI system that generates or manipulates image, audio or video content that appreciably resembles existing persons, objects, places or other entities or events and would falsely appear to a person to be authentic or truthful.

Amendment 1112
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 3 - paragraph 1 - point 44 b (new)
(44 b) ‘artificial intelligence system with indeterminate uses’ means an artificial intelligence system without specific and limited provider-defined purposes;

Amendment 1113
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 3 - paragraph 1 - point 44 b (new)
(44b) ‘auditability’ means the ability of an AI system to undergo an assessment of the system’s algorithms, data and design processes;

Amendment 1114
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 3 - paragraph 1 - point 44 c (new)
(44 b) ‘child’ means any person below the age of 18 years.

Amendment 1115
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 3 - paragraph 1 - point 44 c (new)
(44c) ‘reproducibility’ means the ability of an AI system to exhibit the same behaviour when an experiment is repeated under the same conditions;

Amendment 1116
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 44 c (new)
(44 c) ‘affectee(s)’ mean(s) any natural or legal person or group of natural or legal persons affected by the use or outcomes of, or a combination of, AI system(s);

Amendment 1117
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 3 - paragraph 1 - point 44 c (new)
(44 c) ‘profiling’ means any form of automated processing of personal data as defined point (4) of Article 4 of Regulation (EU) 2016/679;

Amendment 1118
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 44 c (new)
(44 c) ‘incident’ means a faulty operation of an AI system;

Amendment 1119
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 44 c (new)
(44 c) “child” is any person under the age of 18.

Amendment 1120
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 44 d (new)
(44 d) ‘artificial intelligence system within determinate uses’ means an artificial intelligence system without specific and limited provider-defined purposes;

Amendment 1121
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 44 d (new)
(44 d) ‘personal data’ means data as defined in point (1) of Article 4 of Regulation (EU) 2016/679;

Amendment 1122
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 44 e (new)
(44 e) 'deep fake' means generated or manipulated image, audio or video content produced by an AI system that appreciably resembles existing persons, objects, places or other entities or events and falsely appears to a person to be authentic or truthful;

Amendment 1123
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 44 e (new)
(44 e) ‘non-personal data’ means data other than personal data as defined in point (1) of Article 4 of Regulation (EU) 2016/679;

Amendment 1124
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 44 f (new)
(44 f) ‘critical infrastructure’ means an asset, system or part thereof which is neccesary for the delivery of a service that is essential for the maintenance of vital societal functions or economic activities within the meaning of Article 2 (4) and (5) of Directive of the European Parliament and of the Council on the resilience of critical entities (2020/0365 (COD));

Amendment 1125
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 3 - paragraph 1 - point 44 g (new)
(44 f) 'redress by design' means technical mechanisms and/or operational procedures, established from the design phase, in order to be able to effectively detect, audit, rectify the consequences and implications of wrong predictions by an AI system and improve it.

Amendment 1126
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 44 g (new)
(44 g) ‘harmful subliminal technique’ means a measure whose existence and operation is entirely imperceptible by a natural person on whom it is used, and which has the purpose and direct effect to induce actions leading to that persons physical or phychological harm;

Amendment 1127
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 3 - paragraph 1 - point 44 h (new)
(44 h) 'unfair bias' means an inclination of prejudice towards or against a natural person that can result in discriminatory and/or unfair treatment of some natural persons with respect to others.

Amendment 1128
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 3 - paragraph 1 a (new)
Social scoring' means the evaluation or categorization of an individual natural person, or a group, based on their behaviour or (personality) characteristics, where one or more of the following conditions apply: (1) the information is not reasonably relevant, necessary for, or proportionate to the evaluation or categorization; (2) the information is generated or collected in another domain than that of the evaluation or categorization; (3) the information contains or reveals special categories.

Amendment 1129
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Vlad-Marius Botoş, Moritz Körner, Ondřej Kovařík, Jan-
Article 3 a (new)
Article 3 a', 'General Purpose AI', '1. General purpose AI applications shall not be considered as having an intended purpose within the meaning of this Regulation unless those systems have been adapted to a specific intended purpose that falls within the scope of this Regulation.', '2. Any natural or legal person that adapts a general purpose AI application to a specific intended purpose and places it on the market or puts it into service shall be considered the provider and be subject to the obligations laid down in this Regulation.', '3.The initial provider of a general purpose AI application shall comply with Article 15 of this Regulation at all times. After placing it on the market or putting it to service, and without compromising its own intellectual property rights or trade secrets, provide the new provider referred to in paragraph 2 with all essential, relevant and reasonably expected information that is necessary to comply with the obligations set out in this Regulation.', '4. The initial provider of a general purpose AI application shall only be responsible for the accuracy of the provided information and compliance with Article 15 of this Regulation towards the natural or legal person that adapts the general purpose AI application to a specific intended purpose.

Amendment 1130
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky
Article 4
deleted

Amendment 1131
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 4
deleted

Amendment 1132
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 4
deleted

Amendment 1133
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 4
deleted

Amendment 1134
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 4 - paragraph 1
deleted

Amendment 1135
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 4 - paragraph 1
The Commission is empowered to adopt delegated acts in accordance with Article 73, after ensuring adequate consultation with relevant stakeholders, to amend the list of techniques and approaches listed in Annex I within the scope of the definition of an AI system as provided for in Article 3(1), in order to update that list to market and technological developments on the basis of transparent criteria.', 'Every time the list of techniques and approaches listed in Annex I is amended, providers and users of AI systems, which become in scope of the Regulation shall have 24 months to apply the relevant requirements and obligations. Article 83 shall apply for AI systems already placed on the market before delegated acts are published.

Amendment 1136
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner, Ondřej Kovařík, Jan-Christoph Oetjen
Article 4 - paragraph 1
The Commission is empowered to adopt delegated acts in accordance with Article 73, after an adequate and transparent consultation process involving the relevant stakeholders, to amend the list of techniques and approaches listed in Annex I within the scope of the definition of an AI system as provided for in Article 3(1), in order to update that list to market and technological developments on the basis of transparent characteristics. Providers and users of AI systems should be given 24 months to comply with any amendment to Annex I.

Amendment 1137
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Article 4 - paragraph 1
The Commission is empowered to adopt delegated acts in accordance with Article 73 to amend the list of techniques and approaches listed in Annex I, within the scope of the definition of an AI system as provided for in Article 3(1), in order to update that list to market and technological developments on the basis of characteristics and hazards that are similar to the techniques and approaches listed therein.

Amendment 1138
EPP - Group of the European Peoples Party (Christian Democrats)
Barbara Thaler, Lukas Mandl, Axel Voss, Deirdre Clune
Article 4 - paragraph 1
The Commission is empowered to adopt delegated acts in accordance with Article 73 to amend the list of techniques and approaches listed in Annex I, in order to update that list to market and technological developments on the basis of characteristics that are similar to the techniques and approaches listed therein. As an adequate transitional period, two years shall be applied to each amendment.

Amendment 1139
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 4 - paragraph 1
The Commission is empowered to adopt delegated acts in accordance with Article 73 to amend the list of techniques and approaches listed in Annex I, in order to update that list to market and technological developments by means of additions or non-restrictive precisions on the basis of characteristics that are similar to the techniques and approaches listed therein.

Amendment 1140
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Article 4 - paragraph 1
The Commission is empowered to adopt delegated acts in accordance with Article 73 after consulting relevant stakeholders to amend the list of techniques and approaches listed in Annex I, in order to update that list to market and technological developments on the basis of characteristics that are similar to the techniques and approaches listed therein.

Amendment 1141
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Bettina Vollath
Article 4 - paragraph 1 a (new)
Article 4 a', 'Principles applicable to all AI systems', 'All operators of AI systems shall respect the following principles:', '1.Operators of AI systems shall respect fundamental rights and the Union values, as enshrined in Article 2 TEU, throughout the AI system lifecycle.To ensure this, operators shall implement mechanisms and safeguards that are appropriate to the context and consistent with the state of art (‘fairness’)', '2.Operators shall be accountable for the proper functioning of AI systems and for the respect of the fairness principle, based on their roles, the context, and consistent with the state of art. Operators shall ensure the proper functioning, throughout their lifecycle, of the AI systems that they design, develop, operate or deploy, in accordance with their role and applicable regulatory framework, and by demonstrating this through their actions and decision-making processes (‘accountability’)', '3.Operators shall commit to transparency and responsible disclosure regarding AI systems.To this end, they shall provide meaningful information, appropriate to the context, and consistent with the state of art:', '(a) to foster a general understanding of AI systems,', '(b) to make affected persons aware that they are interacting with an AI system and an explanation thereof,', '(c) to enable those affected by an AI system to understand the outcome, and', '(d) to enable those adversely affected by an AI system to challenge its outcome based on plain and easy-to-understand information on the factors, and the logic that served as the basis for the prediction, recommendation or decision (‘transparency and explainability’)', '4.Operators shall ensure that AI systems are robust, secure and safe throughout their entire lifecycle so that, in conditions of normal use, foreseeable use or misuse, or other adverse conditions, they functionappropriately and do not pose unreasonable risk.Operators shall ensure, based on their roles and the context, traceability including in relation to datasets, processes and decisions made during the AI system lifecycle, to enable the analysis of the outcomes of the AI system and responses to inquiry, appropriate to the context and consistent with the state of art.', 'Operators shall, based on their roles, the context, and their ability to act, apply a systematic risk management approach to each phase of the AI system lifecycle on a continuous basis to address the risks related to AI systems, including privacy, protection of personal data, digital security, safety and bias (‘privacy and security’)', '5.Operators shall proactively engage in pursuit of beneficial outcomes for people, socieites and the planet, such as advancing inclusion, reducing economic, social, gender and other inequalities, and protecting natural environments, therefore invigorating inclusive growth, sustainable development and well-being (‘social benefit’)', '6. Operators should be motivated to follow a human-centric approach. AI available in the Union market or otherwise affecting people in the Union should be designed human centered, so that people can trust that the technology is used in a way that is safe and compliant with the law, including the respect of fundamental rights what requires a shift towards a Human Centered AI Engineering, also in research and education.

Amendment 1142
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 4 - paragraph 1 a (new)
The techniques and approaches listed in Annex I may only be amended by an amending regulation if the amendment concerns a withdrawal, a restrictive precision or a change in the definition of those techniques and approaches.

Amendment 1143
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina Penkova, René Repasi, Birgit Sippel, Maria Grapini, Adriana Maldonado López, Maria-Manuel Leitão-Marques, Marc Angel
Article 4 a (new)
Article 4 a', 'Principles applicable to all AI systems', 'All operators of AI systems shall respect the following principles:', '1. Operators of AI systems shall respect fundamental rights and the Union values, as enshrined in Article 2 TEU, throughout the AI system lifecycle. To ensure this, operators shall implement mechanisms and safeguards that are appropriate to the context and consistent with the state of art (‘fairness’)', '2. Operators shall be accountable for the proper functioning of AI systems and for the respect of the fairness principle, based on their roles, the context, and consistent with the state of art. Operators shall ensure the proper functioning, throughout their lifecycle, of the AI systems that they design, develop, operate or use, in accordance with their role and applicable regulatory framework, and by demonstrating this through their actions and decision-making processes (‘accountability’)', '3. Operators shall commit to transparency and responsible disclosure regarding AI systems. To this end, they shall provide meaningful information, appropriate to the context, and consistent with the state of the art:', '(a) to foster a general understanding of AI systems,', '(b) to make affected persons aware that they are interacting with an AI system and an explanation thereof,', '(c) to make affected persons aware about their rights conferred in this Regulation,', '(d) to enable those affected by an AI system to understand the outcome, and', '(e) to enable those adversely affected by an AI system to challenge its outcome based on plain and easy-to-understand information on the factors, and the logic that served as the basis for the prediction, recommendation or decision (‘transparency and explainability’).', '4. Operators shall ensure that AI systems are robust, secure and safe throughout their entire lifecycle so that, in conditions of normal use, foreseeable use or misuse, or other adverse conditions, they function appropriately and do not pose unreasonable risk. Operators shall ensure, based on their roles and the context, traceability including in relation to datasets, processes and decisions made during the AI system lifecycle, to enable the analysis of the outcomes of the AI system and responses to inquiry, appropriate to the context and consistent with the state of the art. Operators shall, based on their roles, the context, and their ability to act, apply a systematic risk management approach to each phase of the AI system lifecycle on a continuous basis to address the risks related to AI systems, including privacy, protection of personal data, digital security, safety and bias (‘privacy and security’)', '5. Operators shall proactively engage in pursuit of beneficial outcomes for people, societies and the planet, such as advancing inclusion, reducing economic, social, gender and other inequalities, and protecting natural environments, therefore invigorating inclusive growth, sustainable development and well-being (‘social benefit’).

Amendment 1144
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 4 a (new)
Article 4 a', 'Trustworthy AI systems', '1. The principles set out in this Article establish a high-level framework for a coherent and coordinated human-centric European approach on trustworthy AI systems that respect and promote the values on which the Union is founded. This Regulation takes those principles into account by establishing certain requirements for high-risk AI systems listed in Article 8 to 15.', '• ‘human agency and oversight’ means that AI systems shall be developed and used as a tool that serves people, respects human dignity and personal autonomy, and that is functioning in a way that can be controlled and overseen by humans in a manner that is appropriate to the circumstances of the case.', '• ‘technical robustness and safety’ means that AI systems shall be developed and used in a way to minimize unintended and unexpected harm as well as being robust in case of problems and being resilient against attempts to alter the use or performance of the AI system by malicious third parties.', '• ‘privacy and data governance’ means that AI systems shall be developed and used in compliance with existing privacy and data protection rules, while processing data that meets high standards in terms of quality and integrity.', '• ‘transparency’ means that AI systems shall be developed and used in a way that allows appropriate traceability and explainability, while making humans Aware that they communicate or interact with an AI system as well as duly informing users of the capabilities and limitations of that AI system.', '• ‘diversity, non-discrimination and fairness’ means that AI systems shall be developed and used in a way that includes diverse actors and promotes equal access, while avoiding discriminatory impacts that are prohibited by Union or Member States law.', '• ‘social and environmental well-being’ means that AI systems shall be developed and used in a sustainable and environmentally friendly manner as well as in away to benefit all human beings, while monitoring and assessing the long-term impacts on the individual, society and democracy.', '• ‘accountability’ means that AI systems shall be developed or used in a way that facilitates auditability and accountability pursuant to applicable Union and Member States law, while making clear who is legally responsible in case the AI system causes negative impacts.', '2. Paragraph 1 is without prejudice to obligations set up by existing Union and Member States legislation and does not create any additional obligations for providers or users.', '3. European Standardisation Organisations shall understand the principles referred to in paragraph 1 as outcome-based objectives when developing the appropriate harmonised standards for high risk AI systems as referred to in Article 40(2b). For all other AI systems, the voluntary application on the basis of harmonised standards, technical specifications and codes of conducts as referred to in Article 69(1a) is encouraged.

Amendment 1145
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar
Article 4 a (new)
Article 4 a', 'Principles applicable to all AI systems', 'All operators of AI systems shall respect the following principles:', '1. Operators of AI systems shall respect fundamental rights and the Union values, as enshrined in Article 2 TEU, throughout the AI system lifecycle. To ensure this, operators shall implement mechanisms and safeguards that are appropriate to the context and consistent with the state of art (‘fairness’)', '2. Operators shall be accountable for the proper functioning of AI systems and for the respect of the fairness principle, based on their roles, the context, and consistent with the state of art. Operators shall ensure the proper functioning, throughout their lifecycle, of the AI systems that they design, develop, operate or deploy, in accordance with their role and applicable regulatory framework, and by demonstrating this through their actions and decision-making processes (‘accountability’)', '3. Operators shall commit to transparency and responsible disclosure regarding AI systems. To this end, they shall provide meaningful information, appropriate to the context, and consistent with the state of art:', '(a) to foster a general understanding of AI systems,', '(b) to make affected persons aware that they are interacting with an AI system and an explanation thereof,', '(c) to enable those affected by an AI system to understand the outcome, and', '(d) to enable those adversely affected by an AI system to challenge its outcome based on plain and easy-to-understand information on the factors, and the logic that served as the basis for the prediction, recommendation or decision (‘transparency and explainability’)', '4. Operators shall ensure that AI systems are robust, secure and safe throughout their entire lifecycle so that, in conditions of normal use, foreseeable use or misuse, or other adverse conditions, they function appropriately and do not pose unreasonable risk. Operators shall ensure, based on their roles and the context, traceability including in relation to datasets, processes and decisions made during the AI system lifecycle, to enable the analysis of the outcomes of the AI system and responses to inquiry, appropriate to the context and consistent with the state of art.', 'Operators shall, based on their roles, the context, and their ability to act, apply a systematic risk management approach to each phase of the AI system lifecycle on a continuous basis to address the risks related to AI systems, including privacy, protection of personal data, digital security, safety and bias (‘privacy and security’)', '5. Operators shall proactively engage in pursuit of beneficial outcomes for people, socieites and the planet, such as advancing inclusion, reducing economic, social, gender and other inequalities, and protecting natural environments, therefore invigorating inclusive growth, sustainable development and well-being (‘social benefit’)

Amendment 1146
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 4 a (new)
Article 4 a', 'Transparency Rights', '1. Providers and deployers of AI systems which affect natural persons, in particular, by evaluating or assessing them, making predictions about them, recommending information, goods or services to them or determining or influencing their access to goods and services, shall inform the natural persons that they are subject to the use of such an AI system.', '2. The information referred to in paragraph 1 shall include a clear and concise indication about the provider or deployer and the purpose of the AI system, information about the rights of the natural person conferred under this Regulation, and a reference to publicly available resource where more information about the AI system can be found, in particular the relevant entry in the EU database referred to in Article 60, if applicable.', '3. This information shall be presented in a concise, intelligible and easily accessible form, including for persons with disabilities.', '4. This obligation shall be without prejudice to other Union or Member State laws, in particular Regulation 2016/679 [GDPR], Directive 2016/680 [LED], Regulation 2022/XXX [DSA].', '5. AI subjects will have the right not to be subject to a high-risk AI system.

Amendment 1147
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Patryk Jaki, Vincenzo Sofo, Adam Bielan
Article 4 a (new)
Article 4 a', 'Notification about the use of an AI system', '1. Users of AI systems which affect natural persons, in particular, by evaluating or assessing them, making predictions about them, recommending information, goods or services to them or determining or influencing their access to goods and services, shall inform the natural persons that they are subject to the use of such an AI system.', '2. The information referred to in paragraph 1 shall include a clear and concise indication of the user and the purpose of the AI system, information about the rights of the natural person conferred under this Regulation, and a reference to publicly available resource where more information about the AI system can be found, in particular the relevant entry in the EU database referred to in Article 60, if applicable.', '3. This information shall be presented in a concise, intelligible and easily accessible form, including for persons with disabilities.', '4. This obligation shall be without prejudice to other Union or Member State laws, in particular Regulation 2016/679, Directive 2016/680, Regulation 2022/XXX.

Amendment 1148
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina Penkova, Petar Vitanov, René Repasi, Birgit Sippel, Maria Grapini, Adriana Maldonado López, Maria-Manuel Leitão-Marques, Marc Angel
Article 4 b (new)
Article 4 b', 'Accessibility Requirements for providers and users of AI systems', '1. Providers of AI systems shall ensure that their systems are accessible in accordance with the accessibility requirements set out in Section I, Section II, Section VI, and Section VII of Annex I of Directive (EU) 2019/882 prior to those systems being placed on the market or put into service.', '2. Users of AI systems shall use such systems in accordance with the accessibility requirements set out in Section III, Section IV, Section VI, and Section VII of Annex I of Directive (EU) 2019/882.', '3. Users of AI systems shall prepare the necessary information in accordance with Annex V of Directive (EU) 2019/882. Without prejudice to Annex VIII of this Regulation, the information shall be made available to the public in an accessible manner for persons with disabilities and be kept for as long as the AI system is in use.', '4. Without prejudice to the rights of affected persons to information about the use and functioning of AI systems, transparency obligations for providers and users of AI, obligations to ensure consistent and meaningful public transparency under this Regulation, providers and users of AI systems shall ensure that information, forms and measures provided pursuant to this Regulation are made available in such a manner that they are easy to find, easy to understand, and accessible in accordance with Annex I to Directive 2019/882.', '5. Users of AI systems shall ensure that procedures are in place so that the use of AI systems remains in conformity with the applicable accessibility requirements. Changes in the characteristics of the use, changes in applicable accessibility requirements and changes in the harmonised standards or in technical specifications by reference to which use of an AI system is declared to meet the accessibility requirements shall be adequately taken into account by the user.', '6. In the case of non-conformity, users of AI systems shall take the corrective measures necessary to conform with the applicable accessibility requirements. When necessary, and at the request of the user, the provider of the AI system in question shall cooperate with the user to bring the use of the AI system into compliance with applicable accessibility requirements.', '7. Furthermore, where the use of an AI system is not compliant with applicable accessibility requirements, the user shall immediately inform the competent national authorities of the Member States in which the system is being used, to that effect, giving details, in particular, of the non-compliance and of any corrective measures taken. They shall cooperate with the authority, at the request of that authority, on any action taken to bring the use of the AI system into compliance with applicable accessibility requirements.', '8. AI systems and the use of thereof, which are in conformity with harmonised technical standards or parts thereof derived from Directive (EU) 2019/882 the references of which have been published in the Official Journal of the European Union, shall be presumed to be in conformity with the accessibility requirements of this Regulation in so far as those standards or parts thereof cover those requirements.', '9. AI systems and use of thereof, which are in conformity with the technical specifications or parts thereof adopted for the Directive (EU) 2019/882 shall be presumed to be in conformity with the accessibility requirements of this Regulation in so far as those technical specifications or parts thereof cover those requirements.

Amendment 1149
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Patryk Jaki, Adam Bielan
Article 4 b (new)
Article 4 b', 'Explanation of individual decision-making', '1. A decision made by or with the assistance of a high risk AI system which produces legal effects concerning a person, or which similarly significantly affects that person, shall be accompanied by a meaningful, relevant explanation of at least:', '(a) the role of the AI system in the decision-making process;', '(b) the input data relating to the affected person, including the indication of his or her personal data on the basis of which the decision was made;', '(c) for high-risk AI systems, the link to the entry in the EU database referred to in Article 60;', '(d) the information about the person’s rights under this Regulation, including the right to lodge a complaint with the national supervisory authority.', 'For information on input data under point b) to be meaningful it must include an easily understandable description of inferences drawn from other data.', '2. Paragraph 1 shall not apply to the use of AI systems:', '(a) that are authorised by law to detect, prevent, investigate and prosecute criminal offences or other unlawful behaviour under the conditions laid down in Article 3(41) and Article 52 of this Regulation, if not explaining the decision is necessary and proportionate for detection, prevention, investigation and prosecution of a specific of-fence;', '(b) for which exceptions from, or restrictions to, the obligation under paragraph 1 follow from Union or Member State law, which lays down appropriate other safeguards for the affected person’s rights and freedoms and legitimate interests.', '3. The explanation within the meaning of paragraph 1 shall be provided at the time when the decision is communicated to the affected person and shall be provided in a clear, easily understandable, and intelligible way, accessible for persons with disabilities.', '4. If the affected person believes that the decision produced legal effects or similarly significantly affects him or her, but the deployer has not provided the explanation, he or she may request it. The deployer shall inform the affected person within 7 days about how he assessed the request and if it is accepted, the explanation shall be provided without undue delay. If the request is refused, the deployer shall in-form the affected person of the right to complain to the national supervisory authority.

Amendment 1150
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 4 b (new)
Article 4 b', 'Principles applicable to all AI systems', '1. Providers and deployers of AI systems shall respect the following principles:', '(a) AI systems must be used in a fair and transparent manner in relation to AI subjects;', '(b) AI subjects shall have a right to automatically receive an explanation in accordance with Article 4c;', '(c) AI subjects shall have the right to object to a decision taken solely by an AI system, or relying to a significant degree on the output of an AI system, which produces legal effects concerning him or her, or similarly significantly affects him or her. This paragraph is without prejudice to Article 22 of Regulation 2016/679;', '(d) AI systems shall not be used to exploit power and information asymmetries to the detriment of AI subjects, regardless of whether such asymmetries already exist or may be created or aggravated by the use of AI systems themselves. In particular, AI systems may not be used to discriminate against AI subjects on the basis of the characteristics listed in Article 21 of the European Charter of Fundamental Rights, on the basis of biometrics-based data, as well as on the basis of economic factors;', '(e) AI systems must be safe and secure, ensuring a performance that is reliable, accurate, and robust throughout their lifecycle;', '(f) AI systems intended to interact with AI subjects shall be designed and developed in such a way that natural individuals are informed that they are interacting with an AI system, especially where its outputs or behaviour may be reasonably mistaken for that of a human being;', '2. Providers of AI systems shall be responsible for, and be able to demonstrate compliance with, the principles established in paragraph 1. This requirement shall apply accordingly to deployers where they have substantially influenced the intended purpose or the manner of operation of the AI system;', '3. The functioning of AI systems shall be regularly monitored and assessed to ensure they respect the rights and obligations set out in Union law;', '4. These principles shall apply without prejudice to existing obligations relating to transparency, explanation or motivation of decision-making under Member State or Union law.

Amendment 1151
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 4 b (new)
Article 4 b', 'A right to explanation of individual decision-making', '1. A decision which is taken by the user on the basis of the output from an AI system and which produces legal effects on an affected person, or which similarly significantly affects that person, shall be accompanied by a meaningful explanation of:', '(a) the role of the AI system in the decision-making process;', '(b) the logic involved, the main parameters of the decision-making, and their relative weight; and', '(c) the input data relating to the affected person and each of the main parameters on the basis of which the decision was made.', 'For information on input data under point c) to be meaningful, it must include an easily understandable description of inferences drawn from other data, if it is the inference that relates to the main parameter.', '2. For the purpose of Paragraph 1, it shall be prohibited for the law enforcement authorities or the judiciary in the Union to use AI systems that are considered closed or labelled as proprietary by the providers or the distributors;', '3. The explanation within the meaning of paragraph 1 shall be provided at the time when the decision is communicated to the affected person.

Amendment 1152
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 4 c (new)
Article 4 c', 'Explanation of individual decision-making', '1. A decision made by or with the assistance of an AI system which produces legal effects concerning an AI subject, or which similarly significantly affects an AI subject, shall be accompanied by a meaningful, relevant explanation of at least:', '(a) the role of the AI system in the decision-making process and the extent to which the output produced by the AI system influenced the decision in this case;', '(b) the logic involved, the main parameters of decision-making, and their relative weight;', '(c) the input data relating to the AI subject, including the indication of his or her personal data, and each of the parameters on the basis of which the decision was made. For the information on input data to be meaningful it must include an easily understandable description of inferences drawn from other data;', '(d) if applicable, the category or group into which the AI subject has been classified;', '(e) whether the same decision was taken in relation to other persons in similar circumstances and if not - an explanation why the AI subject was treated differently, without prejudice to the protection of personal data;', '(f) for high-risk AI systems, the link to the entry in the EU database referred to in Article 60;', '(g) the information about the person’s rights under this Regulation, including the right to lodge a complaint with a supervisory authority;', '2. Paragraph 1 shall not apply to the use of AI systems:', '(a) that are authorised by law to detect, prevent, investigate and prosecute criminal offences or other unlawful behaviour under the conditions laid down in Article 3(41) and Article 52 of this Regulation, if not explaining the decision is necessary and proportionate for detection, prevention, investigation and prosecution of a specific offence;', '(b) for which exceptions from, or restrictions to, the obligation under paragraph 1 follow from Union or Member State law, which lays down appropriate other safeguards for the affected person’s rights and freedoms and legitimate interests;', '3. The explanation within the meaning of paragraph 1 shall be provided by default at the same time when the decision is communicated to the AI subject and shall be provided in a clear, easily understandable, and intelligible way, accessible for persons with disabilities;', '4. If an AI subject has not received an explanation by default, AI subjects have the right to request it. The deployer shall inform the affected person within 7 days. If the request is refused, the deployer shall inform the AI subject of the right to complain to the national supervisory authority.

Amendment 1153
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 4 c (new)
Article 4 c', 'Right to receive an explanation of individual decision-making', '1. A decision which is taken by the user on the basis of the output from an AI system and which produces legal effects on an affected person, or which similarly significantly affects that person, shall be accompanied by a meaningful explanation of', '(a) the role of the AI system in the decision-making process;', '(b) the logic involved, the main parameters of the decision-making, and their relative weight; and', '(c) the input data relating to the affected person and each of the main parameters on the basis of which the decision was made.', 'For information on input data under point c) to be meaningful, it must include an easily understandable description of inferences drawn from other data, if it is the inference that relates to the main parameter.', '2. For the purpose of Paragraph 1, it shall be prohibited for the law enforcement authorities or the judiciary in the Union to use AI systems that are considered closed or labelled as proprietary by the providers or the distributors;', '3. The explanation within the meaning of paragraph 1 shall be provided at the time when the decision is communicated to the affected person.

Amendment 1154
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 4 d (new)
Article 4 d', 'Right not to be subject to non-compliant AI systems', 'Natural persons shall have the right not to be subject to AI systems that:', '(a) pose an unacceptable risk pursuant to Article 5, or', '(b) otherwise do not comply with the requirements of this Regulation.

Amendment 1155
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - title
5 -1. Any practices related to artificial intelligence and AI systems whose development, deployment or use, or reasonably foreseeable misuse, that adversely affect, or are likely to adversely affect, the essence of any fundamental right shall be prohibited.

Amendment 1156
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - paragraph 1 - introductory part
1. In addition to paragraph -1, the following artificial intelligence practices shall be prohibited:

Amendment 1157
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina Penkova, René Repasi, Birgit Sippel, Maria Grapini, Adriana Maldonado López, Maria-Manuel Leitão-Marques, Marc Angel
Article 5 - paragraph 1 - point a
(a) the placing on the market, putting into service or use of an AI system that deploys techniques with the effect or likely effect of materially distorting a person’s behaviour by appreciably impairing the persons’ ability to make an informed decision, thereby causing the person to take a decision that they would not have taken otherwise, in a manner that causes or is likely to cause that person or another person, or a group of persons material or non-material harm, including physical, psychological or economic harm;

Amendment 1158
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - paragraph 1 - point a
(a) the development, the placing on the market, putting into service, deployment or use of an AI system that deploys techniques with the effect or likely effect of materially distorting a person’s or a group's behaviour, including by impairing the person’s ability to make an informed decision, thereby causing the person to take a decision that they would not otherwise have taken, in a manner that causes or is likely to cause any person or society at large physical, economic or psychological harm;

Amendment 1159
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point a
(a) the placing on the market, putting into service or use of an AI system deployed, aimed at, or used for manipulation, deception or distorting a person’s behaviour or exploit a person’s characteristics, in a manner that causes, or is likely to cause, harm to:', '(i) that person’s, another person’s or group of persons’ fundamental rights, including their physical or psychological health and safety, and/or', '(ii) democracy, the rule of law, or society at large;

Amendment 1160
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 5 - paragraph 1 - point a
(a) the placing on the market, putting into service or use of an AI system that deploys techniques with the effect or the likely effect of materially distorting the behaviour of a person by impairing their ability to make an autonomous decision, thereby causing them to take a decision that they would not have taken otherwise, in a manner that causes or is likely to cause that person or other persons material or non-material harm, including physical, psychological or economic harm;

Amendment 1161
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 5 - paragraph 1 - point a
(a) the placing on the market, putting into service or use of an AI system that deploys subliminal techniques beyond a person’s consciousness in order to distort a person’s behaviour;

Amendment 1162
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point a
(a) the placing on the market, putting into service or use of an AI system that deploys manipulative, including subliminal, techniques beyond a person’s consciousness;

Amendment 1163
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 5 - paragraph 1 - point a
(a) the placing on the market, putting into service or use of an AI system that deploys subliminal techniques, with the exception of AI systems using such techniques for scientific research and for approved therapeutical purposes on the basis of explicit consent of the natural persons that are exposed to them, which systems shall be classified as high risk for the purposes of this Regulation;

Amendment 1164
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 5 - paragraph 1 - point a
(a) the placing on the market, putting into service or use of an AI system that deploys subliminal techniques beyond a person’s consciousness in order to materially distort a person’s behaviour;

Amendment 1165
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Article 5 - paragraph 1 - point a
(a) the placing on the market, putting into service or use of an AI system that deploys subliminal techniques beyond a person’s consciousness in order to materially distort a person’s behaviour in a manner that causes or is likely to cause that person or another person physical or psychological harm that could be predicted with due diligence;

Amendment 1166
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 5 - paragraph 1 - point a
(a) the placing on the market, putting into service or use of an AI system with the objective to significantly and materially distorting a person’s behaviour or directly causing that person or another person significant harm;

Amendment 1167
EPP - Group of the European Peoples Party (Christian Democrats)
Karlo Ressler
Article 5 - paragraph 1 - point a
(a) the placing on the market, putting into service, or use of an AI system that deploys harmful subliminal techniques beyond a person’s consciousness with the objective to materially distort a person’s behavior in a manner that causes or, that foreseeably may cause that person or another person material, physical or psychological harm;

Amendment 1168
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 5 - paragraph 1 - point a
(a) the placing on the market, putting into service or use of an AI system that deploys subliminal techniques beyond a person’s consciousness in order to materially distort a person’s behaviour in a manner intended that causes or is likely to cause that person or another person physical or psychological harm;

Amendment 1169
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Karen Melchior, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 5 - paragraph 1 - point a
(a) the placing on the market, putting into service or use of an AI system with the objective to or the effect of materially distorting a person’s behaviour in a manner that causes or is reasonably likely to cause that person or another person physical or psychological harm;

Amendment 1170
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
René Repasi, Marc Angel, Andreas Schieder, Maria-Manuel Leitão-Marques
Article 5 - paragraph 1 - point a
(a) the placing on the market, putting into service or use of an AI system that deploys techniques beyond a person’s consciousness in order to materially distort a person’s behaviour in a manner that causes or is likely to cause that person or another person physical or psychological harm;

Amendment 1171
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Article 5 - paragraph 1 - point a
(a) the placing on the market, putting into service or use of an AI system that deploys subliminal techniques beyond a person’s consciousness in order to materially distort a person’s behaviour in a manner that causes that person or another person physical or psychological harm;

Amendment 1172
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 5 - paragraph 1 - point a a (new)
(a a) The placing on the market, putting into service or use of an AI system that deploys purposefully manipulative or deceptive techniques in order to materially distort a person’s behaviour in a manner that causes or is likely to cause that person or another person physical or psychological harm, infringe on that person’s or another person’s fundamental rights, or contravene the Union values enshrined in Article 2 TEU;

Amendment 1173
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 5 - paragraph 1 - point a a (new)
(a a) the placing on the market, putting into service or use of an AI system that deploys subliminal techniques.

Amendment 1174
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - paragraph 1 - point b
(b) the development, placing on the market, putting into service, deployment or use of an AI system that exploits or may be reasonably foreseen to exploit any of the characteristics of one or more individuals, or a specific group of persons, including those characteristic of known, inferred or predicted personality traits, orientations, or social or economic situation, with the effect or likely effect of materially distorting the behaviour of one or more persons that are part of that group in a manner that causes or is likely to cause any person material or non-material harm, including physical, economic or psychological harm or affecting democracy or society at large;

Amendment 1175
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point b
(b) the placing on the market, putting into service or use of an AI system that exploits any of the characteristics of a specific group of persons due to their age, gender, ethnic origin, sexual orientation, disability, or any other biological, physical, physiological, behavioural or social characteristics that results in a detrimental, unfavourable, or discriminatory treatment vis-à-vis persons without those characteristics, or that is used in order to materially distort the behaviour of a person pertaining to that group in a manner that causes or is likely to cause that person or another person physical, psychological or material harm;

Amendment 1176
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 5 - paragraph 1 - point b
(b) the placing on the market, putting into service or use of an AI system that exploits or may be reasonably foreseen to exploit vulnerabilities of children or characteristics of a person or a specific group of persons due to their age, physical or mental ability, gender, sexual orientation, ethnicity, race, origin, and religion or social or economic situation, with the effect or likely effect of materially distorting the behaviour of a person pertaining to that group in a manner that causes or is likely to cause that person or another person material or non-material harm, including physical, psychological or economic harm;

Amendment 1177
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 5 - paragraph 1 - point b
(b) the placing on the market, putting into service or use of an AI system that exploits or may be reasonably foreseen to exploit the vulnerabilities of a specific group of persons due to their age, physical or mental ability, sex, gender, sexual orientation, ethnic or social origin, race, religion or belief, or social or economic situation, with the effect or the likely effect of materially distorting the behaviour of a person in a manner that causes or is likely to cause that person or other persons material or non-material harm, including physical, psychological or economic harm;

Amendment 1178
ECR - European Conservatives and Reformists Group
Rob Rooken
Article 5 - paragraph 1 - point b
(b) the placing on the market, putting into service or use of an AI system that exploits any of the vulnerabilities of a person or a group of persons based on any characteristic or a combination thereof, including but not limited to: their age, race, sex, colour, health status, social and economic status, disability, political or other opinion, in order to materially distort the behaviour of a person pertaining to that group in a manner that causes or is likely to cause that person or another person physical or psychological harm;

Amendment 1179
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 5 - paragraph 1 - point b
(b) the placing on the market, putting into service or use of an AI system that exploits any of the vulnerabilities of a person or a specific group of persons, such as age or physical or mental disability;

Amendment 1180
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 5 - paragraph 1 - point b
(b) the placing on the market, putting into service or use of an AI system that exploits, intentionally or not, any of the vulnerabilities of a person or group of persons based on any sensitive or protected characteristic, including but not limited to age, gender and gender identity, racial or ethnic origin, health status, sexual orientation, sex characteristics, social or economic status, worker status, migration status, or disability in accordance with Article 21 of the Charter of Fundamental Rights;

Amendment 1181
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Karen Melchior, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 5 - paragraph 1 - point b
(b) the placing on the market, putting into service or use of an AI system that exploits any of the vulnerabilities of an individual, including characteristics of such individual’s known or predicted personality or social or economic situation, a specific group of persons due to their age or disability, in order to materially distort the behaviour of a person pertaining to that group in a manner that causes or is likely to cause that person or another person physical or psychological harm;

Amendment 1182
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
René Repasi, Marc Angel, Andreas Schieder, Paul Tang, Maria-Manuel Leitão-
Article 5 - paragraph 1 - point b
(b) the placing on the market, putting into service or use of an AI system that exploits any of the vulnerabilities of an individual or a specific group of persons due to their age, physical or mental disability, in order to materially distort the behaviour of a person pertaining to that group in a manner that causes or is likely to cause that person or another person physical or psychological harm, material or economic damage;

Amendment 1183
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Article 5 - paragraph 1 - point b
(b) the placing on the market, putting into service or use of an AI system that exploits any of the vulnerabilities of a specific group of persons due to their age, physical or mental disability, in order to materially distort the behaviour of a person pertaining to that group in a manner that causes or is likely to cause that person or another person physical or psychological harm that could be predicted with due diligence;

Amendment 1184
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 5 - paragraph 1 - point b
(b) the placing on the market, putting into service or use of an AI system that exploits any of the vulnerabilities of a specific group of persons due to their age, physical or mental disability, with the objective to or the effect of materially distorting the behaviour of a person pertaining to that group in a manner that causes or is likely to directly cause that person or another person significant harm;

Amendment 1185
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 5 - paragraph 1 - point b
(b) the placing on the market, putting into service or use of an AI system that exploits any of the vulnerabilities of a specific group of persons in order to materially distort the behaviour of a person pertaining to that group in a manner that causes or is likely to cause that person or another person physical or psychological harm;

Amendment 1186
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Article 5 - paragraph 1 - point b
(b) the placing on the market, putting into service or use of an AI system that exploits any of the vulnerabilities of a specific group of persons due to their age, physical or mental disability, in order to materially distort the behaviour of a person pertaining to that group in a manner that causes that person or another person physical or psychological harm;

Amendment 1187
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point c - introductory part
(c) The placing on the market, putting into service or use of AI systems by or on behalf of public authorities or by private actors for the purpose of social scoring.

Amendment 1188
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 5 - paragraph 1 - point c - introductory part
(c) the placing on the market, putting into service or use of AI systems for the evaluation or classification of the trustworthiness of natural persons over a certain period of time based on their social behaviour or known or predicted personal or personality characteristics;

Amendment 1189
ECR - European Conservatives and Reformists Group
Vincenzo Sofo
Article 5 - paragraph 1 - point c - introductory part
(c) the placing on the market, putting into service or use of AI systems by public authorities or on their behalf as well as private companies, including social media and cloud service providers, for the evaluation or classification of the trustworthiness of natural persons over a certain period of time based on their social behaviour or known or predicted personal or personality characteristics, with the social score leading to either or both of the following:

Amendment 1190
ECR - European Conservatives and Reformists Group
Jorge Buxadé Villalba
Article 5 - paragraph 1 - point c - introductory part
(c) the placing on the market, putting into service or use of AI systems by public authorities or on their behalf for the evaluation or classification of the trustworthiness of natural persons over a certain period of time based on their social behaviour or known or predicted personal or personality characteristics.

Amendment 1191
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 5 - paragraph 1 - point c - introductory part
(c) the placing on the market, putting into service or use of AI systems for the scoring, evaluation or classification of natural persons or groups related to their education, employment, housing, socioeconomic situation, health, reliability, social behaviour, location or movements;

Amendment 1192
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Article 5 - paragraph 1 - point c - introductory part
(c) the placing on the market, putting into service or use of AI systems by private actors or public authorities or on their behalf for the evaluation or classification of the trustworthiness of natural persons based on their social behaviour or known or predicted personal or personality characteristics;

Amendment 1193
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point c - introductory part
(c) the placing on the market, putting into service or use of AI systems for the evaluation or classification of the trustworthiness of natural persons or groups thereof relating to their education, employment, housing, socio-economic situation, health, reliability, social behaviour, location or movements.

Amendment 1194
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 5 - paragraph 1 - point c - introductory part
(c) the placing on the market, putting into service or use of AI systems for calculation or establishment of a 'social score' resulting from the evaluation or classification of natural persons based on their physical attributes, social behaviour or known or predicted personal or personality characteristics.

Amendment 1195
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - paragraph 1 - point c - introductory part
(c) the development, placing on the market, putting into service, deployment or use of AI systems for the evaluation or classification of the trustworthiness or social standing of natural persons over a certain period of time based on their social behaviour or known, inferred or predicted personal or personality characteristics, potentially leading to detrimental or unfavourable treatment of persons or whole groups;

Amendment 1196
ECR - European Conservatives and Reformists Group
Rob Rooken
Article 5 - paragraph 1 - point c - introductory part
(c) the placing on the market, putting into service or use of AI systems for the scoring, evaluation or classification of natural persons or groups thereof relating to their social behaviour or known or predicted personal or personality characteristics, where the score or assessment leads to any of the following:

Amendment 1197
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 5 - paragraph 1 - point c - introductory part
(c) the placing on the market, putting into service or use of AI systems by public authorities or on their behalf for the evaluation or classification of natural persons over an extended period of time based on their social behaviour or known or predicted personal or personality characteristics (social scoring),with the social score leading to either of the following:

Amendment 1198
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 5 - paragraph 1 - point c - point i
deleted

Amendment 1199
ECR - European Conservatives and Reformists Group
Jorge Buxadé Villalba
Article 5 - paragraph 1 - point c - point i
deleted

Amendment 1200
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 5 - paragraph 1 - point c - point i
deleted

Amendment 1201
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 5 - paragraph 1 - point c - point i
deleted

Amendment 1202
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Article 5 - paragraph 1 - point c - point i
deleted

Amendment 1203
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - paragraph 1 - point c - point i
deleted

Amendment 1204
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 5 - paragraph 1 - point c - point i
deleted

Amendment 1205
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point c - point i
deleted

Amendment 1206
ECR - European Conservatives and Reformists Group
Rob Rooken
Article 5 - paragraph 1 - point c - point i
(i) detrimental or unfavourable treatment affecting the fundamental rights of certain natural persons or whole groups thereof in social contexts which are unrelated to the contexts in which the data was originally generated or collected;

Amendment 1207
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Patryk Jaki, Adam Bielan
Article 5 - paragraph 1 - point c - point i
(i) preferential, detrimental or unfavourable treatment of certain natural persons or whole groups thereof in social contexts which are unrelated to the contexts in which the data was originally generated or collected;

Amendment 1208
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 5 - paragraph 1 - point c - point i
(i) detrimental or unfavourable treatment of certain natural persons or whole groups thereof in social contexts that are unrelated to the contexts in which the data was originally generated or collected;

Amendment 1209
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 5 - paragraph 1 - point c - point i
(i) detrimental or unfavourable treatment of certain natural persons or groups thereof in social contexts which are unrelated to the contexts in which the data was originally generated or collected;

Amendment 1210
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul Garraud
Article 5 - paragraph 1 - point c - point ii
deleted

Amendment 1211
ECR - European Conservatives and Reformists Group
Jorge Buxadé Villalba
Article 5 - paragraph 1 - point c - point ii
deleted

Amendment 1212
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 5 - paragraph 1 - point c - point ii
deleted

Amendment 1213
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 5 - paragraph 1 - point c - point ii
deleted

Amendment 1214
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - paragraph 1 - point c - point ii
deleted

Amendment 1215
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 5 - paragraph 1 - point c - point ii
deleted

Amendment 1216
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point c - point ii
deleted

Amendment 1217
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Article 5 - paragraph 1 - point c - point ii
deleted

Amendment 1218
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Patryk Jaki, Adam Bielan
Article 5 - paragraph 1 - point c - point ii
(ii) preferential, detrimental or unfavourable treatment of certain natural persons or whole groups thereof that is unjustified or disproportionate to their social behaviour or its gravity;

Amendment 1219
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 5 - paragraph 1 - point c - point ii
(ii) detrimental or unfavourable treatment of certain natural persons or groups thereof that is unjustified or disproportionate to their social behaviour or its gravity;

Amendment 1220
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 5 - paragraph 1 - point c - point ii a (new)
(ii a) privileged treatment of certain natural persons or whole groups thereof in social contexts that are unrelated to the contexts in which the data was originally generated or collected;

Amendment 1221
ECR - European Conservatives and Reformists Group
Rob Rooken
Article 5 - paragraph 1 - point c - point ii a (new)
(ii a) treatment of certain natural persons or whole groups thereof otherwise amounting to an unnecessary or disproportionate restriction on fundamental rights.

Amendment 1222
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Article 5 - paragraph 1 - point c a (new)
(c a) the placing on the market, putting into service or use of an AI system for making individual or place-based risk assessments of natural persons in order to assess the risk of a natural person for offending or reoffending or for predicting the occurrence or reoccurrence of an actual or potential criminal offence based on profiling of a natural person or on assessing personality traits and characteristics or past criminal behaviour of natural persons or groups of natural persons;

Amendment 1223
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Samira
Article 5 - paragraph 1 - point c a (new)
(c a) the placing on the market, putting into service or use of an AI system for making individual risk assessments of natural persons in order to assess the risk of a natural person for offending or reoffending or for predicting the occurrence or reoccurrence of an actual or potential criminal offence based on profiling of a natural person or on assessing personality traits and characteristics or past criminal behaviour of natural persons or groups of natural persons;

Amendment 1224
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Markus Buchheit, Hélène Laporte, Jean-Paul Garraud
Article 5 - paragraph 1 - point c a (new)
(c a) the placing on the market, putting into service or use of an AI system that takes decisions to dispatch or set priorities for dispatching emergency response services on which the lives of those rescued depend;

Amendment 1225
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 5 - paragraph 1 - point c a (new)
(c a) the placing on the market, putting into service, or use of AI systems intended to be used as polygraphs and similar tools to detect the emotional state, trustworthiness or related characteristics of a natural person;

Amendment 1226
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Markus Buchheit, Hélène Laporte
Article 5 - paragraph 1 - point c b (new)
(c b) the placing on the market, putting into service or use of an AI system that performs individual risk assessments, serves as polygraphs or similar tools, or analyses the emotional state of natural persons, or predicts the occurrence or repetition of an actual or potential criminal offence on the basis of profiling of natural persons or groups, or which assesses the personality traits of natural persons or groups for profiling purposes in the context of detection, investigation or prosecution of criminal offences;

Amendment 1227
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte
Article 5 - paragraph 1 - point c c (new)
(c c) the placing on the market, putting into service or use of an AI system for the administration of justice and for democratic processes, which helps judicial authorities to investigate and interpret facts and the law, and to apply the law to a specific set of facts, with the exception of purely ancillary administrative activities which have no impact on the actual administration of justice in individual cases;

Amendment 1228
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 5 - paragraph 1 - point c d (new)
(c d) the placing on the market, putting into service or use of an AI system that performs genomic, physiological, psychological or behavioural analyses of a natural person for the purpose of profiling that natural person;

Amendment 1229
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 5 - paragraph 1 - point c e (new)
(c e) the placing on the market, putting into service or use of an AI system that may affect the cognitive integrity or personality of a natural person, with or without the support of physical implants;

Amendment 1230
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 5 - paragraph 1 - point d
deleted

Amendment 1231
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte
Article 5 - paragraph 1 - point d - introductory part
(d) the use of biometric identification systems, except those strictly used for individual authentication of access to protected spaces or systems, those used for the execution of administrative procedures by tax and customs authorities, and by law enforcement authorities if and in as far as such use is strictly necessary for one of the following objectives:

Amendment 1232
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 5 - paragraph 1 - point d - introductory part
(d) putting into service, by public and private entities or on their behalf, of remote biometric identification systems that are or may be used in publicly-accessible, including online, spaces; and the use of remote biometric identification systems in publicly accessible, including online, spaces, but without affecting employees who work in publicy accessibe spaces.

Amendment 1233
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 5 - paragraph 1 - point d - introductory part
(d) the use of ‘real-time’ remote biometric identification systems in publicly accessible spaces

Amendment 1234
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und
Article 5 - paragraph 1 - point d - introductory part
(d) the use of ‘real-time’ remote biometric identification systems in publicly accessible spaces.

Amendment 1235
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka, Róża Thun und Hohenstein
Article 5 - paragraph 1 - point d - introductory part
(d) The placing on the market, putting into service or use of of AI for an automated recognition of human features in publicly accessible spaces - such as of faces but also of gait, fingerprints, DNA, voice, keystrokes and other biometric or behavioral signals - for any purpose, including law enforcement.

Amendment 1236
ECR - European Conservatives and Reformists Group
Rob Rooken
Article 5 - paragraph 1 - point d - introductory part
(d) the placing on the market and use of remote biometric identification systems in publicly accessible spaces;

Amendment 1237
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Article 5 - paragraph 1 - point d - introductory part
(d) the use of remote biometric identification systems in publicly or privately accessible spaces, both online and offline.

Amendment 1238
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point d - introductory part
(d) the placing or making available on the market or putting into service of remote biometric identification systems that are or may be used in publicly-accessible spaces, as well as online spaces, and the use of remote biometric identification systems in publicly accessible spaces;

Amendment 1239
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Article 5 - paragraph 1 - point d - introductory part
(d) the use of ‘real-time’ remote biometric identification systems in publicly accessible spaces for the purpose of law enforcement;

Amendment 1240
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Article 5 - paragraph 1 - point d - introductory part
(d) the use of ‘real-time’ remote biometric identification function of an AI system in publicly accessible spaces by law enforcement or on their behalf, unless and in as far as such use is strictly necessary used for one of the following objectives:

Amendment 1241
ECR - European Conservatives and Reformists Group
Jorge Buxadé Villalba
Article 5 - paragraph 1 - point d - introductory part
(d) the use and installation of 'real-time' or 'post' remote biometric identification systems in publicly accessible spaces for the purpose of law enforcement, except in relation to border control and in the context of the fight against terrorism:

Amendment 1242
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - paragraph 1 - point d - introductory part
(d) the development, placing on the market, putting into service, deployment or use of remote biometric identification systems or biometrics-based in publicly accessible spaces, including online accessible spaces;

Amendment 1243
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Article 5 - paragraph 1 - point d - introductory part
(d) the use of ‘real-time’ remote biometric identification systems in publicly accessible spaces, unless and in as far as such use by law enforcement is strictly necessary for one of the following objectives:

Amendment 1244
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 5 - paragraph 1 - point d - introductory part
(d) the placing or making available on the market, the putting into service or use of remote biometric identification systems that are or maybe used in publicly or privately accessible spaces, as well as online spaces;

Amendment 1245
ECR - European Conservatives and Reformists Group
Jorge Buxadé Villalba
Article 5 - paragraph 1 - point d - point i
deleted

Amendment 1246
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 5 - paragraph 1 - point d - point i
deleted

Amendment 1247
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 5 - paragraph 1 - point d - point i
deleted

Amendment 1248
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - paragraph 1 - point d - point i
deleted

Amendment 1249
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 5 - paragraph 1 - point d - point i
deleted

Amendment 1250
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Article 5 - paragraph 1 - point d - point i
deleted

Amendment 1251
ECR - European Conservatives and Reformists Group
Rob Rooken
Article 5 - paragraph 1 - point d - point i
deleted

Amendment 1252
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Article 5 - paragraph 1 - point d - point i
deleted

Amendment 1253
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 5 - paragraph 1 - point d - point i
deleted

Amendment 1254
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Vlad-Marius Botoş,
Article 5 - paragraph 1 - point d - point i
deleted

Amendment 1255
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 5 - paragraph 1 - point d - point i
(i) the targeted search for specific potential victims of crime;

Amendment 1256
ECR - European Conservatives and Reformists Group
Jorge Buxadé Villalba
Article 5 - paragraph 1 - point d - point ii
deleted

Amendment 1257
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 5 - paragraph 1 - point d - point ii
deleted

Amendment 1258
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 5 - paragraph 1 - point d - point ii
deleted

Amendment 1259
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - paragraph 1 - point d - point ii
deleted

Amendment 1260
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Vlad-Marius Botoş,
Article 5 - paragraph 1 - point d - point ii
deleted

Amendment 1261
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Article 5 - paragraph 1 - point d - point ii
deleted

Amendment 1262
ECR - European Conservatives and Reformists Group
Rob Rooken
Article 5 - paragraph 1 - point d - point ii
deleted

Amendment 1263
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 5 - paragraph 1 - point d - point ii
deleted

Amendment 1264
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 5 - paragraph 1 - point d - point ii
deleted

Amendment 1265
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Article 5 - paragraph 1 - point d - point ii
deleted

Amendment 1266
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 5 - paragraph 1 - point d - point ii
(ii) the prevention of a specific and substantial threat to the critical infrastructure, life, health or physical safety of natural persons or of a terrorist attack;

Amendment 1267
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Article 5 - paragraph 1 - point d - point ii
(ii) the prevention of a threat to the life or physical safety of natural persons or of a terrorist attack;

Amendment 1268
ECR - European Conservatives and Reformists Group
Jorge Buxadé Villalba
Article 5 - paragraph 1 - point d - point iii
deleted

Amendment 1269
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Article 5 - paragraph 1 - point d - point iii
deleted

Amendment 1270
ECR - European Conservatives and Reformists Group
Rob Rooken
Article 5 - paragraph 1 - point d - point iii
deleted

Amendment 1271
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 5 - paragraph 1 - point d - point iii
deleted

Amendment 1272
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 5 - paragraph 1 - point d - point iii
deleted

Amendment 1273
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 5 - paragraph 1 - point d - point iii
deleted

Amendment 1274
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Vlad-Marius Botoş,
Article 5 - paragraph 1 - point d - point iii
deleted

Amendment 1275
ECR - European Conservatives and Reformists Group
Vincenzo Sofo, Kosma Złotowski
Article 5 - paragraph 1 - point d - point iii
deleted

Amendment 1276
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point d - point iii
deleted

Amendment 1277
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Article 5 - paragraph 1 - point d - point iii
deleted

Amendment 1278
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point d - point iii
deleted

Amendment 1279
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - paragraph 1 - point d - point iii
deleted

Amendment 1280
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Article 5 - paragraph 1 - point d - point iii
(iii) the localisation or identification of a natural person for the purpose of conducting a criminal investigation, prosecution or exeuting a criminal penalty for offences referred to in Article 2(2) of Council Framework Decision 2002/584/JHA62 and punishable in the Member State concerned by a custodial sentence or a detention order for a maximum period of at least three years, or other specific offences punishable in the Member State concerned by a custodial sentence or a detention order for a maximum period of at least five years as determined by the law of that Member State.' '62 Council Framework Decision 2002/584/JHA of 13 June 2002 on the European arrest warrant and the surrender procedures between Member States (OJ L 190, 18.7.2002, p. 1).

Amendment 1281
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Markus Buchheit, Hélène Laporte
Article 5 - paragraph 1 - point d - point iii
(iii) the detection, localisation, identification or prosecution of a perpetrator or suspect of a criminal offence punishable in the Member State concerned by a custodial sentence or a detention order for a maximum period of at least ten years, as determined by the law of that Member State.

Amendment 1282
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 5 - paragraph 1 - point d - point iii a (new)
(iii a) searching for missing persons, especially those who are minors or have medical conditions that affect memory, communication, or independent decision-making skills;

Amendment 1283
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point d a (new)
(d a) the placing on the market, putting into service or use of:', '(i) AI systems intended to be used for the purpose of determining access or assigning natural persons to educational and vocational training institutions;', '(ii) AI systems intended to be used for the purpose of assessing students in educational and vocational training institutions.', '(iii) AI systems intended to be used for recruitment or selection of natural persons, notably for advertising vacancies, screening or filtering applications, evaluating candidates in the course of interviews or tests;', '(iv) AI systems intended to be used for making decisions on promotion and termination of work-related contractual relationships, for task allocation and for monitoring and evaluating performance and behavior of persons in such relationships.', '(v) AI systems intended to be used by public authorities, private entities or on their behalf to evaluate the eligibility of natural persons for public assistance benefits and services, essential private services, as well as to grant, reduce, revoke, or reclaim such benefits and services;', '(vi) AI systems intended to be used to evaluate the creditworthiness of natural persons or establish their credit score, with the exception of AI systems put into service by small scale providers for their own use;', '(vii) AI systems intended to be used by competent authorities for migration, asylum and border control management to assess a risk, including a security risk, a risk of irregular immigration, or a health risk, posed by a natural person who intends to enter or has entered into the territory of a Member State;', '(viii) AI systems intended to be used by public authorities, including competent authorities for migration, asylum and border control management, as polygraphs and similar tools or to detect the emotional state of a natural person;

Amendment 1284
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Maria-Manuel Leitão-Marques, Eva Kaili
Article 5 - paragraph 1 - point d a (new)
(d a) the placing on the market, putting into service, or use of an AI system for the specific technical processing of brain or brain-generated data in order to access, infer, influence, or manipulate a person's thoughts, emotions, memories, intentions, beliefs, or other mental states against that person's will or in a manner that causes or is likely to cause that person or another person physical or psychological harm.

Amendment 1285
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point d a (new)
(d a) AI systems intended to be used by law enforcement authorities for making individual risk assessments of natural persons in order to assess the risk of a natural person for offending or reoffending or the risk for potential victims of criminal offences;

Amendment 1286
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Moritz Körner, Jan-Christoph Oetjen, Karen Melchior,
Article 5 - paragraph 1 - point d a (new)
(d a) the use of an AI system for the general monitoring, detection and interpretation of private content in interpersonal communication services, including all measures that would undermine end-to-end encryption..

Amendment 1287
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka, Róża Thun und Hohenstein
Article 5 - paragraph 1 - point d a (new)
(d a) The creation or expansion of facial recognition or other biometric databases through the untargeted scraping of biometric data from social media profiles or CCTV footage or equivalent methods;

Amendment 1288
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 5 - paragraph 1 - point d a (new)
(d a) the creation or expansion of biometric databases through the untargeted or generalised scraping of biometric data from social media profiles or CCTV footage, or equivalent methods;

Amendment 1289
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - paragraph 1 - point d a (new)
(d a) the development, placing on the market, putting into service, deployment or use of of biometric categorisation systems;

Amendment 1290
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Article 5 - paragraph 1 - point d a (new)
(d a) The use of predictive, profiling and risk assessment AI systems in law enforcement and criminal justice;

Amendment 1291
ECR - European Conservatives and Reformists Group
Rob Rooken
Article 5 - paragraph 1 - point d a (new)
(d a) The use of private biometric databases for the purpose of law enforcement;

Amendment 1292
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Article 5 - paragraph 1 - point d b (new)
(d b) The use of predictive, profiling and risk assessment AI system by or on behalf of competent authorities in migration, asylum or border control management, to profile an individual or assess a risk, including a security risk, a risk of irregular immigration, or a health risk, posed by a natural person who intends to enter or has entered the territory of a Member State, on the basis of personal or sensitive data, known or predicted, except for the sole purpose of identifying specific care and support needs;

Amendment 1293
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point d b (new)
(d b) the placing on the market, putting into service or use of AI systems to infer emotions of a natural person, except for health or research purposes or other exceptional purposes, and subject to full regulatory review and with full and informed consent at all times.

Amendment 1294
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point d b (new)
(d b) AI systems intended to be used by law enforcement authorities or other competent public authorities as polygraphs and similar tools or to detect the emotional state of a natural person;

Amendment 1295
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - paragraph 1 - point d b (new)
(d b) the placing on the market, putting into service, deployment or use of of emotion recognition systems other than for the personal use of natural persons as an assistive technology;

Amendment 1296
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka, Róża Thun und Hohenstein
Article 5 - paragraph 1 - point d b (new)
(d b) The use of private facial recognition or other private biometric databases for the purpose of law enforcement

Amendment 1297
ECR - European Conservatives and Reformists Group
Rob Rooken
Article 5 - paragraph 1 - point d b (new)
(d b) The placing on the market, putting into service or use of ‘emotion recognition systems’;

Amendment 1298
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 5 - paragraph 1 - point d b (new)
(d b) the use of remote biometric categorisation systems in publicly accessible spaces;

Amendment 1299
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka, Róża Thun und Hohenstein
Article 5 - paragraph 1 - point d c (new)
(d c) The placing on the market, putting into service or use of 'emotion recognition systems', unless for health purposes, which would be considered high risk.Emotion recognition systems for health purposes shall be limited to their intended purpose, subject to all applicable data protection conditions and limits, and:", '(i) undergo strict testing to ensure scientific and clinical validity;', '(ii) contain clear advice to anyone that may procure or use them about the limitations of such technologies and their potential risks, including of flawed or potentially harmful outcomes;', '(iii) be developed with the active participation and input of the groups they are intended to benefit, as well as those with expertise in the range of fundamental rights that could be deliberately or inadvertently impacted;', '(iv) be developed and deployed in a manner that respects the rights of all persons likely to be affected by them;', '(v) be subject to an opinion of the Health Security Committee and the Fundamental Rights Agency.

Amendment 1300
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 5 - paragraph 1 - point d c (new)
(d c) the placing on the market, putting into service or use of biometric categorisation systems, or other AI systems, that categorise natural persons according to sensitive or protected attributes or characteristics, or infer those attributes or characteristics.Sensitive attributes or characteristics include, but are not limited to:', '(i) Gender & gender identity', '(ii) Race', '(iii) Ethnic origin', '(iv) Migration or citizenship status', '(v) Political orientation', '(vi) Sexual orientation', '(vii) Religion', '(viii) Disability', '(ix) Or any other grounds on which discrimination is prohibited under Article 21 of the EU Charter of Fundamental Rights as well as under Article 9 of the Regulation (EU) 2016/679;

Amendment 1301
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point d c (new)
(d c) the use of AI systems by or on behalf of competent authorities in migration, asylum or border control management, to profile an individual or assess a risk, including a security risk, a risk of irregular immigration, or a health risk, posed by a natural person who intends to enter or has entered the territory of a Member State, on the basis of personal or sensitive data, known or predicted, except for the sole purpose of identifying specific care and support needs;

Amendment 1302
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point d c (new)
(d c) AI systems intended to be used by law enforcement authorities for predicting the occurrence or reoccurrence of an actual or potential criminal offence based on profiling of natural persons as referred to in Article 3(4) of Directive (EU) 2016/680 or assessing personality traits and characteristics or past criminal behaviour of natural persons, groups, or locations;

Amendment 1303
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Article 5 - paragraph 1 - point d c (new)
(d c) the placing on the market, putting into service, or use of AI systems by law enforcement authorities or by competent authorities in migration, asylum and border control management, such as polygraphs and similar tools to detect deception, trustworthiness or related characteristics;

Amendment 1304
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - paragraph 1 - point d c (new)
(d c) the development, placing on the market, putting into service, deployment or use of AI systems for automated monitoring and analysis of human behaviour in publicly accessible spaces, including online;

Amendment 1305
ECR - European Conservatives and Reformists Group
Rob Rooken
Article 5 - paragraph 1 - point d c (new)
(d c) The use of biometric categorisation systems;

Amendment 1306
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - paragraph 1 - point d d (new)
(d d) the development, placing on the market, putting into service, deployment or use of an AI system that can reasonably foreseeably be used for constant monitoring of an individual’s behaviour to identify, predict or deter rule-breaking or fraud in a relationship of power, such as at work or in education, in particular where this constant monitoring has potential punitive or detrimental consequences for individuals;

Amendment 1307
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 5 - paragraph 1 - point d d (new)
(d d) the placing on the market, putting into service or use of an AI system for making predictions, profiles or risk assessments based on data analysis or profiling of natural persons, groups or locations, for the purpose of predicting the occurrence or reoccurrence of an actual or potential criminal offence(s) or other criminalised social behaviour;

Amendment 1308
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Article 5 - paragraph 1 - point d d (new)
(d d) the use of AI systems by or on behalf of competent authorities in migration, asylum and border control management, to forecast or predict individual or collective movement for the purpose of, or in any way reasonably foreseeably leading to, the interdicting, curtailing or preventing migration or border crossings;

Amendment 1309
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point d d (new)
(d d) The creation or expansion of facial recognition or other biometric databases through the untargeted or generalised scraping of biometric data from social media profiles or closed circuit television (CCTV) footage, or equivalent methods;

Amendment 1310
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point d d (new)
(d d) AI systems intended to be used by law enforcement authorities for profiling of natural persons as referred to in Article 3(4) of Directive (EU) 2016/680 in the course of detection, investigation or prosecution of criminal offences;

Amendment 1311
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka, Róża Thun und Hohenstein
Article 5 - paragraph 1 - point d d (new)
(d d) AI systems intended to be used by law enforcement authorities as polygraphs and similar tools or to detect the emotional state of a natural person;

Amendment 1312
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point d d (new)
(d d) The use of private facial recognition or other private biometric databases for the purpose of law enforcement;

Amendment 1313
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 5 - paragraph 1 - point d e (new)
(d e) The placing on the market, putting into service or use of AI systems including, but not limited to polygraphs and similar tools to detect deception, trustworthiness or related characteristics, by or on behalf of competent authorities in migration, asylum or border control management, to profile an individual or assess a risk, including a security risk, a risk of irregular immigration, or a health risk, posed by a natural person who intends to enter or has entered the territory of a Member state, on the basis of personal or sensitive data, known or predicted, except for the sole purpose of identifying specific care and support needs;

Amendment 1314
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point d e (new)
(d e) AI systems intended to be used for crime analytics regarding natural persons, allowing law enforcement authorities to search complex related and unrelated large data sets available in different data sources or in different data formats in order to identify unknown patterns or discover hidden relationships in the data.

Amendment 1315
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - paragraph 1 - point d e (new)
(d e) the placing on the market, putting into service, deployment or use of recommender systems aimed at generating interaction that systematically suggest disinformation or illegal content;

Amendment 1316
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 5 - paragraph 1 - point d e (new)
(d e) the use of private facial recognition or other private biometric databases for the purpose of law enforcement;

Amendment 1317
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka, Róża Thun und Hohenstein
Article 5 - paragraph 1 - point d f (new)
(d f) the placing on the market, putting into service or use of AI systems that use psysiological, behavioural or biometric data to infer attributes or characteristics of persons or groups which are not solely determined by such data or are not externally observable or whose complexity is not possible to fully capture in data, including but not limited to gender, race, colour, ethnic or social origin, as well as political or sexual orientation, or other grounds for discrimination prohibited under Article 21 of the Charter.

Amendment 1318
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - paragraph 1 - point d f (new)
(d f) the use of AI systems by law enforcement authorities, criminal justice authorities, migration, asylum and border-control authorities, or other public authorities to make predictions, profiles or risk assessments based on data analysis or profiling of natural persons as referred to in Article 3(4) of Directive EU 2016/680, groups or locations, for the purpose of predicting the occurrence or recurrence of an actual or potential criminal offence(s) or other offences, or rule-breaking;

Amendment 1319
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 5 - paragraph 1 - point d f (new)
(d f) the placing on the market, putting into service, or use of AI systems that are aimed at automating judicial or similarly intrusive binding decisions by state actors;

Amendment 1320
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point d f (new)
(d f) The use of remote biometric identification in migration management, border surveillance and humanitarian aid.

Amendment 1321
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point d f (new)
(d f) the placing on the market, putting into service or use of ‘emotion recognition systems’

Amendment 1322
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 5 - paragraph 1 - point d g (new)
(d g) the placing on the market, putting into service or the use of AI systems by or on behalf of competent authorities in migration, asylum or border control management, to profile an individual or assess a risk, including a security risk, a risk of irregular immigration, or a health risk, posed by a natural person who intends to enter or has entered the territory of a Member State, on the basis of personal or sensitive data, known or predicted, except for the sole purpose of identifying specific care and support needs;

Amendment 1323
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - paragraph 1 - point d g (new)
(d g) the use of AI systems by or on behalf of competent authorities, or third parties acting on their behalf, in migration, asylum or border control management, to profile an individual or assess a risk, including a security risk, a risk of irregular immigration, or a health risk, posed by a natural person on the basis of personal or sensitive data, known or predicted, except for the sole purpose of identifying specific care and support needs;

Amendment 1324
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point d g (new)
(d g) the use of AI systems, by or on behalf of competent authorities in migration, asylum and border control management, to forecast or predict individual or collective movement for the purpose of, or in any way reasonably foreseeably leading to, the interdicting, curtailing or preventing migration or border crossings;

Amendment 1325
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka, Róża Thun und Hohenstein
Article 5 - paragraph 1 - point d g (new)
(d g) AI systems intended to be used by public authorities or on behalf of public authorities to evaluate the eligibility of natural persons for public assistance benefits and services, as well as to grant, reduce, revoke, or reclaim such benefits and services;

Amendment 1326
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point d g (new)
(d g) the use of biometric categorisation systems in publicly-accessible spaces, workplaces (including in hiring processes), and educational settings;

Amendment 1327
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point d h (new)
(d h) the placing on the market, putting into service or use of biometric categorisation systems, or other AI systems, that categorise natural persons according to sensitive or protected attributes or characteristics, or infer those attributes or characteristics, including:', '◦ Sex', '◦ Gender & gender identity', '◦ Race', '◦ Ethnic origin', '◦ Membership of a national minority', '◦ Migration or citizenship status', '◦ Political orientation', '◦ Social origin or class', '◦ Language or dialect', '◦ Trade union membership', '◦ Sexual orientation', '◦ Religion or philosophical orientation', '◦ Disability', '◦ Or any other grounds on which discrimination is prohibited under Article 21 of the EU Charter of Fundamental Rights as well as under Article 9 of the General Data Protection Regulation

Amendment 1328
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 5 - paragraph 1 - point d h (new)
(d h) the placing on the market, putting into service or the use of AI systems, by or on behalf of competent authorities in migration, asylum and border control management, to forecast or predict individual or collective movement for the purpose of, or in any way reasonably foreseeably leading to, the prohibiting, curtailing or preventing migration or border crossings;

Amendment 1329
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - paragraph 1 - point d h (new)
(d h) the placing on the market, putting into service, or use of AI systems by law enforcement authorities, or by competent authorities in migration, asylum and border control management, as polygraphs and similar tools to detect deception, trustworthiness or related characteristics

Amendment 1330
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point d h (new)
(d h) The use of private facial recognition or other private biometric databases for the purpose of law enforcement;

Amendment 1331
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point d i (new)
(d i) the use of AI systems by law enforcement authorities, criminal justice authorities, or other public authorities in conjunction with law enforcement and criminal justice authorities, to make predictions, profiles or risk assessments based on data analysis or profiling of natural persons [as referred to in Article 3(4) of Directive EU)2016/680], groups or locations, for the purpose of predicting the occurrence or reoccurrence of an actual or potential criminal offence(s) or other criminalised social behaviour.”

Amendment 1332
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 5 - paragraph 1 - point d i (new)
(d i) the placing on the market, putting into service or the use of AI systems intended to assist competent authorities for the examination of application for asylum, visa and residence permits and associated complaints with regard to the eligibility of the natural persons applying for a status;

Amendment 1333
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point d i (new)
(d i) The creation or expansion of facial recognition or other biometric databases through the untargeted or generalised scraping of biometric data from social media profiles or CCTV footage, or equivalent methods;

Amendment 1334
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - paragraph 1 - point d i (new)
(d i) The development of private facial recognition or other private biometric databases and the use of such databases for the purpose of law enforcement;

Amendment 1335
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point d j (new)
(d j) the use of AI systems, by or on behalf of competent authorities in migration, asylum and border control management, to forecast or predict individual or collective movement for the purpose of, or in any way reasonably foreseeably leading to, the interdicting, curtailing or preventing migration or border crossings;

Amendment 1336
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - paragraph 1 - point d j (new)
(d j) The creation or expansion of facial recognition or other biometric databases through the untargeted or generalised scraping of biometric data from social media profiles or CCTV footage, or equivalent methods;

Amendment 1337
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point d j (new)
(d j) the placing on the market, putting into service or use of ‘emotion recognition systems’;

Amendment 1338
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point d k (new)
(d k) The use of AI systems by law enforcement and criminal justice authorities to make predictions, profiles or risk assessments for the purpose of predicting crime.

Amendment 1339
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point d k (new)
(d k) the use of biometric categorisation systems in publicly-accessible spaces, workplaces (including in hiring processes), and educational settings;

Amendment 1340
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - paragraph 1 - point d k (new)
(d k) The use of remote biometric identification for the purpose of migration management, border surveillance and humanitarian aid;

Amendment 1341
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 1 - point d l (new)
(d l) the placing on the market, putting into service or use of:', '(i) AI systems intended to be used for the purpose of determining access or assigning natural persons to educational and vocational training institutions;', '(ii) AI systems intended to be used for the purpose of assessing students in educational and vocational training institutions.', '(iii) AI systems intended to be used for recruitment or selection of natural persons, notably for advertising vacancies, screening or filtering applications, evaluating candidates in the course of interviews or tests;', '(iv) AI systems intended to be used for making decisions on promotion and termination of work-related contractual relationships, for task allocation and for monitoring and evaluating performance and behaviour of persons in such relationships;', '(v) AI systems intended to be used by public authorities, private entities or on their behalf to evaluate the eligibility of natural persons for public assistance benefits and services, essential private services, as well as to grant, reduce, revoke, or reclaim such benefits and services;', '(vi) AI systems intended to be used to evaluate the creditworthiness of natural persons or establish their credit score;

Amendment 1342
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - paragraph 1 - point d l (new)
(d l) the use of AI systems for indiscriminate surveillance applied in a generalised manner to a large number of natural persons without differentiation;

Amendment 1343
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - paragraph 1 - point d m (new)
(d m) The collection or generation of data for practices and AI systems listed in paragraphs -1 and 1 shall also be prohibited throughout their lifecycle, including training, validation and testing;

Amendment 1344
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - paragraph 1 - point d n (new)
(d n) The placing on the market, putting into use or deployment of AI systems built on, designed, trained, validated or tested with data that was collected, processed or generated illegally;

Amendment 1345
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - paragraph 1 - point d o (new)
(d o) The Union shall not fund research into and development of AI systems which are likely to be used for indiscriminate surveillance of publicly accessible spaces applied in a generalised manner to a large number of natural persons without differentiation.

Amendment 1346
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - paragraph 1 a (new)
1 a. In Accordance with Article 73, the Commission is empowered to amend paragraph 1 of this Article by means of a delegated act by adding systems that adversely affect, or are likely to adversely affect, the essence of fundamental rights. In doing so the Commission shall consult civil society and human rights experts annually to reflect state-of-the-art knowledge regarding the potential impacts of technology on fundamental rights.

Amendment 1347
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
René Repasi, Marc Angel, Andreas Schieder, Paul Tang, Maria-Manuel Leitão-
Article 5 - paragraph 1 a (new)
1 a. the placing on the market, putting into service or use of an AI system that analyses and understands human non-verbal signs such as facial expressions, body language, gestures and voice tones to assess their emotional state or perform biometric categorisation.

Amendment 1348
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 5 - paragraph 2
deleted

Amendment 1349
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - paragraph 2
deleted

Amendment 1350
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 5 - paragraph 2
deleted

Amendment 1351
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Article 5 - paragraph 2
deleted

Amendment 1352
ECR - European Conservatives and Reformists Group
Rob Rooken
Article 5 - paragraph 2
deleted

Amendment 1353
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Article 5 - paragraph 2
deleted

Amendment 1354
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und
Article 5 - paragraph 2
deleted

Amendment 1355
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 5 - paragraph 2
deleted

Amendment 1356
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und
Article 5 - paragraph 2 - point a
deleted

Amendment 1357
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 5 - paragraph 2 - point a
deleted

Amendment 1358
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und
Article 5 - paragraph 2 - point b
deleted

Amendment 1359
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 5 - paragraph 2 - point b
deleted

Amendment 1360
ECR - European Conservatives and Reformists Group
Vincenzo Sofo, Kosma Złotowski
Article 5 - paragraph 2 - point b a (new)
(b a) the full respect of fundamental rights and freedoms in conformity with Union values, the Universal Declaration of Human Rights, the European Convention of Human Rights and the Charter of Fundamental Rights of the EU.

Amendment 1361
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und
Article 5 - paragraph 2 - subparagraph 1
deleted

Amendment 1362
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 5 - paragraph 2 - subparagraph 1
deleted

Amendment 1363
ECR - European Conservatives and Reformists Group
Jorge Buxadé Villalba
Article 5 - paragraph 2 - subparagraph 1
In addition, the use of ‘real-time’ or 'post' remote biometric identification systems in publicly accessible spaces for the purpose of law enforcement for any of the objectives referred to in paragraph 1 point d) shall comply with necessary and proportionate safeguards and conditions in relation to the use.

Amendment 1364
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 5 - paragraph 3
deleted

Amendment 1365
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 5 - paragraph 3
deleted

Amendment 1366
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - paragraph 3
deleted

Amendment 1367
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und
Article 5 - paragraph 3
deleted

Amendment 1368
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Article 5 - paragraph 3
deleted

Amendment 1369
ECR - European Conservatives and Reformists Group
Rob Rooken
Article 5 - paragraph 3
deleted

Amendment 1370
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 5 - paragraph 3
deleted

Amendment 1371
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Article 5 - paragraph 3
deleted

Amendment 1372
ECR - European Conservatives and Reformists Group
Jorge Buxadé Villalba
Article 5 - paragraph 3 - introductory part
3. As regards paragraphs 1, point (d) and 2, each individual use for the purpose of law enforcement of a ‘real-time’ or 'post' remote biometric identification system in publicly accessible spaces shall be subject to a prior authorisation granted by a judicial authority or by an independent administrative authority of the Member State in which the use is to take place, issued upon a reasoned request and in accordance with the detailed rules of national law referred to in paragraph 4. However, in a duly justified situation of urgency, the use of the system may be commenced without an authorisation and the authorisation may be requested only during or after the use. If the prior justification does not comply with the principles of necessity and proportionality, the results obtained by the use of this technology may not be used for law enforcement purposes.

Amendment 1373
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Article 5 - paragraph 3 - introductory part
3. As regards paragraphs 1, point (d) and 2, each use for the purpose of law enforcement of a ‘real-time’ remote biometric identification system in publicly accessible spaces shall be subject to a prior authorisation granted by a judicial authority or by an independent administrative authority of the Member State in which the use is to take place, issued upon a reasoned request and in accordance with the detailed rules of national law referred to in paragraph 4. However, in a duly justified situation of urgency, the use of the system may be commenced without an authorisation if such authorisation is requested without undue delay, and, if such authorisation is rejected, the system’s use is stopped with immediate effect.

Amendment 1374
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 3 - introductory part
3. As regards paragraphs 1, point (d) and 2, each individual use for the purpose of law enforcement of a ‘real-time’ remote biometric identification system in publicly accessible or online spaces shall be subject to a prior authorisation granted by a judicial authority or by an independent administrative authority of the Member State in which the use is to take place, issued upon a reasoned request and in accordance with the detailed rules of national law referred to in paragraph 4. However, in a duly justified situation of urgency, the use of the system may be commenced without an authorisation and the authorisation may be requested only during or after the use.

Amendment 1375
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und
Article 5 - paragraph 3 - subparagraph 1
deleted

Amendment 1376
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 5 - paragraph 3 - subparagraph 1
deleted

Amendment 1377
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - paragraph 3 - subparagraph 1
deleted

Amendment 1378
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 5 - paragraph 3 - subparagraph 1
The competent judicial or administrative authority shall only grant the authorisation where it is satisfied, based on objective evidence or clear indications presented to it, that the use of the ‘real-time’ remote biometric identification system at issue is necessary for and proportionate to achieving one of the objectives specified in paragraph 1, point (d), as identified in the request. In deciding on the request, the competent judicial or administrative authority shall take into account the elements referred to in paragraph 2. It shall grant the authorisation for a limited period and scope. Any renewal or amendment of the authorisation shall be subject to the submission of a new request to the competent judicial or administrative authority.

Amendment 1379
ECR - European Conservatives and Reformists Group
Jorge Buxadé Villalba
Article 5 - paragraph 3 - subparagraph 1
The competent judicial or administrative authority shall only grant the authorisation where it is satisfied, based on objective evidence or clear indications presented to it, that the use of the ‘real-time’ or 'post' remote biometric identification system at issue is necessary for and proportionate to achieving one of the objectives specified in paragraph 1, point (d), as identified in the request. In deciding on the request, the competent judicial or administrative authority shall take into account the elements referred to in paragraph 2.

Amendment 1380
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Article 5 - paragraph 3 - subparagraph 1 - point 1 (new)
(1) The placing on the market, putting into service or use of biometric categorisation systems, or other AI systems, that categorise natural persons or groups of persons according to sensitive or protected attributes or characteristics, or infer those attributes or characteristics. Sensitive attributes or characteristics include, but are not limited to: gender and gender identity, race, ethnic origin, migration or citizenship status, political orientation, sexual orientation, religion, disability or any other grounds on which discrimination is prohibited under Article 21 of the EU Charter of Fundamental Rights as well as under Article 9 of the Regulation (EU) 2016/679.

Amendment 1381
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 5 - paragraph 4
deleted

Amendment 1382
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Article 5 - paragraph 4
deleted

Amendment 1383
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 5 - paragraph 4
deleted

Amendment 1384
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Article 5 - paragraph 4
deleted

Amendment 1385
ECR - European Conservatives and Reformists Group
Rob Rooken
Article 5 - paragraph 4
deleted

Amendment 1386
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 5 - paragraph 4
deleted

Amendment 1387
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Róża Thun und Hohenstein, Vlad-Marius
Article 5 - paragraph 4
deleted

Amendment 1388
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 5 - paragraph 4
deleted

Amendment 1389
ECR - European Conservatives and Reformists Group
Vincenzo Sofo, Kosma Złotowski
Article 5 - paragraph 4
4. A Member State may decide to provide for the possibility to fully or partially authorise the use of ‘real-time’ remote biometric identification systems in publicly accessible spaces for the purpose of law enforcement within the limits and under the conditions listed in paragraphs 1, point (d), 2 and 3. That Member State shall lay down in its national law the necessary detailed rules for the request, issuance and exercise of, as well as supervision relating to, the authorisations referred to in paragraph 3. Those rules shall fully comply with EU values, the Universal Declaration of Human Rights, the European Convention of Human Rights and the Charter of Fundamental Rights of the EU and shall specify in respect of which of the objectives listed in paragraph 1, point (d), including which of the criminal offences referred to in point (iii) thereof, the competent authorities may be authorised to use those systems for the purpose of law enforcement.

Amendment 1390
ECR - European Conservatives and Reformists Group
Jorge Buxadé Villalba
Article 5 - paragraph 4
4. A Member State may decide to provide for the possibility to fully or partially authorise the use of ‘real-time’ or 'post' remote biometric identification systems in publicly accessible spaces for the purpose of law enforcement within the limits and under the conditions listed in paragraphs 1, point (d), 2 and 3. That Member State shall lay down in its national law the necessary detailed rules for the request, issuance and exercise of, as well as supervision relating to, the authorisations referred to in paragraph 3. Those rules shall also specify in respect of which of the objectives listed in paragraph 1, point (d) the competent authorities may be authorised to use those systems for the purpose of law enforcement.

Amendment 1391
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Article 5 - paragraph 4
4. A Member State may decide to provide for the possibility to fully or partially authorise the use of ‘real-time’ remote biometric identification systems in publicly accessible spaces for the purpose of law enforcement within the limits and under the conditions listed in paragraphs 1, point (d), 2 and 3. That Member State shall lay down in its national law the necessary detailed rules for the request, issuance and exercise of, as well as supervision and reporting relating to, the authorisations referred to in paragraph 3. Those rules shall also specify in respect of which of the objectives listed in paragraph 1, point (d), including which of the criminal offences referred to in point (iii) thereof, the competent authorities may be authorised to use those systems for the purpose of law enforcement.

Amendment 1392
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 5 - paragraph 4
4. A Member State may decide to provide for the possibility to fully or partially authorise the use of ‘real-time’ remote biometric identification systems in publicly accessible or online spaces for the purpose of law enforcement within the limits and under the conditions listed in paragraphs 1, point (d), 2 and 3. That Member State shall lay down in its national law the necessary detailed rules for the request, issuance and exercise of, as well as supervision relating to, the authorisations referred to in paragraph 3. Those rules shall also specify in respect of which of the objectives listed in paragraph 1, point (d), including which of the criminal offences referred to in point (iii) thereof, the competent authorities may be authorised to use those systems for the purpose of law enforcement.

Amendment 1393
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 5 - paragraph 4 a (new)
4 a. When assessing for the purposes of paragraph 1 whether an AI system poses a risk of harm to the health and safety or a risk of adverse impact on worker’s rights that is equivalent to or greater than the risk of harm posed by the high-risk AI systems already referred to in Annex III, the Commission shall seek and take into account the opinion of social partners.

Amendment 1394
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 5 - paragraph 4 a (new)
4 a. This Article shall not affect the restrictions, prohibitions or enforcement that apply where an artificial intelligence practice infringes another EU law, including EU acquis on data protection, privacy, or the confidentiality of communications, on non discrimination, consumer protection or on competition.

Amendment 1395
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Article 5 - paragraph 4 a (new)
4 a. The placing on the market, putting into service or use of AI systems intended to be used as polygraphs, emotion recognition systems or similar tools to detect the emotional state, trustworthiness or related characteristics of a natural person.

Amendment 1396
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
René Repasi, Marc Angel, Andreas Schieder, Maria-Manuel Leitão-Marques
Article 5 - paragraph 4 a (new)
4 a. In order to increase public transparency and oversight every decision about the deployment or marketing of any AI system that is categorised as posing an unacceptable risk shall be made public.

Amendment 1397
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 5 - paragraph 4 b (new)
4 b. Member States may, by law or collective agreement, decide to prohibit or to limit the use of AI systems or provide more specific provisions for this purpose to ensure the protection of the rights of workers in the employment context, in particular for the purposes of the recruitment, the performance of the contract of employment, including discharge of obligations laid down by law or by collective agreements, management, planning and organisation of work, equality and diversity in the workplace, health and safety at work, protection of employer’s or customer’s property and for the purposes of the exercise and enjoyment, on an individual or collective basis, of rights and benefits related to employment, and for the purpose of the termination of the employment relationship.

Amendment 1398
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 5 - paragraph 4 b (new)
4 b. Member States may, by law or collective agreements, decide to prohibit or to limit the use of AI systems to ensure the protection of the rights of workers in the employment context, in particular for the purposes of the recruitment, the performance of the contract of employment, including discharge obligations laid down by law or by collective agreements, management, planning and organization of work, equality and diversity at the workplace, health and safety at work, protection of employers or customers' property and for the purposes of the exercise and enjoyment, on an individual or collective basis, of rights and benefits related to employment, and for the purpose of the termination of the employment relationship.

Amendment 1399
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Article 5 - paragraph 4 c (new)
4 c. the placing on the market, putting into service or the use of AI systems by or on behalf of competent authorities in migration, asylum or border control management, to profile an individual or assess a risk, including a security risk, a risk of irregular immigration, or a health risk, posed by a natural person who intends to enter or has entered the territory of a Member State, on the basis of personal or sensitive data, known or predicted, except for the sole purpose of identifying specific care and support needs;

Amendment 1400
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Article 5 - paragraph 4 d (new)
4 d. the placing on the market, putting into service or use of AI systems by competent authorities or on their behalf in migration, asylum and border control management, to forecast or predict individual or collective movement for the purpose of, or in any way reasonably foreseeably leading to, the prohibiting, curtailing or preventing migration or border crossings;

Amendment 1401
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Article 5 - paragraph 4 f (new)
4 e. the placing on the market, putting into service or the use of AI systems intended to assist competent authorities for the examination of application for asylum, visa and residence permits and associated complaints with regard to the eligibility of the natural persons applying for a status;

Amendment 1402
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 5 - paragraph 4 f (new)
4 f. the placing on the market, putting into service, or use of an AI system for the specific technical processing of brain or brain-generated data in order to access, infer, influence, or manipulate a person's thoughts, emotions, memories, intentions, beliefs, or other mental states against that person's will or in a manner that causes or is likely to cause that person or another person physical or psychological harm;

Amendment 1403
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 5 a (new)
Article 5 a', 'Accessibility Requirements for providers and users of AI systems', '1. Providers of AI systems shall ensure that their systems are accessible in accordance with the accessibility requirements set out in Section I, Section II, Section VI, and Section VII of Annex I of Directive (EU) 2019/882 prior to those systems being placed on the market or put into service.', '2. Users of AI systems shall use such systems in accordance with the accessibility requirements set out in Section III, Section IV, Section VI, and Section VII of Annex I of Directive (EU) 2019/882.', '3. Users of AI systems shall prepare the necessary information in accordance with Annex V of Directive (EU) 2019/882. Without prejudice to Annex VIII of this Regulation, the information shall be made available to the public in an accessible manner for persons with disabilities and be kept for as long as the AI system is in use.', '4. Without prejudice to right of affected persons to information about the use and functioning of AI systems, transparency obligations for providers and users of AI, obligations to ensure consistent and meaningful public transparency under this Regulation, providers and users of AI systems shall ensure that information, forms and measures provided pursuant to this Regulation are made available in a manner that they are easy to find, easy to understand, and accessible in accordance with Annex I to Directive 2019/882.', '5. Users of AI systems shall ensure that procedures are in place so that the use of AI systems remains in conformity with the applicable accessibility requirements. Changes in the characteristics of the use, changes in applicable accessibility requirements and changes in the harmonised standards or in technical specifications by reference to which use of an AI system is declared to meet the accessibility requirements shall be adequately taken into account by the user.', '6. In the case of non-conformity, users of AI systems shall take the corrective measures necessary to conform with the applicable accessibility requirements. When necessary, and at the request of the user, the provider of the AI system in question shall cooperate with the user to bring the use of the AI system into compliance with applicable accessibility requirements.', '7. Furthermore, where the use of an AI system is not compliant with applicable accessibility requirements, the user shall immediately inform the competent national authorities of the Member States in which the system is being used, to that effect, giving details, in particular, of the non-compliance and of any corrective measures taken. They shall cooperate with the authority, at the request of that authority, on any action taken to bring the use of the AI system into compliance with applicable accessibility requirements.', '8. AI systems and the use of thereof, which are in conformity with harmonised technical standards or parts thereof derived from Directive (EU) 2019/882 the references of which have been published in the Official Journal of the European Union, shall be presumed to be in conformity with the accessibility requirements of this Regulation in so far as those standards or parts thereof cover those requirements.', '9. AI systems and use of thereof, which are in conformity with the technical specifications or parts thereof adopted for the Directive (EU) 2019/882 shall be presumed to be in conformity with the accessibility requirements of this Regulation in so far as those technical specifications or parts thereof cover those requirements.

Amendment 1404
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Cornelia Ernst, Elena Kountoura
Article 5 a (new)
Article 5 a', '1. The Commission is empowered to adopt delegated acts in accordance with Article 73 to update the list of prohibited artificial intelligence practices referred to in Article 5 by adding AI systems that pose an unacceptable risk of harm to health and safety, or an unacceptable risk of adverse impact on fundamental rights.', '2. When assessing for the purposes of paragraph 1 whether an AI system poses an unacceptable risk of harm to health and safety, or an unacceptable risk of adverse impact on fundamental rights, the Commission shall take into account the following non-cumulative criteria:', 'a) the extent to which the intended purpose of the AI system, or the reasonably foreseeable consequences of its use, conflict with the essence of the rights and freedoms established by the Charter, such that these rights and freedoms would lose their value either for the rights holder or for society as a whole;', 'b) the extent to which the risks posed by an AI system cannot be sufficiently mitigated, including by the obligations imposed upon high-risk AI systems under this Regulation;', 'c) the extent to which an AI system violates human dignity;', 'd) the extent to which the use of an AI system has already caused harm to the health and safety of persons or disproportionate impact on their fundamental rights or has given rise to significant concerns in relation to the materialisation of such harm or disproportionate impact, as demonstrated by reports or documented allegations available to national competent authorities;', 'e) the potential extent of such harm or such disproportionate impact, in particular in terms of its intensity and its ability to affect a plurality of persons or to affect a particular group of persons disproportionately;', 'f) the extent to which potentially harmed or adversely impacted persons are dependent on the outcome produced with an AI system, in particular because for practical or legal reasons it is not reasonably possible to opt-out from that outcome;', 'g) the extent to which potentially harmed or adversely impacted persons are in a vulnerable position in relation to the user of an AI system, in particular due to an imbalance of power, knowledge, economic or social circumstances, accessibility barriers or age;', 'h) the extent to which the outcome produced with an AI system is easily reversible, whereby outcomes having an impact on the health or safety of persons or on their fundamental rights shall not be considered as easily reversible;', 'i) the extent to which existing Union legislation lacks:', '1) effective measures of redress in relation to the risks posed by an AI system, with the exclusion of claims for damages;', '2) effective measures to prevent those risks.

Amendment 1405
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Article 5 a (new)
Article 5 a', 'Amendments to Article 5', 'The Commission is empowered to adopt delegated acts in accordance with Article 73 to update the list of AI systems and practices prohibited under Article 5 of the present regulation, according to the latest development in technology and to the assessment of increased or newly emerged risks to fundamental rights.

Amendment 1406
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 5 b (new)
Article 5 b', 'Delegated acts to update the list of prohibited AI practices', '1. The Commission is empowered to adopt delegated acts in accordance with Article 73 to update the list of prohibited artificial intelligence practices referred to in Article 5 by adding AI systems that pose an unacceptable risk of harm to health and safety, or an unacceptable risk of adverse impact on fundamental rights.2. When assessing for the purposes of paragraph 1 whether an AI system poses an unacceptable risk of harm to health and safety, or an unacceptable risk of adverse impact on fundamental rights, the Commission shall take into account the following non-cumulative criteria:', 'a) the extent to which the intended purpose of the AI system, or the reasonably foreseeable consequences of its use, conflict with the essence of the rights and freedoms established by the Charter, such that these rights and freedoms would lose their value either for the rights holder or for society as a whole;', 'b) the extent to which the risks posed by an AI system cannot be sufficiently mitigated, including by the obligations imposed upon high-risk AI systems under this Regulation;', 'c) the extent to which an AI system violates human dignity;', 'd) the extent to which the use of an AI system has already caused harm to the health and safety of persons or disproportionate impact on their fundamental rights or has given rise to significant concerns in relation to the materialisation of such harm or disproportionate impact, as demonstrated by reports or documented allegations available to national competent authorities;', 'e) the potential extent of such harm or such disproportionate impact, in particular in terms of its intensity and its ability to affect a plurality of persons or to affect a particular group of persons disproportionately;', 'f) the extent to which potentially harmed or adversely impacted persons are dependent on the outcome produced with an AI system, in particular because for practical or legal reasons it is not reasonably possible to opt-out from that outcome;', 'g) the extent to which potentially harmed or adversely impacted persons are in a vulnerable position in relation to the user of an AI system, in particular due to an imbalance of power, knowledge, economic or social circumstances, accessibility barriers or age;', 'h) the extent to which the outcome produced with an AI system is easily reversible, whereby outcomes having an impact on the health or safety of persons or on their fundamental rights shall not be considered as easily reversible;', 'i) the extent to which existing Union legislation lacks: i) effective measures of redress in relation to the risks posed by an AI system, with the exclusion of claims for damages; ii) effective measures to prevent those risks.

Amendment 1407
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Title II a (new)
Horizonal Requirements for all AI systems Title for a new Article -Accessibility Requirements for providers and users of AI systems 1.Providers of AI systems shall ensure that their systems are accessible in accordance with the accessibility requirements set out in Section I, Section II, Section VI, and Section VII of Annex I of Directive (EU) 2019/882 prior to those systems being placed on the market or put into service. 2.Users of AI systems shall use such systems in accordance with the accessibility requirements set out in Section III, Section IV, Section VI, and Section VII of Annex I of Directive (EU) 2019/882. 3.Users of AI systems shall prepare the necessary information in accordance with Annex V of Directive (EU) 2019/882.Without prejudice to Annex VIII of this Regulation, the information shall be made available to the public inan accessible manner for persons with disabilities and be kept for as long as the AI system is in use. 4.Without prejudice to right of affected persons to information about the use and functioning of AI systems, transparency obligations for providers and users of AI, 4obligations to ensure consistent and meaningful public transparency under this Regulation , providers and users of AI systems shall ensure that information, forms and measures provided pursuant to this Regulation are made available in a manner that they are easy to find, easy to understand, and accessible in accordance with Annex I to Directive 2019/882. 5.Users of AI systems shall ensure that procedures are in place 6 so that the use of AI systems remains in conformity with the applicable accessibility requirements.Changes in the characteristics of the use, changes in applicable accessibility requirements and changes in the harmonised standards or in technical specifications by reference to which use of an AI system is declared to meet the accessibility requirements shall be adequately taken into account by the user. 6.In the case of non-conformity, users of AI systems shall take the corrective measures necessary to conform with the applicable accessibility requirements.When necessary, and at the request of the user, the provider of the AI system in question shall cooperate with the user to bring the use of the AI system into compliance with applicable accessibility requirements. 7.Furthermore, where the use of an AI system is not compliant with applicable accessibility requirements, the user shall immediately inform the competent national authorities of the Member States in which the system is being used, to that effect, giving details, in particular, of the non-compliance and of any corrective measures taken.They shall cooperate with the authority, at the request of that authority, on any action taken to bring the use of the AI system into compliance with applicable accessibility requirements. 8.AI systems and the use of thereof, which are in conformity with harmonised technical standards or parts thereof derived from Directive (EU) 2019/882 the references of which have been published in the Official Journal of the European Union, shall be presumed to be in conformity with the accessibility requirements of this Regulation in so far as those standards or parts thereof cover those requirements. 9.AI systems and use of thereof, which are in conformity with the technical specifications or parts thereof adopted for the Directive(EU) 2019/882 shall be presumed to be in conformity with the accessibility requirements of this Regulation in so far as those technical specifications or parts thereof cover those requirements.

Amendment 1408
EPP - Group of the European Peoples Party (Christian Democrats)
Geoffroy Didier
Title III
HIGH-RISK USES OF AI SYSTEMS

Amendment 1409
EPP - Group of the European Peoples Party (Christian Democrats)
Geoffroy Didier
Title III - Chapter 1 - title
1 CLASSIFICATION OF AI SYSTEMS AS WITH HIGH-RISK USES

Amendment 1410
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 6 - title


Amendment 1411
EPP - Group of the European Peoples Party (Christian Democrats)
Geoffroy Didier
Article 6 - title
Classification rules for high-risk uses of AI systems

Amendment 1412
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski, Radosław Sikorski
Article 6 - paragraph -1 (new)
-1. The AI system shall be considered high-risk where it meets the following two cumulative criteria: ', '(a) the AI system is used or applied in a sector where, given the characteristics of the activities typically undertaken, significant risks of harm to the health and safety or a risk of adverse impact on fundamental rights of users, as outlined in Article 7(2) can be expected to occur.', '(b) the AI system application in the sector in question is used in such a manner that significant risks of harm to the health and safety or a risk of adverse impact on fundamental rights of users, as outlined in Article 7(2) are likely to arise.

Amendment 1413
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 6 - paragraph -1 (new)
-1. AI systems referred to in Annex III shall be considered high-risk for the purposes of this Regulation.

Amendment 1414
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 6 - paragraph 1 - introductory part
1. An AI system that is itself a product shall be considered as high risk AI system if, under the applicable Union harmonisation legislation listed in Annex II, it is classified as high-risk AI system or an equivalent thereof and has to undergo a third-party conformity assessment for meeting essential safety requirements prior to placing it on the market or putting it into service.', 'An AI system intended to be used as a core and essential safety component of a product under the applicable Union harmonisation legislation listed in Annex II, shall be considered as high risk if such Union harmonisation legislation classifies it as high-risk or an equivalent thereof and requires it to undergo a third-party conformity assessment for meeting essential safety requirements with a view to placing it on the market or putting it into service.', 'The high-risk classification set in paragraph 1 shall not impact or determine the outcome of other risk classification procedures established in Union harmonisation legislation listed in Annex II

Amendment 1415
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 6 - paragraph 1 - introductory part
1. Irrespective of whether an AI system is placed on the market or put into service independently from the products referred to in point (a), that AI system shall be considered high-risk where:

Amendment 1416
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 6 - paragraph 1 - introductory part
1. Irrespective of whether an AI system is placed on the market or put into service independently from the products referred to in points (a) and (b), that AI system shall be considered high-risk where one of the following conditions are fulfilled:

Amendment 1417
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 6 - paragraph 1 - point a
deleted

Amendment 1418
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 6 - paragraph 1 - point a
(a) the AI system is intended to be used as a safety component of a product, or is itself a product or it is required to undergo a third-party conformity assessment with a view to the placing on the market or putting into service of that product pursuant to the Union harmonisation legislation listed in Annex II;

Amendment 1419
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Article 6 - paragraph 1 - point a
(a) the AI system has a self-evolving behaviour, the failure of which results in an immediate hazardous condition in a specific domain, and is intended to be used as a safety component of a product, or is itself a product, covered by the Union harmonisation legislation listed in Annex II;

Amendment 1420
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka, Róża Thun und Hohenstein
Article 6 - paragraph 1 - point a
(a) the AI system is intended to be used or reasonably foreseeable used as a safety component of a product, or is itself a product, covered by the Union harmonisation legislation listed in Annex II;

Amendment 1421
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 6 - paragraph 1 - point a
(a) the AI system is intended to be used as a component of a product, or is itself a product, the failure or malfunctioning of which endangers the health, safety or fundamental rights of persons;

Amendment 1422
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Article 6 - paragraph 1 - point a
(a) the AI system is intended to be used as a safety component of a product, or is itself a product involving significant risks, covered by the Union harmonisation legislation listed in Annex II;

Amendment 1423
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş, Moritz Körner, Ondřej Kovařík, Jan-Christoph Oetjen
Article 6 - paragraph 1 - point a
(a) the AI system is intended to be used as a main safety component of a product, or is itself a product, covered by the Union harmonisation legislation listed in Annex II;

Amendment 1424
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 6 - paragraph 1 - point a a (new)
(a a) its uses are undetermined or indeterminate;

Amendment 1425
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 6 - paragraph 1 - point a b (new)
(a b) in the course of the self-assessment pursuant to Article 6 a of this Regulation, the AI system or its operation is found to result in a high risk to the rights and freedoms of natural persons; or

Amendment 1426
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 6 - paragraph 1 - point a c (new)
(a c) it is listed in Annex III.

Amendment 1427
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 6 - paragraph 1 - point b
deleted

Amendment 1428
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 6 - paragraph 1 - point b
deleted

Amendment 1429
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 6 - paragraph 1 - point b
(b) the product whose main safety component is the AI system, or the AI system itself as a product, is required to undergo a third-party conformity assessment in order to ensure compliance with essential safety requirements with a view to the placing on the market or putting into service of that product pursuant to the Union harmonisation legislation listed in Annex II.

Amendment 1430
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 6 - paragraph 1 - point b
(b) the product whose safety component as meant under (a) is the AI system, or the AI system itself as a product, is required to undergo a third-party conformity assessment with a view to the placing on the market or putting into service or use of that product pursuant to the Union harmonisation legislation listed in Annex II.

Amendment 1431
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 6 - paragraph 1 - point b
(b) the product whose safety component is the AI system, or the AI system itself as a product, is required to undergo a third-party conformity assessment related to safety with a view to the placing on the market or putting into service of that product pursuant to the Union harmonisation legislation listed in Annex II.

Amendment 1432
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 6 - paragraph 1 - point b a (new)
(b a) the AI system is used by a public authority.

Amendment 1433
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 6 - paragraph 2
deleted

Amendment 1434
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 6 - paragraph 2
2. In addition to the high-risk AI systems referred to in paragraph 1, AI systems identified as posing a risk to fundamental human rights as defined in the EU Charter of Fundamental Rights, in relation to a specific intended use shall also be considered high-risk. Such risk is to be determined by completion of a Human Rights Impact Assessment by the user of the AI in relation to the specific use intended for the AI system, with records of such assessment retained for regulatory inspection.', "The provider shall apply a precautionary principle and, in case of uncertainty over the AI system's classification, shall consider the AI system high-risk.

Amendment 1435
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 6 - paragraph 2
2. In addition to the high-risk AI systems referred to in paragraph 1, AI systems referred to in Annex III shall also be considered high-risk, with the exception of those AI systems that are not safety components of a product and that fulfil both of the following conditions:', '(a) they are not developed with and do not use biometric data, biometrics-based data, or personal data as inputs;', '(b) they are not intended to influence decisions of natural persons or to make decisions or to assist in the making of decisions affecting natural persons.

Amendment 1436
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 6 - paragraph 2
2. In addition to the high-risk AI systems referred to in paragraph 1, each AI system with an intended purpose - as specified in its instruction to use in accordance with Art 3(12) and Art 13(2) - that means that it will be deployed in a way that falls under one of the critical use cases referred to in Annex III shall also be considered high-risk if that AI system will make a final decision that puts significantly at risk the health, safety or fundamental rights of natural persons.

Amendment 1437
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Samira Rafaela,
Article 6 - paragraph 2
2. In addition to the high-risk AI systems referred to in paragraph 1, AI systems shall also be considered high-risk in the meaning of this regulation, if they will be deployed in a critical area referred to in Annex III and an individual assessment of the specific application carried out in accordance with Art. 6a showed that a significant harm is likely to arise.

Amendment 1438
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Article 6 - paragraph 2
2. In addition to the high-risk AI systems referred to in paragraph 1, AI systems referred to in Annex III shall also be considered high-risk if they pose a risk of harm to the health and safety or a risk of adverse impact on fundamental rights.

Amendment 1439
EPP - Group of the European Peoples Party (Christian Democrats)
Geoffroy Didier
Article 6 - paragraph 2
2. In addition to the high-risk AI systems referred to in paragraph 1, AI systems referred to in Annex III shall also be considered high-risk, if they pose a risk of harm to either physical health and safety or fundamental human rights, or both.

Amendment 1440
EPP - Group of the European Peoples Party (Christian Democrats)
Nathalie Colin-Oesterlé
Article 6 - paragraph 2
2. In addition to the high-risk AI systems referred to in paragraph 1, AI systems referred to in Annex III shall also be considered high-risk if they pose a threat to the health, safety or fundamental rights of persons.

Amendment 1441
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Vincenzo Sofo, Adam Bielan
Article 6 - paragraph 2
2. In addition to the high-risk AI systems referred to in paragraph 1, AI systems referred to in Annex III shall also be considered high-risk, if they pose a risk of harm to either physical health and safety or human rights, or both.

Amendment 1442
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Article 6 - paragraph 2
2. In addition to the high-risk AI systems referred to in paragraph 1, AI systems referred to in Annex III shall also be considered high-risk when no internal risk-mitigation mechanisms embedded in the AI system apply.

Amendment 1443
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Article 6 - paragraph 2
2. In addition to the high-risk AI systems referred to in paragraph 1 and in accordance with Article 6- paragraph -1a, AI systems referred to in Annex III shall also be considered high-risk.

Amendment 1444
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 6 - paragraph 2 a (new)
2 a. The classification as high-risk as a consequence of Article 6(1) and 6(2) shall be disregarded for AI systems whose intended purpose demonstrates that the generated output is a recommendation requiring a human intervention to convert this recommendation into a decision and for AI systems which do not lead to autonomous decisions or actions of the overall system.

Amendment 1445
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 6 - paragraph 2 a (new)
2 a. The assessment by the provider of whether an AI system puts at risk the health, safety or fundamental rights of natural persons shall also take into account the factors enumerated in Article 7(2).

Amendment 1446
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 6 - paragraph 2 a (new)
2 a. The assessment referred to in paragraph 2 shall be conducted by the Commission annually and under the consultation conditions laid down in this regulation, notably in Article 73;

Amendment 1447
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 6 - paragraph 2 a (new)
2 a. An artificial intelligence system with indeterminate uses shall also be considered high risk if so identified per Article 9, paragraph 2, point (a).

Amendment 1448
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 6 - paragraph 2 a (new)
2 a. In addition to the high-risk AI systems referred to in paragraph 1, AI systems referred to in Annex III shall also be considered high-risk.

Amendment 1449
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 6 - paragraph 2 b (new)
2 b. Where the Commission finds in the course of the assessment pursuant to paragraphs 1 and 2 that an AI system or an area of AI systems must be considered "high risk" or can not or no longer be considered “high risk”, including due to improvements in technology or to social or legal safeguards put in place, it is empowered to adopt delegated acts in accordance with Article 73 to update the list in Annex III by adding or removing AI systems and areas of AI systems.

Amendment 1450
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 6 - paragraph 2 b (new)
2 b. In addition to the high-risk AI systems referred to in paragraphs 1, AI systems that have over 20 million EU citizens across the EU or 50% of any given Member States’ population as active monthly users, or whose users have cumulatively over 20 million customers or beneficiaries in the EU affected by it shall be considered high-risk, unless these are placed onto the market.

Amendment 1451
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 6 - paragraph 2 b (new)
2 b. When assessing an AI system for the purposes of paragraph 1 of Article 6, a safety component shall be assessed against the essential health and safety requirements of the relevant EU harmonisation legislation listed in Annex II.

Amendment 1452
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 6 - paragraph 2 b (new)
2 b. In addition to the high-risk AI systems referred to in paragraph 1 and paragraph 2, AI systems that create foreseeable high-risks when combined shall also be considered high-risk.

Amendment 1453
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 6 - paragraph 2 c (new)
2 c. In addition to the high-risk AI systems referred to in paragraph 1, AI systems affecting employees in the employment relationship or in matters of training or further education shall be considered high risk.

Amendment 1454
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 6 - paragraph 2 d (new)
2 d. In addition to the high-risk AI systems referred to in paragraph 1, AI systems likely to interact with children shall be considered high-risk.

Amendment 1455
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 6 - paragraph 2 e (new)
2 e. In addition to the high-risk AI systems referred to in paragraph 1, an artificial intelligence system with indeterminate uses shall also be considered high risk.

Amendment 1456
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Catharina
Article 6 a (new)
Article 6 a', 'Risk assessment', '1. In order to determine the level of risk of AI systems, the provider of an AI system with an intended purpose in the areas referred to in Annex III has to conduct a risk assessment.', '2.The risk assessment has to contain the following elements:', 'a) name all possible harms to life, health and safety or fundamental rights of potentially impacted persons or entities or society at large;', 'b) asses the likelihood and severity these harms might materialise;', 'c) name the potential benefits of such system for the potentially impacted persons and society at large;', 'd) name possible and taken measures to address, prevent, minimise or mitigate the identified harms with a high probability to materialise;', 'e) asses the possibilities to reverse these negative outcome;', 'f) the extent to which decision-making of the system is autonomous and outside of human influence.', '3. If the risk assessment showed a significant harm is likely to materialise the provider has to comply with Chapter 2 in a way that is appropriate and proportionate to the identified risks.

Amendment 1457
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 6 a (new)
Article 6 a', 'Preliminary self-assessment', '1. Before the conformity assessment procedure foreseen in Articles 43 for high-risk AI systems and 51a for other than high-risk AI system, the provider of the AI system shall carry out a preliminary self-assessment to determine whether:', '(a) the intended purpose, potential use, or reasonably foreseeable misuse of the AI system constitute a prohibited practice pursuant to Article 5; or', '(b) the AI system is classified as ‘high-risk’ pursuant to Article 6.', '2. The provider of the AI system shall keep a detailed record, including all relevant documentation, of that self-assessment at the disposal of the national competent authorities during the lifespan of the AI system concerned.', '3. Where the preliminary self-assessment indicates non-compliance of the AI system with this Regulation, in particular due to it falling within the scope of Article 5, the provider shall, without delay, take measures to ensure compliance of the concerned AI system with this Regulation, or immediately desist from placing it on the market.

Amendment 1458
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 6 a (new)
Article 6 a', 'Risk assessment', 'The European Artificial Intelligence Board shall develop guidance for the risk assessment.

Amendment 1459
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 7
deleted

Amendment 1460
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 7 - paragraph 1 - introductory part
deleted

Amendment 1461
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 7 - paragraph 1 - introductory part
1. The Commission is empowered to adopt delegated acts in accordance with Article 73 to update the list in Annex III by adding high-risk AI systems where the following condition is fulfilled: the AI systems pose a risk of harm to health and safety, or a risk of adverse impact on fundamental rights, that is, in respect of its severity or probability of occurrence, equivalent to or greater than the risk of harm or of adverse impact associated with the high-risk AI systems already referred to in Annex III. Where an AI system is not intended to be used in any of the areas listed in points 1 to 8 of Annex III, the Commission is empowered to update the list of areas in Annex III by including new areas or extending the scope of existing areas.

Amendment 1462
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 7 - paragraph 1 - introductory part
1. The Commission is empowered to adopt delegated acts in accordance with Article 73 to update Annex III, including by adding new areas of high-risk AI systems, where a type of AI system poses a risk of harm to the health and safety, a risk of adverse impact on fundamental rights, on climate change mitigation and adaptation, the environment, or a risk of contravention of the Union values enshrined in Article 2 TEU, and that risk is, in respect of its severity and probability of occurrence, equivalent to or greater than the risk of harm or of adverse impact posed by the high-risk AI systems in use in the areas listed in Annex III.

Amendment 1463
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 7 - paragraph 1 - introductory part
1. The Commission is empowered to adopt delegated acts in accordance with Article 73 to update or amend the list in Annex III by adding areas of high-risk AI systems where the AI systems pose a risk of harm to the health and safety, or a risk of adverse impact on fundamental rights, a risk of breach of the Union values enshrined in Article 2 TEU or a risk of adverse impact on the society and the environment.

Amendment 1464
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 7 - paragraph 1 - introductory part
1. The Commission is empowered to adopt delegated acts in accordance with Article 73 to update the list in Annex III by adding high-risk AI systems where both of the following conditions are fulfilled and areas of high-risk systems that pose a risk of harm to health and safety, or a risk of adverse impact on fundamental rights, environment, society, rule of law or democracy, a risk of economic harm or to consumer protection that is, in respect of its severity or probability of occurrence;

Amendment 1465
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul Garraud
Article 7 - paragraph 1 - introductory part
1. The Commission is empowered to adopt delegated acts in accordance with Article 73 to update the list set out in Annex III by adding fields of high-risk AI systems where they present a risk of harm to health and safety or a risk of a negative impact on fundamental rights which, taking into account its severity and likelihood of occurrence, is equivalent to or higher than the risk of harm or negative impact of high-risk AI systems already listed in Annex III.

Amendment 1466
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 7 - paragraph 1 - introductory part
1. The Commission is empowered to adopt delegated acts in accordance with Article 73, after an adequate and transparent consultation process involving the relevant stakeholders, to update the list in Annex III by withdrawing areas from that list or by adding critical areas. For additions both of the following conditions need to be fulfilled:

Amendment 1467
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 7 - paragraph 1 - introductory part
1. The Commission is empowered to adopt delegated acts in accordance with Article 73, after ensuring adequate consultation with relevant stakeholders, to update the list in Annex III by adding high-risk AI systems where both of the following conditions are fulfilled:

Amendment 1468
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Article 7 - paragraph 1 - introductory part
1. The Commission is empowered to adopt delegated acts in accordance with Article 73 to update the list in Annex III by adding new area headings and high-risk AI systems where both of the following conditions are fulfilled:

Amendment 1469
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 7 - paragraph 1 - introductory part
1. The Commission is empowered to adopt delegated acts in accordance with Article 73 to update the list in Annex III by adding high-risk AI systems.

Amendment 1470
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 7 - paragraph 1 - introductory part
1. The Commission is empowered to adopt delegated acts in accordance with Article 73 to update the list in Annex III by adding high-risk AI systems where either of the following conditions is fulfilled:

Amendment 1471
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 7 - paragraph 1 - point a
deleted

Amendment 1472
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 7 - paragraph 1 - point a
deleted

Amendment 1473
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 7 - paragraph 1 - point a
deleted

Amendment 1474
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 7 - paragraph 1 - point a
deleted

Amendment 1475
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 7 - paragraph 1 - point a
deleted

Amendment 1476
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Article 7 - paragraph 1 - point a
(a) the AI systems are intended to be used in any of the areas listed in points 1 to 8 of Annex III or in the newly identified area headings;

Amendment 1477
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 7 - paragraph 1 - point b
deleted

Amendment 1478
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 7 - paragraph 1 - point b
deleted

Amendment 1479
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 7 - paragraph 1 - point b
deleted

Amendment 1480
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 7 - paragraph 1 - point b
deleted

Amendment 1481
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 7 - paragraph 1 - point b
deleted

Amendment 1482
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 7 - paragraph 1 - point b
(b) the AI systems pose a risk of economic harm, negative societal impacts or harm to the environment, health and safety, or a risk of adverse impact on fundamental rights, democracy and the rule of law, that is, in respect of its severity and probability of occurrence, equivalent to or greater than the risk of harm or of adverse impact posed by the high-risk AI systems already referred to in Annex III.

Amendment 1483
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Patryk Jaki, Vincenzo Sofo, Adam Bielan
Article 7 - paragraph 1 - point b
(b) the AI systems pose a risk of harm to the health, natural environment and safety, or a risk of adverse impact on fundamental rights, that is, in respect of its severity and probability of occurrence, equivalent to or greater than the risk of harm or of adverse impact posed by the high-risk AI systems already referred to in Annex III.

Amendment 1484
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 7 - paragraph 1 - point b
(b) the AI systems pose a serious risk of harm to the health and safety, or a serious risk of adverse impact on fundamental rights, that is, in respect of its severity and probability of occurrence, equivalent to or greater than the risk of harm or of adverse impact.

Amendment 1485
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 7 - paragraph 1 - point b a (new)
(b a) the AI systems pose a risk of harm to occupational health and safety, including psychosocial risks.

Amendment 1486
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 7 - paragraph 2
deleted

Amendment 1487
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 7 - paragraph 2 - introductory part
2. When assessing an AI system for the purposes of paragraph 1, the Commission shall take into account the following criteria:

Amendment 1488
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 7 - paragraph 2 - introductory part
2. When assessing for the purposes of paragraph 1, the Commission shall take into account the following criteria:

Amendment 1489
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 7 - paragraph 2 - introductory part
2. When assessing for the purposes of paragraph 1 the Commission shall take into account the following non-cumulative criteria:

Amendment 1490
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 7 - paragraph 2 - introductory part
2. When assessing for the purposes of paragraph 1 whether an AI system poses a risk of harm to the health and safety or a risk of adverse impact on fundamental rights or on the environment, democracy and rule of law that is equivalent to or greater than the risk of harm posed by the high-risk AI systems already referred to in Annex III, the Commission shall consult social partners and civil society and take into account, including but not limited to, the following non-cumulative criteria:

Amendment 1491
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 7 - paragraph 2 - introductory part
2. When assessing for the purposes of paragraph 1 whether an AI system poses a risk of harm to the health and safety or a risk of adverse impact on fundamental rights that is equivalent to or greater than the risk of harm posed by the high-risk AI systems already referred to in Annex III, the Commission shall take into account, including but not limited to, the following criteria:

Amendment 1492
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Patryk Jaki, Vincenzo Sofo, Adam Bielan
Article 7 - paragraph 2 - introductory part
2. When assessing for the purposes of paragraph 1 whether an AI system poses a risk of harm to the health, natural environment and safety or a risk of adverse impact on fundamental rights that is equivalent to or greater than the risk of harm posed by the high-risk AI systems already referred to in Annex III, the Commission shall take into account the following criteria:

Amendment 1493
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Article 7 - paragraph 2 - point a
(a) a description of the AI system, including the intended purpose, the concrete use and context, complexity and autonomy of the AI system, the potential persons impacted, the extent to which the AI system has been used or is likely to be used, the extent to which any outcomes produced are subject to human review or intervention;

Amendment 1494
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 7 - paragraph 2 - point a
(a) the intended purpose of the AI system, or the reasonably foreseeable consequences of its use;

Amendment 1495
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 7 - paragraph 2 - point a
(a) the intended purpose of the AI system, potential use, or reasonably foreseeable misuse;

Amendment 1496
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 7 - paragraph 2 - point a
(a) the intended purpose or the reasonably foreseeable use of the AI system;

Amendment 1497
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 7 - paragraph 2 - point a a (new)
(a a) the general capabilities and functionalities of the AI system independent of its intended purpose;

Amendment 1498
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Article 7 - paragraph 2 - point b
(b) an assessment of the potential benefits provided by the use of the AI system, as well as reticence risk and/or opportunity costs of not using the AI for individuals, groups of individuals, or society at large. This includes weighing the benefits of deploying the AI system against keeping the status quo;

Amendment 1499
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 7 - paragraph 2 - point b
(b) the extent to which an AI system has been used or is likely to be used, including its reasonably foreseeable misuse;

Amendment 1500
ECR - European Conservatives and Reformists Group
Vincenzo Sofo, Kosma Złotowski
Article 7 - paragraph 2 - point b
(b) the extent to which an AI system has been used or is likely to be used and misused;

Amendment 1501
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 7 - paragraph 2 - point b a (new)
(b a) the extent to which the AI system acts with a certain level of autonomy;

Amendment 1502
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 7 - paragraph 2 - point b a (new)
(b a) the type and nature of the data processed and used by the AI system;

Amendment 1503
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 7 - paragraph 2 - point b a (new)
(b a) the extent to which the AI system acts autonomously;

Amendment 1504
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 7 - paragraph 2 - point b b (new)
(b b) the extent to which the AI system respects the principles of Article 4a;

Amendment 1505
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Article 7 - paragraph 2 - point c
(c) an assessment of the probability of worst-case scenario, likelihood and severity of harm, to the health and safety or fundamental rights of potentially impacted persons and its irreversibility, including:', '(i) the extent to which the AI system has already been evaluated and proven to have caused material harm as demonstrated by studies or reports published by the national competent authorities;', '(ii) the extent to which potentially impacted persons are dependent on the outcome produced from the AI system, in particular because of practical or legal reasons it is not reasonably possible to opt-out from that outcome;', '(iii) the extent to which the outcome produced by the AI system is easily reversible;', '(iv) the extent to which potentially impacted persons are in a vulnerable position in relation to the user of the AI system, in particular due to an imbalance of power, knowledge, economic or social circumstances, or age.

Amendment 1506
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 7 - paragraph 2 - point c
(c) the extent to which the use of an AI system has already caused harm to natural persons, has breached the Union values enshrined in Article 2 TEU, has caused harm to the health and safety or has had an adverse impact on the fundamental rights, on the environment or the society or has given rise to significant concerns in relation to the materialisation of such harm or adverse impact, as demonstrated by reports or documented allegations submitted to the national supervisory authority, to the national competent authorities, to the Commission, to the Board, to the EDPS or to the European Union Agency for Fundamental Rights (FRA);

Amendment 1507
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 7 - paragraph 2 - point c
(c) the extent to which the use of an AI system has already caused harm to natural persons, has contravened the Union values enshrined in Article 2 TEU, has caused harm to the health and safety or has had an adverse impact on the fundamental rights, on the environment or society, or has given rise to significant concerns in relation to the materialisation of such harm or adverse impact, as demonstrated by reports or documented allegations submitted to national competent authorities, to the Commission, to the Board, to the EDPS or to the European Union Agency for Fundamental Rights (FRA);

Amendment 1508
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 7 - paragraph 2 - point c
(c) the extent to which the use of an AI system has already caused harm to the health and safety or adversely impacted fundamental rights, environment, society, rule of law or democracy, consumer protection or caused economic harm or has given rise to reasonable concerns in relation to the likelihood of such harm or adverse impact;

Amendment 1509
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Patryk Jaki, Vincenzo Sofo, Adam Bielan
Article 7 - paragraph 2 - point c
(c) the extent to which the use of an AI system has already caused harm to the health, natural environment and safety or adverse impact on the fundamental rights or has given rise to significant concerns in relation to the materialisation of such harm or adverse impact, as demonstrated by reports or documented allegations submitted to national competent authorities;

Amendment 1510
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 7 - paragraph 2 - point c
(c) the extent to which the use of an AI system has already caused harm to the health and safety or adverse impact on the fundamental rights, democracy, rule of law and the environment has given rise to significant concerns in relation to the materialisation of such harm or adverse impact, as demonstrated by available reports or documented allegations;

Amendment 1511
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 7 - paragraph 2 - point d
(c a) the AI systems pose a risk of harm to occupational health and safety, including psychosocial risks and mental health;

Amendment 1512
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Article 7 - paragraph 2 - point d
(d) measures taken to address or mitigate the identified risks, including to the extent existing Union legislation provides for:', '(i) effective measures of redress in relation to the risks posed by an AI system, with the exclusion of claims for damages;', '(ii) effective measures to prevent or substantially minimise those risks.

Amendment 1513
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 7 - paragraph 2 - point d
(d) the potential extent of such harm or such adverse impact, in particular in terms of its intensity and its ability to affect a plurality of persons or on the environment or to affect a particular group of persons disproportionately;

Amendment 1514
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 7 - paragraph 2 - point d
(d) the potential extent of such harm or such adverse impact;

Amendment 1515
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Article 7 - paragraph 2 - point e
deleted

Amendment 1516
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 7 - paragraph 2 - point e
(e) the extent to which potentially harmed or adversely impacted persons are dependent on the outcome produced with an AI system with a distinction to be made between an AI system used in an advisory capacity or one used directly to make a decision, in particular because for practical or legal reasons it is not reasonably possible to opt-out from that outcome;

Amendment 1517
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 7 - paragraph 2 - point e
(e) the extent to which potentially harmed or adversely impacted persons are dependent on the outcome produced by a process involving an AI system, in particular because for practical or legal reasons it is not reasonably possible to opt-out of that outcome;

Amendment 1518
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 7 - paragraph 2 - point e
(e) the extent to which potentially harmed or adversely impacted persons are dependent on the outcome produced involving an AI system, in particular because for practical or legal reasons it is not reasonably possible to opt-out from that outcome;

Amendment 1519
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 7 - paragraph 2 - point e
(e) the extent to which potentially harmed or adversely impacted persons are dependent on the outcome produced with an AI system, in particular because for practical or legal reasons it is not reasonably possible to opt-out from that outcome;

Amendment 1520
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 7 - paragraph 2 - point e a (new)
(e a) the potential misuse and malicious use of the AI system and of the technology underpinning it;

Amendment 1521
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 7 - paragraph 2 - point e a (new)
(e a) the potential misuse and malicious use of the AI system and of the technology underpinning it;

Amendment 1522
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Article 7 - paragraph 2 - point f
deleted

Amendment 1523
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 7 - paragraph 2 - point f
(f) the extent to which there is an imblanace of power, or the potentially harmed or adversely impacted persons are in a vulnerable position in relation to the user of an AI system, in particular due to status, authority, knowledge, economic or social circumstances, or age;

Amendment 1524
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Article 7 - paragraph 2 - point g
deleted

Amendment 1525
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 7 - paragraph 2 - point g
(g) the extent to which the outcome produced with an AI system is easily reversible, whereby outcomes having an impact on the fundamental rights of persons, the environment or the society, the health or safety of persons, or on the Union values enshrined in Article 2 TEU, shall not be considered as easily reversible;

Amendment 1526
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 7 - paragraph 2 - point g
(g) the extent to which the outcome produced with an AI system is easily reversible, whereby outcomes having an impact on the health or safety of persons, the fundamental rights of persons, the environment or society, or on the Union values enshrined in Article 2 TEU shall not be considered as easily reversible;

Amendment 1527
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 7 - paragraph 2 - point g
(g) the extent to which the outcome produced involving an AI system is easily reversible and can effectively be appealed by AI subjects. Outcomes having an impact on the fundamental rights or health or safety of persons shall not be considered as easily reversible;

Amendment 1528
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 7 - paragraph 2 - point g
(g) the extent to which the outcome produced with an AI system is not easily reversible, whereby outcomes having an impact on the health or safety of persons or on their fundamental rights shall not be considered as easily reversible;

Amendment 1529
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 7 - paragraph 2 - point g
(g) the extent to which the outcome produced with an AI system is not easily reversible or remedied, whereby outcomes having an impact on the health or safety of persons shall not be considered as easily reversible;

Amendment 1530
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 7 - paragraph 2 - point g a (new)
(g a) the extent of the availability and use of demonstrated technical solutions and mechanisms for the control, reliability and corrigibility of the AI system;

Amendment 1531
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 7 - paragraph 2 - point g a (new)
(g a) magnitude and likelihood of benefit of the deployment of the AI system for individuals, groups, or society at large;

Amendment 1532
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 7 - paragraph 2 - point g b (new)
(g b) the extent of human oversight and the possibility for a human to intercede in order to override a decision or recommendations that may lead to potential harm;

Amendment 1533
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 7 - paragraph 2 - point g c (new)
(g c) the magnitude and likelihood of benefit of the deployment of the AI system for industry, individuals, or society at large;

Amendment 1534
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 7 - paragraph 2 - point g d (new)
(g d) the reticence risk and/or opportunity costs of not using the AI system for industry, individuals, or society at large;

Amendment 1535
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 7 - paragraph 2 - point g e (new)
(g e) the amount and nature of data processed;

Amendment 1536
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 7 - paragraph 2 - point g f (new)
(g f) the benefits provided by the use of the AI system, including making products safer;

Amendment 1537
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Article 7 - paragraph 2 - point h
deleted

Amendment 1538
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 7 - paragraph 2 - point h - introductory part
(h) the extent to which existing Union legislation, in particular the GDPR, provides for:

Amendment 1539
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Article 7 - paragraph 2 - point h - introductory part
(h) the extent to which existing Union legislation, in particular GDPR, provides for:

Amendment 1540
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 7 - paragraph 2 - point h - introductory part
(h) the extent to which existing Union legislation lacks:

Amendment 1541
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 7 - paragraph 2 - point h - point i
(i) effective measures of redress, the availability of redress-by-design mechanisms and procedures in relation to the risks posed by an AI system, including claims for material and non-material damages;

Amendment 1542
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Article 7 - paragraph 2 - point h a (new)
(i) effective measures of redress in relation to the damage caused by an AI system, with the exclusion of claims for direct or indirect damages;

Amendment 1543
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 7 - paragraph 2 - point h a (new)
(h a) The general capabilities and functionalities of the AI system independent of its foreseeable use;

Amendment 1544
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 7 - paragraph 2 - point h b (new)
(h b) The extent of the availability and use of demonstrated technical solutions and mechanisms for the control, reliability and corrigibility of the AI system;

Amendment 1545
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 7 - paragraph 2 a (new)
(h c) The potential misuse and malicious use of the AI system and of the technology underpinning it.

Amendment 1546
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 7 - paragraph 2 a (new)
2a. When assessing an AI system for the purposes of paragraph 1, the Commission shall consult, where appropriate, national and European authorities and bodies, representatives of the groups concerned by that system, industry professionals, independent experts and civil society organisations. The Commission shall organise public consultations in this regard.

Amendment 1547
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 7 - paragraph 2 a (new)
2 a. When carrying out the assessment referred to in paragraph 1 the Commission shall consult, where relevant, representatives of groups on which an AI system has an impact, stakeholders, independent experts and civil society organisations. The Commission shall organise public consultations in this regard.

Amendment 1548
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 7 - paragraph 2 a (new)
2 a. The Commission may remove AI systems from the list in Annex III if the conditions referred to in paragraph 1 are no longer met.

Amendment 1549
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş,
Article 7 - paragraph 2 a (new)
2 a. The Commission shall provide a transitional period of at least 24 months following each update of Annex III.

Amendment 1550
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 7 - paragraph 2 b (new)
2 b. The Board, notified bodies and other actors may request the Commission to reassess an AI system. The AI system shall then be reviewed for reassessment and may be re-categorized. The Commission shall give reasons for its decision and publish the reasons. The details of the application procedure shall be laid down by the Commission by means of delegated acts in accordance with Article 73.

Amendment 1551
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 7 - paragraph 2 b (new)
2b. The Commission shall publish a detailed report on the assessment referred to in paragraph 2.

Amendment 1552
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 7 - paragraph 2 c (new)
2c. The Commission shall consult the Board before adopting delegated acts pursuant to paragraph 1.

Amendment 1553
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 8 - paragraph 1
1. High-risk AI systems shall comply with the requirements established in this Chapter throughout the entire lifecycle of the AI system. This includes their placing on the market as well as their deployment and use. Providers and deployers of AI systems shall ensure compliance by establishing technical and operational measures in line with this Chapter.

Amendment 1554
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Article 8 - paragraph 1
1. High-risk AI systems shall comply with the requirements established in this Chapter, taking into account the generally acknowledged state of the art and industry standards, including as reflected in relevant harmonised standards or common specifications.

Amendment 1555
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 8 - paragraph 1
1. High-risk AI systems shall comply with the requirements established in this Chapter, taking into account the generally acknowledged state of the art, including as reflected in relevant harmonised standards or common specifications.

Amendment 1556
EPP - Group of the European Peoples Party (Christian Democrats)
Geoffroy Didier
Article 8 - paragraph 1
1. High-risk AI systems shall comply with the requirements established in this Chapter, taking into account the generally acknowledged state of the art and industry standards, including as reflected in relevant harmonised standards or common specifications.

Amendment 1557
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 8 - paragraph 1
1. High-risk AI systems shall comply with the essential requirements established in this Chapter, taking into account the generally acknowledged state of the art, including as reflected in relevant industry and harmonised standards.

Amendment 1558
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 8 - paragraph 1
1. 1. Operators of high-risk AI systems shall comply with the requirements established in this Chapter.

Amendment 1559
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 8 - paragraph 1 a (new)
1 a. In complying with the requirements established in this Chapter, operators of high-risk AI systems shall take into account the generally-acknowledged state of the art, including as reflected in the relevant harmonised standards and common specifications referenced in Articles 40 and 41.

Amendment 1560
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 8 - paragraph 1 a (new)
1 a. Where a deployer discovers non-compliance of a high-risk AI system with this regulation during reasonably foreseeable use, the deployer shall have the right to obtain the necessary modifications from the provider to the high-risk AI system.

Amendment 1561
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 8 - paragraph 1 b (new)
1 b. Prospective deployers of high-risk AI systems shall have certified third parties assess and confirm the conformity of the AI system and its use with this Regulation and relevant applicable Union legislation before putting it into use. The conformity certificate shall be uploaded to the database pursuant to Article 60.

Amendment 1562
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 8 - paragraph 1 c (new)
1 c. Where personal data is processed or is expected to be processed in the use of a high-risk AI system, this shall be understood as constituting a high risk in the meaning of Article 35 of Regulation (EU) 2016/679.

Amendment 1563
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 8 - paragraph 2
2. The intended purpose of the high-risk AI system, the foreseeable uses and foreseeable misuses of AI systems with indeterminate uses and the risk management system referred to in Article 9 shall be taken into account when ensuring compliance with those requirements.

Amendment 1564
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 8 - paragraph 2
2. The foreseeable uses and foreseeable misuses of AI systems with indeterminate uses of the high-risk AI system and the risk management system referred to in Article 9 shall be taken into account when ensuring compliance with those requirements.

Amendment 1565
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 8 - paragraph 2
2. The intended purpose, the potential or reasonably foreseeable use or misuse of the high-risk AI system and the risk management system referred to in Article 9 shall be taken into account when ensuring compliance with those requirements.

Amendment 1566
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 8 - paragraph 2
2. The intended purpose, reasonably foreseeable uses and foreseeable misuses of the high-risk AI system and the risk management system referred to in Article 9 shall be taken into account when ensuring compliance with those requirements.

Amendment 1567
EPP - Group of the European Peoples Party (Christian Democrats)
Geoffroy Didier
Article 8 - paragraph 2
2. The intended purpose of the high-risk AI system and the risk management system referred to in Article 9 shall be taken into account when ensuring compliance with the relevant requirements depending on the type of risks posed.

Amendment 1568
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 8 - paragraph 2
2. The intended purpose or reasonably foreseeable use of the high-risk AI system and the risk management system referred to in Article 9 shall be taken into account when ensuring compliance with those requirements.

Amendment 1569
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 8 - paragraph 2 a (new)
2 a. AI systems referred to in Article 6 may be wholly or partially exempted from fulfilling the requirements referred to in Articles 8-15 if risks posed by the AI systems are sufficiently eliminated or mitigated through appropriate operational countermeasures or built-in fail-safe systems.

Amendment 1570
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Article 8 - paragraph 2 a (new)
2 a. This article shall not apply where the content forms part of an evidently artistic, creative, satirical, fictional or analogous work or programme.

Amendment 1571
Renew - Renew Europe Group
Morten Løkkegaard
Article 8 - paragraph 2 a (new)
2 a. This article shall not apply where the content forms part of an evidently artistic, creative, satirical, fictional and analogous work or programme.

Amendment 1572
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 9 - paragraph 1
1. A risk management system shall be established, implemented, documented and maintained in relation to high-risk AI systems. The risk management system can be integrated into, or a part of, already existing risk management procedures insofar as it fulfils the requirements of this article.

Amendment 1573
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 9 - paragraph 1
1. A risk management system shall be established, implemented, documented and maintained in relation to high-risk AI systems, unless the AI system is covered by New Legislative Framework (NLF) legislation.

Amendment 1574
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 9 - paragraph 1
1. A risk management system shall be established, implemented, documented and maintained in relation to high-risk AI systems if this system poses a risk of harm to health and safety or a risk of adverse impacts on fundamental rights.

Amendment 1575
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Article 9 - paragraph 1
1. A risk management system shall be established, implemented, documented and maintained in appropriate relation to high-risk AI systems and its risks identified in the risk assessment referred to in Art. 6a.

Amendment 1576
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Article 9 - paragraph 1
1. A risk management system shall be established, implemented, documented and maintained in relation to high-risk AI systems or be included in existing risk management procedures.

Amendment 1577
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 9 - paragraph 1
1. A risk management system shall be established, implemented, documented and maintained in relation to high-risk AI systems, throughout the entire lifecycle of the AI system.

Amendment 1578
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 9 - paragraph 1
1. A risk management system shall be established, implemented, documented and maintained in relation to high-risk AI systems throughout the entire lifecycle of the AI system.

Amendment 1579
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 9 - paragraph 2 - introductory part
2. The risk management system shall consist of a continuous iterative process run throughout the entire lifetime of a high-risk AI system, requiring regular review of the suitability of the risk management process to ensure its continuing effectiveness, and documentation of any decisions and actions taken. It shall comprise the following steps and all of these steps shall be integrated into already existing risk management procedures relating to the relevant Union sectoral legislation to avoid unnecessary bureaucracy:

Amendment 1580
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 9 - paragraph 2 - introductory part
2. The risk management system shall consist of a continuous iterative process run throughout the entire lifecycle of a high-risk AI system, requiring regular systematic review and updating, including when the high-risk AI system is subject to significant changes in its design or purpose. It shall comprise the following steps:

Amendment 1581
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 9 - paragraph 2 - introductory part
2. The risk management system shall consist of a continuous iterative process run throughout the entire lifecycle of a high-risk AI system, requiring regular systematic review and updating. It shall comprise the following steps:

Amendment 1582
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 9 - paragraph 2 - point a
(a) identification and analysis of the known and the reasonably foreseeable risks that the high-risk AI system, and AI systems with indeterminate uses can pose to:', '(i) the health or safety of natural persons;', '(ii) the legal rights or legal status of natural persons;', '(iii) the fundamental rights of natural persons;', '(iv) the equal access to services and opportunities of natural persons;', '(v) the Union values enshrined in Article 2 TEU;', '(vi) society at large and the environment.

Amendment 1583
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 9 - paragraph 2 - point a
(a) identification and analysis of the known and the reasonably foreseeable risks that the high-risk AI system, and AI systems with indeterminate uses, can pose to:', '(i) the health or safety of natural persons;', '(ii) the legal rights or legal status of natural persons;', '(iii) the fundamental rights;', '(iv) the equal access to services and opportunities of natural persons;', '(v) the Union values enshrined in Article 2 TEU.

Amendment 1584
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 9 - paragraph 2 - point a
(a) identification and analysis of the known and reasonably foreseeable risks associated with each high-risk AI system with respect to health, safety, fundamental rights, and the values of the Union as enshrined in Article 2 TEU;

Amendment 1585
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 9 - paragraph 2 - point a
(a) identification and analysis of the known and reasonable foreseeable risks of harms most likely to occur to the health, safety or fundamental rights in view of the intended purpose of the high-risk AI system;

Amendment 1586
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 9 - paragraph 2 - point a
(a) identification and analysis of the known and foreseeable risks associated with each high-risk AI system, including by means of a fundamental rights impact assessment as provided for in Article 9a;

Amendment 1587
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 9 - paragraph 2 - point a
(a) identification and analysis of the known and foreseeable risks most likely to occur to health, safety and fundamental rights in view of the intended purpose of the high-risk AI system;

Amendment 1588
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Article 9 - paragraph 2 - point a
(a) identification and analysis of the known and foreseeable risks to the health and safety or fundamental rights of a person associated with each high-risk AI system;

Amendment 1589
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 9 - paragraph 2 - point a a (new)
(aa) identification of the risks, damage and harm actually caused by the high-risk AI system in the past, whether these are the result of use of the high-risk AI system for its intended purpose or of another use;

Amendment 1590
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 9 - paragraph 2 - point a a (new)
(a a) evaluation of how the principles of Article 4a are adhered to;

Amendment 1591
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Article 9 - paragraph 2 - point b
deleted

Amendment 1592
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 9 - paragraph 2 - point b
deleted

Amendment 1593
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 9 - paragraph 2 - point b
(b) estimation and evaluation of the risks that may emerge when the high-risk AI system is used in accordance with its intended purpose or reasonably foreseeable use and under conditions of reasonably foreseeable misuse;

Amendment 1594
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 9 - paragraph 2 - point b
(b) estimation and evaluation of the risks that may emerge when the high-risk AI system is used in accordance with its intended purpose or reasonably foreseeable use and under conditions of reasonably foreseeable misuse;

Amendment 1595
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Article 9 - paragraph 2 - point b
(b) estimation and evaluation of the risks that may emerge when the high-risk AI system is used in accordance with its intended purpose;

Amendment 1596
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 9 - paragraph 2 - point b
(b) estimation and evaluation of the risks that may emerge when the high-risk AI system is used in accordance with its intended purpose and under conditions of reasonably foreseeable use or misuse;

Amendment 1597
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 9 - paragraph 2 - point c
(c) evaluation of new risks consistent with those described in paragraph (2a) of this Article and identified based on the analysis of data gathered from the post-market monitoring system referred to in Article 61;

Amendment 1598
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Article 9 - paragraph 2 - point c a (new)
(c) evaluation of new arising significant risks based on the analysis of data gathered from the post-market monitoring system referred to in Article 61;

Amendment 1599
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 9 - paragraph 2 - point c a (new)
(ca) sandbox experimentation on the functioning of the AI systems;

Amendment 1600
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 9 - paragraph 2 - point d
(d) adoption of appropriate and targeted risk management measures designed to address identified known and foreseeable risks to health and safety or fundamental rights, in accordance with the provisions of the following paragraphs.

Amendment 1601
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner, Jan-Christoph Oetjen
Article 9 - paragraph 2 - point d
(d) adoption of appropriate and targeted risk management measures to address identified significant risks in accordance with the provisions of the following paragraphs.

Amendment 1602
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 9 - paragraph 2 a (new)
2 a. The risks referred to in paragraph 2 shall concern only those which may be reasonably mitigated or eliminated through the development or design of the high-risk AI system, or the provision of adequate technical information.

Amendment 1603
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 9 - paragraph 3
3. The risk management measures referred to in paragraph 2, point (d) shall give due consideration to the effects and possible interactions resulting from the combined application of the requirements set out in this Chapter 2, with a view to treating risks effectively while ensuring an appropriate and proportionate implementation of the requirements. They shall take into account the generally acknowledged state of the art, including as reflected in relevant harmonised standards.

Amendment 1604
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 9 - paragraph 3
3. The risk management measures referred to in paragraph 2, point (d) shall give due consideration to the effects and possible interactions resulting from the combined application of the requirements set out in this Chapter 2. They shall take into account the generally acknowledged state of the art, including as reflected in the common technical specifications adopted by the Commission or in relevant harmonised standards.

Amendment 1605
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 9 - paragraph 3
3. The risk management measures referred to in paragraph 2, point (d) shall give due consideration to the effects and possible interactions resulting from the combined application of the requirements set out in this Chapter 2, with a view to minimising risks more effectively while achieving an appropriate balance in implementing the measures to fulfil those requirements.

Amendment 1606
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 9 - paragraph 3
3. The risk management measures referred to in paragraph 2, point (d) shall give due consideration to the effects and possible interactions resulting from the combined application of the requirements set out in this Chapter 2. They shall take into account the state of the art, including as reflected in relevant harmonised standards or common specifications.

Amendment 1607
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan, Vincenzo Sofo
Article 9 - paragraph 4 - introductory part
4. The risk management measures referred to in paragraph 2, point (d) shall be such that the overall residual risk of the high-risk AI systems is reasonably judged to be acceptable, having regard to the benefits that the high-risk AI system is reasonably expected to deliver and, provided that the high-risk AI system is used in accordance with its intended purpose or under conditions of reasonably foreseeable misuse, subject to terms, conditions as made available by the provider, and contractual and license restrictions. Those residual risks shall be communicated to the user.

Amendment 1608
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 9 - paragraph 4 - introductory part
4. The risk management measures referred to in paragraph 2, point (d) shall be such that any residual risk associated with each hazard, as well as the overall residual risk of the high-risk AI systems, is:

Amendment 1609
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Article 9 - paragraph 4 - introductory part
4. The risk management measures referred to in paragraph 2, point (d) shall be such that any residual significant risk associated with each hazard as well as the overall residual risk of the high-risk AI systems is reasonably judged to be acceptable, having regard to the benefits that the high-risk AI system is reasonably expected to deliver and provided that the high-risk AI system is used in accordance with its intended purpose or under conditions of reasonably foreseeable misuse. Those residual significant risks shall be communicated to the user.

Amendment 1610
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 9 - paragraph 4 - introductory part
4. The risk management measures referred to in paragraph 2, point (d) shall be such that any residual risk associated with each hazard as well as the overall residual risk of the high-risk AI systems is judged acceptable, provided that the high-risk AI system is used in accordance with its intended purpose or under conditions of reasonably foreseeable misuse. Those residual risks and the reasoned judgements made shall be communicated to the deployer and made available to AI subjects.

Amendment 1611
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 9 - paragraph 4 - introductory part
4. The risk management measures referred to in paragraph 2, point (d) shall be such that any significant residual risk of the high-risk AI systems is reasonably judged to be acceptable, having regards to the benefits that the high-risk AI system is reasonably expected to deliver and provided that the high-risk AI system is used in accordance with its intended purpose or under conditions of reasonably foreseeable misuse. Significant residual risks shall be communicated to the user.

Amendment 1612
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 9 - paragraph 4 - introductory part
4. The risk management measures referred to in paragraph 2, point (d) shall be such that any residual risk associated with each hazard as well as the overall residual risk of the high-risk AI systems is judged acceptable, provided that the high-risk AI system is used in accordance with its intended purpose or reasonably foreseeable use or under conditions of reasonably foreseeable misuse. Those residual risks shall be communicated to the user.

Amendment 1613
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Article 9 - paragraph 4 - introductory part
4. The risk management measures referred to in paragraph 2, point (d) shall be such that any residual risk associated with each hazard as well as the overall residual risk of the high-risk AI systems is judged acceptable, provided that the high-risk AI system is used in accordance with its intended purpose. Those residual risks shall be communicated to the user.

Amendment 1614
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 9 - paragraph 4 - introductory part
4. The risk management measures referred to in paragraph 2, point (d) shall be such that any relevant residual risk associated with each hazard as well as the overall residual risk of the high-risk AI systems is judged acceptable, provided that the high-risk AI system is used in accordance with its intended purpose or under conditions of reasonably foreseeable misuse. Those residual risks shall be communicated to the user.

Amendment 1615
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 9 - paragraph 4 - introductory part
4. The risk management measures referred to in paragraph 2, point (d) shall be such that any residual risk associated with each hazard as well as the overall residual risk of the high-risk AI systems is judged acceptable, provided that the high-risk AI system is used in accordance with its intended purpose or under conditions of reasonably foreseeable use or misuse. Those residual risks shall be communicated to the user.

Amendment 1616
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 9 - paragraph 4 - subparagraph 1 - introductory part
In identifying the most appropriate risk management measures, the following shall be taken into account:

Amendment 1617
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 9 - paragraph 4 - subparagraph 1 - introductory part
In identifying appropriate risk management measures, the following outcomes shall be pursued:

Amendment 1618
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 9 - paragraph 4 - subparagraph 1 - point a
(a) reduction of identified and evaluated risks as far as proportionate and technologically possible in light of the generally acknowledged state of the art and industry standards, through adequate design and development of the high risk AI system in question;

Amendment 1619
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 9 - paragraph 4 - subparagraph 1 - point a
(a) elimination or reduction of risks as far as possible through adequate design and development involving relevant domain and other experts and internal and external stakeholders, including but not limited to representative bodies and the social partners;

Amendment 1620
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 9 - paragraph 4 - subparagraph 1 - point a
(a) elimination or reduction of risks as far as commercially reasonable and technologically feasible in light of the generally acknowledged state of the art, through appropriate design and development measures;

Amendment 1621
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 9 - paragraph 4 - subparagraph 1 - point a
(a) elimination or reduction of identified and evaluated risks as far as economically and technologically feasible through adequate design and development of the high-risk AI system;

Amendment 1622
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Article 9 - paragraph 4 - subparagraph 1 - point a
(a) reduction of identified and evaluated risks as far as commercially reasonable and technologically feasable through adequate design and development;

Amendment 1623
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Article 9 - paragraph 4 - subparagraph 1 - point b
deleted

Amendment 1624
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Article 9 - paragraph 4 - subparagraph 1 - point b
(b) where appropriate, implementation of adequate mitigation and control measures in relation to significant risks that cannot be eliminated;

Amendment 1625
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 9 - paragraph 4 - subparagraph 1 - point b
(b) where appropriate, implementation of adequate mitigation and control measures addressing risks that cannot be eliminated;

Amendment 1626
ECR - European Conservatives and Reformists Group
Vincenzo Sofo, Kosma Złotowski
Article 9 - paragraph 4 - subparagraph 1 - point c
(c) provision of adequate information pursuant to Article 13, in particular as regards the risks referred to in paragraph 2, point (b) of this Article, and, where appropriate, and relevant information on necessary competence training and authority for natural persons exercising such oversight.

Amendment 1627
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Article 9 - paragraph 4 - subparagraph 1 - point c
(c) provision of adequate information pursuant to Article 13 and, where appropriate, training to users.

Amendment 1628
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 9 - paragraph 4 - subparagraph 1 - point c
(c) provision of the required adequate information pursuant to Article 13 of this Article, and, where appropriate, training to users.

Amendment 1629
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 9 - paragraph 4 - subparagraph 1 - point c
(c) provision of adequate information pursuant to Article 13, in particular as regards the risks referred to in paragraph 2, point (a) and (b) of this Article, and, where appropriate, training to users.

Amendment 1630
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 9 - paragraph 4 - subparagraph 1 - point c
(c) provision of adequate information pursuant to Article 13, in particular as regards the risks referred to in paragraph 2, point (b) of this Article, and, where appropriate, training to deployers.', '(This amendment applies throughout the text. Adopting it will necessitate corresponding changes throughout.)

Amendment 1631
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 9 - paragraph 4 - subparagraph 1 - point c a (new)
(c a) the governance structures to mitigate risks.

Amendment 1632
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä, Sylwia
Article 9 - paragraph 4 - subparagraph 2
In eliminating or reducing risks related to the use of the high-risk AI system, due consideration shall be given to the technical knowledge, experience, education, training to be expected by the deployer, to the socio-technical context in which the system is intended to be used, and to reasonably foreseeable use or misuse.

Amendment 1633
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 9 - paragraph 4 - subparagraph 2
In eliminating or reducing risks related to the use of the high-risk AI system, due consideration shall be given to the technical knowledge, experience, education, training to be expected by the user and the environment in which the system is intended or reasonably foreseeable to be used.

Amendment 1634
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 9 - paragraph 4 - subparagraph 2
In seeking to reduce risks related to the use of the high-risk AI system, providers shall take into due consideration the technical knowledge, experience, education, training the user may need, including in relation to the environment in which the system is intended to be used.

Amendment 1635
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 9 - paragraph 4 - subparagraph 2
In seeking to eliminate or reduce risks related to the use of the high-risk AI system, due consideration shall be given to the technical knowledge, experience, education, training to be expected by the user and the environment in which the system is intended to be used.

Amendment 1636
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 9 - paragraph 4 - point a (new)
(a) technically and structurally minimised by the high-risk AI system;

Amendment 1637
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 9 - paragraph 4 - point b (new)
(b) deemed acceptable, provided that the high-risk AI system is used for its intended purpose or under conditions of reasonably foreseeable misuse.

Amendment 1638
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 9 - paragraph 4 a (new)
4a. Those residual risks shall be communicated to the user.

Amendment 1639
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Article 9 - paragraph 5
5. High-risk AI systems shall be evaluated for the purposes of identifying the most appropriate and targeted risk management measures and weighing any such measures against the potential benefits and intended goals of the system. Evaluations shall ensure that high-risk AI systems perform consistently for their intended purpose and they are in compliance with the relevant requirements set out in this Chapter.

Amendment 1640
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 9 - paragraph 5
5. High-risk AI systems shall be tested for the purposes of identifying appropriate risk management measures for the specific scenario in which the system will be operating and to ensure that a system is performing appropriately for a given use case. Testing shall ensure that high-risk AI systems perform in a manner that is consistent with their intended purpose and they are in compliance with the requirements set out in this Chapter.

Amendment 1641
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 9 - paragraph 5
5. High-risk AI systems shall be evaluated for the purposes of identifying the most appropriate and targeted risk management measures and weighing any such measures against the potential benefits and intended goals of the system. Evaluations shall ensure that high-risk AI systems perform consistently for their intended purpose and they are in compliance with the relevant requirements set out in this Chapter.

Amendment 1642
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 9 - paragraph 5
5. High-risk AI systems shall be tested for the purposes of identifying the most appropriate risk management measures. Testing shall ensure that high-risk AI systems perform consistently, safely during reasonably foreseeable conditions of use or misuse, and they are in compliance with the requirements set out in this Chapter.

Amendment 1643
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia Sardone, Annalisa Tardino
Article 9 - paragraph 5
5. High-risk AI systems shall be evaluated for the purposes of identifying the most appropriate and targeted risk management measures and weighing any such measures against the potential benefits and intended goals of the system.

Amendment 1644
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 9 - paragraph 5
5. High-risk AI systems shall be tested for the purposes of identifying the most appropriate risk management measures. Testing shall ensure that high-risk AI systems perform consistently for their intended purpose or reasonably foreseeable use and they are in compliance with the requirements set out in this Chapter.

Amendment 1645
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 9 - paragraph 6
deleted

Amendment 1646
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 9 - paragraph 6
6. Testing procedures shall be suitable to achieve the intended purpose of the AI system.

Amendment 1647
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 9 - paragraph 6
6. Testing procedures shall be suitable to achieve the intended purpose or reasonably foreseeable use of the AI system and do not need to go beyond what is necessary to achieve that purpose.

Amendment 1648
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 9 - paragraph 6
6. Evaluation or testing procedures shall be suitable to achieve the intended purpose of the AI system.

Amendment 1649
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 9 - paragraph 6 - subparagraph 1 (new)
They shall test:

Amendment 1650
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 9 - paragraph 6 - point a (new)
(a) the ability of the high-risk AI system to generate an accurate and robust result;

Amendment 1651
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul Garraud
Article 9 - paragraph 6 - point b (new)
(b) the trustworthiness of the high-risk AI system and its ability to actually generate a result such as that expected in accordance with its intended purpose;

Amendment 1652
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 9 - paragraph 6 - point c (new)
(c) the structural and technical capacity of the high-risk AI system to ensure it cannot be used for purposes other than its intended purpose.

Amendment 1653
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş,
Article 9 - paragraph 7
7. The testing of the high-risk AI systems shall be performed prior to the placing on the market or the putting into service. Testing shall be made against preliminarily defined metrics and probabilistic thresholds that are appropriate to the intended purpose of the high-risk AI system.

Amendment 1654
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 9 - paragraph 7
7. The testing of the high-risk AI systems shall be performed, as appropriate, at any point in time throughout the development process, and, in any event, prior to the placing on the market or the putting into service. Testing shall be made against metrics and probabilistic thresholds that are preliminarily defined according to common standards or technical specifications and appropriate to the intended purpose of the high-risk AI system.

Amendment 1655
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 9 - paragraph 7
7. The testing of the high-risk AI systems shall be performed, as appropriate, at any point in time throughout the development process, and, in any event, prior to the placing on the market or the putting into service. Testing shall be made against preliminarily defined metrics and probabilistic thresholds that are appropriate to the intended purpose or reasonably foreseeable use of the high-risk AI system.

Amendment 1656
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 9 - paragraph 7
7. The testing of the high-risk AI systems shall be performed, as appropriate, at any point in time throughout the development process, and, in any event, prior to the placing on the market or the putting into service. Testing shall be made against preliminarily defined metrics and probabilistic thresholds that are appropriate to the intended use or reasonably foreseeable misuse of the high-risk AI system.

Amendment 1657
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 9 - paragraph 7
7. The testing of the high-risk AI systems shall be performed, as appropriate, at any point in time throughout the development process, and, in any event, prior to the placing on the market or the putting into service. Testing shall be made against prior defined metrics, such as probabilistic thresholds that are appropriate to the intended purpose of the high-risk AI system.

Amendment 1658
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Patryk Jaki, Adam Bielan
Article 9 - paragraph 7
7. The testing of the high-risk AI systems shall be performed, as appropriate, at any point in time throughout the development process, and, in any event, prior to the placing on the market or the putting into service. Testing shall be made against preliminarily defined metrics and rubrics that are appropriate to the intended purpose of the high-risk AI system.

Amendment 1659
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 9 - paragraph 8
8. When implementing the risk management system described in paragraphs 1 to 7, specific consideration shall be given to whether the high-risk AI system is likely to be accessed by or have an impact on children or natural persons suffering from disabilities that render them legally unable to give their consent.

Amendment 1660
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 9 - paragraph 8
8. When implementing the risk management system described in paragraphs 1 to 7, specific consideration shall be given to whether the high-risk AI system is likely to:

Amendment 1661
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 9 - paragraph 8
8. When implementing the risk management system described in paragraphs 1 to 7, shall give specific consideration to whether the high-risk AI system is likely to be accessed by or have an impact on children.

Amendment 1662
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä, Sylwia
Article 9 - paragraph 8 - point b (new)
(a) adversely affect specific groups of people, in particular on the basis of gender, sexual orientation, age, ethnicity, disability, religion, socio-economic standing, religion or origin, including asylum seekers including migrants, refugees and asylum seekers;

Amendment 1663
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 9 - paragraph 8 - point b (new)
(b) have an adverse impact on the environment, or;

Amendment 1664
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 9 - paragraph 8 - point c (new)
(c) be implemented on children;

Amendment 1665
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 9 - paragraph 8 - point e (new)
(d) have an adverse effect on mental health, individual’s behaviour;

Amendment 1666
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 9 - paragraph 8 - point e (new)
(e) amplify the spread of disinformation and amplify polarisation;

Amendment 1667
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 9 - paragraph 8 - point f (new)
(f) amplify the spread of disinformation and amplify polarisation;

Amendment 1668
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Patryk Jaki, Adam Bielan
Article 9 - paragraph 9
9. For AI systems already covered by Union law that requires a specific risk assessment, the aspects described in paragraphs 1 to 8 may be incorporated into that risk assessment, without the need to conduct a separate, additional risk assessment in order to comply with this Article.

Amendment 1669
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 9 - paragraph 9
9. For providers and AI systems already covered by Union law that require them to establish a specific risk management, the aspects described in paragraphs 1 to 8 shall be part of the risk management procedures established by that Union law or deemed to be covered as part of it.

Amendment 1670
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 9 - paragraph 9
9. For AI systems already covered by Union law that require them to carry out specific risk assessments, the aspects described in paragraphs 1 to 8 shall be combined with the risk assessment procedures established by that Union law or deemed to be covered as part of it.

Amendment 1671
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä, Sylwia
Article 9 a (new)
Article 9 a', 'Fundamental rights impact assessments for high-risk AI systems', '1. Providers, and deployers at each proposed deployment, must designate the categories of individuals and groups likely to be impacted by the system, assess the system’s impact on fundamental rights, its accessibility for persons with disabilities, and its impact on the environment and broader public interest. Deployers of high-risk AI systems as defined in Article 6(2) shall, prior to putting the system into use, publish a fundamental rights impact assessment of the systems’ impact in the context of use throughout the entire lifecycle. This assessment shall include at least:', 'a) the intended purpose for which the system will be used;', 'b) the intended geographic and temporal scope of the system;', 'c) the potential risks of the use to the rights and freedoms of natural persons, including any indirect impacts or consequences of the systems;', 'd) the categories of natural persons and groups likely or foreseen to be affected;', 'e) the proportionality and necessity of the system’s use;', 'f) verification of the legality of the use of the system in accordance with Union and national law;', 'g) any specific risk of harm likely to impact marginalised, vulnerable persons or groups at risk of discrimination, and risk of increasing existing societal inequalities;', 'h) the foreseeable impact of the use of the system on the environment over its entire life cycle, including but not limited to energy consumption;', 'i) any other negative impact on the public interest and clear plans relating to how the harms identified will be mitigated, and how effective this mitigation is expected to be; and', 'j) the governance system the deployer will put in place, including human oversight, complaint-handling and redress.', '2. If adequate steps to mitigate the risks outlined in the course of the assessment in paragraph 1 cannot be identified, the system shall not be put into use. Market surveillance authorities, pursuant to Articles 65 and 67, may take this information into account when investigating systems which present a risk at national level.', '3. The obligation outlined under paragraph 1 applies for each new deployment of the high-risk AI system.', '4. Deployers shall consult with relevant stakeholders, in particular groups of natural persons exposed to heightened risks from the AI system, civil society and social partners when preparing the impact assessment. The impact assessment shall be repeated on a regular basis throughout the entire lifecycle.', '5. Publication of the results of the impact assessment shall be part of the registration of use pursuant to Article 51(2).', '6. Where the deployer is already required to carry out a data protection impact assessment under Article 35 of Regulation(EU) 2016/679 or Article 27 of Directive (EU) 2016/680, the impact assessment outlined in paragraph 1 shall be conducted in conjunction to the data protection impact assessment and be published as an addendum.', '7. Deployers of high-risk AI systems shall use the information provided under Article 13 to comply with their obligation under paragraph 1.

Amendment 1672
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 10 - paragraph 1
1. High-risk AI systems which make use of techniques involving the training of models with data shall be developed on the basis of training, validation and testing data sets that meet the quality criteria referred to in paragraphs 2 to 5.', 'Techniques such as unsupervised learning and reinforcement learning that do not use validation and testing data sets shall be developed on the basis of training data sets the quality criteria referred to in paragraphs 2 to 5.

Amendment 1673
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Article 10 - paragraph 1
1. High-risk AI systems which make use of techniques involving the training of models with data shall be, as far as this can be reasonably expected and is feasible from a technical and economical point of view, developed on the basis of training, validation and testing data sets that meet the quality criteria referred to in paragraphs 2 to 5.

Amendment 1674
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 10 - paragraph 1
1. High-risk AI systems which make use of techniques involving the training of models with data shall be, as far this can be reasonably expected and is feasible from a technical point of view, developed with the best efforts to ensure training, validation and testing data sets that meet the quality criteria referred to in paragraphs 2 to 5.

Amendment 1675
EPP - Group of the European Peoples Party (Christian Democrats)
Karlo Ressler
Article 10 - paragraph 1
1. High-risk AI systems which make use of techniques involving the training of models with data shall be, with reasonable expectations and in accordance with the state-of-art, developed on the basis of training, validation and testing data sets that meet the quality criteria referred to in paragraphs 2 to 5;

Amendment 1676
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 10 - paragraph 1
1. High-risk AI systems which make use of techniques involving the training of models with data shall be developed on the basis of training, validation and testing data sets that meet the quality criteria referred to in paragraphs 2 to 5, when applicable.

Amendment 1677
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Patryk Jaki, Adam Bielan
Article 10 - paragraph 1
1. High-risk AI systems which make use of techniques involving the training of models with data shall be developed on the basis of training, validation and testing data sets that meet the quality and fairness criteria referred to in paragraphs 2 to 5.

Amendment 1678
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 10 - paragraph 1 a (new)
1 a. Validation datatsets shall be separate datasets from both the testing and the training datasets, in order for the evaluation to be unbiased. If only one dataset is available, it shall be divided in three parts: a training set, a validation set, and a testing set. Each set shall comply with paragraph 3 of this Article.

Amendment 1679
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 10 - paragraph 1 a (new)
1 a. Techniques such as unsupervised learning and reinforcement learning, that do not use validation and testing data sets, shall be developed on the basis of training data sets that meet the quality criteria referred to in paragraphs 2 to 5.

Amendment 1680
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 10 - paragraph 1 b (new)
1 b. Techniques such as unsupervised learning and reinforcement learning, that do not use validation and testing datasets, shall be developed on the basis of training datasets that meet the quality criteria referred to in paragraphs 2 to 4.

Amendment 1681
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 10 - paragraph 2 - introductory part
2. Training, validation and testing data sets as well as data that is collected, fed into, or used by the AI system, after deployment of the system and throughout its lifecycle shall be subject to appropriate data governance and management practices. Those practices shall concern in particular,

Amendment 1682
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 10 - paragraph 2 - introductory part
2. Training, validation and testing data sets shall be subject to appropriate data governance and management practices for the entire lifecycle of data processing. Where relevant to appropriate risk management measures, those practices shall concern in particular,

Amendment 1683
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad- Marius Botoş, Moritz Körner, Ondřej Kovařík, Jan-Christoph Oetjen
Article 10 - paragraph 2 - introductory part
2. Training, validation and testing data sets shall be subject to data governance and management practices appropriate for the context of the use as well as the intended purpose of the AI system. Those practices shall concern in particular,

Amendment 1684
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 10 - paragraph 2 - introductory part
2. Training, validation and testing data sets shall be subject to appropriate data governance and management practices. throughout the entire lifecycle of the AI system. Those practices shall concern in particular,

Amendment 1685
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 10 - paragraph 2 - introductory part
2. Training, machine-learning validation and testing data sets shall be subject to appropriate data governance and management practices during the expected lifetime. Those practices shall concern, where relevant:

Amendment 1686
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 10 - paragraph 2 - introductory part
2. Training, validation and testing data sets shall be subject to appropriate data governance and management practices for the entire lifecycle of data processing. Those practices shall concern in particular,

Amendment 1687
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 10 - paragraph 2 - point a
(a) the relevant design choices, including the extent to which the functioning of the algorithms can be audited and reproduced;

Amendment 1688
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 10 - paragraph 2 - point a
(a) the design choices for training and machine learning validation;

Amendment 1689
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 10 - paragraph 2 - point a
(a) the design choices;

Amendment 1690
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 10 - paragraph 2 - point b
(b) data collection processes;

Amendment 1691
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 10 - paragraph 2 - point b
(b) data collection processes;

Amendment 1692
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 10 - paragraph 2 - point c
(c) data preparation processing operations, such as annotation, labelling, cleaning, enrichment and aggregation;

Amendment 1693
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 10 - paragraph 2 - point c
(c) data preparation processing operations, such as annotation, labelling, cleaning, enrichment and aggregation;

Amendment 1694
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 10 - paragraph 2 - point c
(c) data preparation processing operations, such as annotation, labelling, cleaning, enrichment and aggregation;

Amendment 1695
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 10 - paragraph 2 - point d
(d) the formulation of relevant, justified and reasonable assumptions, notably with respect to the information that the data are supposed to measure and represent;

Amendment 1696
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 10 - paragraph 2 - point e
deleted

Amendment 1697
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 10 - paragraph 2 - point e
(e) an assessment of the availability, quantity and suitability of the data sets that are needed;

Amendment 1698
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Radosław Sikorski,
Article 10 - paragraph 2 - point f
(f) examination in view of possible biases defined as a statistical error or a top-down introduction of assumptions harmful to an individual, that are likely to affect health and safety of persons or lead to discrimination prohibited by Union law;

Amendment 1699
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 10 - paragraph 2 - point f
(f) examination in view of possible unfair biases that are likely to affect the health and safety of persons or lead to discrimination prohibited under Union law;

Amendment 1700
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Vincenzo Sofo, Adam Bielan
Article 10 - paragraph 2 - point f
(f) examination in view of possible biases, that are likely to affect health and safety of persons or lead to discrimination prohibited by Union law;

Amendment 1701
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 10 - paragraph 2 - point f
(f) examination of possible biases, especially where data outputs are used as an input for future operations(‘feedback loops’);

Amendment 1702
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 10 - paragraph 2 - point f
(f) examination in view of possible biases that are likely to affect the output of the AI system;

Amendment 1703
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 10 - paragraph 2 - point f
(f) examination in view of biases;

Amendment 1704
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Vincenzo Sofo, Adam Bielan
Article 10 - paragraph 2 - point g
(g) the identification of any other data gaps or shortcomings that materially increase the risks of harm to the health, natural environment and safety or the fundamental rights of persons, and how those gaps and shortcomings can be addressed.

Amendment 1705
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 10 - paragraph 2 - point g
(g) the identification of significant and consequential data gaps or shortcomings, and how those gaps and shortcomings can be addressed;

Amendment 1706
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona Strugariu, Dragoş Pîslaru, Lucia Ďuriš Nicholsonová, Irena Joveva, Malik Azmani, Alin Mituța
Article 10 - paragraph 2 - point g
(g) the identification of relevant possible data gaps or shortcomings, and how those gaps and shortcomings can be addressed.

Amendment 1707
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 10 - paragraph 2 - point g
(g) the identification of significant data gaps or shortcomings, and how those gaps and shortcomings can be addressed.

Amendment 1708
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 10 - paragraph 2 - point g
(g) the identification of possible data gaps or shortcomings, and how those gaps and shortcomings can be addressed.

Amendment 1709
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 10 - paragraph 2 - point g a (new)
(g a) the presumable context of the use as well as the intended purpose of the AI System.

Amendment 1710
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 10 - paragraph 2 - point g a (new)
(g a) verification of the legality of the sources of the data.

Amendment 1711
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
René Repasi, Marc Angel, Andreas Schieder, Maria-Manuel Leitão-Marques
Article 10 - paragraph 2 a (new)
2 a. the evaluation of the impacts of a high-risk AI system, designed to ensure it is functioning as intended, that there are no errors or risks left unaddressed and that the system continues to meet the state-of-the-art standards required by this Regulation (ex post requirement).

Amendment 1712
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 10 - paragraph 3
3. Training data sets, validation and testing data sets, including the labels, as well as data that is collected, fed into, or used by the AI system, after deployment of the system and throughout its lifecycle shall be relevant, representative, free of errors and complete. They shall have the appropriate properties, including, where applicable, as regards the persons or groups of persons on which the high-risk AI system is intended to be used. The required characteristics should be met at the level of each individual dataset, whether in combination or not.', 'Training validation and testing data sets shall be relevant, representative, free of errors and complete. They shall have the appropriate properties, including, where applicable, as regards the persons or groups of persons on which the high-risk AI system is intended to be used.

Amendment 1713
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Article 10 - paragraph 3
3. Training, validation and testing data sets shall be relevant, representative and as complete and close to zero error as possible, having regard to the intended purpose of the AI system. They shall have the appropriate statistical properties, including, where applicable, as regards the persons or groups of persons on which the high-risk AI system is intended to be used. These characteristics of the data sets may be met at the level of individual data sets or a combination thereof. In case of observational data, a common approach on data requirements shall be defined together with regulators.

Amendment 1714
EPP - Group of the European Peoples Party (Christian Democrats)
Nathalie Colin-Oesterlé
Article 10 - paragraph 3
3. Training, validation and testing data sets shall be relevant, representative, reliable, limited in terms of bias, and complete. These characteristics of the data sets may be met at the level of individual data sets or a combination thereof.

Amendment 1715
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 10 - paragraph 3
3. High-risk AI systems shall be designed and developed with the best efforts to ensure that training, validation and testing data sets shall be relevant, representative, and to the best extent possible, free of errors and complete in accordance with industry standards. They shall have the appropriate statistical properties, including, where applicable, as regards the persons or groups of persons on which the high-risk AI system is intended to be used. These characteristics of the data sets may be met at the level of individual data sets or a combination thereof.

Amendment 1716
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Andrzej Halicki, Adam Jarubas, Jerzy Buzek, Janusz Lewandowski,
Article 10 - paragraph 3
3. Training, validation and testing datasets sets shall be relevant, representative, up-to-date, and to the extent that it could be reasonably expected, taking into account the state of the art, free of errors and as complete as could be reasonably expected . They shall have the appropriate statistical properties, including, where applicable, as regards the persons or groups of persons on which the high-risk AI system is intended to be used. These characteristics of the data sets may be met at the level of individual data sets or a combination thereof.

Amendment 1717
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Article 10 - paragraph 3
3. High risk AI systems should be designed and developed with the best efforts to ensure that, where appropriate, training, validation and testing data sets are sufficiently relevant, representative and appropriately vetted for errors. They shall have the appropriate statistical properties, including, where applicable, as regards the persons or groups of persons on which the high-risk AI system is intended to be used. These characteristics of the datasets may be met at the level of individual data sets or a combination thereof.

Amendment 1718
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 10 - paragraph 3
3. Training datasets, and where applicable, validation and testing datasets, including the labels, shall be relevant, representative, up-to-date, and to the best extent possible, free of errors and complete. They shall have the appropriate statistical properties, including, where applicable, as regards the persons or groups of persons on which the high-risk AI system is intended to be used. These characteristics of the datasets shall be met at the level of each individual data set.

Amendment 1719
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina Penkova, René Repasi, Birgit Sippel, Maria Grapini, Adriana Maldonado López, Maria-Manuel Leitão-Marques, Marc Angel
Article 10 - paragraph 3
3. Training, validation and testing datasets shall be relevant, representative, up-to-date, and to the best extent possible, taking into account the state of the art, free of errors and be as complete as possible. They shall have the appropriate statistical properties, including, where applicable, as regards the persons or groups of persons on which the high-risk AI system is intended to be used. These characteristics of the datasets shall be met at the level of each individual dataset.

Amendment 1720
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 10 - paragraph 3
3. Training, validation and testing data sets shall be relevant, sufficiently diverse to mitigate bias, and, to the best extent possible, representative, free of errors and complete. They shall have the appropriate statistical properties, including, where applicable, as regards the persons or groups of persons on which the high-risk AI system is intended to be used. These characteristics of the data sets may be met at the level of individual data sets or a combination thereof.

Amendment 1721
EPP - Group of the European Peoples Party (Christian Democrats)
Geoffroy Didier
Article 10 - paragraph 3
3. Training, validation and testing data sets shall be relevant, representative, and to the best extent possible free of errors and complete. They shall have the appropriate statistical properties, including, where applicable, as regards the persons or groups of persons on which the high-risk uses of AI system is intended to be used. These characteristics of the data sets may be met at the level of individual data sets or a combination thereof.

Amendment 1722
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 10 - paragraph 3
3. Training, validation and testing data sets shall be relevant, representative, free of errors and statistically complete. They shall have the appropriate statistical properties, including, where applicable, as regards the persons or groups of persons in relation to whom the high-risk AI system is intended to be used. These characteristics of the data sets may be met at the level of individual data sets or a combination thereof.

Amendment 1723
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Article 10 - paragraph 3
3. Training, validation and testing data sets shall be relevant and representative. They shall have the appropriate statistical properties, including, where applicable, as regards the persons or groups of persons on which the high-risk AI system is intended to be used. These characteristics of the data sets may be met at the level of individual data sets or a combination thereof.

Amendment 1724
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 10 - paragraph 3
3. Training, validation and testing data sets shall be relevant and representative. They shall have the appropriate statistical properties, including, where applicable, as regards the persons or groups of persons on which the high-risk AI system is intended to be used. These characteristics of the data sets may be met at the level of individual data sets or a combination thereof.

Amendment 1725
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 10 - paragraph 3
3. High Risk AI systems should be designed and developed with the best efforts to ensure that, where appropriate, training datasets, machine-learning validation and testing data sets are sufficiently accurate, relevant and representative in view of the intended purpose of the AI system. These characteristics may be met at the level of individual data sets or a combination thereof.

Amendment 1726
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 10 - paragraph 3 a (new)
3 a. In assessing the quality of a data set, account shall be taken to the extent to which the data set is constructed with a view to fulfilling in particular the following aspects:', 'a) provides a similar output for relevant demographic Groups impacted by the system;', 'b) minimizes disparities in outcomes for relevant demographic groups impacted by the system, in case where the system allocates resources or opportunities to natural persons;', 'c) minimizes the potential for stereotyping, demeaning, or erasing relevant demographic groups impacted by the system where the system describes, depicts, or otherwise represents people, cultures, or society.

Amendment 1727
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 10 - paragraph 4
deleted

Amendment 1728
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 10 - paragraph 4
4. Training, validation and testing data sets as well as data that is collected, fed into, or used by the AI system, after deployment of the system and throughout its lifecycle shall take into account, to the extent required by the intended purpose or reasonably foreseeable use , the characteristics or elements that are particular to the specific geographical, behavioural or functional setting within which the high-risk AI system is intended to be used.

Amendment 1729
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 10 - paragraph 4
4. Data sets shall take into account, to the extent required by the intended purpose, the foreseeable uses and reasonably foreseeable misuses of AI systems with indeterminate uses, the characteristics or elements that are particular to the specific geographical, ,behavioural or functional setting within which the high-risk AI system is intended to be used.

Amendment 1730
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 10 - paragraph 4
4. Training, validation and testing data sets shall take into account the characteristics or elements that are particular to the specific geographical, behavioural or functional setting within which the high-risk AI system is used.

Amendment 1731
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 10 - paragraph 4
4. Training, validation and testing data sets shall be sufficiently diverse to accurately capture, to the extent required by the intended purpose, the characteristics or elements that are particular to the specific geographical, behavioural or functional setting within which the high-risk AI system is intended to be used.

Amendment 1732
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 10 - paragraph 4
4. Data sets shall take into account, to the extent required by the intended purpose, the reasonably foreseeable uses and misuses of AI systems, the characteristics or elements that are particular to the specific geographical, cultural, behavioural or functional setting within which the high-risk AI system is intended to be used.

Amendment 1733
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Article 10 - paragraph 4 a (new)
4 a. The processing of personal data to train, validate and test data sets of an AI system in order to meet the requirements of this Regulation shall be lawful for the purpose of the legitimate interest of the provider as referred to in Article 6(1f) GDPR or in accordance with Article 6(4) GDPR subject to appropriate safeguards in line with Article 89 GDPR for ensuring to the extent necessary and proportionate one or more of the following objectives:', 'a) national and common security;', 'b) functioning of the internal market;', 'c) prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, including the safeguarding against and the prevention of threats to public security;', 'd) exercise of public authorities’ official mission, such as tax and customs authorities, financial investigation units, independent administrative authorities, or financial market authorities responsible for the regulation and supervision of securities markets should not be regarded as recipients if they process personal data to train, validate and test an AI system which are necessary to carry out a particular inquiry in the general interest, in accordance with Union or Member State law;', 'e) network and information security to the extent necessary and proportionate for this purpose;', 'f) protection of an interest which is essential for the life of the data subject or that of another natural person, in particular where it is necessary for reasons of public interest in the areas of public health.

Amendment 1734
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 10 - paragraph 5
deleted

Amendment 1735
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 10 - paragraph 5
deleted

Amendment 1736
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 10 - paragraph 5
deleted

Amendment 1737
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 10 - paragraph 5
deleted

Amendment 1738
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Article 10 - paragraph 5
5. To the extent that it is necessary for the purposes of ensuring bias monitoring, detection and correction in relation to the high-risk AI systems, the providers of such systems will have a legal basis and necessary exception to process special categories of personal data referred to in Article 9(1) of Regulation (EU) 2016/679, Article 10 of Directive (EU) 2016/680 and Article 10(1) of Regulation (EU) 2018/1725, subject to appropriate safeguards for the fundamental rights and freedoms of natural persons, including:', '(i) state-of-the-art security and privacy-preserving measures, such as data-minimization, pseudonymisation, encryption, and where anonymisation may significantly affect the purpose pursued;', '(ii) measures ensuring availability and resilience of processing systems and services, and the ability to restore the availability and access to special category personal data in a timely manner in the event of a physical or technical incident;', '(iii) processes for regularly testing, assessing and evaluating the effectiveness of technical and organisational measures in order to ensure the security of the processing;', '(iv) measures for user identification, authorisation, protection of data during transmission, protection of data during storage, ensuring physical security of locations at which personal data are processed, internal IT and IT security governance and management, certification/assurance of processes and products;', '(v) measures for ensuring data minimisation, data quality, limited data retention, and data portability and ensuring erasure.

Amendment 1739
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 10 - paragraph 5
5. To the extent that it is strictly necessary for the purposes of ensuring bias monitoring, detection and correction in relation to the high-risk AI systems, the providers of such systems may process special categories of personal data referred to in Article 9(1) of Regulation (EU) 2016/679, Article 10 of Directive (EU) 2016/680 and Article 10(1) of Regulation (EU) 2018/1725, subject to appropriate safeguards for the fundamental rights and freedoms of natural persons, including technical limitations on the re-use and use of state-of-the-art security and privacy-preserving measures, such as pseudonymisation, or encryption where anonymisation may significantly affect the purpose pursued. This should also guarantee explainability of AI driven recommendations or decisions.

Amendment 1740
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 10 - paragraph 5
5. To the extent that it is strictly necessary for the purposes of ensuring bias monitoring, detection and correction in relation to the high-risk AI systems, the providers of such systems may process special categories of personal data referred to in Article 9(1) of Regulation (EU) 2016/679, Article 10 of Directive (EU) 2016/680 and Article 10(1) of Regulation (EU) 2018/1725, subject to appropriate safeguards for the fundamental rights and freedoms of natural persons, including technical limitations on the re-use and use of state-of-the-art security and privacy-preserving measures, such as pseudonymisation, or encryption or biometric template protection technologies where anonymisation may significantly affect the purpose pursued.

Amendment 1741
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 10 - paragraph 5 a (new)
5a. The dissemination of data by an AI system to other AI systems, whether or not they are of the same origin and whether or not they are installed on the same medium, shall be checked by the provider and may be retracted if necessary.

Amendment 1742
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 10 - paragraph 6
6. For the development of high-risk AI systems not using techniques involving the training of models, paragraphs 2 to 5 shall apply only to the testing data sets.

Amendment 1743
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 10 - paragraph 6 a (new)
6 a. Providers and user may comply with the obligations set out in this Article through the use of third-parties that offer certified compliance services including verification of data governance, data set integrity, and data training, validation and testing practices.

Amendment 1744
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Article 10 - paragraph 6 a (new)
6 a. The training, testing and validation processes of data sets should have a duration based on the training periodicity of the systems, the timing of notification of incidents and the normal supervisory activity of the national competent authority

Amendment 1745
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 10 - paragraph 6 b (new)
6 b. Where the provider cannot comply with the obligations laid down in this Article because it does not have access to the data and/or the data is held exclusively by the user, the user may, on the basis of a contract, be made responsible for any infringement of this Article.

Amendment 1746
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 10 a (new)
Article 10 a', 'Environmental Impact of high-risk AI systems', '1. High-risk AI systems shall be designed and developed making use of state-of-the-art methods to reduce energy use, resource use and waste, as well as to increase energy efficiency, and the overall efficiency of the system. They shall be designed and developed and set up with capabilities enabling the measurement and logging of the consumption of energy and resources, and other environmental impact the deployment and use of the systems may have over their entire lifecycle.', '2. Member States shall ensure that relevant national authorities issue guidelines and provide support to providers and deployers in their efforts to reduce the environmental impact and resource use of high-risk AI systems.', '3. The Commission shall be empowered to adopt delegated acts in accordance with Article 73 to detail the measurement and logging procedures, taking into account state-of-the-art methods, in particular to enable the comparability of the environmental impact of systems, and taking into account the economies of scale.

Amendment 1747
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Milan Brglez, Hilde Vautmans, Catharina Rinzema
Article 10 a (new)
Article 10 a', 'Risk management system for AI systems likely to interact with children', 'AI systems likely to interact with or impact on children shall implement a riskmanagement system addressing content, contact, conduct and contract risks to children;

Amendment 1748
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 11 - paragraph 1 - introductory part
1. The technical documentation of a high-risk AI system shall be drawn up, where possible, relevant, and without compromising intellectual property rights or trade secrets, before that system is placed on the market or put into service and shall be kept up-to date.

Amendment 1749
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 11 - paragraph 1 - introductory part
1. The technical documentation of a high-risk AI system shall be drawn up before that system is placed on the market or put into service and shall be kept up-to date throughout its entire lifecycle, and where appropriate, beyond.

Amendment 1750
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 11 - paragraph 1 - subparagraph 1
The technical documentation shall be drawn up, where possible, relevant, and without compromising intellectual property rights or trade secrets, in such a way to demonstrate that the high-risk AI system complies with the requirements set out in this Chapter and provide national competent authorities and notified bodies with all the necessary information to assess the compliance of the AI system with those requirements. It shall contain, at a minimum, the elements set out in Annex IV or in the case of SME’s and start-ups, any equivalent documentation meeting the same objectives, subject to approval of the competent national authority.

Amendment 1751
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Article 11 - paragraph 1 - subparagraph 1
The technical documentation shall vary according to each use of the AI system and drawn up in such a way to demonstrate that the high-risk AI system complies with the requirements set out in this Chapter and provide national competent authorities and notified bodies with all the necessary information to assess the compliance of the AI system with those requirements. It shall contain, at a minimum, the elements set out in Annex IV or in the case of SMEs and start-ups, any equivalent documentation meeting the same objectives, subject to approval of the competent national authority.

Amendment 1752
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Article 11 - paragraph 1 - subparagraph 1
The technical documentation shall be appropriate to the context of application or use of the AI system and drawn up in such a way to demonstrate that the high-risk AI system complies with the requirements set out in this Chapter and provide national competent authorities and notified bodies with all the necessary information to assess the compliance of the AI system with those requirements. It shall contain, at a minimum, the elements set out in Annex IV or any equivalent documentation meeting the same objectives, subject to approval of the competent authority.

Amendment 1753
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 11 - paragraph 1 - subparagraph 1
The technical documentation shall be drawn up in such a way to demonstrate that the high-risk AI system complies with the requirements set out in this Chapter and provide national competent authorities and notified bodies with all the necessary information to assess the compliance of the AI system with those requirements. It shall contain, at a minimum, the elements set out in Annex IV or, in the case of SMEs and start-ups, any equivalent documentation meeting the same objectives, subject to approval of the competent authority.

Amendment 1754
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 11 - paragraph 1 - subparagraph 1
The technical documentation shall be drawn up in such a way to demonstrate that the high-risk AI system complies with the requirements set out in this Chapter and provide national competent authorities and notified bodies with all the necessary information to assess the compliance of the AI system with those requirements. It shall contain, at a minimum, the elements set out in Annex IV or equivalent documentation meeting the same objectives, subject to the approval of the competent authority.

Amendment 1755
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 11 - paragraph 1 - subparagraph 1
The technical documentation shall be drawn up in such a way to demonstrate that the high-risk AI system complies with the requirements set out in this Chapter and provide the national supervisory authority, the national competent authorities and notified bodies with all the necessary information to assess the compliance of the AI system with those requirements. It shall contain, at a minimum, the elements set out in Annex IV.

Amendment 1756
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Article 11 - paragraph 1 - point 1 (new)
The technical documentation shall be drawn up in such a way to demonstrate that the high-risk AI system complies with the requirements set out in this Chapter and provide national competent authorities and notified bodies with the necessary information to assess the compliance of the AI system with those requirements. It shall contain, at a minimum, the elements set out in Annex IV.

Amendment 1757
EPP - Group of the European Peoples Party (Christian Democrats)
Nathalie Colin-Oesterlé
Article 11 - paragraph 1 - point 1 (new)
(1) Technical documentation is not mandatory, but it is recommended for the testing of a high-risk AI system before it is placed on the market or made available.

Amendment 1758
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 11 - paragraph 2
2. Where a high-risk AI system related to a product, to which the legal acts listed in Annex II, section A apply, is placed on the market or put into service only one single and appropriate technical documentation shall be drawn up for each product, containing all the information set out in Annex IV as well as the information required under those legal acts.

Amendment 1759
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 11 - paragraph 2
2. Where a high-risk AI system related to a product, to which the legal acts listed in Annex II, section A apply, is placed on the market or put into service one single technical documentation shall be drawn up containing all the information set out in paragraph 1 as well as the information required under those legal acts.

Amendment 1760
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Article 11 - paragraph 2
2. Where a high-risk AI system related to a product, to which the legal acts listed in Annex II, section A apply, is placed on the market or put into service appropriate technical documentation shall be drawn up containing all the information set out in Annex IV as well as the information required under those legal acts.

Amendment 1761
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 11 - paragraph 2 a (new)
2 a. To ensure that a single technical documentation is possible, terms and definitions related to this required documentation and any required documentation in the appropriate Union sectoral legislation shall be aligned as much as possible;

Amendment 1762
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 11 - paragraph 3
deleted

Amendment 1763
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 11 - paragraph 3 a (new)
3. The Commission is empowered to adopt delegated acts in accordance with Article 73 to add to Annex IV where necessary to ensure that, in the light of technical progress, the technical documentation provides all the necessary information to assess the compliance of the system with the requirements set out in this Chapter.

Amendment 1764
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 11 - paragraph 3 a (new)
3 a. Providers that are credit institutions regulated by Directive 2013/36/EU shall maintain the technical documentation as part of the documentation concerning internal governance, arrangements, processes and mechanisms pursuant to Article 74 of that Directive.

Amendment 1765
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 12 - paragraph 1
1. High-risk AI systems shall be designed and developed with capabilities enabling the automatic recording of events (‘logs’) while the high-risk AI systems are operating. Those logging capabilities shall conform to recognised standards or common specifications. Where possible, these capabilities shall be local ones and the logs shall be stored on the medium employed by the user of the AI system.

Amendment 1766
Renew - Renew Europe Group
Morten Løkkegaard
Article 12 - paragraph 1
1. Where reasonably practicable high-risk AI systems, which are capable of changing behaviour during operation, shall be designed and developed with capabilities enabling the automatic recording of events (‘logs’) while the high-risk AI systems is operating. Those logging capabilities shall conform to recognised standards or common specifications.

Amendment 1767
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 12 - paragraph 1
1. High-risk AI systems shall technically allow the automatic recording of events (‘logs’) over the durations of the lifetime of the system.

Amendment 1768
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 12 - paragraph 1
1. High-risk AI systems shall be designed and developed with capabilities enabling the automatic recording of events (‘logs’) while the high-risk AI systems is operating. Those logging capabilities shall conform to the state of the art and recognised standards or common specifications.

Amendment 1769
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Patryk Jaki
Article 12 - paragraph 1
1. High-risk AI systems shall be designed and developed with appropriate technical and organizational measures to enable effective monitoring and human oversight by those using the system as well as effective supervision by regulators.

Amendment 1770
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 12 - paragraph 1
1. All AI systems shall be designed and developed with capabilities enabling the automatic recording of events (‘logs’) while the AI systems is operating. Those logging capabilities shall conform to recognised standards or common specifications.

Amendment 1771
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 12 - paragraph 2
2. In order to ensure a level of traceability of the AI system’s functioning which is appropriate to the intended purpose of the system, the logging capabilities shall enable the recording of events relevant for the identification of situations that may:', '(i) result in the AI system presenting a risk within the meaning of Article 65 (1);or', '(ii) lead to a substantial modification that facilitates the post market monitoring referred to in Article 61.

Amendment 1772
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Article 12 - paragraph 2
2. The logging capabilities shall ensure a level of traceability of the AI system’s functioning that is appropriate to the intended purpose of the system. The storage period should be determined on the business needs and informational value, without exceeding a maximum of 10 fiscal years

Amendment 1773
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 12 - paragraph 2
2. The logging capabilities shall ensure a level of traceability of the AI system’s functioning throughout its lifecycle that is appropriate to the intended purpose or reasonably foreseeable use of the system.

Amendment 1774
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 12 - paragraph 2
2. The logging capabilities shall ensure a level of traceability of the AI system’s functioning throughout its lifecycle that is appropriate to the intended purpose or reasonably foreseeable use of the system.

Amendment 1775
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 12 - paragraph 2
2. The logging capabilities shall ensure a level of traceability of the AI system’s functioning while the AI system is used within its lifecycle that is appropriate to the intended purpose of the system.

Amendment 1776
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 12 - paragraph 3
deleted

Amendment 1777
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 12 - paragraph 3 a (new)
3 a. For records constituting trade secrets as defined in Article 2 of Directive (EU) 2016/943, provider may elect to confidentially provide such trade secrets only to relevant public authorities to the extent necessary for such authorities to perform their obligations hereunder.

Amendment 1778
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş,
Article 12 - paragraph 4
deleted

Amendment 1779
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 12 - paragraph 4
deleted

Amendment 1780
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Article 12 - paragraph 4
deleted

Amendment 1781
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 12 - paragraph 4 - introductory part
4. For high-risk AI systems referred to in Annex III, the logging capabilities shall provide, at a minimum:

Amendment 1782
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina Penkova, René Repasi, Birgit Sippel, Maria Grapini, Adriana Maldonado López, Maria-Manuel Leitão-Marques, Marc Angel
Article 12 - paragraph 4 - point a
(a) recording of the period of each use of the system;

Amendment 1783
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Article 12 - paragraph 4 - point c
deleted

Amendment 1784
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 12 - paragraph 4 a (new)
4 a. For high-risk self-learning AI systems the logging of self-learning shall be maintained.The logging shall provide, at a minimum:', '(a) the input data used for self-learning;', '(b) the used algorithms of the input data interpretation;', '(c) the results of self-learning.

Amendment 1785
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 12 - paragraph 4 b (new)
4 b. Where a decision and/or proposal of decision is the outcome of an AI system, the logging shall cover information comprehensively sufficient for further human manual review of the decision/proposal with no need to refer to the AI system itself.The logging shall provide, at a minimum:', '(a) the input data;', '(b)the reference database, if such present;', '(c) the algorithms that could had been used;', '(d) the algorithms that actually had been used;', '(e) output data (decision and/or proposal);', '(f) comprehensive mechanism of how the input data resulted into the output data.

Amendment 1786
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 12 - paragraph 4 c (new)
4 c. For all high-risk AI systems, including those mentioned in paragraphs 4-6 above, the logging shall provide, at a minimum:', '(a) log-in information (user, date, time, authentication type);', '(b) the input data;', '(c) the output data.

Amendment 1787
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 12 - paragraph 4 d (new)
4 d. The Commission is empowered to adopt delegated acts in accordance with Article 73 to define more minimum logging requirements for AI systems or their certain types.

Amendment 1788
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 13 - title
Transparency and provision of information to deployers and AI subjects

Amendment 1789
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 13 - paragraph 1
1. High-risk AI systems shall be designed and developed in such a way to ensure that their operation is sufficiently transparent to enable users to reasonably understand the system’s functioning. An appropriate type and degree of transparency shall be ensured, depending on the intended purpose of the system, with a view to achieving compliance with the relevant obligations of the user and of the provider set out in Article 16 and Article 29 of this Title. The explanation shall be provided at least in the language of the country where the AI system is deployed.', 'Transparency shall thereby mean that, to the extent that can be reasonably expected and is feasible in technical terms at the time when the AI system is placed on the market, the AI system is interpretable to the provider, in that the provider can understand the rationale of decisions taken by the high risk AI system, while enabling the user to understand and use the AI system appropriately, by generally knowing how the AI system works and what data it processes.

Amendment 1790
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 13 - paragraph 1
1. High-risk AI systems shall be designed and developed in such a way to ensure that their operation is sufficiently transparent to enable users to interpret the system’s output and use it appropriately. An appropriate type and degree of transparency shall be ensured, with a view to achieving compliance with the relevant obligations of the user and of the provider set out in Chapter 3 of this Title. Transparency shall thereby mean that, to the extent that can be reasonably expected and is feasible in technical terms, the AI systems output is interpretable by the user and the user is able to understand the general functionality of the AI system and its use of data.

Amendment 1791
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 13 - paragraph 1
1. High-risk AI systems shall be designed and developed in such a way to ensure that their operation is sufficiently transparent to enable deployers to interpret the system’s output and use it appropriately. An appropriate type and degree of transparency shall be ensured, with a view to achieving compliance with the relevant obligations of the deployer and of the provider set out in Chapter 3 of this Title. Where individuals are passively subject to AI systems (AI subjects), information to ensure an appropriate type and degree of transparency shall be made publicly available, with full respect to the privacy, personality, and related rights of subjects.

Amendment 1792
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 13 - paragraph 2
2. High-risk AI systems shall be accompanied by comprehensible instructions for use in an appropriate digital format or made otherwise available that include concise, correct and clear information that helps supporting informed decision-making by users and is reasonably relevant, accessible and comprehensible to users.

Amendment 1793
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 13 - paragraph 2
2. High-risk AI systems shall be accompanied by instructions for use in an appropriate digital format or otherwise that include concise, complete, correct and clear information that helps supporting informed decision-making by users and is relevant, accessible and comprehensible to users.

Amendment 1794
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 13 - paragraph 3 - introductory part
2. High-risk AI systems shall be accompanied by instructions for use in an appropriate digital format or otherwise that include concise, statistically complete, correct and clear information that is relevant, accessible and comprehensible to deployers.

Amendment 1795
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 13 - paragraph 3 - introductory part
3. To the extent neccessary to achieve the outcomes referred to in paragraph 1, the information referred to in paragraph 2 shall specify:

Amendment 1796
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 13 - paragraph 3 - point a
(a) the identity and the contact details of the provider, where applicable, of their authorised representative;

Amendment 1797
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 13 - paragraph 3 - point b - introductory part
(b) the capabilities and limitations of performance of the high-risk AI system that are relevant to the material risks associated with the intended purpose, including where appropriate:

Amendment 1798
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 13 - paragraph 3 - point b - point ii
(ii) the level of accuracy, robustness and cybersecurity referred to in Article 15 against which the high-risk AI system has been tested and validated and which can be expected, and any known and foreseeable circumstances that may have an impact on that expected level of accuracy, robustness and cybersecurity, including an overview of the capabilities and performance metrics of the AI system, and of representative use cases based on the intended purpose;

Amendment 1799
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 13 - paragraph 3 - point b - point ii
(ii) the performance metrics and its appropriateness, including the level of accuracy, robustness and cybersecurity referred to in Article 15 against which the high-risk AI system has been tested and validated and which can be expected, and any known and foreseeable circumstances that may have an impact on that expected level of performance, robustness and cybersecurity;

Amendment 1800
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 13 - paragraph 3 - point b - point ii
(ii) the level of accuracy, robustness and cybersecurity referred to in Article 15 against which the high-risk AI system has been tested and validated before being placed on the market and which can be expected, and any known and foreseeable circumstances that may have an impact on that expected level of accuracy, robustness and cybersecurity;

Amendment 1801
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner, Ondřej Kovařík, Jan-Christoph Oetjen
Article 13 - paragraph 3 - point b - point iii
deleted

Amendment 1802
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 13 - paragraph 3 - point b - point iii
(iii) the known or foreseeable circumstances, related to the use of the high-risk AI system in accordance with its intended purpose or under conditions of reasonably foreseeable misuse, which may lead to risks to the health and safety or fundamental rights, including, where appropriate, illustrative examples of such limitations and of scenarios for which the system should not be used;

Amendment 1803
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 13 - paragraph 3 - point b - point iii
(iii) any known or foreseeable circumstance, related to the use of the high-risk AI system in accordance with its intended purpose or under conditions of reasonably foreseeable use or misuse, which may lead to risks to the health, safety, fundamental rights, the environment, or democracy;

Amendment 1804
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 13 - paragraph 3 - point b - point v
(v) relevant information about user actions that may influence system performance, including type or quality of input data, or any other relevant information in terms of the training, validation and testing data sets used, taking into account the intended purpose of the AI system.

Amendment 1805
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 13 - paragraph 3 - point b - point v
(v) when appropriate, specifications for the input data, or any other relevant information in terms of the data sets used, including their limitation and assumptions, taking into account the intended purpose, the foreseeable and reasonably foreseeable misuses of the AI system.

Amendment 1806
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 13 - paragraph 3 - point d
(d) the human oversight measures referred to in Article 14, including the technical measures put in place to facilitate the interpretation of the outputs of AI systems by the deployers;

Amendment 1807
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 13 - paragraph 3 - point e a (new)
(e a) a description of the mechanisms included within the AI system that allow users to properly collect, store and interpret the logs in accordance with Art 12(1), where relevant.

Amendment 1808
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş,
Article 13 - paragraph 3 - point e a (new)
(e a) a description of the mechanisms included within the AI system that allow users to properly collect, store and interpret the logs in accordance with Article 12(1).

Amendment 1809
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 13 - paragraph 3 - point e a (new)
(e a) the level of extraction and consumption of natural resources.

Amendment 1810
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 13 a (new)
Article 13 a', 'Transparency for affectees of AI systems', '1) High-risk AI systems shall be designed, developed and used in such a way that an affectee can obtain an explanation from the developer and user for any decision taken or supported by a high-risk AI system that significantly affects the affectee;', "2) Providers and users of high-risk AI systems shall provide access to the person of persons designated with the exercise of 'human oversight' as described in Art. 14 to discuss and to clarify the facts, circumstances and reasons having led to the decision by the AI system;", '3) Providers and users of high-risk AI systems shall provide the affectee with a written statement of the reasons for any decision taken or supported by a high-risk AI system;', '4) Where the affectee is not satisfied with the explanation or the written statement of reasons obtained or consider that the decision referred to in paragraph (1) jeopardizes their health, safety or fundamental rights, the provider or user, as the case may be, shall review that decision, upon reasonable request by the affectee. The provider or user, as the case maybe, shall respond to such request by providing the affectee with a substantiated reply without undue delay and in any event within one week of receipt of the request.

Amendment 1811
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 14 - paragraph 1
1. Where proportionate to the risks associated with the high-risk system and where technical safeguards are not sufficient, high-risk AI systems shall be designed and developed in such a way, including with appropriate human-machine interface tools, that they allow informed oversight by natural persons during the expected lifetime of the device. Oversight capabilities should be tailored to the AI system’s intended purpose and the context of use and take into account cases where human oversight may compromise the correct and safe functioning of the AI system.

Amendment 1812
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Article 14 - paragraph 1
1. Where proportionate to the risks associated with the high-risk system and where technical safeguards are not sufficient, high-risk AI systems shall be designed and developed in such a way, including with appropriate human-machine interface tools, that they can be effectively overseen by natural persons during the period in which the AI system is in use.

Amendment 1813
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Article 14 - paragraph 1
1. High-risk AI systems shall be designed and developed in such a way, including with appropriate human-machine interface tools, that they can be effectively overseen by natural persons during the period in which the AI system is in use, where required by the risk analysis as foreseen in the product legislations listed in Annex II.

Amendment 1814
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 14 - paragraph 1
1. High-risk AI systems shall be designed and developed in such a way, including with appropriate human-machine interface tools, that they can be effectively overseen by natural persons during the period in which the AI system is in use, and to allow for thorough investigation after an incident.

Amendment 1815
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 14 - paragraph 2
2. Human oversight shall aim at preventing or minimising the risks to health, safety or fundamental rights that may emerge when a high-risk AI system is used in accordance with its intended purpose or under conditions of reasonably foreseeable misuse, provided that those risks, if they persist notwithstanding the application of other requirements set out in this Chapter, do not result in a requirement for the high-risk AI system to be recalled or withdrawn.

Amendment 1816
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst, Kateřina Konečná
Article 14 - paragraph 2
2. Human oversight shall aim at preventing or minimising the risks to health, safety or fundamental rights that may emerge when AI systems that pose risks to health and safety or fundamental rights or AI systems subjected to the transparency obligations ex Article 52 are used in accordance with their foreseeable uses or under conditions of reasonably foreseeable misuse, in particular when such risks persist notwithstanding the application of other requirements set out in this Chapter.

Amendment 1817
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 14 - paragraph 2
2. Human oversight shall aim at preventing or minimising the risks to health, safety, fundamental rights, democracy, or the environment that may emerge when a high-risk AI system is used in accordance with its intended purpose or under conditions of reasonably foreseeable use or misuse, in particular when such risks persist notwithstanding the application of other requirements set out in this Chapter.

Amendment 1818
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Article 14 - paragraph 2
2. Human oversight shall aim at preventing or minimising the risks to health, safety or fundamental rights that may emerge when a high-risk AI system is used in accordance with its intended purpose, in particular when such risks persist notwithstanding the application of other requirements set out in this Chapter.

Amendment 1819
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 14 - paragraph 3 - introductory part
3. The degree of human oversight shall be adapted to the specific risks, the level of automation, and context of the AI system and shall be ensured through either one or all of the following types of measures:

Amendment 1820
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Article 14 - paragraph 3 - introductory part
3. The degree of human oversight shall be adapted to the specific risks, the level of automation, and context of the AI system and shall be ensured through either one or all of the following measures:

Amendment 1821
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 14 - paragraph 3 - introductory part
3. Human oversight shall be ensured through either one or both of the following:

Amendment 1822
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 14 - paragraph 3 - point a
(a) measures identified by the provider building human oversight, when technically feasible, into the high-risk AI system before it is placed on the market or put into service;

Amendment 1823
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 14 - paragraph 3 - point a
(a) identified and built, when technically feasible and appropriate, into the high-risk AI system by the provider before it is placed on the market or put into service;

Amendment 1824
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 14 - paragraph 3 - point b
(b) other measures identified by the provider before placing the high-risk AI system on the market or putting it into service and that are appropriate to be implemented by the deployer, such as user guides.

Amendment 1825
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 14 - paragraph 3 - point b
(b) identified by the provider operationalized before placing the high-risk AI system on the market or putting it into service and that are appropriate to be implemented by the user;

Amendment 1826
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 14 - paragraph 3 - point b a (new)
(b a) required of the user, if appropriate, for their implementation;

Amendment 1827
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 14 - paragraph 3 - point b b (new)
(b b) included during the development, testing, or monitoring processes.

Amendment 1828
EPP - Group of the European Peoples Party (Christian Democrats)
Barbara Thaler, Lukas Mandl, Axel Voss, Deirdre Clune
Article 14 - paragraph 3 a (new)
3 a. The commission, in accordance with the relevant stakeholders, shall provide comprehensive guidelines, in order to clarify the required form of human supervision for high-risk AI systems.

Amendment 1829
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 14 - paragraph 4 - introductory part
4. For the purpose of implementing paragraphs 1 to 3, the high-risk AI system shall be provided to the user in such a way that natural persons to whom human oversight is assigned can do the following, as appropriate and proportionate to the circumstances and instructions for use and in accordance with industry standards:

Amendment 1830
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 14 - paragraph 4 - point a
4. For the purpose of implementing paragraphs 1 to 3, the high-risk AI system shall be provided to the user in such a way that the individuals to whom human oversight is assigned are enabled as appropriate and proportionate, to the circumstances and in accordance with industry standards:

Amendment 1831
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 14 - paragraph 4 - point a
(a) to be aware and sufficiently understand the relevant capacities and limitations of the high-risk AI system and be able to duly monitor its operation, so that signs of anomalies, dysfunctions and unexpected performance can be detected and addressed as soon as possible;

Amendment 1832
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 14 - paragraph 4 - point a
(a) to be aware of and sufficiently understand the capacities and limitations of the high-risk AI system and be able to duly monitor its operation, so that signs of anomalies, dysfunctions and unexpected performance can be detected and addressed as soon as possible;

Amendment 1833
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş,
Article 14 - paragraph 4 - point b
(b) remain aware of the possible tendency of automatically relying or over-relying on the output produced by a high-risk AI system (‘automation bias’);

Amendment 1834
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 14 - paragraph 4 - point b
(b) remain aware of the possible tendency of automatically relying or over-relying on the output produced by a high-risk AI system (‘automation bias’);

Amendment 1835
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 14 - paragraph 4 - point b
(b) mitigate the risk of automatically relying or over-relying on the output produced by a high-risk AI system (‘automation bias’), in particular for high-risk AI systems used to provide information or recommendations for decisions to be taken by natural persons;

Amendment 1836
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 14 - paragraph 4 - point c
(c) to correctly interpret the high-risk AI system’s output, taking into account for example the interpretation tools and methods available;

Amendment 1837
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 14 - paragraph 4 - point c
(c) be able to correctly interpret the high-risk AI system’s output, taking into account, for example, the interpretation tools and methods available;

Amendment 1838
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 14 - paragraph 4 - point d
(d) to be able to decide, in any particular situation, not to use the high-risk AI system or otherwise disregard, override or reverse the output of the high-risk AI system;

Amendment 1839
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 14 - paragraph 4 - point d
(d) be free to decide, in any particular situation, not to use the high-risk AI system or otherwise disregard, override or reverse the output of the high-risk AI system;

Amendment 1840
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 14 - paragraph 4 - point e
(e) be able to intervene on the operation of the high-risk AI system or interrupt, where reasonable and technically feasible, the system through a “stop” button or a similar procedure, except if the human interference increases the risk or would negatively impact the performance in consideration of generally acknowledge state-of-the-art.

Amendment 1841
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 14 - paragraph 4 - point e
(e) to be able to intervene on the operation of the high-risk AI system, halt or interrupt the system where reasonable and technically feasible and except if the human interference increases the risks or would negatively impact the performance in consideration of generally acknowledged state-of-the-art.

Amendment 1842
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 14 - paragraph 4 - point e
(e) be able to intervene in the operation of the high-risk AI system or interrupt the system through a “stop” button or a similar procedure that allows the system to come to a halt in a safe state.

Amendment 1843
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 14 - paragraph 5
5. For high-risk AI systems referred to in point 1(a) of Annex III, the measures referred to in paragraph 3 shall be such as to ensure that, in addition, no action or decision is taken by the user on the basis of the identification resulting from the system unless this has been separately verified and confirmed by at least two natural persons on-site or remotely, except for temporary actions or decisions which cannot be delayed due to safety or security reasons for the purpose of law enforcement.

Amendment 1844
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 14 - paragraph 5
5. For high-risk AI systems referred to in point 1(a) of Annex III, the measures referred to in paragraph 3 shall be such as to ensure that, in addition, no action or decision is taken by the user on the basis of the identification resulting from the system unless this has been verified and confirmed by at least two natural persons separately.

Amendment 1845
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 14 - paragraph 5
5. For high-risk AI systems referred to in point 1(a) and 1(b) of Annex III, the measures referred to in paragraph 3 shall be such as to ensure that, in addition, no action or decision is taken by the deployer on the basis of the output from the system unless this has been verified and confirmed by at least two natural persons.

Amendment 1846
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 14 - paragraph 5 a (new)
5 a. For the purpose of implementing paragraph 2, in the case where the result of an identification is inconclusive, the human oversight requirements from paragraphs 3 to 5 shall be performed directly internally by the closest entity to the user in the supply chain of the high-risk AI system.

Amendment 1847
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 14 - paragraph 5 b (new)
5 b. With the exception of high-risk AI systems referred to in point 1(a) of Annex III, the measures referred to in paragraph 3 shall not be interpreted as requiring a human to review every action or decision taken by the AI system. Full automation of such systems shall be possible provided that technical measures are put in place to comply with provisions in paragraphs 1 to 4.

Amendment 1848
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 15 - paragraph 1
1. High-risk AI systems shall be designed and developed in such a way that they achieve, in the light of their intended purpose and to the extent that can be reasonably expected and is in accordance with relevant industry standards, an appropriate level of accuracy, reliability, robustness and cybersecurity, and the basic pillars of information security and protection, such as confidentiality, integrity and availability as well as to perform consistently in those respects throughout their lifetime while taking their evolving nature into account.

Amendment 1849
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 15 - paragraph 1
1. High-risk AI systems shall be designed and developed in such a way that they achieve, in the light of their intended purpose, the foreseeable uses and reasonably foreseeable misuses, an appropriate level of perfomance (such as accuracy, reliability and true positive rate), robustness and cybersecurity, and perform consistently in those respects throughout their lifecycle.

Amendment 1850
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 15 - paragraph 1
1. High-risk AI systems shall be designed and developed in such a way that they achieve, in the light of their intended purpose and to the extent that can be reasonably expected and is in accordance with relevant industry standards, an appropriate level of accuracy, robustness and cybersecurity, and perform consistently in those respects throughout their lifecycle.

Amendment 1851
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 15 - paragraph 1
1. High-risk AI systems shall be designed and developed in such a way that they achieve security by design and by default, in the light of their intended purpose, an appropriate level of accuracy, reliability, robustness, resilience, safety and cybersecurity throughout their lifecycle.

Amendment 1852
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 15 - paragraph 1 a (new)
1 a. To address the technical aspects of how to measure the appropriate levels of accuracy and robustness in paragraph 1, the European Artificial Intelligence Board shall bring together national metrology and benchmarking authorities and provide non-binding guidance on the matter as per Article 56(2a) of this Regulation.

Amendment 1853
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 15 - paragraph 2
2. The levels of accuracy and the relevant accuracy metrics of high-risk AI systems shall be assessed by an independent entity and declared in the accompanying instructions of use. The language used shall be clear, free of misunderstandings or misleading statements.

Amendment 1854
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 15 - paragraph 2
2. The perfomance metrics and its appropriateness, including the levels of accuracy and the relevant accuracy metrics of high-risk AI systems shall be declared in the accompanying instructions of use.

Amendment 1855
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 15 - paragraph 2
2. The range of expected performance and the operational factors that affect that performance, shall be declared, where possible, in the accompanying instructions of use.

Amendment 1856
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş,
Article 15 - paragraph 2
2. The range of expected performance and the operational factors that affect that performance shall be declared in the accompanying instructions of use.

Amendment 1857
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 15 - paragraph 3 - introductory part
3. High-risk AI systems shall be designed and developed with safety and security by design mechanism by default so that they achieve, in the light of their intended purpose, an appropriate level of cyber resilience as regards errors, faults or inconsistencies that may occur within the system or the environment in which the system operates, in particular due to their interaction with natural persons or other systems.

Amendment 1858
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 15 - paragraph 3 - introductory part
3. High-risk AI systems shall be designed and developed with safety and security-by-design mechanism so that they achieve, in the light of their intended purpose, an appropriate level of cyber resilience as regards to errors, faults or inconsistencies that may occur within the system or the environment in which the system operates, in particular due to their interaction with natural persons or other systems.

Amendment 1859
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 15 - paragraph 3 - introductory part
3. High-risk AI systems shall be robust as regards errors, faults or inconsistencies that may occur within the system or the environment in which the system operates, in particular due to their interaction with natural persons or other systems.

Amendment 1860
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 15 - paragraph 3 - subparagraph 1
The robustness of high-risk AI systems may be achieved through diverse technical redundancy solutions, which may include reasonably designed backup or fail-safe plans by the appropriate provider or user or as mutually agreed by the provider and the user.

Amendment 1861
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 15 - paragraph 3 - subparagraph 2
High-risk AI systems that continue to learn after being put into service shall ensure that 'feedback loops' caused by biased outputs are adequately addressed with appropriate mitigation measures.

Amendment 1862
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 15 - paragraph 3 - subparagraph 2
High-risk AI systems that continue to learn after being placed on the market or put into service shall be developed in such a way to ensure that possibly biased outputs influencing an input for future operations (‘feedback loops’) are duly addressed with appropriate mitigation measures.

Amendment 1863
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 15 - paragraph 3 - subparagraph 2
High-risk AI systems that continue to learn after being placed on the market or put into service shall be developed in such a way to ensure that possibly biased outputs influencing input for future operations (‘feedback loops’) are duly addressed with appropriate mitigation measures.

Amendment 1864
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 15 - paragraph 3 - subparagraph 2 a (new)
It shall be possible for the user, the provider, the national competent authority or authorities and the Commission, as appropriate, to audit and reproduce the functioning of the high-risk AI systems.

Amendment 1865
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 15 - paragraph 3 a (new)
3 a. In accordance with Article 42 (2), the compliance with Article 15 for high-risk AI systems that have already been certified or for which a statement of conformity has been issued under a cybersecurity scheme pursuant to Regulation (EU) 2019/881 shall be assumed.

Amendment 1866
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 15 - paragraph 4 - introductory part
4. High-risk AI systems shall be adequately protected against attempts by unauthorised third parties to alter their use or performance.

Amendment 1867
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 15 - paragraph 4 - subparagraph 1
The technical solutions aimed at ensuring and organisational measures designed to uphold the cybersecurity of high-risk AI systems shall be appropriate to the relevant circumstances and the risks.

Amendment 1868
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 15 - paragraph 4 - subparagraph 1
The technical solutions and organisational measures designed to uphold the cybersecurity of high-risk AI systems shall be appropriate to the relevant circumstances and the risks.

Amendment 1869
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 15 - paragraph 4 - subparagraph 1
The technical and orgaisational measures aimed at ensuring the cybersecurity of high-risk AI systems shall be appropriate to the relevant circumstances and the risks.

Amendment 1870
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 15 - paragraph 4 - subparagraph 2
The technical solutions may include, where appropriate, measures to prevent and control for attacks trying to manipulate the training dataset (‘data poisoning’), inputs designed to cause the model to make a mistake (‘adversarial examples’), or model flaws, or exploratory attacks that may aim to extract knowledge, algorithms, trade secrets or training information from the AI.

Amendment 1871
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 15 - paragraph 4 - subparagraph 2
The technical and orgaisational measures to address AI specific vulnerabilities shall include at least, where appropriate, measures to prevent and control attacks trying to manipulate the training dataset (‘data poisoning’), inputs designed to cause the model to make a mistake (‘adversarial examples’), or model flaws.

Amendment 1872
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 15 - paragraph 4 a (new)
4 a. High risk AI shall be accompanied by security solutions and patches for the lifetime of the product it is embedded in, or in case of the absence of dependence on a specific product, for a time that needs to be stated by the manufacturer and cannot be less then 10 years.

Amendment 1873
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 15 a (new)
Article 15 a', 'Sustainable AI systems reporting', '1. Providers of high-risk AI systems shall make publicly available information on the energy consumption of the AI system, in particular its carbon footprint with regard to the development of hardware, computational resources, as well as algorithm design and training, testing and validating processes of the high-risk AI systems. The provider shall include this information in the technical documentation referred to in Article 11.', '2. The Commission shall develop, by means of an implementing act, a standardised document to facilitate the disclosure of information on the energy used in the training and execution of AI systems and their carbon intensity.

Amendment 1874
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Title III - Chapter 3 - title
3 OBLIGATIONS OF PROVIDERS AND DEPLOYERS OF HIGH-RISK AI SYSTEMS and other parties

Amendment 1875
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 16 - title
Obligations of providers and deployers of high-risk AI systems

Amendment 1876
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Article 16 - paragraph 1 - introductory part
As long as providers of high-risk AI systems exercise full control over the systems, they shall:

Amendment 1877
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 16 - paragraph 1 - introductory part
Providers and, where applicable, deployers of high-risk AI systems shall:

Amendment 1878
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 16 - paragraph 1 - point a
(a) ensure that their high-risk AI systems are compliant with the requirements set out in Chapter 2 of this Title before placing them on the market or putting them into service, and shall be responsible for compliance of these systems after that point only to the extent that they exercise actual control over relevant aspects of the system;

Amendment 1879
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 16 - paragraph 1 - point a
(a) ensure that their high-risk AI systems are compliant with the requirements set out in Chapter 2 of this Title before placing them on the market or putting them into service;

Amendment 1880
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Article 16 - paragraph 1 - point a
(a) ensure that their high-risk AI systems are compliant with the requirements set out in Chapter 2 of this Title as long as the provider exercise control over the AI systems;

Amendment 1881
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 16 - paragraph 1 - point a a (new)
(a a) indicate their name, registered trade name or registered trade mark, the address at which they can be contacted on the high-risk AI system or, where that is not possible, on its packaging or its accompanying documentation, as applicable;

Amendment 1882
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 16 - paragraph 1 - point a a (new)
(a a) indicate their name, registered trade name or registered trade mark, and their address on the high-risk AI system or, where that is not possible, on its packaging or its accompanying documentation, as appropriate;

Amendment 1883
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 16 - paragraph 1 - point a a (new)
(a a) ensure that the performance of their high-risk AI system is measured appropriately, including its level of accuracy, robustness and cybersecurity;

Amendment 1884
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 16 - paragraph 1 - point a a (new)
(a a) ensure that, in the case of a general purpose AI system, the reasonably foreseeable uses of this system are assessed.

Amendment 1885
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 16 - paragraph 1 - point a a (new)
(a a) include name and contact information;

Amendment 1886
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 16 - paragraph 1 - point a b (new)
(a b) provide specifications for the input data, or any other relevant information in terms of the data sets used, including their limitation and assumptions, taking into account of the intended purpose and the foreseeable and reasonably foreseeable misuses of the AI system;

Amendment 1887
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 16 - paragraph 1 - point c
(c) draw-up the technical documentation of the high-risk AI system referred to in Article 18;

Amendment 1888
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 16 - paragraph 1 - point c
(c) keep the documentation referred to in Article 18;

Amendment 1889
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 16 - paragraph 1 - point d
(d) when under their control, keep the logs automatically generated by their high-risk AI systems for a period of at least two years, or as long as is appropriate in the light of the intended purpose of high-risk AI system and applicable legal obligations under Union or national law;

Amendment 1890
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 16 - paragraph 1 - point d
(d) when under their control, keep the logs automatically generated by their high-risk AI systems, in accordance with Article 20;

Amendment 1891
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 16 - paragraph 1 - point d
(d) keep the logs automatically generated by their high-risk AI systems as referred to in Article 20;

Amendment 1892
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 16 - paragraph 1 - point e
(e) ensure that the high-risk AI system undergoes the relevant conformity assessment procedure prior to its placing on the market or putting into service, and ensure it is periodically reviewed;

Amendment 1893
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 16 - paragraph 1 - point e
(e) ensure that the high-risk AI system undergoes the relevant conformity assessment procedure as referred to in Article 43, prior to its placing on the market or putting into service;

Amendment 1894
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 16 - paragraph 1 - point e
(e) ensure that the high-risk AI system undergoes the relevant independent third party assessment procedure, prior to its placing on the market or putting into service;

Amendment 1895
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 16 - paragraph 1 - point e
(e) ensure that the high-risk AI system undergoes the relevant third party conformity assessment procedure, prior to its placing on the market or putting into service;

Amendment 1896
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 16 - paragraph 1 - point e
(e) ensure that the high-risk AI system undergoes the relevant conformity assessment procedure, prior to its placing on the market or putting into service or use;

Amendment 1897
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 16 - paragraph 1 - point e
(e) carry out the relevant conformity assessment procedure, as provided for in Article 19, prior to its placing on the market or putting into service;

Amendment 1898
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 16 - paragraph 1 - point g
(g) take the necessary corrective action, if the high-risk AI system is not in conformity with the requirements set out in Chapter 2 of this Title, before the high-risk AI system concerned is placed on the market, made available on the market or put into service, or before a high-risk AI system that has been withdrawn or recalled is placed on the market, made available on the market or put into service once again;

Amendment 1899
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 16 - paragraph 1 - point g
(g) take the necessary corrective actions as referred to in Article 21, if the high-risk AI system is not in conformity with the requirements set out in Chapter 2 of this Title;

Amendment 1900
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 16 - paragraph 1 - point g
(g) take the necessary corrective actions as referred to in Art 21, if the high-risk AI system is not in conformity with the requirements set out in Chapter 2 of this Title;

Amendment 1901
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 16 - paragraph 1 - point i
(i) affix the CE marking to their high-risk AI systems to indicate the conformity with this Regulation in accordance with Article 49;

Amendment 1902
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Article 16 - paragraph 1 - point j
(j) upon reasoned request of a national competent authority, provide the relevant information and documentation to demonstrate the conformity of the high-risk AI system with the requirements set out in Chapter 2 of this Title.

Amendment 1903
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 16 - paragraph 1 - point j
(j) upon request of a national supervisory authority or a national competent authority, demonstrate the conformity of the high-risk AI system with the requirements set out in Chapter 2 of this Title.

Amendment 1904
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 16 - paragraph 1 - point j
(j) upon reasoned request of a national competent authority, provide the relevant information and documentation to demonstrate the conformity of the high-risk AI system.

Amendment 1905
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 16 - paragraph 1 - point j a (new)
(j a) refrain from placing on the market or putting into service a High-Risk AI system that:', '(i) is not in conformity with the requirements set out in Chapter 2 of this Title;or', '(ii) poses a risk of harm to health, safety or fundamental rights despite its conformity with the requirements set out in Chapter 2 of this Title.

Amendment 1906
ECR - European Conservatives and Reformists Group
Rob Rooken
Article 16 - paragraph 1 - point j a (new)
(j a) conduct and publish a fundamental rights impact assessment.

Amendment 1907
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 16 - paragraph 1 - point j b (new)
(j b) ensure that the individual to whom human oversight is assigned shall either be fully independent from the provider or user or, be adequately protected against negative consequences for their position within the organisation, resulting from or related to their exercise of human oversight.

Amendment 1908
ECR - European Conservatives and Reformists Group
Vincenzo Sofo, Kosma Złotowski
Article 16 - paragraph 1 a (new)
The obligations contained in paragraph 1 shall be without prejudice to obligations applicable to providers of high-risk AI systems arising from Regulation (EU) 2016/679 of the European Parliament and of the Council and Regulation (EU) 2018/1725 of the European Parliament and of the Council

Amendment 1909
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Article 17 - paragraph 1 - introductory part
Article 16 a', 'Obligations of users of high-risk AI systems', 'Users of high-risk AI systems shall conduct and publish a fundamental rights impact assessment, detailing specific information relating to the context of use of the high-risk AI system in question, including:', '(a) the affected persons,', '(b) intended purpose,', '(c) geographic and temporal scope,', '(d) assessment of the legality and fundamental rights impacts of the system,', '(e) compatibility with accessibility legislation,', '(f) potential direct and indirect impact on fundamental rights,', '(g) any specific risk of harm likely to impact marginalised persons or those at risk of discrimination,', '(h) the foreseeable impact of the use of the system on the environment,', '(i) any other negative impact on the public interest,', '(j) clear steps as to how the harms identified will be mitigated and how effective this mitigation is likely to be.

Amendment 1910
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Article 17 - paragraph 1 - introductory part
1. Unless existing risk management systems are already in place to warrant the quality of the high-risk AI systems, providers of high-risk AI systems shall put a quality management system in place that ensures compliance with this Regulation. That system shall be documented in a systematic and orderly manner in the form of written policies, procedures and instructions, and shall include at least the following aspects:

Amendment 1911
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Article 17 - paragraph 1 - introductory part
1. In case there are no risk management systems already in place, providers and users of high-risk AI systems shall implement a quality management system to ensure compliance with this Regulation and corresponding obligations. That system shall be documented in a systematic and orderly manner in the form of written policies, procedures and instructions, and shall include at least the following aspects:

Amendment 1912
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 17 - paragraph 1 - introductory part
1. Providers and, where applicable, deployers of high-risk AI systems shall put a quality management system in place that ensures compliance with this Regulation. That system shall be documented in a systematic and orderly manner in the form of written policies, procedures and instructions, and shall include at least the following aspects:

Amendment 1913
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 17 - paragraph 1 - introductory part
1. Providers of high-risk AI systems shall put a quality management system in place, certified by an independent third party that ensures compliance with this Regulation. That system shall be documented in a systematic and orderly manner in the form of written policies, procedures and instructions, and shall include at least the following aspects:

Amendment 1914
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş,
Article 17 - paragraph 1 - introductory part
1. Providers of high-risk AI systems shall put a quality management system in place that ensures compliance with this Regulation. That system shall be documented in a systematic and orderly manner in the form of written policies, procedures or instructions, and shall include at least the following aspects:

Amendment 1915
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 17 - paragraph 1 - introductory part
1. Providers of high-risk AI systems shall put a quality management system in place that ensures compliance with this Regulation and that shall be incorporated as part of an existing quality management system under sectoral legislation or as provided by the International Organisation for Standardization.

Amendment 1916
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Article 17 - paragraph 1 - point a
deleted

Amendment 1917
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 17 - paragraph 1 - point a
deleted

Amendment 1918
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 17 - paragraph 1 - point b
deleted

Amendment 1919
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 17 - paragraph 1 - point c
deleted

Amendment 1920
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 17 - paragraph 1 - point d
deleted

Amendment 1921
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Article 17 - paragraph 1 - point e
deleted

Amendment 1922
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 17 - paragraph 1 - point e
deleted

Amendment 1923
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 17 - paragraph 1 - point e
(e) technical specifications, including standards, to be applied and, where the relevant harmonised standards are not applied in full, or do not cover all of the relevant requirements, the means to be used to ensure that the high-risk AI system complies with the requirements set out in Chapter 2 of this Title;

Amendment 1924
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 17 - paragraph 1 - point f
deleted

Amendment 1925
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 17 - paragraph 1 - point f
(f) systems and procedures for data management, including data acquisition, data collection, data analysis, data labelling, data storage, data filtration, data mining, data aggregation, data retention and any other operation regarding the data that is performed before and for the purposes of the placing on the market, putting into service, and deployment of high-risk AI systems;

Amendment 1926
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Article 17 - paragraph 1 - point f
(f) systems and procedures for data management, including data collection, data analysis, data labelling, data storage, data filtration, data mining, data aggregation, data retention and any other operation regarding the data that is performed before for the purposes of the placing on the market or putting into service of high-risk AI systems, and after deployment of the high-risk AI;

Amendment 1927
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 17 - paragraph 1 - point f
(f) systems and procedures for data management, including data collection, data analysis, data labelling, data storage, data filtration, data mining, data aggregation, data retention and any other operation regarding the data that is performed before and for the purposes of the placing on the market or putting into service or use of high-risk AI systems;

Amendment 1928
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 17 - paragraph 1 - point g
deleted

Amendment 1929
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 17 - paragraph 1 - point h
deleted

Amendment 1930
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 17 - paragraph 1 - point i
deleted

Amendment 1931
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 17 - paragraph 1 - point i
(i) procedures related to the reporting of serious incidents and of malfunctioning, including near misses, in accordance with Article 62;

Amendment 1932
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 17 - paragraph 1 - point j
(i) procedures related to the reporting of serious incidents and of malfunctioning, including near misses, in accordance with Article 62;

Amendment 1933
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 17 - paragraph 1 - point j
deleted

Amendment 1934
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Article 17 - paragraph 1 - point j
(j) the handling of communication with national competent authorities, competent authorities, including sectoral ones;

Amendment 1935
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Article 17 - paragraph 1 - point k
deleted

Amendment 1936
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 17 - paragraph 1 - point k
deleted

Amendment 1937
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 17 - paragraph 1 - point l
deleted

Amendment 1938
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 17 - paragraph 1 - point m
deleted

Amendment 1939
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 17 - paragraph 2
deleted

Amendment 1940
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Article 17 - paragraph 2
2. The implementation of aspects referred to in paragraph 1 shall be proportionate to the size of the provider’s organisation and can be fulfilled by further elaborating existing quality management systems.

Amendment 1941
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Article 17 - paragraph 2
2. The implementation of aspects referred to in paragraph 1 shall be proportionate to the size of the provider’s and user's organisation.

Amendment 1942
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 17 - paragraph 3
3. This Article applies without prejudice to the obligations for providers that are credit institutions regulated by Directive 2013/36/ EU.

Amendment 1943
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 17 - paragraph 3 a (new)
3 a. High-risk AI systems shall make use of high quality models, that use relevant, justified and reasonable parameters and features and optimise for justified goals;

Amendment 1944
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 17 - paragraph 3 b (new)
3 b. High-risk AI systems shall only be used in a different domain or environment where they are generalisable to such domain or environment

Amendment 1945
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 18
deleted

Amendment 1946
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 18 - paragraph 1
1. The provider shall, for a period of 3 years after the AI system has been placed on the market or put into service, keep at the disposal of the national competent authorities:', '(a) the technical documentation referred to in Article 11 and Annex IV;', '(b) the documentation concerning the quality management system referred to in Article 17;', '(c) the documentation concerning the changes approved by notified bodies where applicable;', '(d) the decisions and other documents issued by the notified bodies where applicable;', '(e) the EU declaration of conformity referred to in Article 48.

Amendment 1947
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 18 - paragraph 1
1. Providers of high-risk AI systems shall draw up the technical documentation referred to in Article 11 in accordance with Annex IV. When applicable, the technical documentation shall be treated as containing trade secrets as regulated by Directive (EU) 2016/943.

Amendment 1948
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 18 - paragraph 1
1. Providers of high-risk AI systems shall draw up the technical documen\xadtation referred to in Article 11 in accordance with Annex IV and make it available at the request of a national competent authority.

Amendment 1949
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 19 - title
Independent Third party Conformity assessment

Amendment 1950
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 19 - paragraph 1
1. Providers of high-risk AI systems shall ensure that their systems undergo an independent third party conformity assessment procedure in accordance with Article 43 and Annex VII, prior to their placing on the market or putting into service. Where the compliance of the AI systems with the requirements set out in Chapter 2 of this Title has been demonstrated following that conformity assessment, the providers shall draw up an EU declaration of conformity in accordance with Article 48 and affix the CE marking of conformity in accordance with Article 49. The conformity assessment shall be publicly available.

Amendment 1951
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 19 - paragraph 1
1. Providers of high-risk AI systems shall ensure that their systems undergo the relevant conformity assessment procedure in accordance with Article 43, before they are placed on the market, made available on the market or put into service. Where the compliance of the AI systems with the requirements set out in Chapter 2 of this Title has been demonstrated following that conformity assessment, the providers shall draw up an EU declaration of conformity in accordance with Article 48 and affix the CE marking of conformity in accordance with Article 49.

Amendment 1952
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 19 - paragraph 1
1. Providers of high-risk AI systems shall ensure that their systems undergo the relevant conformity assessment procedure in accordance with Article 43, prior to their placing on the market or putting into service or use. Where the compliance of the AI systems with the requirements set out in Chapter 2 of this Title has been demonstrated following that conformity assessment, the providers shall draw up an EU declaration of conformity in accordance with Article 48 and affix the CE marking of conformity in accordance with Article 49.

Amendment 1953
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 20 - paragraph 1
1. Providers of high-risk AI systems shall keep the logs automatically generated by their high-risk AI systems, to the extent such logs are under their control by virtue of a contractual arrangement with the user or otherwise by law. The logs shall be kept for a period that is appropriate in the light of the intended purpose of high-risk AI system and applicable legal obligations under Union or national law. When applicable, the automatically generated logs shall be treated as containing trade secrets as regulated by Directive (EU) 2016/943.

Amendment 1954
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 20 - paragraph 1
1. Providers of high-risk AI systems shall guarantee the storage of the logs automatically generated by their high-risk AI systems, where possible on the media employed by users, to the extent such logs are under their control by virtue of a contractual arrangement with the user or otherwise by law. The logs shall be kept for a period that is appropriate in the light of the intended purpose of the high-risk AI system and applicable legal obligations under Union or national law.

Amendment 1955
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 20 - paragraph 1
1. Providers of high-risk AI systems shall keep the logs automatically generated by their high-risk AI systems, to the extent such logs are under their control by virtue of a contractual arrangement with the user or otherwise by law. The logs shall be kept for a period that is appropriate in the light of the intended purpose or reasonably foreseeable use of high-risk AI system and applicable legal obligations under Union or national law.

Amendment 1956
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 20 - paragraph 1
1. Providers of high-risk AI systems shall keep the logs automatically generated by their high-risk AI systems, to the extent such logs are under their control by virtue of a contractual arrangement with the user or otherwise by law. The logs shall be kept for a period that is appropriate in the light of industry standards, the intended purpose of high-risk AI system and applicable legal obligations under Union or national law.

Amendment 1957
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 20 - paragraph 1
1. Providers of high-risk AI systems shall keep the logs automatically generated by their high-risk AI systems, to the extent such logs are under their control by virtue of a contractual arrangement with the deployer or otherwise by law. The logs shall be kept for a period that is appropriate in the light of the intended purpose of high-risk AI system and applicable legal obligations under Union or national law.

Amendment 1958
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 20 - paragraph 1
1. Providers of high-risk AI systems shall keep the logs automatically generated by their high-risk AI systems, to the extent such logs are under their control by law as well as under their factual control and to the extent that it is technically feasible. They shall keep them for a period of at least six months, unless provided otherwise in applicable Union or national law.

Amendment 1959
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 21 - paragraph 1
Providers of high-risk AI systems which consider or have reason to consider that a high-risk AI system which they have placed on the market or put into service is not in conformity with this Regulation shall immediately, where applicable, investigate the causes in collaboration with the user and, take the necessary corrective actions to bring that system into conformity, to withdraw it or to recall it, as appropriate. They shall inform the distributors of the high-risk AI system in question and, where applicable, the authorised representative and importers accordingly.

Amendment 1960
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 21 - paragraph 1
Providers of high-risk AI systems which consider or have reason to consider that a high-risk AI system which they have placed on the market or put into service is not in conformity with this Regulation shall immediately inform the competent authorities and take the necessary corrective actions to bring that system into conformity, to withdraw it, to disable it, or to recall it, as appropriate. They shall inform the distributors and deployers of the high-risk AI system in question and, where applicable, the authorised representative and importers accordingly.

Amendment 1961
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 21 - paragraph 1
Providers of high-risk AI systems which consider or have reason to consider that a high-risk AI system which they have placed on the market or put into service is not in conformity with this Regulation shall immediately take the necessary corrective action to withdraw or recall the system, as appropriate, so as to bring it into conformity. They shall inform the distributors of the high-risk AI system in question and, where applicable, the authorised representative and importers accordingly.

Amendment 1962
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 21 - paragraph 1 a (new)
In the cases referred to in paragraph 1, providers shall immediately inform the distributors of the high-risk AI system and, where applicable, the legal representative, importers and users accordingly. They shall also immediately inform the national supervisory authority and the national competent authorities of the Member States where they made the AI system available or put it into service, and where applicable, the notified body of the non-compliance and of any corrective actions taken.

Amendment 1963
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 22 - paragraph 1
Where the high-risk AI system presents a risk within the meaning of Article 65(1) and that risk is known by the provider of the system, the provider shall immediately inform the national supervisory authority and the national competent authorities of the Member States in which it made the system available and, where applicable, the user, the notified body that issued a certificate for the high-risk AI system, in particular of the non-compliance and of any corrective actions taken. Where applicable, the provider shall also inform the users of the high-risk AI system.

Amendment 1964
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 22 - paragraph 1
Where the high-risk AI system presents a risk within the meaning of Article 65(1) and that risk is known to the provider of the system, that provider shall immediately inform the market surveillance authorities of the Member States in which it made the system available and, where applicable, the notified body that issued a certificate for the high-risk AI system, in particular the nature of the non-compliance and of any relevant corrective actions taken by the provider.

Amendment 1965
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 22 - paragraph 1
Where the high-risk AI system presents a risk within the meaning of Article 65(1) and that risk is known to the provider of the system, that provider shall immediately inform the market surveillance authorities of the Member States in which it made the system available and, where applicable, the notified body that issued a certificate for the high-risk AI system, in particular of the non-compliance and of any corrective actions taken.

Amendment 1966
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 22 - paragraph 1
Where the high-risk AI system presents a risk within the meaning of Article 65(1) and the provider of the system becomes aware of that risk, that provider shall immediately inform the competent authorities of the Member States in which it made the system available and, where applicable, the notified body that issued a certificate for the high-risk AI system, in particular of the non-compliance and of any corrective actions taken.

Amendment 1967
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 23 - title
Cooperation with competent authorities, the AI Office and the Commission

Amendment 1968
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 23 - paragraph 1
Providers of high-risk AI systems shall, upon a reasoned request by a national competent authority, provide that authority with all the information and documentation necessary to demonstrate the conformity of the high-risk AI system with the requirements set out in Chapter 2 of this Title, in a language that can be easily understood by that national competent authority. Upon a reasoned request from a national competent authority, providers shall also give that authority access to the logs automatically generated by the high-risk AI system, to the extent such logs are under their control by virtue of a contractual arrangement with the user or otherwise by law. Any information submitted in accordance with the provision of this article shall be considered by the national competent authority a trade secret of the company that is submitting such information and kept strictly confidential.

Amendment 1969
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Article 23 - paragraph 1
Providers of high-risk AI systems shall, upon request by a national competent authority, provide that authority with all the information and documentation necessary to demonstrate the conformity of the high-risk AI system with the requirements set out in Chapter 2 of this Title, in an official Union language determined by the Member State concerned. Upon a reasoned request from a national competent authority, providers shall also give that authority access to the logs automatically generated by the high-risk AI system, to the extent such logs are under their control by virtue of a contractual arrangement with the user or otherwise by law. Any information submitted in accordance with the provision of this article shall be considered by the national competent authority a trade secret of the company that is submitting such information and kept strictly confidential.

Amendment 1970
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 23 - paragraph 1
Providers of high-risk AI systems and where applicable, users shall, upon request by a national competent authority or where applicable, by the AI Office or the Commission, provide them with all the information and documentation necessary to demonstrate the conformity of the high-risk AI system with the requirements set out in Chapter 2 of this Title, in an official Union language determined by the Member State concerned.

Amendment 1971
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 23 - paragraph 1
Providers and, where applicable, users of high-risk AI systems shall, upon request by a national supervisory authority or a national competent authority or, where applicable, by the Board or the Commission, provide them with all the information and documentation necessary to demonstrate the conformity of the high-risk AI system with the requirements set out in Chapter 2 of this Title, in an official Union language determined by the Member State concerned.

Amendment 1972
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 23 - paragraph 1
Providers of high-risk AI systems shall, upon request by a competent authority, provide that authority with all the information and documentation necessary to demonstrate the conformity of the high-risk AI system with the requirements set out in Chapter 2 of this Title, in an official Union language determined by the Member State concerned. Upon a request from a competent authority, providers shall also give that authority access to the logs automatically generated by the high-risk AI system, to the extent such logs are under their control.

Amendment 1973
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Article 23 - paragraph 1
Providers of high-risk AI systems shall, upon reasoned request by a national competent authority, provide that authority with all the information and documentation they deem necessary to demonstrate the conformity of the high-risk AI system with the requirements set out in Chapter 2 of this Title, in an official Union language determined by the Member State concerned. Upon a reasoned request from a national competent authority, providers shall also give that authority access to the logs automatically generated by the high-risk AI system, to the extent such logs are under their control by virtue of a contractual arrangement with the user or otherwise by law.

Amendment 1974
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 23 - paragraph 1 a (new)
Upon a reasoned request by a national competent authority or, where applicable, by the Commission, providers and, where applicable, users shall also give the requesting national competent authority or the Commission, as applicable, access to the logs automatically generated by the high-risk AI system, to the extent such logs are under their control by virtue of a contractual arrangement with the user or otherwise by law. The national competent authorities or, where applicable, the Commission, shall keep confidential all trade secrets contained in the information received, in accordance with Article 70(2).

Amendment 1975
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 23 - paragraph 1 a (new)
Upon a reasoned request by a national supervisory authority or a national competent authority or, where applicable, by the Board or the Commission, providers and, where applicable, users shall also give them access to the logs automatically generated by the high-risk AI system, to the extent such logs are under their control by virtue of a contractual arrangement with the user or otherwise by law.

Amendment 1976
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 23 a (new)
Article 23 a', 'Clarification of responsibilities along the AI value chain', '1. Concerning high risk AI systems, any natural or legal person shall be considered a new provider for the purposes of this Regulation and shall be subject to the obligations of the provider under Article 16, in any of the following circumstances:', '(a) they put their name or trademark on a high-risk AI system already placed on the market or put into service, without prejudice to contractual arrangements stipulating that the obligations are allocated otherwise;', '(b) they make a substantial modification or modify the intended purpose of a high-risk AI system already placed on the market or put into service;', '(c) they modify the intended purpose of a non high-risk AI system already placed on the market or put into service, in a way which makes the modified system a high-risk AI System;', '(d) they adapt a general purpose AI system system, already placed on the market or put into service, to a specific intended purpose.', '2 . Where the circumstances referred to in paragraphs 1(a), (b) and (c) occur, the former provider shall no longer be considered a provider for the purposes of this Regulation. The former provider shall upon request and without compromising its own intellectual property rights or trade secrets, provide the new provider with all essential, relevant and reasonably expected information that is necessary to comply with the obligations set out in this Regulation.', '3. The original provider of a general purpose AI system shall, without compromising its own intellectual property rights or trade secrets and to the extent appropiate and feasible:', '(a) ensure that the general purpose AI system which may be used as high-risk AI system complies with the requirements established in Article 9, 10, 11, 13(2)/(3) and 15 of this Regulation;', '(b) comply with the obligations set out in Art 16aa, 16e, 16f, 16g, 16i, 16j, 48 and 61 of this Regulation;', '(c) assess the reasonable foreseeable misuses of the general purpose AI system that may arise during the expected lifetime and install mitigation measures against those cases based on the generally acknowledged state of the art;', '(d) provide the new provider referred to in paragraph 1(d) with all essential, relevant and reasonably expected information that is necessary to comply with the obligations set out in this Regulation.', '4. For high-risk AI systems that are safety components of products to which the legal acts listed in Annex II, section A apply, the manufacturer of those products shall be considered the provider of the high-risk AI system and shall be subject to the obligations referred to in Article 16 under either of the following scenarios:', '(i) the high-risk AI system is placed on the market together with the product under the name or trademark of the product manufacturer; or', '(ii) the high-risk AI system is put into service under the name or trademark of the product manufacturer after the product has been placed on the market.', '5. Third parties involved in the sale and the supply of software including general purpose application programming interfaces (API), software tools and components, providers who develop and train AI systems on behalf of a deploying company in accordance with their instruction, or providers of network services shall not be considered providers for the purposes of this Regulation.

Amendment 1977
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Vlad-Marius Botoş, Moritz Körner, Jan-Christoph Oetjen
Article 23 a (new)
Article 23 a', 'Conditions for other persons to be subject to the obligations of a provider', '1. Concerning high risk AI systems any natural or legal person shall be considered a provider for the purposes of this Regulation and shall be subject to the obligations of the provider under Article 16, in any of the following circumstances:', '(a) they put their name or trademark on a high-risk AI system already placed on the market or put into service, without prejudice to contractual arrangements stipulating that the obligationsare allocated otherwise;', '(b) they make a substantial modification to or modify the intended purpose of a high-risk AI system already placed on the market or put into service;', '(c) they modify the intended purpose of a non-high-risk AI system already placed on the market or put it to service, in a way which makes the modified system a high-risk AI system;', '(d) they fulfil the conditions referred in Article 3a(2).', '2. Where the circumstances referred to in paragraph 1 occur, the provider that initially placed the high-risk AI system on the market or put it into service shall no longer be considered a provider for the purposes of this Regulation. The initial provider subject to the previous sentence, shall upon request and without compromising its own intellectual property rights or trade secrets, provide the new provider referred to in paragraph (1a), (1b) or (1c) with all essential, relevant and reasonably expected information that is necessary to comply with the obligations set out in this Regulation.', '3. For high-risk AI systems that are safety components of products to which the legal acts listed in Annex II, section A apply, the manufacturer of those products shall be considered the provider of the high-risk AI system and shall be subject to the obligations referred to in Article 16 under either of the following scenarios:', '(i) the high-risk AI system is placed on the market together with the product under the name or trademark of the product manufacturer; or', '(ii) the high-risk AI system is put into service under the name or trademark of the product manufacturer after the product has been placed on the market.', '4. Third parties involved in the sale and the supply of software including general purpose application programming interfaces (API), software tools and components, providers who develop and train AI systems on behalf of a deploying company in accordance with their instruction, or providers of network services shall not be considered providers for the purposes of this Regulation.

Amendment 1978
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Article 24
deleted

Amendment 1979
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 24
deleted

Amendment 1980
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 25
deleted

Amendment 1981
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 25 - paragraph 1
1. Prior to making their systems available on the Union market providers established outside the Union shall, by written mandate, appoint an authorised representative which is established in the Union.

Amendment 1982
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 25 - paragraph 1
1. Prior to making their systems available on the Union market, providers established outside the Union shall, by written mandate, appoint an authorised representative which is established in the Union.

Amendment 1983
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 25 - paragraph 1 a (new)
1a. As of the time they are appointed, authorised representatives must be able to correspond, exchange technical information and carry out the duties required of them under this Regulation with the national authorities and in the official languages of all the Member States.

Amendment 1984
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 25 - paragraph 2 - introductory part
2. The authorised representative shall perform the tasks specified in the mandate received from the provider. For the purpose of this Regulation, the mandate shall empower the authorised representative to carry out only the following tasks:

Amendment 1985
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 25 - paragraph 2 - point a
(a) carry out or commission the conformity assessment referred to in Article 43;

Amendment 1986
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 25 - paragraph 2 - point a
(a) ensure that the EU declaration of conformity and the technical documentation have been drawn up and that an appropriate conformity assessment procedure has been carried out by the provider;

Amendment 1987
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 25 - paragraph 2 - point b
(b) keep a copy of the EU declaration of conformity and the technical documentation at the disposal of the national competent authorities and national authorities referred to in Article 63(7);

Amendment 1988
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 25 - paragraph 2 - point b
(b) provide a national competent authority with all the information and documentation necessary to demonstrate the conformity of a high-risk AI system with the requirements set out in Chapter 2 of this Title, including access to the logs automatically generated by the high-risk AI system to the extent such logs are under the control of the provider;

Amendment 1989
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 25 - paragraph 2 - point b a (new)
(b a) keep at the disposal of the national competent authorities and national authorities referred to in Article 63(7), for a period ending 3 years after the high-risk AI system has been placed on the market or put into service, a copy of the EU declaration of conformity, the technical documentation and, if applicable, the certificate issued by the notified body;

Amendment 1990
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul Garraud
Article 25 - paragraph 2 - point c
(c) provide a national competent authority, upon a reasoned request, with all the information and documentation necessary to demonstrate the conformity of a high-risk AI system with the requirements set out in Chapter 2 of this Title, including access to the logs automatically generated by the high-risk AI system to the extent such logs are under the control of the provider by virtue of a contractual arrangement with the user or otherwise by law;

Amendment 1991
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz Körner, Jan-
Article 25 - paragraph 2 - point c
(c) cooperate with competent national authorities, upon a reasoned request, on any action the latter takes to reduce and mitigate the risks posed by a high-risk AI system covered by the authorised representative's mandate.

Amendment 1992
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 25 - paragraph 2 - point c
(c) cooperate with national supervisory authorities, upon a reasoned request, on any action the latter takes in relation to the high-risk AI system;

Amendment 1993
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 25 - paragraph 2 - point c a (new)
(c a) comply with the registration obligations referred to in Article 51 or, if the registration is carried out by the provider itself, ensure that the information referred to in point 3 of Annex VIII is correct.

Amendment 1994
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 25 - paragraph 2 - point c a (new)
(ca) cooperate with competent national authorities, upon a reasoned request, on any action the latter takes in relation to the high-risk AI system.

Amendment 1995
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 25 - paragraph 2 - subparagraph 1 (new)
The authorised representative shall terminate the mandate if it considers or has reason to consider that the provider acts contrary to its obligations under this Regulation. In such a case, it shall also immediately inform the market surveillance authority of the Member State in which it is established, as well as, where applicable, the relevant notified body, about the termination of the mandate and the reasons thereof.

Amendment 1996
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 26 - paragraph 1 - introductory part
1. Before placing a high-risk AI system on the market, importers of such system shall ensure that such a system is in conformity with this Regulation by ensuring that:

Amendment 1997
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 26 - paragraph 1 - point a
(a) the appropriate conformity assessment procedure has been carried out by the provider of that AI system following its import and prior to its deployment;

Amendment 1998
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 26 - paragraph 1 - point a
(a) the relevant conformity assessment procedure referred to in Article 43 has been carried out by the provider of that AI system;

Amendment 1999
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 26 - paragraph 1 - point c
(c) the system bears the required conformity marking and is accompanied by the required documentation and instructions of use;

Amendment 2000
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 26 - paragraph 1 - point c a (new)
(c a) the authorised representative referred to in Article 25 has been established by the Provider.

Amendment 2001
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 26 - paragraph 2
2. Where an importer considers or has reason to consider that a high-risk AI system is not in conformity with this Regulation, or is falsified, or accompanied by falsified documentation it shall not place that system on the market until that AI system has been brought into conformity. Where the high-risk AI system presents a risk within the meaning of Article 65(1), the importer shall inform the provider of the AI system and the market surveillance authorities to that effect.

Amendment 2002
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 26 - paragraph 3
3. Importers shall indicate their name, registered trade name or registered trade mark, and the address at which they can be contacted on the high-risk AI system and, on its packaging or its accompanying documentation, where applicable.

Amendment 2003
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 26 - paragraph 4
4. Importers shall keep, for a period ending 3 years after the AI system has been placed on the market or put into service, a copy of the certificate issued by the notified body, where applicable, of the instructions for use and of the EU declaration of conformity.

Amendment 2004
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 26 - paragraph 5
5. Importers shall provide the national supervisory authority and the national competent authorities, upon a reasoned request, with all the necessary information and documentation to demonstrate the conformity of a high-risk AI system with the requirements set out in Chapter 2 of this Title in a language which can be easily understood by them, including access to the logs automatically generated by the high-risk AI system to the extent such logs are under the control of the provider by virtue of a contractual arrangement with the user or otherwise by law. They shall also cooperate with those authorities on any action the national supervisory authority and the national competent authority take in relation to that system.

Amendment 2005
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 26 - paragraph 5
5. Importers shall provide national competent authorities, upon request, with all necessary information and documentation to demonstrate the conformity of a high-risk AI system with the requirements set out in Chapter 2 of this Title in a language which can be easily understood by that national competent authority, including access to the logs automatically generated by the high-risk AI system to the extent such logs are under the control of the provider. They shall also cooperate with those authorities on any action national competent authority takes in relation to that system.

Amendment 2006
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 26 - paragraph 5
5. Where no authorised representative has been established, importers shall provide national competent authorities, upon a reasoned request, with all necessary information and documentation to demonstrate the conformity of a high-risk AI system with the requirements set out in Chapter 2 of this Title in a language which can be easily understood by that national competent authority. To this purpose they shall also ensure that the technical documentation can be made available to those authorities.

Amendment 2007
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 26 - paragraph 5
5. Importers shall provide national competent authorities, upon a reasoned request, with all necessary information and documentation to demonstrate the conformity of a high-risk AI system with the requirements set out in Chapter 2 of this Title in an official language of that national competent authority, including access to the logs automatically generated by the high-risk AI system to the extent such logs are under the control of the provider by virtue of a contractual arrangement with the user or otherwise by law. They shall also cooperate with those authorities on any action national competent authority takes in relation to that system.

Amendment 2008
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 26 - paragraph 5 a (new)
5 a. Importers shall cooperate with national competent authorities on any action those authorities take in relation to an AI system.

Amendment 2009
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 27 - paragraph 1
1. Before making a high-risk AI system available on the market, distributors shall verify that the high-risk AI system bears the required CE conformity marking, that it is accompanied by the required documentation and instruction of use, and that the provider and the importer of the system, as applicable, have complied with their obligations set out in this Regulation in Article 16 and Article 26(3), respectively.

Amendment 2010
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 27 - paragraph 2
2. Where a distributor considers or has reason to consider, on the basis of the information in its possession, that a high-risk AI system is not in conformity with the requirements set out in Chapter 2 of this Title, it shall not make the high-risk AI system available on the market until that system has been brought into conformity with those requirements. Furthermore, where the system presents a risk within the meaning of Article 65(1), the distributor shall inform the provider or the importer of the system, as applicable, to that effect, and the market surveillance authorities.

Amendment 2011
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 27 - paragraph 2
2. Where a distributor considers or has reason to consider that a high-risk AI system is not in conformity with the requirements set out in Chapter 2 of this Title, it shall not make the high-risk AI system available on the market until that system has been brought into conformity with those requirements. Furthermore, where the system presents a risk within the meaning of Article 65(1), the distributor shall inform the provider or the importer of the system as well as the market surveillance authorities, as applicable, to that effect.

Amendment 2012
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 27 - paragraph 2
2. Where a distributor considers or has reason to consider that a high-risk AI system is not in conformity with the requirements set out in Chapter 2 of this Title, it shall not make the high-risk AI system available on the market until that system has been brought into conformity with those requirements. Furthermore, where the system presents a risk within the meaning of Article 65(1), the distributor shall inform the market surveillance authority and the provider or the importer of the system, as applicable, to that effect.

Amendment 2013
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 27 - paragraph 2
2. Where a distributor considers or has reason to consider that a high-risk AI system is not in conformity with the requirements set out in Chapter 2 of this Title, it shall not make the high-risk AI system available on the market until that system has been brought into conformity with those requirements. Furthermore, where the system presents a risk within the meaning of Article 65(1), the distributor shall inform the competent authorities and the provider or the importer of the system, as applicable, to that effect.

Amendment 2014
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 27 - paragraph 4
4. A distributor that considers, on the basis of the information in its possession, or has reason to consider that a high-risk AI system which it has made available on the market is not in conformity with the requirements set out in Chapter 2 of this Title shall take the corrective actions necessary to bring that system into conformity with those requirements, to withdraw it or recall it or shall ensure that the provider, the importer or any relevant operator, as appropriate, takes those corrective actions. Where the high-risk AI system presents a risk within the meaning of Article 65(1), the distributor shall immediately inform the provider or importer of the system and the national competent authorities of the Member States in which it has made the product available to that effect, giving details, in particular, of the non-compliance and of any corrective actions taken.

Amendment 2015
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 27 - paragraph 4
4. A distributor that considers or has reason to consider that a high-risk AI system which it has made available on the market is not in conformity with the requirements set out in Chapter 2 of this Title shall take the corrective actions necessary to bring that system into conformity with those requirements, to withdraw it or recall it or shall ensure that the provider, the importer or any relevant operator, as appropriate, takes those corrective actions. Where the high-risk AI system presents a risk within the meaning of Article 65(1), the distributor shall immediately inform the provider or the importer of the system as well as the national competent authorities of the Member States in which it has made the product available to that effect, giving details, in particular, of the non-compliance and of any corrective actions taken.

Amendment 2016
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 27 - paragraph 4
4. A distributor that considers or has reason to consider that a high-risk AI system which it has made available on the market is not in conformity with the requirements set out in Chapter 2 of this Title shall take the corrective actions necessary to to withdraw or recall that system in order to bring it into conformity with those requirements, or shall ensure that the provider, the importer or any relevant operator, as appropriate, takes those corrective actions. Where the high-risk AI system presents a risk within the meaning of Article 65(1), the distributor shall immediately inform the national competent authorities of the Member States in which it has made the product available to that effect, giving details, in particular, of the non-compliance and of any corrective actions taken.

Amendment 2017
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 27 - paragraph 4
4. A distributor that considers or has reason to consider that a high-risk AI system which it has made available on the market is not in conformity with the requirements set out in Chapter 2 of this Title shall take the corrective actions necessary to bring that system into conformity with those requirements, to withdraw it or recall it or shall ensure that the provider, the importer or any relevant operator, as appropriate, takes those corrective actions. Where the high-risk AI system presents a risk within the meaning of Article 65(1), the distributor shall immediately inform the competent authorities of the Member States in which it has made the product available to that effect, giving details, in particular, of the non-compliance and of any corrective actions taken.

Amendment 2018
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Article 27 - paragraph 5
5. Upon a reasoned request from a national competent authority, distributors of high-risk AI systems shall provide that authority with all the information and documentation regarding its activities pursuant to paragraphs 1 to 4.

Amendment 2019
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 27 - paragraph 5
5. Upon a reasoned request from a national competent authority, distributors of high-risk AI systems shall provide that authority with all the information and documentation in its possession or available to it, in accordance with the obligations of distributors as outlined by this Regulation, that are necessary to demonstrate the conformity of a high-risk system with the requirements set out in Chapter 2 of this Title. Distributors shall also cooperate with that national competent authority on any action taken by that authority.

Amendment 2020
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 27 - paragraph 5
5. Upon a reasoned request from a national competent authority and where no authorised representative has been appointed, distributors of high-risk AI systems shall provide that authority with all the information and documentation regarding its activities as described in paragraphs 1 to 4.

Amendment 2021
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 27 - paragraph 5
5. Upon request from a competent authority, distributors of high-risk AI systems shall provide that authority with all the information and documentation necessary to demonstrate the conformity of a high-risk system with the requirements set out in Chapter 2 of this Title. Distributors shall also cooperate with that competent authority on any action taken by that authority.

Amendment 2022
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 27 - paragraph 5 a (new)
5 a. Importers shall cooperate with national competent authorities on any action those authorities take in relation to an AI system.

Amendment 2023
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 28
deleted

Amendment 2024
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Vlad-Marius Botoş, Moritz Körner, Jan-Christoph Oetjen
Article 28
deleted

Amendment 2025
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 28 - title
Obligations of distributors, importers, deployers or any other third-party

Amendment 2026
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 28 - paragraph 1 - introductory part
1. Any distributor, importer, user or other third-party shall be considered a provider of a high-risk AI system for the purposes of this Regulation and shall be subject to the obligations of the provider under Article 16, in any of the following circumstances:

Amendment 2027
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 28 - paragraph 1 - introductory part
1. Any distributor, importer, deployer or other third-party shall be considered a provider for the purposes of this Regulation and shall be subject to the obligations of the provider under Article 16, in any of the following circumstances:

Amendment 2028
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 28 - paragraph 1 - point b
(b) they modify the intended purpose or reasonably foreseeable use of a high-risk AI system already placed on the market or put into service;

Amendment 2029
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 28 - paragraph 1 - point b a (new)
(ba) they have placed on the market or put into service a high-risk AI system which they have substantially modified by their own means;

Amendment 2030
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 28 - paragraph 1 - point b a (new)
(b a) they deploy a high-risk system for a purpose other than the intended purpose;

Amendment 2031
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 28 - paragraph 1 - point c a (new)
(c a) they modify the intended purpose of an AI system which is not high-risk and is already placed on the market or put into service, in a way which makes the modified system a high-risk AI system.

Amendment 2032
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 28 - paragraph 1 - point c a (new)
(c a) they modify the intended purpose of an AI system which is not high-risk and is already placed on the market or put into service, in a way which makes the modified system a high-risk AI system.

Amendment 2033
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 28 - paragraph 2 a (new)
2 a. Providers that initially placed the high-risk AI system on the market or put it into service shall cooperate closely with distributors, importers, users, or other third-parties to supply them with the necessary information or documentation in their possession that is required for the fulfilment of the obligations set out in this Regulation, in particular at the moment when such distributors, importers, users or other third-parties become the new providers as determined in paragraph 1 and the initial providers are no longer considered a provider for the purposes of this Regulation as determined in paragraph 2.

Amendment 2034
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst, Kateřina Konečná
Article 28 a (new)
Article 28 a', 'Obligations of employers', '1. Employers shall have the following additional obligations when deploying AI surveillance or monitoring systems in the workplace:', '(a) consult trade unions on the use of high risk and intrusive forms of AI in the workplace;', '(b) ensure that workers are aware of the AI systems at the workplace, including their impact on data, digital footprint and work organisation;', '(c) ensure a human review of decisions made by AI systems that could affect the worker;', '(d) deliver an annual conformity assessment for workplace-based AI to guard against discrimination by algorithm.

Amendment 2035
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 29 - title
29 Obligations of deployers of high-risk AI systems', '(This amendment applies throughout the text. Adopting it will necessitate corresponding changes throughout.)

Amendment 2036
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 29 - paragraph -1 (new)
-1. Users of high-risk AI systems shall ensure that natural persons assigned to ensure or entrusted with human oversight for high-risk AI systems are competent, properly qualified and trained, free from external influence and neither seek nor take instructions from anybody. They shall have the necessary resources in order to ensure the effective supervision of the system in accordance with Article 14.

Amendment 2037
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 29 - paragraph 1
1. Users of high-risk AI systems shall use such systems and implement human oversight in accordance with the instructions of use accompanying the systems, pursuant to paragraphs 2 and 5 of this Article. Users shall bear sole responsibility in case of any use of the AI system that is not in accordance with the instructions of use accompanying the systems.

Amendment 2038
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 29 - paragraph 1
1. Deployers of high-risk AI systems shall take appropriate technical and organisational measures and ensure that the use of such systems is in accordance with the instructions of use accompanying the systems and enables human oversight and decision-making, pursuant to paragraphs 2 and 5.

Amendment 2039
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,
Article 29 - paragraph 1
1. Users of high-risk AI systems shall use such systems and implement human oversight in accordance with the instructions of use accompanying the systems, pursuant to paragraphs 2 and 5 of this article.

Amendment 2040
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 29 - paragraph 1
1. Users of high-risk AI systems shall use such systems and implement human oversight in accordance with the instructions of use accompanying the systems, pursuant to paragraphs 2 and 5.

Amendment 2041
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 29 - paragraph 1 a (new)
1. Users shall bear sole responsibility in case of any use of the AI system that is not in accordance with the instructions of use accompanying the systems.

Amendment 2042
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 29 - paragraph 1 a (new)
1 a. To the extent the user exercises control over the high-risk AI system, that user shall only assign human oversight to natural persons who have the necessary competence, training and authority as well as ensure that relevant and appropriate robustness and cybersecurity measures are in place and are regularly adjusted or updated.

Amendment 2043
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 29 - paragraph 1 a (new)
1 a. Deployers shall identify the categories of natural persons and groups likely to be affected by the system before putting it into use.

Amendment 2044
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,
Article 29 - paragraph 1 a (new)
1 a. Users shall assign human oversight to natural persons who have the necessary competence, training and authority.

Amendment 2045
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 29 - paragraph 1 b (new)
1 b. Human oversight following paragraph 1 shall be carried out by natural persons having the necessary competences, training, authority and independence.

Amendment 2046
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 29 - paragraph 2
2. The obligations in paragraph 1 are without prejudice to other user obligations under Union or national law and to the user’s discretion in organising its own resources and activities for the purpose of implementing the human oversight measures indicated by the provider.', 'This regulation does not conflict with the scope of Art. 153 TFEU, which sets minimum requirements for Member States that may be exceeded.

Amendment 2047
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 29 - paragraph 2
2. The obligations in paragraph 1 are without prejudice to other deployer obligations under Union or national law and shall take due account of the deployer's discretion in organising its own resources and activities for the purpose of implementing the human oversight measures indicated by the provider.

Amendment 2048
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 29 - paragraph 2
2. The obligations in paragraph 1 and 1a are without prejudice to other user obligations under Union or national law and to the user’s discretion in organising its own resources and activities for the purpose of implementing the human oversight measures indicated by the provider.

Amendment 2049
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 29 - paragraph 3
3. Without prejudice to paragraph 1, to the extent the user exercises control over the input data, that user shall ensure that input data is relevant in view of the intended purpose of the high-risk AI system. To the extent the user exercises control over the high-risk AI system, that user shall also ensure that relevant and appropriate robustness and cybersecurity measures are in place and are regularly adjusted or updated.

Amendment 2050
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 29 - paragraph 3
3. Without prejudice to paragraph 1, to the extent the user exercises control over the input data, that user shall ensure that input data is relevant in view of the intended purpose of the high-risk AI system. To the extent the user exercises control over the high-risk AI system, that user shall also ensure that relevant and appropriate robustness and cybersecurity measures are in place and are regularly adjusted or updated.

Amendment 2051
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 29 - paragraph 3
3. Without prejudice to paragraph 1, to the extent the user exercises control over the input data, that user shall ensure that input data is relevant and sufficiently representative in view of the intended purpose of the high-risk AI system.

Amendment 2052
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 29 - paragraph 3
3. Without prejudice to paragraph 1, to the extent the user exercises control over the input data, that user shall ensure that input data is relevant in view of the intended purpose or reasonably foreseeable use of the high-risk AI system.

Amendment 2053
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 29 - paragraph 4 - introductory part
4. Users shall monitor the operation of the high-risk AI system on the basis of the instructions of use and, when relevant, inform providers in accordance with Article 61. To the extent the user exercises control over the high-risk AI system, users shall also perform risk assessments in line with Article 9 but limited to the potential adverse effects of using the high-risk AI system and the respective mitigation measures. When they have reasons to consider that the use in accordance with the instructions of use may result in the AI system presenting a risk within the meaning of Article 65(1) they shall inform the provider or distributor and relevant regulatory authority and suspend the use of the system. They shall also inform the provider or distributor and relevant regulatory authority when they have identified any serious incident and interrupt the use of the AI system. In case the user is not able to reach the provider, importer or distributer Article 62 shall apply mutatis mutandis.

Amendment 2054
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz Körner, Jan-
Article 29 - paragraph 4 - introductory part
4. Users shall monitor the operation of the high-risk AI system on the basis of the instructions of use and, when relevant, inform providers in accordance with Article 61. To the extent the user exercises control over the high-risk AI system, the user shall also establish a risk management system in line with Article 9 but limited to the potential adverse effects of using the high-risk AI system, the respective mitigation measures. When they have reasons to consider that the use in accordance with the instructions of use may result in the AI system presenting a risk within the meaning of Article 65(1) they shall inform the provider or distributor and suspend the use of the system. They shall also inform the provider or distributor when they have identified any serious incident or any malfunctioning within the meaning of Article 62 and interrupt the use of the AI system. In case the user is not able to reach the provider, Article 62 shall apply mutatis mutandis.

Amendment 2055
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 29 - paragraph 4 - introductory part
4. Users shall monitor the operation of the high-risk AI system on the basis of the instructions of use. When they have reasons to consider that the use in accordance with the instructions of use may result in the AI system presenting a risk within the meaning of Article 65(1) they shall inform the national competent authorities and the provider or distributor and suspend the use of the system. They shall also inform the national competent authorities and the provider or distributor when they have identified any serious incident or any malfunctioning, including near misses, within the meaning of Article 62 and interrupt the use of the AI system. In case the user is not able to reach the provider, Article 62 shall apply mutatis mutandis.

Amendment 2056
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 29 - paragraph 4 - introductory part
4. Users shall monitor the operation of the high-risk AI system on the basis of the instructions of use. When they have reasons to consider that the use in accordance with the instructions of use may result in the AI system presenting a risk within the meaning of Article 65(1) they shall immediately inform the provider or distributor and suspend the use of the system. They shall also immediately inform the provider or distributor when they have identified any serious incident or any malfunctioning, including near misses, within the meaning of Article 62 and interrupt the use of the AI system. In case the user is not able to reach the provider, Article 62 shall apply mutatis mutandis.

Amendment 2057
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 29 - paragraph 5 - introductory part
5. Users of high-risk AI systems shall keep the logs automatically generated by that high-risk AI system, to the extent such logs are under their control. The logs shall be kept for a period that is appropriate in the light of the intended purpose or reasonably foreseeable use of the high-risk AI system and applicable legal obligations under Union or national law.

Amendment 2058
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 29 - paragraph 5 - introductory part
5. Users of high-risk AI systems shall keep the logs automatically generated by that high-risk AI system, to the extent such logs are under their control. They shall keep them for a period of at least six months, unless provided otherwise in applicable Union or national law.

Amendment 2059
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 29 - paragraph 5 - introductory part
5. Users of high-risk AI systems shall keep the logs automatically generated by that high-risk AI system, to the extent such logs are under their control. The logs shall be kept for a period that is appropriate in the light of industry standards, the intended purpose of the high-risk AI system and applicable legal obligations under Union or national law.

Amendment 2060
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 29 - paragraph 5 - subparagraph 1 a (new)
Prior to putting into service or use an AI system at the workplace, users shall consult workers representatives, inform the affected employees that they will be subject to the system and obtain their consent.

Amendment 2061
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Andrzej Halicki, Adam Jarubas, Jerzy Buzek, Janusz Lewandowski,
Article 29 - paragraph 5 a (new)
5 a. Users of high-risk AI systems which affect natural persons, in particular, by evaluating or assessing them, making predictions about them, recommending information, goods or services to them or determining or influencing their access to goods and services, shall inform the natural persons that they are subject to the use of such an high-risk AI system.', 'This information shall include a clear and concise indication of the user and the purpose of the high-risk AI system, information about the rights of the natural person conferred under this Regulation, and a reference to publicly available resource where more information about the high-risk AI system can be found, in particular the relevant entry in the EU database referred to in Article 60, if applicable.This information shall be presented in a concise, intelligible and easily accessible form, including for persons with disabilities.', 'This obligation shall be without prejudice to other Union or Member State laws, in particular Regulation 2016/679 [GDPR], Directive 2016/680 [LED], Regulation 2022/XXX [DSA].

Amendment 2062
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 29 - paragraph 5 a (new)
5 a. Users of high-risk AI systems that are public authorities or Union institutions, bodies, offices and agencies shall conduct a fundamental rights impact assessment prior to commencing the use of a high-risk AI system;

Amendment 2063
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 29 - paragraph 5 a (new)
5 a. Users of high-risk AI systems shall comply with the registration obligations referred to in Article 51.

Amendment 2064
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 29 - paragraph 6
6. Users of high-risk AI systems shall use the information provided under Article 13 to comply with their obligation to carry out a data protection impact assessment under Article 35 of Regulation (EU) 2016/679 or Article 27 of Directive (EU) 2016/680, and may revert in part to those data protection impact assessments for fulfilling the obligations set out in this article.

Amendment 2065
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 29 - paragraph 6
6. Users of high-risk AI systems shall use the information provided under Article 13 to comply with their obligation to carry out a data protection impact assessment under Article 35 of Regulation (EU) 2016/679 or Article 27 of Directive (EU) 2016/680 and may revert in part to those data protection impact assessments for fulfilling the obligations set out in this Article.

Amendment 2066
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 29 - paragraph 6
6. Users of high-risk AI systems shall use the information provided under Article 13 to comply with their obligation to carry out a data protection impact assessment under Article 35 of Regulation (EU) 2016/679 or Article 27 of Directive (EU) 2016/680, where applicable.', 'The data protection impact assessment shall be published.

Amendment 2067
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 29 - paragraph 6 a (new)
6 a. Users of high-risk AI systems shall carry out a human rights impact assessment for the different uses of the system, containing specific information on the context of use of that system, including, the intended purpose or reasonable foreseeably use, geographic and temporal scope, assessment of the legality and fundamental rights impacts of the system, any specific risk of harm likely to impact marginalised persons or those at risk of discrimination, any other negative impact on the public interest;and clear steps as to how the harms identified will be mitigated, and how effective this mitigation is likely to be.', 'The human rights impact assessment shall be published, and be registered by the user in the database referred to under Article 60.

Amendment 2068
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz Körner, Jan-
Article 29 - paragraph 6 a (new)
6 a. Where a user of a high risk AI system is obliged pursuant to Regulation (EU) 2016/679 to provide information regarding the use of automated decision making procedures, the user shall not be obliged to provide information on how the AI system reached a specific result. When fulfilling the information obligations under Regulation (EU) 2016/679, the user shall not be obliged to provide information beyond the information he or she received from the provider under Article 13 of this Regulation.

Amendment 2069
ECR - European Conservatives and Reformists Group
Vincenzo Sofo, Kosma Złotowski
Article 29 - paragraph 6 a (new)
6 a. Users of high risk systems involving an emotion recognition system or a biometric categorisation system in accordance with Article 52 shall implement suitable measures to safeguard the natural person's rights and freedoms and legitimate interests in such a system, including providing the natural person with the ability to express his or her point of view on the resulting categorisation and to contest the decision.

Amendment 2070
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Patryk Jaki, Adam Bielan
Article 29 - paragraph 6 a (new)
6 a. Users shall monitor the performance of high-risk AI systems deployed by end-users and shall ensure that all possible malfunctioning and performance issues are recorded, and when not able to justify or ensure proper performance, communicated to the AI provider. In such cases, the provider and the user shall coordinate to establish the cause of a possible malfunctioning or performance issue.

Amendment 2071
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 29 - paragraph 6 a (new)
6 a. Users of high-risk AI systems shall refrain from placing on the market or putting into service a high-risk AI system that:', '(i) is not in conformity with the requirements set out in Chapter 2 of this Title;or', '(ii) poses a risk of harm to health, safety or fundamental rights despite its conformity with the requirements set out in Chapter 2 of this Title.

Amendment 2072
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 29 - paragraph 6 a (new)
6 a. Users of high-risk AI systems referred to in Annex III that make decisions or assist in making decisions related to an affected person, shall inform them that they are subject to the use of the high-risk AI system. This information shall include the type of the AI system used, its intended purpose and the type of decisions it makes.

Amendment 2073
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 29 - paragraph 6 a (new)
6 a. Users of high risk AI systems, who modify or extend the purpose for which the conformity of the AI system was originally assessed, shall establish and document a post-market monitoring system (Art. 61)and must undergo a new conformity assessment (Art. 43) involved by a notified body.

Amendment 2074
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 29 - paragraph 6 a (new)
6 a. The provider shall be obliged to cooperate closely with the user and in particular provide the user with the necessary information to allow the fulfilment of the obligations set out in this Article.

Amendment 2075
ECR - European Conservatives and Reformists Group
Rob Rooken
Article 29 - paragraph 6 a (new)
6 a. Users of high-risk AI systems shall conduct and publish a fundamental rights impact assessment.

Amendment 2076
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz Körner, Ondřej
Article 29 - paragraph 6 b (new)
6 b. The obligations established by this Article shall not apply to users who use the AI system in the course of a personal non-professional activity.

Amendment 2077
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 29 - paragraph 6 b (new)
6 b. Users shall cooperate with national competent authorities on any action those authorities take in relation to an AI system.

Amendment 2078
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 29 a (new)
Article 29 a', 'Fundamental rights impact assessment for a high-risk AI system', '1. Prior to putting a high-risk AI system into use, as defined in Article 6(2), the user shall conduct an assessment of the system’s impact in the context of use. This assessment shall consist of, but not limited to, the following elements:', '(a) a clear outline of the intended purpose for which the system will be used;', '(b) a clear outline of the intended geographic and temporal scope of the system’s use;', '(c) verification that the use of the system is compliant with Union and national law;', '(d) categories of natural persons and groups likely to be affected by the use of the system;', '(e) the foreseeable direct and indirect impact on fundamental rights of putting the high-risk AI system into use;', '(f) any specific risk of harm likely to impact marginalised persons or vulnerable groups;', '(g) the foreseeable impact of the use of the system on the environment, including, but not limited to, energy consumption;', '(h) any other negative impact on the protection of the values enshrined in Article 2 TEU;', '(i) in the case of public authorities, any other impact on democracy, rule of law and allocation of public funds; and', '(j) detailed plan on how the risk of harm or the negative direct and indirect impact on fundamental rights identified will be mitigated.', '2. If a detailed plan to mitigate the risks outlined in the course of the assessment in paragraph 1 cannot be identified, the user shall refrain from putting the high-risk AI system into use and inform the provider, the national supervisory authority and market surveillance authority without undue delay. Market surveillance authorities or, where relevant, national supervisory authorities, pursuant to their capacity under Articles 65, 67 and 67a, shall take this information into account when investigating systems which present a risk at national level.', '3. The obligations as per paragraph 1 apply for each new deployment of the high-risk AI system.', '4. In the course of the impact assessment, the user shall notify the national supervisory authority, the market surveillance authority and the relevant stakeholders. and involve representatives of the foreseeable persons or groups of persons affected by the high-risk AI system, as identified in paragraph 1, including but not limited to: equality bodies, consumer protection agencies, social partners and data protection agencies, with a view to receiving input into the impact assessment. The user must allow a period of six weeks for bodies to respond.', '5. The user shall publish the results of the impact assessment as part of the registration of use pursuant to their obligation under Article 51(2).', '6. Where the user is already required to carry out a data protection impact assessment pursuant to Article 29(6), the impact assessment outlined in paragraph 1 shall be conducted in conjunction to the data protection impact assessment.

Amendment 2079
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 29 a (new)
Article 29 a', 'Fundamental rights impact assessment for high-risk AI systems', '1. Prior to putting a high-risk AI system as defined in Article 6(2) into use, users shall conduct an assessment of the systems’ impact in the specific context of use. This assessment shall include, at a minimum, the following elements:', '(a) a clear outline of the intended purpose for which the system will be used;', '(b) a clear outline of the intended geographic and temporal scope of the system’s use;', '(ba) categories of natural persons and groups likely to be affected by the use of the system;', '(c) verification that the use of the system is compliant with relevant Union and national law, and with fundamental rights law;', '(d) the foreseeable direct or indirect impact on fundamental rights of putting the high-risk AI system into use;', '(e) any specific risk of harm likely to impact marginalised persons or vulnerable groups;', '(f) the foreseeable impact of the use of the system on the environment including, but not limited to, energy consumption;', '(g) any other negative impact on the protection of the values enshrined in Article 2 TEU;', '(h) in the case of public authorities, any other impact on democracy, rule of law and allocation of public funds; and', '(i) a detailed plan as to how the harms and the negative direct or indirect impact on fundamental rights identified will be mitigated.', '2. If a detailed plan to mitigate the risks outlined in the course of the assessment outlined in paragraph 1 cannot be identified, the user shall refrain from putting the high-risk AI system into use and inform the provider and the relevant national competent authorities without undue delay. Market surveillance authorities, pursuant to Articles 65 and 67, shall take this information into account when investigating systems which present a risk at national level.', '3. The obligation outlined under paragraph 1 applies for each new use of the high-risk AI system.', '4. In the course of the impact assessment, the user shall notify relevant national competent authorities and relevant stakeholders and involve representatives of the persons or groups of persons that are reasonably foreseeable to be affected by the high-risk AI system, as identified in paragraph 1, including but not limited to: equality bodies, consumer protection agencies, social partners and data protection agencies, with a view to receiving input into the impact assessment. The user must allow a period of six weeks for bodies to respond.', '5. The user that is a public authority shall publish the results of the impact assessment as part of the registration of use pursuant to their obligation under Article 51(2).

Amendment 2080
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Andrzej Halicki, Adam Jarubas, Jerzy Buzek, Janusz Lewandowski,
Article 29 a (new)
Article 29 a', 'Fundamental rights impact assessments for high-risk AI systems', '1. The user of a high-risk AI system as defined in Article 6 paragraph 2 shall conduct an assessment of the system’s impact on fundamental rights and public interest in the context of use before putting the system into use and at least every two years afterwards. The information on clear steps as to how the potential harms identified will be mitigated and how effective this mitigation is likely to be should be included.', '2. If adequate steps to mitigate the risks outlined in the course of the assessment in paragraph 1 cannot be identified, the system shall not be put into use. Market surveillance authorities, pursuant to their capacity under Articles 65 and 67, shall take this information into account when investigating systems which present a risk at national level.', '3. In the course of the impact assessment, the user shall notify relevant national authorities and all relevant stakeholders.', '4. Where, following the impact assessment process, the user decides to put the high-risk AI system into use, the user shall be required to publish the results of the impact assessment as part of the registration of use pursuant to their obligation under Article 51 paragraph 2.', '5. Users of high-risk AI systems shall use the information provided to them by providers of high-risk AI systems under Article 13 to comply with their obligation under paragraph 1.', '6. The obligations on users in paragraph 1 is without prejudice to the obligations on users of all high-risk AI systems as outlined in Article 29.

Amendment 2081
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Patryk Jaki, Vincenzo Sofo
Article 29 a (new)
Article 29 a', 'Human rights impact assessment for high-risk AI systems', '1. The user of a high-risk AI system as defined in Article 6 paragraph 2 may conduct an assessment of the system’s impact on fundamental rights and public interest in the context of use before putting the system into use and at least every three years afterwards. This assessment shall include, at minimum, the following:', 'a) a clear outline of the intended purpose for which the system will be used;', 'b) a clear outline of the intended geographic and temporal scope of the system’s use;', 'c) categories of natural persons and groups likely to be affected by the use of the system;', 'd) the likely impact on human rights of affected persons identified pursuant to point (c), including any indirect impacts or consequences of the system’s use;', 'e) in the case of public authorities, any other impact on the public interest, including democracy and allocation of public funds;', '2. Where the user of a high-risk AI system is already required to carry out a data protection impact assessment under Article 35 of Regulation (EU) 2016/679 or Article 27 of Directive (EU) 2016/680, the impact assessment outlined in paragraph 1 may be conducted in conjunction to the data protection impact assessment. The user may publish the results of both assessments, following the obligation under Article 51 paragraph 2.

Amendment 2082
ECR - European Conservatives and Reformists Group
Rob Rooken
Article 29 a (new)
Article 29 a', 'Fundamental rights impact assessment for users of high-risk AI', 'Users of high-risk AI systems as defined in Article 6(2) shall conduct an assessment of the systems’ impact in the context of use before putting the system into use. This assessment shall include, but is not limited to, the following:', 'a. a clear outline of the intended purpose for which the system will be used;', 'b. a clear outline of the intended geographic and temporal scope of the system’s use;', 'c. verification of the legality of the system in accordance with Union and national law, fundamental rights law, Union accessibility legislation, and the extent to which the system is in compliance with this Regulation;', 'd. the likely impact on fundamental rights of the high-risk AI system, including any indirect impacts or consequences of the system’s use;', 'e. any specific risk of harm likely to impact persons or groups of persons at risk of discrimination, or increase existing societal inequalities;', 'f. risk to the health of individuals and public health;', 'g. any other negative impact on the public interest; and', 'h. clear steps as to how the harms identified will be mitigated, and how effective this mitigation is likely to be.

Amendment 2083
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 29 a (new)
Article 29 a', 'Obligation on users to define affected persons', '1. Before putting into use a high-risk AI system as defined in Article 6(2), the user shall define categories of natural persons and groups likely to be affected by the use of the system.

Amendment 2084
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 29 a (new)
Article 29 a', 'A fiduciary duty for providers and users of high-risk AI systems', 'Providers and users of high-risk AI systems have a fiduciary duty to act in the interest of the affectees.

Amendment 2085
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 29 b (new)
Article 29 b', 'Fundamental rights impact assessments for high-risk AI systems', '1. Users of high-risk AI systems as defined in Article 6(2) shall conduct an assessment of the systems’ impact in the context of use before putting the system into use. This assessment shall include, but is not limited to, the following:', 'a. a clear outline of the intended purpose for which the system will be used;', 'b. a clear outline of the intended geographic and temporal scope of the system’s use;', 'c. verification of the legality of the system in accordance with Union and national law, fundamental rights law, Union accessibility legislation, and the extent to which the system is in compliance with this Regulation;', 'd. the likely impact on fundamental rights of the high-risk AI system, including any indirect impacts or consequences of the system’s use;', 'e. any specific risk of harm likely to impact marginalised persons or those groups at risk of discrimination, or increase existing societal inequalities;', 'f. the foreseeable impact of the use of the system on the environment, including but not limited to energy consumption;', 'g. any other negative impact on the public interest; and', 'h. clear steps as to how the harms identified will be mitigated, and how effective this mitigation is likely to be.', '2. If adequate steps to mitigate the risks outlined in the course of the assessment in paragraph 1 cannot be identified, the system shall not be put into use. Market surveillance authorities, pursuant to their capacity under Articles 65 and 67, may take this information into account when investigating systems which present a risk at national level.', '3. The obligation outlined under paragraph 1 applies for each new deployment of the high-risk AI system.', '4. In the course of the impact assessment, the user shall notify relevant national authorities and allrelevant stakeholders, including but not limited to: equality bodies, consumer protection agencies, social partners and data protection agencies, with a view to receiving input into the impact assessment.The user must allow a period of six weeks for bodies to respond.', '5. Where, following the impact assessment process, the user decides to put the high-risk AI system into use, the user shall be required to publish the results of the impact assessment as part of the registration of use pursuant to their obligation under Article 51(2).', '6. Where the user is already required to carry out a data protection impact assessment under Article 35 of Regulation (EU) 2016/679 or Article 27 of Directive (EU) 2016/680, the impact assessment outlined in paragraph 1 shall be conducted in conjunction to the data protection impact assessment and be published as an addendum.', '7. Users of high-risk AI systems shall use the information provided under Article 13 to comply with their obligation under paragraph 1.', '8. Where the user, pursuant to their obligation to define affected categories of persons under Article 29a,finds that use of a high-risk system poses a particular risk to a specific group of natural persons, the user has the obligation to notify established representatives or interest groups acting on behalf of those persons before putting the system into use, with a view to receiving input into the impact assessment.', '9 The obligations on users in paragraph 1 is without prejudice to the obligations on users of all high risk AI systems as outlined in Article 29.

Amendment 2086
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 30 - paragraph 1
1. Each Member State shall designate or establish a notifying authority responsible for setting up and carrying out the necessary procedures for the assessment, designation and notification of conformity assessment bodies and for their monitoring. These procedures shall be developed in cooperation between the notifying authorities of all Member States and shall result in standard procedures implemented equally in all Member States, with a view to removing administrative border barriers and ensuring that the potential of the internal market is realised.

Amendment 2087
EPP - Group of the European Peoples Party (Christian Democrats)
Barbara Thaler, Lukas Mandl, Axel Voss, Deirdre Clune
Article 30 - paragraph 1
1. Each Member State shall designate or establish a notifying authority responsible for setting up and carrying out the necessary procedures for the assessment, designation and notification of conformity assessment bodies and for their monitoring. To this end, Member States shall ensure a sufficient number of conformity assessment bodies, in order to make the certification feasible in a timely manner.

Amendment 2088
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 30 - paragraph 7
1. Each Member State shall designate the national Data Protection Authority (DPA) as the notifying authority responsible for setting up and carrying out the necessary procedures for the assessment, designation and notification of conformity assessment bodies and for their monitoring

Amendment 2089
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 30 - paragraph 7
7. Notifying authorities shall have a sufficient number of competent personnel at their disposal for the proper performance of their tasks. Where applicable, competent personnel shall have necessary expertise in supervision of fundamental rights.

Amendment 2090
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 30 - paragraph 8
8. Notifying authorities shall make sure that conformity assessments are carried out in a proportionate manner, avoiding unnecessary burdens for providers and that notified bodies perform their activities taking due account of the size of an undertaking, the sector in which it operates, its structure and the degree of complexity of the AI system in question. Particular attention shall be paid to minimising administrative burdens and compliance costs for micro, small and medium-sized enterprises as defined in Commission Recommendation 2003/361/EC.

Amendment 2091
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 30 - paragraph 8
8. Notifying authorities shall make sure that conformity assessments are carried out in a proportionate manner, avoiding unnecessary burdens for providers and that notified bodies perform their activities taking due account of the size of an undertaking, the sector in which it operates, its structure and the degree of complexity of and risk posed by the AI system in question.

Amendment 2092
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 30 - paragraph 8
8. Notifying authorities shall make sure that conformity assessments are carried out in a proportionate and timely manner, avoiding unnecessary burdens for providers and that notified bodies perform their activities taking due account of the size of an undertaking, the sector in which it operates, its structure and the degree of complexity of the AI system in question.

Amendment 2093
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 31 - paragraph 2
2. The application for notification shall be accompanied by a description of the conformity assessment activities, the conformity assessment module or modules for which the conformity assessment body claims to be competent, as well as by an accreditation certificate, where one exists, issued by a national accreditation body attesting that the conformity assessment body fulfils the requirements laid down in Article 33. Any valid document related to existing designations of the applicant notified body under any other Union harmonisation legislation shall be added.

Amendment 2094
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 32 - paragraph 1
3. Where the conformity assessment body concerned cannot provide an accreditation certificate, it shall provide the notifying authority with all the documentary evidence necessary for the verification, recognition and regular monitoring of its compliance with the requirements laid down in Article 33. For notified bodies which are designated under any other Union harmonisation legislation, all documents and certificates linked to those designations may be used to support their designation procedure under this Regulation, as appropriate.

Amendment 2095
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 32 - paragraph 1
1. Notifying authorities shall notify only conformity assessment bodies which have satisfied the requirements laid down in Article 33.

Amendment 2096
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 32 - paragraph 3
3. The notification referred to in paragraph 2 shall include full details of the conformity assessment activities, the conformity assessment module or modules and the artificial intelligence technologies concerned, as well as the relevant attestation of competence.

Amendment 2097
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 32 - paragraph 3
3. The notification shall include full details of the conformity assessment activities, the conformity assessment module or modules concerned.

Amendment 2098
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 32 - paragraph 4
4. The conformity assessment body concerned may perform the activities of a notified body only where no objections are raised by the Commission or the other Member States. within two weeks of the validation of the notification where it includes an accreditation certificate referred to in Article 31(2), or within two months of the notification where it includes documentary evidence referred to in Article 31(3).

Amendment 2099
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 32 - paragraph 4
4. The conformity assessment body concerned may begin to perform the activities of a notified body only where no objections are raised by the Commission or the other Member States within one month of a notification.

Amendment 2100
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 32 - paragraph 4 a (new)
4 a. Where objections are raised, the Commission shall without delay enter into consultation with the relevant Member States and the conformity assessment body. In view thereof, the Commission shall decide whether the authorisation is justified or not. The Commission shall address its decision to the Member State concerned and the relevant conformity assessment body.

Amendment 2101
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 33 - paragraph 2
2. Notified bodies shall satisfy the minimum cybersecurity requirements set out for public administration entities identified as operators of essential services pursuant to Directive (…) on measures for a high common level of cybersecurity across the Union, repealing Directive (EU) 2016/1148;

Amendment 2102
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 33 - paragraph 2 a (new)
2 a. Notified bodies shall satisfy the minimum cybersecurity requirements set out for public administration entities identified as operators of essential services pursuant to Directive XXXX/XX on measures for a high common level of cybersecurity across the Union (NIS 2), repealing Directive (EU) 2016/1148.

Amendment 2103
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 33 - paragraph 4
4. Notified bodies shall be independent of the provider of a high-risk AI system in relation to which it performs conformity assessment activities. Notified bodies shall also be independent of any other operator having an economic interest in the high-risk AI system that is assessed, as well as of any competitors of the provider. Notified bodies and their employees should not have provided any service to the provider of a high-risk system for 12 months before the assessment. They should also commit not to work for the provider of a high-risk system assessed or a professional organisation or business association of which the provider of a high-risk system is a member for 12 months after their position in the auditing organisation has ended.

Amendment 2104
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 33 - paragraph 4
4. Notified bodies shall be independent of the provider of a high-risk AI system in relation to which it performs conformity assessment activities. Notified bodies shall also be independent of any other operator having an economic interest in the high-risk AI system that is assessed, as well as of any competitors of the provider. This shall not preclude the use of assessed AI systems that are necessary for the operations of the conformity assessment body or the use of such systems for personal purposes.

Amendment 2105
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Vincenzo Sofo, Adam Bielan
Article 33 - paragraph 6
6. Notified bodies shall have documented procedures in place ensuring that their personnel, committees, subsidiaries, subcontractors and any associated body or personnel of external bodies respect the confidentiality of the information which comes into their possession during the performance of conformity assessment activities, except when disclosure is required by law. The staff of notified bodies shall be bound to observe professional secrecy with regard to all information obtained in carrying out their tasks under this Regulation, except in relation to the notifying authorities of the Member State in which their activities are carried out. Any information and documentation obtained by notified bodies pursuant to the provisions of this Article shall be treated in compliance with the confidentiality obligations set out in Article 70.

Amendment 2106
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 33 - paragraph 7
7. Notified bodies shall have procedures for the performance of activities which take due account of the size of an undertaking, the sector in which it operates, its structure and the degree of complexity of and risk posed by the AI system in question.

Amendment 2107
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 33 - paragraph 10
10. Notified bodies shall have sufficient internal competences to be able to effectively evaluate the tasks conducted by external parties on their behalf. To that end, at all times and for each conformity assessment procedure and each type of high-risk AI system in relation to which they have been designated, the notified body shall have permanent availability of sufficient administrative, technical and scientific personnel who possess experience and knowledge relating to AI, data and data computing and to the requirements set out in Chapter 2 of this Title.

Amendment 2108
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 34 - paragraph 3
3. Activities may be subcontracted or carried out by a subsidiary only with the agreement of the provider and the notifying authority.

Amendment 2109
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 34 - paragraph 4
4. Notified bodies shall keep at the disposal of the notifying authority the relevant documents concerning the verification of the qualifications of the subcontractor or the subsidiary and the work carried out by them under this Regulation.

Amendment 2110
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 36 - paragraph 1
1. Where a notifying authority has suspicions or has been informed that a notified body no longer meets the requirements laid down in Article 33, or that it is failing to fulfil its obligations, that authority shall without delay investigate the matter with the utmost diligence. In that context, it shall inform the notified body concerned about the objections raised and give it the possibility to make its views known. If the notifying authority comes to the conclusion that the notified body no longer meets the requirements laid down in Article 33 or that it is failing to fulfil its obligations, it shall restrict, suspend or withdraw the notification as appropriate, depending on the seriousness of the failure. It shall also immediately inform the Commission and the other Member States accordingly.

Amendment 2111
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 37 - paragraph 1
1. The Commission shall investigate all cases where there are reasons to doubt whether a notified body complies with the requirements laid down in Article 33.

Amendment 2112
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 37 - paragraph 3
3. The Commission shall ensure that all sensitive information obtained in the course of its investigations pursuant to this Article is treated confidentially.

Amendment 2113
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 37 - paragraph 4
4. Where the Commission ascertains that a notified body does not meet or no longer meets the requirements laid down in Article 33, it shall adopt a reasoned decision requesting the notifying Member State to take the necessary corrective measures, including withdrawal of notification if applicable. That implementing act shall be adopted in accordance with the examination procedure referred to in Article 74(2).

Amendment 2114
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 37 - paragraph 4
4. Where the Commission ascertains that a notified body does not meet or no longer meets the requirements laid down in Article 33, it shall adopt a reasoned decision requesting the notifying Member State to take the necessary corrective measures, including withdrawal of notification if necessary. That request shall be adopted in accordance with the examination procedure referred to in Article 74(2).

Amendment 2115
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 38 - paragraph 1
1. The Commission shall ensure that, with regard to the areas covered by this Regulation, appropriate coordination and cooperation between notified bodies active in the conformity assessment procedures of AI systems pursuant to this Regulation are put in place and properly operated in the form of a sectoral group of notified bodies. The coordination role will be held by the European Data Protection Supervisor.

Amendment 2116
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 38 - paragraph 2 a (new)
2 a. The Commission shall provide for the exchange of knowledge and best practices between the Member States' national authorities responsible for notification policy.

Amendment 2117
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 39
deleted

Amendment 2118
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 39 - paragraph 1
1. In line with EU commitments under the World Trade Organization (WTO) Agreement on Technical Barriers to Trade (TBT), the Commission shall endeavour to maximise the acceptance of test results produced by competent conformity assessment bodies, independent of the territory in which they may be established, where necessary to demonstrate conformity with the applicable requirements of the Regulation.

Amendment 2119
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 39 - paragraph 1
Conformity assessment bodies established under the law of a third country with which the Union has concluded an agreement in this respect may be authorised to carry out the activities of notified Bodies under this Regulation.

Amendment 2120
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 39 - paragraph 1 a (new)
2. Conformity assessment bodies established under the law of a third country may carry out the activities of notified bodies under this regulation where they have been accredited as competent by an accreditation body, whether established in the territory of the EU or a third country, that is a signatory of an international accreditation or conformity assessment scheme based on rigorous peer-review processes, such as the International Laboratory Accreditation Collaboration (ILAC) Mutual Recognition Arrangement (MRA) and International Accreditation Forum (IAF) Multilateral Recognition Arrangement (MLA).

Amendment 2121
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 39 - paragraph 1 b (new)
3. In addition, where conformity assessment bodies established under the law of a third country have not been accredited by signatory bodies of such international accreditation or conformity assessment schemes, third-country conformity assessment bodies may carry out the activities of notified bodies where international mutual recognition arrangements, conformity assessment protocols, or other agreements exist between the EU and the country in which the conformity assessment body is established.

Amendment 2122
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 40 - paragraph 1
1. High-risk AI systems which are in conformity with harmonised standards developed in accordance with Regulation 1025/2021 or parts thereof the references of which have been published in the Official Journal of the European Union shall be presumed to be in conformity with the requirements set out in Chapter 2 of this Title, to the extent those standards cover those requirements.

Amendment 2123
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 40 - paragraph 1
High-risk AI systems shall be in conformity with harmonised standards or parts thereof the references of which have been published in the Official Journal of the European Union, to the extent those standards cover those requirements.

Amendment 2124
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 40 - paragraph 1 a (new)
2.When issuing a standardisation request to European standardisation organisations in accordance with Article 10 of Regulation (EU) 1025/2012, the Commission shall specify that standards are coherent, including with sectorial legislation listed in Annex 2, easy to implement and drafted in such a way that they aim to fulfil in particular the following objectives:', "(a) ensure that AI systems placed on the market or put into service in the Union are safe and respect Union values and strengthen the Union's digital sovereignty;", '(b) take into account the concept of trustworthy AI set out in Article 4(a);', '(c) promote investment and innovation in AI, as well as competitiveness and growth of the Union market;', '(d) enhance multistakeholder governance, representative of allrelevant European stakeholders (e.g. industry, SMEs, civil society, researchers);', '(e) contribute to strengthening global cooperation on standardisation in the field of AI that is consistent with Union values and interests.', 'The Commission shall request the European standardisation organisations to provide evidence of their best efforts to fulfil the above objectives.

Amendment 2125
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 40 - paragraph 1 a (new)
The Commission shall issue standardisation requests covering all essential requirements of this Regulation in accordance with Article 10 of Regulation 1025/2012 no later than 6 months after the date of entry into force of this Regulation.

Amendment 2126
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 40 - paragraph 1 a (new)
Harmonised standards shall be limited to technical specifications and procedures. Work organisation and ethical considerations are not applicable.

Amendment 2127
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 40 - paragraph 1 a (new)
When AI systems are intended to be deployed at the workplace, harmonised standards shall be limited to technical specifications and procedures.

Amendment 2128
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 40 - paragraph 1 b (new)
The Commission shall issue standardisation requests covering all essential requirements of the Regulation in accordance with Article 10 of Regulation (EU) No 1025/2012 no later than 6 months after the date of entry into force of the Regulation.

Amendment 2129
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 41
deleted

Amendment 2130
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 41 - paragraph 1
1. The Commission may, by means of implementing acts, adopt common specifications in respect of the requirements set out in Chapter 2 of this Title for the essential requirements where health and safety, the protection of consumers or of the environment, other aspects of public interest, or clarity and practicability so require after consulting the Board, the Committee referred to in Art 22 of Regulation 1025/20212 as well as the relevant stakeholders and where the following conditions have been fulfilled:', '(a) the Commissions has concluded, that contrary to Article 10(6) of Regulation (EU) No 1025/2012 a harmonised standard does not satisfy the requirements which it aims to cover and which are set out in the corresponding Union harmonisation and has therefore not published a reference of such harmonised standard in the Official Journal of the European Union in accordance with Regulation (EU) No 1025/2012;', '(b) the Commission has requested one or more European standardization organisations to draft a harmonised standard for the essential health and safety requirements and there are undue delays in the standardisation procedure;', '(c) the request has, without reason, not been accepted by the European standardization organisations concerned.', 'Those implementing acts shall be adopted in accordance with the examination procedure referred to in Article 74(2).

Amendment 2131
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 41 - paragraph 1
1. Where harmonised standards referred to in Article 40 do not exist or where the Commission considers that the relevant harmonised standards are insufficient or that there is a need to address specific safety or fundamental right concerns, the Commission shall issue a standardisation request to one or several of the European standardization organizations in accordance with Article 10 of Regulation 1025/2012 and may, by means of implementing acts, adopt common specifications in respect of the requirements set out in Chapter 2 of this Title, which shall only be valid until the requested harmonised standards have been elaborated and published in the Official Journal of the European Union. Those implementing acts shall be adopted in accordance with the examination procedure referred to in Article 74(2).

Amendment 2132
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 41 - paragraph 1
1. Where harmonised standards referred to in Article 40 do not exist or where the Commission considers that the relevant harmonised standards are insufficient or that there is a need to address specific safety or fundamental right concerns, the Commission may, by means of implementing acts, adopt common specifications in respect of the requirements set out in Chapter 2 of this Title. Those implementing acts shall be adopted in accordance with the examination procedure referred to in Article 74(2).', 'The Commission shall adopt common specifications setting out how risk management systems should give specific consideration to interaction with or impact on children.

Amendment 2133
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 41 - paragraph 1
1. Where harmonised standards referred to in Article 40 do not exist and are not expected to be published within a reasonable period or where the Commission considers that the relevant harmonised standards are insufficient or that there is a need to address specific safety or fundamental right concerns, the Commission may, by means of implementing acts, adopt common specifications in respect of the requirements set out in Chapter 2 of this Title. Those implementing acts shall be adopted in accordance with the examination procedure referred to in Article 74(2).

Amendment 2134
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Article 41 - paragraph 1
1. Where harmonised standards referred to in Article 40 do not exist or relevant international standards do not apply or where the Commission considers that the relevant harmonised standards are insufficient or that there is a need to address specific safety or fundamental right concerns, the Commission may, by means of implementing acts, adopt common specifications in respect of the requirements set out in Chapter 2 of this Title. Those implementing acts shall be adopted in accordance with the examination procedure referred to in Article 74(2).

Amendment 2135
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Article 41 - paragraph 1
1. Where harmonised standards referred to in Article 40 and international standards do not exist or where the Commission considers that the relevant harmonised standards are insufficient or that there is a need to address specific safety or fundamental right concerns, the Commission may, by means of implementing acts, adopt common specifications in respect of the requirements set out in Chapter 2 of this Title. Those implementing acts shall be adopted in accordance with the examination procedure referred to in Article 74(2).

Amendment 2136
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 41 - paragraph 1
1. Where harmonised standards referred to in Article 40 do not exist or where the Commission considers that the relevant harmonised standards are insufficient or that there is a need to address specific safety, accessibility, or fundamental right concerns, the Commission may, by means of implementing acts, adopt common specifications in respect of the requirements set out in Chapter 2 of this Title. Those implementing acts shall be adopted in accordance with the examination procedure referred to in Article 74(2).

Amendment 2137
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Article 41 - paragraph 1
1. Where harmonised standards referred to in Article 40 do not exist or where the Commission considers that the relevant harmonised standards are insufficient, because there is a need to address specific safety or fundamental right concerns, the Commission may, by means of implementing acts, adopt common specifications in respect of the requirements set out in Chapter 2 of this Title. Those implementing acts shall be adopted in accordance with the examination procedure referred to in Article 74(2).

Amendment 2138
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 41 - paragraph 1 a (new)
1 a. When deciding to draft and adopt common specifications, the Commission shall consult the Board, the European standardisation organisations as well as the relevant stakeholders, and duly justify why it decided not to use harmonised standards. The abovementioned organisations shall be regularly consulted while the Commission is in the process of drafting the common specifications.

Amendment 2139
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 41 - paragraph 2
2. The Commission, when preparing the common specifications referred to in paragraph 1, shall gather the views of relevant stakeholders, including industry, start-ups, and SMEs, and of relevant bodies or expert groups established under relevant sectorial Union law.

Amendment 2140
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 41 - paragraph 2
2. When preparing the common specifications referred to in paragraph 1, the Commission shall fulfil the objectives referred of Article 40(2) and gather the views of relevant bodies or expert groups established under relevant sectorial Union law.

Amendment 2141
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 41 - paragraph 2
2. The Commission, when preparing the common specifications referred to in paragraph 1, shall gather the views of stakeholders, including SMEs and start-ups, relevant bodies or expert groups established under relevant sectorial Union law.

Amendment 2142
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Article 41 - paragraph 2
2. The Commission, when preparing the common specifications referred to in paragraph 1, shall gather the views of relevant bodies, stakeholders or expert groups established under relevant sectorial Union law.

Amendment 2143
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Article 41 - paragraph 2
2. The Commission shall, before preparing the common specifications referred to in paragraph 1, consult relevant bodies, expert groups and other relevant stakeholders established under relevant sectorial Union law.

Amendment 2144
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Article 41 - paragraph 2
2. The Commission, when preparing the common specifications referred to in paragraph 1, shall gather the views of relevant bodies, stakeholders or expert groups established under relevant sectorial Union law.

Amendment 2145
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 41 - paragraph 3
deleted

Amendment 2146
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 41 - paragraph 3
3. High-risk AI systems which are in conformity with the common specifications referred to in paragraph 1 shall be presumed to be in conformity with the requirements set out in Chapter 2 of this Title, to the extent those common specifications cover those requirements, and as long as those requirements are not covered by harmonised standards or parts thereof the references of which have been published in the Official Journal of the European Union in accordance with Regulation (EU) No 1025/2012.

Amendment 2147
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 41 - paragraph 4
deleted

Amendment 2148
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 41 - paragraph 4
4. Where providers do not comply with the common specifications referred to in paragraph 1, they shall duly justify that they have adopted technical solutions that meet the requirements referred to in Chapter 2 to a level at least equivalent thereto.

Amendment 2149
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Article 41 - paragraph 4
4. Where providers of high-risk AI systems do not comply with the common specifications referred to in paragraph 1, they shall duly justify that they have adopted technical solutions that are at least equivalent thereto.

Amendment 2150
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 41 - paragraph 4 a (new)
4 a. If harmonised standards referred to in Article 40 are developed and the references to them are published in the Official Journal of the European Union in accordance with Regulation (EU) No 1025/2012 in the future, the relevant common specifications shall no longer apply.

Amendment 2151
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 42
deleted

Amendment 2152
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 42 - paragraph 1
1. Taking into account their intended purpose, high-risk AI systems that have been trained and tested on data concerning the specific geographical, behavioural and functional setting within which they are intended to be used or are reasonably foreseeable to be used shall be presumed to be in compliance with the requirement set out in Article 10(4).

Amendment 2153
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 42 - paragraph 1
1. Taking into account their foreseeable uses, high-risk AI systems that have been trained and tested on data concerning the specific geographical, behavioural and functional setting within which they are intended to be used shall be presumed to be in compliance with the requirement set out in Article 10(4).

Amendment 2154
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 42 - paragraph 2
1. High-risk AI systems that have been trained and tested on data reflecting the specific geographical, behavioural and functional setting within which they are intended to be used shall be presumed to be in compliance with the respective requirements set out in Article 10(4).

Amendment 2155
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 42 - paragraph 2
2. High-risk AI systems that have been certified or for which a statement of conformity has been issued under a cybersecurity scheme to Regulation (EU) 2019/881 of the European Parliament and of the Council63 or pursuant to other harmonization legislation in the field of security of network and information systems and electronic communications networks and services and the references of which have been published in the Official Journal of the European Union shall be presumed to be in compliance with the cybersecurity requirements set out in Article 15 of this Regulation in so far as the cybersecurity certificate or statement of conformity or parts thereof cover those requirements.' '63 Regulation (EU) 2019/881 of the European Parliament and of the Council of 17 April 2019 on ENISA (the European Union Agency for Cybersecurity) and on information and communications technology cybersecurity certification and repealing Regulation (EU) No 526/2013 (Cybersecurity Act) (OJ L 151, 7.6.2019, p. 1).

Amendment 2156
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 43 - title
Third party conformity assessment

Amendment 2157
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 43 - paragraph 1 - introductory part
1. For high-risk AI systems listed in point 1, 3 and 4 of Annex III, where, in demonstrating the compliance of a high-risk AI system with the requirements set out in Chapter 2 of this Title, the provider has applied harmonised standards referred to in Article 40, or, where applicable, common specifications referred to in Article 41, the provider shall follow follow the conformity assessment procedure based on assessment of the quality management system and assessment of the technical documentation, with the involvement of a notified body, referred to in Annex VII.

Amendment 2158
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 43 - paragraph 1 - introductory part
1. For high-risk AI systems listed in point 1 of Annex III, where, in demonstrating the compliance of a high-risk AI system with the requirements set out in Chapter 2 of this Title, the provider has applied harmonised standards referred to in Article 40, or, where applicable, common specifications referred to in Article 41, the provider shall follow the conformity assessment procedure based on assessment of the quality management system and assessment of the technical documentation, with the involvement of a notified body, referred to in Annex VII.

Amendment 2159
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 43 - paragraph 1 - introductory part
1. For high-risk AI systems listed in Annex III, where, in demonstrating the compliance of a high-risk AI system with the requirements set out in Chapter 2 of this Title, the provider has not applied harmonised standards referred to in Article 40, or, where applicable, common specifications referred to in Article 41, the provider shall follow the conformity assessment procedure based on assessment of the quality management system and assessment of the technical documentation, with the involvement of a notified body, referred to in Annex VII.

Amendment 2160
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 43 - paragraph 1 - introductory part
1. For high-risk AI systems listed in Annex III the provider shall have a conformity assessment carried out by an independent third-party, following the conformity assessment procedure set out in Annex VII.

Amendment 2161
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 43 - paragraph 1 - point a
1. For high-risk AI systems listed in point 1 of Annex III, where, in demonstrating the compliance of a high-risk AI system with the requirements set out in Chapter 2 of this Title, the provider has applied harmonised standards referred to in Article 40, or, where applicable, common specifications referred to in Article 41, the provider shall opt for one of the following procedures:

Amendment 2162
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 43 - paragraph 1 - point a
deleted

Amendment 2163
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 43 - paragraph 1 - point a
deleted

Amendment 2164
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 43 - paragraph 1 - point a
deleted

Amendment 2165
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 43 - paragraph 1 - point a
deleted

Amendment 2166
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 43 - paragraph 1 - point a
(a) the conformity assessment procedure based on internal control referred to in Annex VI; or

Amendment 2167
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 43 - paragraph 1 - point b
deleted

Amendment 2168
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 43 - paragraph 1 - point b
deleted

Amendment 2169
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 43 - paragraph 1 - point b
deleted

Amendment 2170
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 43 - paragraph 1 - point b
(b) the conformity assessment procedure based on assessment of the quality management system and assessment of the technical documentation, documentation of analysis and achievement of the tests of strict necessity, proportionality and legality of the system, as well as any associated database or data repository on which it relies; with the involvement of a notified body, referred to in Annex VII, and with the involvement of the relevant national data protection authority.

Amendment 2171
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 43 - paragraph 1 - point b
(b) the conformity assessment procedure based on assessment of the quality management system and technical documentation, with the involvement of a notified body, referred to in Annex VII.

Amendment 2172
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 43 - paragraph 1 - subparagraph 1
deleted

Amendment 2173
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 43 - paragraph 1 - subparagraph 1
deleted

Amendment 2174
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Article 43 - paragraph 1 - subparagraph 1
Where, in demonstrating the compliance of a high-risk AI system with the requirements set out in Chapter 2 of this Title, the provider has not applied or has applied only in part harmonised standards referred to in Article 40, or where such harmonised standards do not exist and common specifications referred to in Article 41 are not available, the provider shall follow the conformity assessment procedure set out in Annex VII. Should the provider already have established internal organisation and structures for existing conformity assessments or requirements under other existing rules, the provider may utilise those, or parts of those, existing compliance structures, so long as they also have the capacity and competence needed to fulfil the requirements for the product set out in this Regulation.

Amendment 2175
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 43 - paragraph 1 - subparagraph 2
deleted

Amendment 2176
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 43 - paragraph 1 - subparagraph 2
deleted

Amendment 2177
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 43 - paragraph 1 - subparagraph 2
For the purpose of carrying out the conformity assessment procedure referred to in Annex VII, the provider may choose any of the notified bodies. However, when the system is intended to be put into service by law enforcement, immigration or asylum authorities as well as EU institutions, bodies or agencies, the market surveillance authority referred to in Article 63(5) or (6), as applicable, shall act as a notified body.

Amendment 2178
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 43 - paragraph 1 a (new)
1 a. Without prejudice to paragraph 1, if the provider has applied harmonised standard referred to in Article 40, or where applicable, common specifications referred to in Article 41, it shall follow the conformity assessment procedure based on internal control referred to in Annex VI.

Amendment 2179
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 43 - paragraph 1 b (new)
1 b. In the following cases, the compliance of the high-risk AI system with requirements laid down in Chapter 2 of this Title shall be assessed following the conformity assessment procedure based on the assessment of the quality management system and the assessment of the technical documentation, with the involvement of a notified body, referred to in Annex VII:', '(a) where harmonised standards, the reference number of which has been published in the Official Journal of the European Union, covering all relevant safety requirements for the AI system, do not exist;', '(b) where the harmonised standards referred to in point (a) exist but the manufacturer has not applied them or has applied them only in part;', '(c) where one or more of the harmonised standards referred to in point (a) has been published with a restriction;', '(d) when the provider considers that the nature, design, construction or purpose of the AI system necessitate third party verification.

Amendment 2180
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 43 - paragraph 2
2. For high-risk AI systems referred to in point 5(b) of Annex III, placed on the market or put into service by credit institutions regulated by Directive 2013/36/EU, the conformity assessment shall be carried out as part of the procedure referred to in Articles 97 to101 of that Directive.

Amendment 2181
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 43 - paragraph 2
2. For high-risk AI systems referred to in point 5(b) of Annex III, placed on the market or put into service by credit institutions regulated by Directive 2013/36/EU, the conformity assessment shall be carried out as part of the procedure referred to in Articles 97 to101 of that Directive.

Amendment 2182
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 43 - paragraph 2
2. For high-risk AI systems referred to in point 5(b) of Annex III, placed on the market or put into service by credit institutions regulated by Directive 2013/36/EU, the conformity assessment shall be carried out as part of the procedure referred to in Articles 97 to101 of that Directive.

Amendment 2183
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 43 - paragraph 2
2. For high-risk AI systems referred to in points 2 to 8 of Annex III, providers shall follow the conformity assessment procedure based on internal control as referred to in Annex VI, which does not provide for the involvement of a notified body. For high-risk AI systems referred to in point 5(b) of Annex III, placed on the market or put into service by credit institutions regulated by Directive 2013/36/EU, the conformity assessment based on internal control shall be verified by means of an ex-post assessment and carried out as part of the procedure referred to in Articles 97 to101 of that Directive but only to the extent that prudential risks and related requirements are concerned.

Amendment 2184
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 43 - paragraph 2
2. For high-risk AI systems referred to in points 2 to 8 of Annex III, providers shall follow the conformity assessment procedure based on assessment of the quality management system and assessment of the technical documentation, with the involvement of a notified body, referred to in Annex VII. For high-risk AI systems referred to in point 5(b) of Annex III, placed on the market or put into service by credit institutions regulated by Directive 2013/36/EU, the conformity assessment shall be carried out as part of the procedure referred to in Articles 97 to101 of that Directive.

Amendment 2185
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 43 - paragraph 3 - subparagraph 2
3. For high-risk AI systems, to which legal acts listed in Annex II, section A, apply, and which are subject to points 1 and 2 of Article 6 the provider shall follow the relevant conformity assessment as required under those legal acts. The requirements set out in Chapter 2 of this Title shall apply to those high-risk AI systems and shall be part of that assessment. Points 4.3., 4.4., 4.5. and the fifth paragraph of point 4.6 of Annex VII shall also apply.

Amendment 2186
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 43 - paragraph 3 - subparagraph 2
deleted

Amendment 2187
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul Garraud
Article 43 - paragraph 3 a (new)
3a. High-risk AI systems shall periodically be subject to a conformity assessment review procedure.

Amendment 2188
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 43 - paragraph 4 - introductory part
4. High-risk AI systems, that have already been subject to a conformity assessment procedure, shall undergo a new conformity assessment procedure in line with the provisions foreseen by the legal acts listed in Annex II, section A, whenever they are substantially modified, regardless of whether the modified system is intended to be further distributed or continues to be used by the current user.

Amendment 2189
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 43 - paragraph 4 - introductory part
4. High-risk AI systems shall undergo a new conformity assessment procedure whenever they are substantially modified, regardless of whether the modified system is intended to be further distributed or continues to be used by the current user, or whenever a change occurs which may affect the compliance with this Regulation.

Amendment 2190
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 43 - paragraph 4 - introductory part
4. High-risk AI systems shall undergo a new conformity assessment procedure whenever they are substantially modified and the changes could impact performance related to essential requirements, regardless of whether the modified system is intended to be further distributed or continues to be used by the current user.

Amendment 2191
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 43 - paragraph 4 - introductory part
4. High-risk AI systems that have already been subject to a conformity assessment procedure shall undergo a new conformity assessment procedure whenever they are substantially modified, if the modified system is intended to be further distributed or continues to be used by the current user.

Amendment 2192
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 43 - paragraph 4 - introductory part
4. High-risk AI systems shall undergo a new third party conformity assessment procedure whenever they are substantially modified, regardless of whether the modified system is intended to be further distributed or continues to be used by the current deployer.

Amendment 2193
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 43 - paragraph 4 - subparagraph 1
For high-risk AI systems that continue to learn after being placed on the market or put into service, changes to the high-risk AI system and its performance that have been pre-determined by the provider at the moment of the initial conformity assessment and are part of the information contained in the technical documentation referred to in point 2(f) of Annex IV, shall not constitute a substantial modification. The same should apply to updates of the AI system for security reasons in general and to protect against evolving threats of manipulation of the system as long as the update does not include significant changes to the functionality of the system.

Amendment 2194
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 43 - paragraph 4 - subparagraph 1
For high-risk AI systems that continue to learn after being placed on the market or put into service, changes to the high-risk AI system and its performance that have been pre-determined by the provider at the moment of the initial conformity assessment and are part of the information contained in the technical documentation referred to in point 2(f) of Annex IV, shall not constitute a substantial modification. A new conformity assessment is always required whenever safety-related limits of continuing learning high-risk AI systems may be exceeded or have an impact on the health or safety.

Amendment 2195
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 43 - paragraph 4 - subparagraph 1
For high-risk AI systems that continue to learn after being placed on the market or put into service, changes to the high-risk AI system and its performance shall constitute a substantial modification, including if they have been pre-determined by the provider at the moment of the initial conformity assessment and are part of the information contained in the technical documentation referred to in point 2(f) of Annex IV.

Amendment 2196
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 43 - paragraph 4 - subparagraph 1 a (new)
The same should apply to updates of the AI system for security reasons in general and to protect against evolving threats of manipulation of the system. This paragraph only applies if the Member State has established a legal framework, which allows the provider of a high risk AI system, which autonomously make substantial modifications to itself, to regularly perform an automated real-time conformity assessment procedure.

Amendment 2197
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 43 - paragraph 4 a (new)
4 a. The specific interests and needs of the small-scale providers shall be taken into account when setting the fees for third-party conformity assessment under this Article, reducing those fees proportionately to their size and market size.

Amendment 2198
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 43 - paragraph 4 a (new)
4 a. Any provider may voluntarily apply for a third-party conformity assessment regardless of the risk level of their AI system.

Amendment 2199
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 43 - paragraph 5
deleted

Amendment 2200
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 43 - paragraph 5
5. After consulting the AI Board referred to in Article 56 and after providing substantial evidence, followed by thorough consultation and the involvement of the affected stakeholders, the Commission is empowered to adopt delegated acts in accordance with Article 73 for the purpose of updating Annexes VI and Annex VII in order to amend elements of the conformity assessment procedures that become necessary or unnecessary in light of technical progress.

Amendment 2201
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 43 - paragraph 5
5. After consulting the AI Board referred to in Article 56 and after providing substantial evidence, followed by thorough consultation and the involvement of the affected stakeholders, the Commission is empowered to adopt delegated acts in accordance with Article 73 for the purpose of updating Annexes VI and Annex VII in order to introduce elements of the conformity assessment procedures that become necessary in light of technical progress.

Amendment 2202
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 43 - paragraph 5
5. The Commission is empowered to adopt delegated acts in accordance with Article 73 for the purpose of updating Annex VII in order to introduce elements of the conformity assessment procedures that become necessary in light of technical progress.

Amendment 2203
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 43 - paragraph 6
deleted

Amendment 2204
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 43 - paragraph 6
deleted

Amendment 2205
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 43 - paragraph 6
deleted

Amendment 2206
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 43 - paragraph 6
deleted

Amendment 2207
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 43 - paragraph 6
6. After consulting the AI Board referred to in Article 56 and after providing substantial evidence, followed by thorough consultation and the involvement of the affected stakeholders, the Commission is empowered to adopt delegated acts to amend paragraphs 1 and 2 in order to subject high-risk AI systems referred to in points 2 to 8 of Annex III to the conformity assessment procedure referred to in Annex VII or parts thereof. The Commission shall adopt such delegated acts taking into account the effectiveness of the conformity assessment procedure based on internal control referred to in Annex VI in preventing or minimizing the risks to health and safety and protection of fundamental rights posed by such systems as well as the availability of adequate capacities and resources among notified bodies.

Amendment 2208
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 43 - paragraph 6
6. After consulting the AI Board referred to in Article 56 and after providing substantial evidence, followed by thorough consultation and the involvement of the affected stakeholders, the Commission is empowered to adopt delegated acts to amend paragraphs 1 and 2 in order to subject high-risk AI systems referred to in points 2 to 8 of Annex III to the conformity assessment procedure referred to in Annex VII or parts thereof. The Commission shall adopt such delegated acts taking into account the effectiveness of the conformity assessment procedure based on internal control referred to in Annex VI in preventing or minimizing the risks to health and safety and protection of fundamental rights posed by such systems as well as the availability of adequate capacities and resources among notified bodies.

Amendment 2209
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 44 - paragraph 1
1. Certificates issued by notified bodies in accordance with Annex VII shall be drawn-up in the official Union language of the Member State in which the notified body is established.

Amendment 2210
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 44 - paragraph 3
3. Where a notified body finds that an AI system no longer meets the requirements set out in Chapter 2 of this Title, it shall suspend or withdraw the certificate issued or impose any restrictions on it, unless compliance with those requirements is ensured by appropriate corrective action taken by the provider of the system within an appropriate deadline set by the notified body. The notified body shall give reasons for its decision.

Amendment 2211
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 46 - paragraph 2 - introductory part
2. Each notified body shall inform the other notified bodies and the notifying authority of:

Amendment 2212
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 46 - paragraph 3
3. Each notified body shall provide the other notified bodies carrying out similar conformity assessment activities with relevant information on issues relating to negative and, on request, positive conformity assessment results.

Amendment 2213
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 46 - paragraph 3
3. Each notified body shall provide the other notified bodies carrying out similar conformity assessment activities covering the same artificial intelligence systems with relevant information on issues relating to negative and, on request, positive conformity assessment results.

Amendment 2214
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 47
deleted

Amendment 2215
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 47
deleted

Amendment 2216
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 47 - paragraph 1
1. By way of derogation from Article 43, any market surveillance authority may request a judicial authority to authorise the placing on the market or putting into service of specific high-risk AI systems within the territory of the Member State concerned, for exceptional reasons of public security or the protection of life and health of persons, environmental protection and the protection of key industrial and infrastructural assets. That authorisation shall be for a limited period of time, while the necessary conformity assessment procedures are being carried out, and shall terminate once those procedures have been completed. The completion of those procedures shall be undertaken without undue delay.

Amendment 2217
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 47 - paragraph 2
1 a. In a duly justified situation of urgency for exceptional reasons of public security or in case of specific, substantial and imminent threat to the life or physical safety of natural persons, law enforcement authorities may put a specific high-risk AI system into service without the authorisation referred to in paragraph 1 provided that such authorisation is requested during or after the use without undue delay, and if such authorisation is rejected, its use shall be stopped with immediate effect.

Amendment 2218
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 47 - paragraph 2
2. The authorisation referred to in paragraph 1 shall be issued only if the market surveillance authority and judicial authority conclude that the high-risk AI system complies with the requirements of Chapter 2 of this Title. The market surveillance authority shall inform the Commission and the other Member States of any request made and any subsequent authorisation issued pursuant to paragraph 1.

Amendment 2219
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 47 - paragraph 4
3. Where, within 15 calendar days of receipt of the information referred to in paragraph 2, no objection has been raised by either a Member State or the Commission in respect to the request of the maret surveillance authority for an authorisation issued by a market surveillance authority of a Member State in accordance with paragraph 1, that request shall be deemed justified.

Amendment 2220
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 47 - paragraph 4
4. Where, within 15 calendar days of receipt of the notification referred to in paragraph 2, objections are raised by a Member State against an authorisation issued by a market surveillance authority of another Member State, or where the Commission considers the authorisation to be contrary to Union law or the conclusion of the Member States regarding the compliance of the system as referred to in paragraph 2 to be unfounded, the Commission shall without delay enter into consultation with the relevant Member State; the operator(s) concerned shall be consulted and have the possibility to present their views. In view thereof, the Commission shall decide whether the authorisation is justified or not. The Commission shall address its decision to the Member State concerned and the relevant operator(s).

Amendment 2221
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 47 - paragraph 4
4. Where, within 15 calendar days of receipt of the notification referred to in paragraph 2, objections are raised by a Member State against a request issued by a market surveillance authority of another Member State, or where the Commission considers the request to be contrary to Union law or the conclusion of the Member States regarding the compliance of the system as referred to in paragraph 2 to be unfounded, the Commission shall without delay enter into consultation with the relevant Member State; the operator(s) concerned shall be consulted and have the possibility to present their views. In view thereof, the Commission shall decide whether the request is justified or not. The Commission shall address its decision to the Member State concerned and the relevant operator or operators.

Amendment 2222
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 47 - paragraph 5
5. If the request is considered unjustified, this shall be withdrawn by the market surveillance authority of the Member State concerned.

Amendment 2223
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 48 - paragraph 1
1. The notifying authority after third party conformity assessment shall draw up a written physical and machine-readable electronic EU declaration of conformity for each AI system and keep it at the disposal of the national competent authorities for 15 years after the AI system has been placed on the market or put into service. The EU declaration of conformity shall identify the AI system for which it has been drawn up. A copy of the EU declaration of conformity shall be given to the relevant national competent authorities upon request.

Amendment 2224
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 48 - paragraph 1
1. The provider shall draw up a written EU declaration of conformity for each high-risk AI system and keep it at the disposal of the national supervisory authority and the national competent authorities after the high-risk AI system has been placed on the market or put into service for the entire lifecycle of the high-risk AI system. A copy of the EU declaration of conformity shall be given to the national supervisory authority and the relevant national competent authorities upon request.

Amendment 2225
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 48 - paragraph 1
1. The provider shall draw up a written or electronically signed EU declaration of conformity for each AI system and keep it at the disposal of the national competent authorities for 10 years after the AI system has been placed on the market or put into service. The EU declaration of conformity shall identify the AI system for which it has been drawn up. A copy of the EU declaration of conformity shall be submitted to the relevant national competent authorities upon request.

Amendment 2226
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 48 - paragraph 2
2. The EU declaration of conformity shall state that the high-risk AI system in question meets the requirements set out in Chapter 2 of this Title, including the requirements related to the respect of the Union data protection acquis. The EU declaration of conformity shall contain the information set out in Annex V and shall be translated into an official Union language or languages required by the Member State(s) in which the high-risk AI system is placed on the market or made available.

Amendment 2227
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 48 - paragraph 4
4. After receiving the EU declaration of conformity, the provider shall assume responsibility for continuous compliance with the requirements set out in Chapter 2 of this Title throughout the entire lifecycle.

Amendment 2228
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 48 - paragraph 5
5. After consulting the Board, the Commission shall be empowered to adopt delegated acts in accordance with Article 73 for the purpose of updating the content of the EU declaration of conformity set out in Annex V in order to introduce elements that become necessary in light of technical progress.

Amendment 2229
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Article 49 - paragraph 1
1. The CE marking shall be in digital format for high-risk AI systems.

Amendment 2230
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 49 - paragraph 1
1. The CE marking shall be affixed visibly, legibly and indelibly for high-risk AI systems before the high-risk AI system is placed on the market. Where that is not possible or not warranted on account of the nature of the high-risk AI system, it shall be affixed to the packaging or to the accompanying documentation, as appropriate. It may be followed by a pictogram or any other marking indicating a special risk or use.

Amendment 2231
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 49 - paragraph 1
1. The CE marking shall be affixed visibly, legibly and indelibly for high-risk AI systems before they are placed on the market, made available on the market or put into service. Where that is not possible or not warranted on account of the nature of the high-risk AI system, it shall be affixed to the packaging or to the accompanying documentation, as appropriate.

Amendment 2232
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 49 - paragraph 1
1. The physical CE marking shall be affixed visibly, legibly and indelibly for high-risk AI systems. Where that is not possible or not warranted on account of the nature of the high-risk AI system, it shall be affixed to the packaging or to the accompanying documentation, as appropriate.

Amendment 2233
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 49 - paragraph 1 a (new)
1. The physical CE marking shall be affixed visibly, legibly and indelibly for high-risk AI systems. Where that is not possible or not warranted on account of the nature of the high-risk AI system, it shall be affixed to the packaging or to the accompanying documentation, as appropriate.

Amendment 2234
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 49 - paragraph 1 a (new)
1 a. A digital CE marking may be used instead of or additionally to the physical marking if it can be accessed via the display of the product or via a machine-readable code or other electronic means.

Amendment 2235
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 49 - paragraph 1 a (new)
1 a. An electronic CE marking may replace the physical marking if it can be accessed via the display of the product or via a machine-readable code.

Amendment 2236
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 49 - paragraph 3 a (new)
3 a. Where high-risk AI systems are subject to other Union legislation which also provides for the affixing of the CE marking, the CE marking shall indicate that the high-risk AI system also fulfil the requirements of that other legislation.

Amendment 2237
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 50
deleted

Amendment 2238
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 50 - paragraph 1 - introductory part
The provider shall, for the entire lifecycle of the AI system or for a period ending 10 years after the AI system has been placed on the market or put into service, whichever is the longest, keep at the disposal of the national competent authorities:

Amendment 2239
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 50 - paragraph 1 - introductory part
The provider shall, for a period ending five years after the AI system has been placed on the market or put into service, keep at the disposal of the national competent authorities:

Amendment 2240
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 50 - paragraph 1 - introductory part
The provider shall, for a period ending 15 years after the AI system has been placed on the market or put into service, keep at the disposal of the national competent authorities:

Amendment 2241
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 50 - paragraph 1 - introductory part
The provider shall, for a period ending 5 years after the AI system has been placed on the market or put into service, keep at the disposal of the national competent authorities:

Amendment 2242
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 50 - paragraph 1 - introductory part
The provider shall, for the entire lifecycle of the AI system, keep at the disposal of the national supervisory authority and the national competent authorities:

Amendment 2243
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 51
deleted

Amendment 2244
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Article 51 - paragraph 1
Before placing on the market or putting into service a high-risk AI system referred to in Article 6(2) and Article 6a, the provider or, where applicable, the authorised representative shall register that system in the EU database referred to in Article 60.

Amendment 2245
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Article 51 - paragraph 1
1. Before placing on the market or putting into service a high-risk AI system referred to in Article 6(2), the provider or, where applicable, the authorised representative shall register that system in the EU database referred to in Article 60.

Amendment 2246
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 51 - paragraph 1
Before placing on the market or putting into service an AI system, the provider or, where applicable, the authorised representative shall register that system in the EU database referred to in Article 60.

Amendment 2247
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 51 - paragraph 1
Before placing on the market or putting into service a high-risk AI system referred to in Article 6, the provider or, where applicable, the authorised representative shall register that system in the EU database referred to in Article 60.

Amendment 2248
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 51 - paragraph 1
Before placing on the market or putting into service a high-risk AI system referred to in Article 6(2), the provider shall register that system in the EU database referred to in Article 60, in accordance with Article 60(2).

Amendment 2249
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 51 - paragraph 1
Before placing on the market or putting into service a high-risk AI system listed in Annex III, the provider or, where applicable, the authorised representative shall register that system in the EU database referred to in Article 60.

Amendment 2250
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Article 51 - paragraph 1 a (new)
2. A high-risk AI system designed, developed, trained, validate, tested or approved to be placed on the market or put into service, outside the EU, can be registered in the EU database referred to in Article 60 and placed on the market or put into service in the EU only if it is proven that at all stages of its design, development, training, validation, testing or approval, all the obligations required from such AI systems in EU have been met;

Amendment 2251
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 51 - paragraph 1 a (new)
Before using a high-risk AI system referred to in Article 6(2), the user or, where applicable, the authorised representative, shall register the uses of that system in the EU database referred to in Article 60. A new registration entry must be completed by the user for each new use of a high-risk AI system.

Amendment 2252
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş,
Article 51 - paragraph 1 a (new)
Before putting into service or using a high-risk AI system in one of the areas listed in Annex III, users who are public authorities or Union institutions, bodies, offices or agencies or users acting on their behalf shall register in the EU database referred to in Article 60.

Amendment 2253
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 51 - paragraph 1 a (new)
Before each deployment of, or substantial modification to, a high-risk AI system referred to in Article 6, the deployer or, where applicable, the authorised representative shall register that system in the EU database referred to in Article 60.

Amendment 2254
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 51 - paragraph 1 a (new)
Before using an AI system, public authorities shall register the uses of that system in the EU database referred to in Article 60. A new registration entry must be completed by the user for each use of an AI system.

Amendment 2255
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 51 - paragraph 1 a (new)
Before putting into service or using a high-risk AI system in accordance with Article 6(2), the user shall register in the EU database referred to in Article 60.

Amendment 2256
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 51 - paragraph 1 b (new)
Before using an AI system, public authorities shall register the uses of that system in the EU database referred to in Article 60. A new registration entry must be completed by the user for each new use of an AI system.

Amendment 2257
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 51 - paragraph 1 b (new)
In case the provider or deployer is a public authority they shall register both high-risk AI systems and all other AI systems.

Amendment 2258
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 51 a (new)
Article 51 a', 'Legal representative', '1. Where an operator pursuant to Article 2 is established outside the Union, they shall designate, in writing, a legal representative in the Union.', '2. The legal representative shall reside or be established in one of the Member States where the activities pursuant to Article 2, paragraphs 1 and 1a, are taking place.', '3. The operator shall provide its legal representative with the necessary powers and resources to comply with its tasks under this Regulation and to cooperate with the competent authorities.', '4. The legal representative shall, where appropriate, also carry out the following compliance tasks:', '(a) keep a copy of the EU declaration of conformity and the technical documentation at the disposal of the national supervisory authority and the national competent authorities and national authorities referred to in Article 63(7);', '(b) provide a national supervisory authority or a national competent authority, upon a reasoned request, with all the information and documentation necessary to demonstrate the conformity of a high-risk AI system with the requirements set out in Chapter 2 of this Title, including access to the logs automatically generated by the high-risk AI system to the extent such logs are under the control of the provider by virtue of a contractual arrangement with the user or otherwise by law;', '(c) cooperate with the national supervisory authority or the national competent authorities, upon a reasoned request, on any action the latter takes in relation to the high-risk AI system;', '(d) where applicable, comply with the registration obligations as referred into Article 51.', '5. The legal representative shall be mandated to be addressed, in addition to or instead of the operator, by, in particular, national supervisory authority or the national competent authorities and affected persons, on all issues related to ensuring compliance with this Regulation.', '6. The legal representative may be held liable for infringements of this Regulation, without prejudice to any liability of or legal actions against the operator, user or provider.

Amendment 2259
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Title IV
TRANSPARENCY OBLIGATIONS

Amendment 2260
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 52 - title
Transparency obligations

Amendment 2261
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 52 - paragraph 1
1. Providers shall ensure that AI systems intended to directly interact with natural persons are designed and developed in such a way that the AI system, the provider itself or the user can inform the natural person exposed to an AI system that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use. Where relevant, this information shall also include which functions are AI enabled, if there is human oversight and who is responsible for the decision-making process. This obligation shall not apply to AI systems authorised by law to detect, prevent, investigate and prosecute criminal offences, unless those systems are available for the public to report a criminal offence.

Amendment 2262
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 52 - paragraph 1
1. Providers shall ensure that AI systems intended to interact with natural persons are designed and developed in such a way that natural persons are informed that they are interacting with an AI system.

Amendment 2263
Renew - Renew Europe Group
Dragoş Tudorache
Article 52 - paragraph 1
1. Providers shall ensure that AI systems intended to interact with natural persons are designed and developed in such a way that natural persons are informed that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use.

Amendment 2264
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 52 - paragraph 1
1. Providers shall ensure that AI systems are designed and developed in such a way that natural persons are informed without delay that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use. This shall also include information on which components and functions are supported through AI, information which main parameters the AI system takes into account, and information on human oversight and which person is responsible for decisions made or influenced by the system as well as information on rectification, redress rights and options.

Amendment 2265
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 52 - paragraph 2
deleted

Amendment 2266
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 52 - paragraph 2
2. Deployers of a remote biometric recognition system or a biometric categorisation system shall inform of the operation of the system the natural persons exposed thereto. This shall also include information on which components and functions are supported through AI, information which main parameters the AI system takes into account, and information on human oversight and which person is responsible for decisions made or influenced by the system as well as information on rectification, redress rights and options.

Amendment 2267
Renew - Renew Europe Group
Dragoş Tudorache
Article 52 - paragraph 2
2. Users of an emotion recognition system or a biometric categorisation system shall inform of the operation of the system the natural persons exposed thereto.

Amendment 2268
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Vlad-Marius Botoş,
Article 52 - paragraph 2
2. Users of an emotion recognition system or a biometric categorisation system shall inform of the operation of the system the natural persons exposed thereto.

Amendment 2269
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 52 - paragraph 3 - introductory part
3. Users of an AI system that generates or manipulates audio or visual content that would falsely appear to be authentic or truthful and which features depictions of people appearing to say or do things they did not say or do, without their consent (‘deep fake’), shall disclose that the content has been artificially generated or manipulated. Disclosure shall mean labelling the content in a way that informs that the content is inauthentic and that is clearly visible for the recipient of that content. To label the content, users shall take into account the generally acknowledged state of the art and relevant harmonised standards and specifications.

Amendment 2270
EPP - Group of the European Peoples Party (Christian Democrats)
Geoffroy Didier
Article 52 - paragraph 3 - introductory part
3. Users of an AI system that generates or manipulates image, audio, text, script or video content that appreciably resembles existing persons, objects, places, text, script or other entities or events and would falsely appear to a person to be authentic or truthful (‘deep fake’), shall disclose that the content has been artificially generated or manipulated.

Amendment 2271
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,
Article 52 - paragraph 3 - introductory part
3. Users of an AI system that generates or manipulates image, audio or video content that appreciably resembles existing persons, objects, places or other entities or events and would falsely appear to a person to be authentic or truthful (‘deep fake’), shall disclose, in an appropriate, clear and visible manner, that the content has been artificially generated or manipulated.

Amendment 2272
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 52 - paragraph 3 - introductory part
3. Deployers of an AI system other than those in paragraphs 1 or 2, that generates or manipulates image, audio or video content that appreciably resembles existing persons, objects, places or other entities or events and would falsely appear to a person to be authentic or truthful (‘deep fake’), shall disclose that the content has been artificially generated or manipulated.

Amendment 2273
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 52 - paragraph 3 - subparagraph 1
deleted

Amendment 2274
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 52 - paragraph 3 - subparagraph 1
deleted

Amendment 2275
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 52 - paragraph 3 - subparagraph 1
However, the first subparagraph shall not apply where the use of an AI system that generates or manipulates audio or visual content is authorized by law to detect, prevent, investigate and prosecute criminal offences or where the content forms part of an evidently creative, satirical, artistic or fictional cinematographic, video game visuals or analogous work or it is necessary for the exercise of the right to freedom of expression and the right to freedom of the arts and sciences guaranteed in the Charter of Fundamental Rights of the EU, and subject to appropriate safeguards for the rights and freedoms of third parties.

Amendment 2276
Renew - Renew Europe Group
Dragoş Tudorache
Article 52 - paragraph 3 - subparagraph 1
However, the first subparagraph shall not apply where it is necessary for the exercise of the right to freedom of expression and the right to freedom of the arts and sciences guaranteed in the Charter of Fundamental Rights of the EU, and subject to appropriate safeguards for the rights and freedoms of third parties.

Amendment 2277
EPP - Group of the European Peoples Party (Christian Democrats)
Geoffroy Didier
Article 52 - paragraph 3 - subparagraph 1
However, the first subparagraph shall not apply where the use is authorised by law to detect, prevent, investigate and prosecute criminal offences and shall be without prejudice to the exercise of the right to freedom of expression and the right to freedom of the arts and sciences guaranteed in the Charter of Fundamental Rights of the EU, and to appropriate safeguards for the rights and freedoms of third parties.

Amendment 2278
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,
Article 52 - paragraph 3 - subparagraph 1
However, the first subparagraph shall not apply where the content is part of an obviously artistic, creative or fictional cinematographic work or it is necessary for the exercise of the right to freedom of expression and the right to freedom of the arts and sciences guaranteed in the Charter of Fundamental Rights of the EU, and subject to appropriate safeguards for the rights and freedoms of third parties.

Amendment 2279
EPP - Group of the European Peoples Party (Christian Democrats)
Geoffroy Didier
Article 52 - paragraph 3 a (new)
3 a. Providers shall ensure that recommendation systems used to disseminate and order cultural and creative content are designed in such a way that the personalised suggestion is explainable and non-discriminatory. A clear explanation regarding the parameters determining ranking shall be provided to users and shall be easily accessible. Natural persons shall have the right to opt out of recommended and personalised services. This opt-out possibility shall be easily accessible and not prevent from using the core service.

Amendment 2280
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 52 - paragraph 3 a (new)
3 a. The obligations in paragraphs 1, 2 and 3 shall be without prejudice to Union law on delaying information of subjects in ongoing criminal investigations, and be without prejudice to the exercise of the right to freedom of expression and the right to freedom of the arts and sciences guaranteed in the Charter of Fundamental Rights of the EU, and subject to appropriate safeguards for the rights and freedoms of third parties.

Amendment 2281
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 52 - paragraph 3 a (new)
3 a. The information referred to in paragraphs 1 to 3 shall be provided to natural persons in a clear and visible manner at the latest at the time of the first interaction or exposure.

Amendment 2282
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 52 - paragraph 4
4. The information in paragraphs 1, 2 and 3 shall be provided in an accessible, easy to understand, yet comprehensive manner, at least in one of the languages of the Member State in which the system was made available, and shall not affect the requirements and obligations set out in Title III of this Regulation.

Amendment 2283
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 52 a (new)
Article 52 a', '1. The Commission is empowered to adopt delegated acts in accordance with Article 73 to update the list of AI systems subject to transparency obligations under Article 52 by adding AI systems that affect individuals or to which they are subject, where: the AI systems pose a risk of manipulation, harm to the health and safety, or a risk of adverse impact on fundamental rights, that is, in respect of its severity or probability of occurrence, equivalent to or greater than the risk of harm or of adverse impact posed by the systems already referred to in Article52.', '2. When assessing for the purposes of paragraph 1 whether an AI system poses a risk that is equivalent to or greater than the risk of harm posed by the AI systems already referred to in Article 52, the Commission shall take into account the following non-cumulative criteria:', 'a. the intended purpose of the AI system, or the reasonably foreseeable consequences of its use;', 'b. the extent to which an AI system poses a risk of manipulation, or of adversely impacting one or more fundamental rights in a manner which could be to some degree mitigated by additional transparency measures;', 'c. the extent to which the use of an AI system impairs natural persons’ agency, autonomy of choice or may lead to or already has led to developing addictive behaviour;', 'd. the extent to which the use of an AI system may lead to or has already led to price discrimination or other form of economic harm;', 'e. the extent to which the use of an AI system may lead to or has already led to negative societal effects such as increased polarisation of opinions, insufficient exposure to objective sources of information and amplification of illegal online content.', 'f. the extent to which an AI system has been used or is likely to be used;', 'g. the extent to which the use of an AI system has already been shown to pose a risk in the senses of points b) to e) above, has caused harm to health and safety or disproportionate impact on fundamental rights or has given rise to significant concerns in relation to the materialisation of such harm or disproportionate impact, as demonstrated by reports or documented allegations available to national competent authorities;', 'h. the potential extent of such harm or such disproportionate impact, in particular in terms of its intensity and its ability to affect a plurality of persons or to affect aparticular group of persons disproportionately;', 'i. the extent to which potentially harmed or adversely impacted persons are dependent on the outcome produced with an AI system, in particular because for practical or legal reasons it is not reasonably possible to opt-out from that outcome or from the functionality of the service which relies on the AI system;', 'j. the extent to which potentially harmed or adversely impacted persons are in a vulnerable position in relation to the user of an AI system, in particular due to an imbalance of power, knowledge, economic or social circumstances, accessibility barriers, or age;', 'k. the extent to which the outcome produced with an AI system is not easily reversible, whereby outcomes having an impact on the health or safety of persons shall not be considered as easily reversible;', 'l. the extent to which existing Union legislation lacks: i. effective measures of redress in relation to the risks posed by an AI system, with the exclusion of claims for damages; ii. effective measures to prevent or substantially minimise those risks.

Amendment 2284
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 52 a (new)
Article 52 a', 'General purpose AI systems', '1. The placing on the market, putting into service or use of general purpose AI systems shall not, by themselves only, make those systems subject to the provisions of this Regulation.', '2. Any person who places on the market or puts into service under its own name or trademark or uses a general purpose AI system made available on the market or put into service for an intended purpose that makes it subject to the provisions of this Regulation shall be considered the provider of the AI system subject to the provisions of this Regulation.', '3. Paragraph 2 shall apply, mutatis mutandis, to any person who integrates a general purpose AI system made available on the market, with or without modifying it, into an AI system whose intended purpose makes it subject to the provisions of this Regulation.', '4. The provisions of this Article shall apply irrespective of whether the general purpose AI system is open source software or not.

Amendment 2285
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 52 a (new)
Article 52 a', 'Limitations for deep fakes of persons', 'Notwithstanding Article 52 and subject to appropriate safeguards for the rights and freedoms of third parties, the use of AI systems that generate or manipulate image, audio or video content that appreciably resembles existing persons and would falsely appear to a person to be authentic or truthful (‘deep fake’), shall be permitted only', '(a) when used for the exercise of the rights to freedom of expression and to artistic expression, or', '(b) with the explicit consent of the affected persons.

Amendment 2286
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Title IV a (new)
Title GENERAL PURPOSE AI SYSTEMS Article 52a (new):Establishment of the Navigator Programme for General purpose AI systems 1.A ‘Navigator Programme for General purpose AI systems’ (the ‘Navigator Programme’) is established and reports to the European AI Board referred to in Article 56. 2.The Navigator Programme shall provide advice and assistance to the Commission in order to: (a) Develop, maintain and enforce a Code of Practice for General purpose AI systems research and development. (b) Coordinate and contribute to the effective cooperation of the Commission and the developers of general purpose AI systems. (c) Assist the Commission in ensuring the enforcement of this Regulation to general purpose AI systems (d) Advise the Commission on the development or alteration of regulatory measures concerning general purpose AI systems to preserve fundamental rights, health and safety of citizens 3.The Navigator Programme shall be composed of staff selected for having the competences most appropriate to fulfill the Navigator Programme’s functions.External experts from government, civil society and academia may be invited on an ad hoc basis to advise on the issues related to the Navigator Programme’s tasks.The Navigator Programme may invite observers to attend its non-confidential meetings and may hold exchanges with interested third parties to an appropriate extent.To that end the Commission may facilitate exchanges between the Navigator Programme and other Union bodies, offices, agencies and advisory groups. 4.The modalities and rules of procedure of the Navigator Programme shall be set out in accordance with the internal rules of the Commission.The modalities shall also contain the operational aspects related to the execution of the Navigator Programme’s tasks as listed in paragraph 7 of this Article. 5.The Navigator Programme shall have a sufficient number of competent personnel for assistance in the proper performance of its tasks. 6.The Navigator Programme shall be organised and operated so as to safeguard the independence, objectivity and impartiality of its tasks.The Navigator Programme shall document and implement a structure and procedures to safeguard impartiality and to promote and apply the principles of impartiality throughout its tasks. 7.When providing advice and assistance to the Commission in the context of paragraph 2, the Navigator Programme shall in particular: (a) Navigate developers of general purpose AI systems in the legal implications of their work for the health and safety and fundamental rights of EU citizens. (b) Assign a staff member for each identified team of developers of General purpose AI systems to have direct bilateral monthly conversations on relevant advances and implications of the General purpose AI system in question.These conversations shall cover: (i) the latest progress and experimentation in the general purpose AI system team including findings related to unexpected behaviors and upcoming research projects, (ii) design measures taken to identify and mitigate risks prior to development, (iii) demonstrations (‘demos’) of new versions of the model and of its compliance-by-design features, (iv) steps to take to manage the model’s implications for fundamental rights, health and safety in line with this Regulation, (v) measures in place within the developers team for quality assurance and risk management and in the design of upcoming general purpose system for accuracy, robustness and control, (vi) the current usage of the general purpose AI system by other providers, including the estimated number of end-users affected by the general purpose AI system’s output monthly, the sectoral, functional, geographic and demographic distribution of applications based on the general purpose AI system, the novel applications, etc. (vii) the adequacy of the self-regulatory measures and of the help provided by the authorities for compliance with the Code of Practice, (viii) the adequacy of the Code of Practice in helping fulfill this Regulation objective of AI adoption and the protection of citizens’ fundamental rights, health and safety and societal interest of the Union, (ix) the state of the art of general purpose AI system research and development and the identification of new competing development teams worldwide that would benefit from joining the Navigator Programme. (c) Build and maintain mutual understanding and a common evidence base over the years on general purpose AI systems, their implications, and measures to govern them. (d) Build and maintain trust-based relationships with the developers. (e) Gain expertise on the topic of general purpose AI systems and transfer this expertise as appropriate to all decisions taken by the Commission related to AI systems. (f) Issue opinions, recommendations or written contributions on matters related to the application of the Union’s regulations to general purpose AI systems. (g) Develop, maintain and update a database of identified general purpose AI systems with assessment of their influence. (h) Develop, maintain and update a list of upcoming general purpose AI systems research and development projects by developer teams of existing general purpose AI systems, 8.The conversations and correspondence generated in the scope of the Navigator Programme shall be covered by a strict confidentiality agreement. 9.In particular, the staff members of the Navigator Programme may not share with each other confidential or commercially sensitive information about their assigned general purpose AI system. 10.The Navigator Programme shall have documented procedures in place ensuring that its personnel, observers, external experts, subcontractors and any associated body or personnel of external bodies respect the confidentiality of the information which comes into their possession during the performance of its tasks, except when disclosure is required by law.The staff of the Navigator Programme shall be bound to observe professional secrecy with regard to all information obtained in carrying out their tasks under this Regulation.The staff of the Navigator Programme shall undergo a cooldown period of 5 years after interruption of their contract during which they may not gain from the confidential information they have acquired, neither through entrepreneurial ventures nor contracts nor employments. 11.Any information and documentation obtained by the Navigator Programme and its staff during the performance of their duty shall be treated in compliance with the confidentiality obligations set out in Article 70. 12.The Code of Practice for general purpose AI systems research and development (the ‘Code of Practice’) shall be drawn following consultation with the developers of identified General purpose AI systems and shall aim to protect fundamental rights, health and safety of EU citizens by considering compliance with proportionate requirements at the design stage (‘compliance-by-design’).The Code of Practice shall be updated yearly in consultation with developers of general purpose AI systems, academics, civil society and national competent authorities in order to be adapted to the evolution of the technology, the progress of the technical safeguards and the maturity and effectiveness of existing institutional safeguards surrounding general purpose AI systems. 13.The developers of general purpose AI systems shall comply with the Code of Practice before allowing their general purpose AI systems to be adapted or used or integrated into AI systems or software put into service or made available on the market or to citizens.The Navigator Programme shall assist in their compliance.14.The Code of Practice and the list of systems whose compliance with it is monitored by the Navigator Programme shall be made public.

Amendment 2287
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Title IV a (new)
Rights of affected persons Article 52 a 1.Natural persons have the right not to be subject to non-compliant AI systems.The placing on the market, putting into service or use of non-compliant AI system gives rise to the right of the affected natural persons subject to such non-compliant AI systems to seek and receive redress. 2.Natural persons have the right to be informed about the use and functioning of AI systems they have been or may be exposed to, particularly in the case of high-risk and other regulated AI systems, according to Article 52. 3.Natural persons and public interest organisations have the right to lodge a complaint before the relevant national supervisory authorities against a producer or user of non-compliant AI systems where they consider that their rights or the rights of the natural persons they represent under the present regulation have been violated, and have the right receive effective remedy.

Amendment 2288
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 53 - paragraph 1
1. The competent authorities of the Member States shall establish several physical and digital AI regulatory sandboxes six months prior to the entry into application of this Regulation based on well-established criteria that provide a controlled environment that facilitates the development, testing and validation of innovative AI systems before their placement on the market or putting into service pursuant to a specific plan. SMEs, start-ups, enterprises, innovators or other relevant actors could be included as partners in the regulatory sandboxes. This shall take place under the direct supervision and guidance by the respective national competent authorities or by the European Data Protection Supervisor in relation to AI systems provided by the EU institutions, bodies and agencies with a view to identify risks to health and safety and fundamental rights, test mitigation measures for identified risks, demonstrate prevention of these risks and otherwise ensuring compliance with the requirements of this Regulation and, where relevant, other Union and Member States legislation supervised within the sandbox. The Commission shall play a complementary role, allowing those Member States with demonstrated experience with sandboxing to build on their expertise and, on the other hand, assisting and providing technical understanding and resources to those Member States that seek guidance on the set-up and running of these regulatory sandboxes.

Amendment 2289
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 53 - paragraph 1
1. AI regulatory sandboxes established by one or more Member States competent authorities or the European Data Protection Supervisor shall provide a controlled environment that facilitates the development, testing and validation of innovative AI systems for a limited time before their placement on the market or putting into service pursuant to a specific plan. Following a fundamental rights impact assessment, as laid out in Article 9a, this shall take place under the direct supervision and guidance by the competent authorities with a view to identifying risks in particular to the environment, health and safety, and fundamental rights, ensuring compliance with the requirements of this Regulation and, where relevant, other Union and Member States legislation supervised within the sandbox. Access to the regulatory sandboxes shall require providers to apply for participation. Supervising authorities shall inform applicants of their decision within 3 months of the application, or, in justified cases, of an extension of this deadline by at most another 3 months. The supervising authority shall inform the European Artificial Intelligence Board of the provision of regulatory sandboxes.

Amendment 2290
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 53 - paragraph 1
1. AI regulatory sandboxes established by the Commission in collaboration with one or more Member States competent authorities or the European Data Protection Supervisor, are considered high risk and shall provide a controlled environment that facilitates the development, testing and validation of innovative AI systems for a limited time before their placement on the market or putting into service pursuant to a specific plan. They shall operate in full compliance with the General Data Protection Regulation. This shall take place under the direct supervision and guidance by the Commission in collaboration with competent authorities with a view to identifying risks to health and safety and fundamental rights, testing mitigation measures for identified risks, demonstrating prevention of these risks and otherwise ensuring compliance with the requirements of this Regulation and, where relevant, other Union and Member States legislation supervised within the sandbox. AI regulatory sandboxes shall remain a technical solution, shall assess potentialadverse effects and not be used on the employment context.

Amendment 2291
EPP - Group of the European Peoples Party (Christian Democrats)
Tomislav Sokol
Article 53 - paragraph 1
1. AI regulatory sandboxes established by SMEs, start-ups, enterprises and other innovators, one or more Member States competent authorities or the European Data Protection Supervisor shall provide a controlled environment that facilitates the safe development, testing and validation of innovative AI systems for a limited time before their placement on the market or putting into service pursuant to a specific plan. For Member States competent authorities or the European Data Protection Supervisor, this shall take place under the direct supervision and guidance by the competent authorities with a view to ensuring compliance with the requirements of this Regulation and, where relevant, other Union and Member States legislation supervised within the sandbox. For SMEs, start-ups, enterprises and other innovators, this shall take place independently from supervising authorities, while following rules and regulations (e.g. a Code of conduct) established in cooperation with Member State competent authorities.

Amendment 2292
EPP - Group of the European Peoples Party (Christian Democrats)
Karlo Ressler
Article 53 - paragraph 1
1. AI regulatory sandboxes established by SMEs, start-ups, enterprises and other innovators, one or more Member States competent authorities or the European Data Protection Supervisor shall provide a controlled environment that facilitates the safe development, testing and validation of innovative AI systems for a limited time before their placement on the market or putting into service pursuant to a specific plan. For Member States competent authorities or the European Data Protection Supervisor, this shall take place under the direct supervision and guidance by the competent authorities with a view to ensuring compliance with the requirements of this Regulation and, where relevant, other Union and Member States legislation supervised within the sandbox. For SMEs, start-ups, enterprises and other innovators, this shall take place independently from supervising authorities, while following rules and regulations established in close cooperation with Member State competent authorities.

Amendment 2293
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 53 - paragraph 1
1. Member States shall establish AI regulatory sandboxes, which shall be operational by [24 months following the entering into force of this Regulation], and shall ensure that the competent authorities responsible for the regulatory sandboxes have sufficient resources available to fulfil their duties effectively and in a timely manner. Regulatory sandboxes can also be established at local, regional or European level.

Amendment 2294
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz
Article 53 - paragraph 1
1. AI regulatory sandboxes established by the European Commission, one or more Member States, or other competent entities shall provide a controlled environment that facilitates the development, testing and validation of innovative AI systems for a limited time before their placement on the market or putting into service pursuant to a specific plan. This shall take place in collaboration with and guidance by the European Commission or the competent authorities in order to identify risks to health and safety and fundamental rights, test mitigation measures for identified risks, demonstrate prevention of these risks and otherwise ensure compliance with the requirements of this Regulation and, where relevant, other Union and Member States legislation supervised within the sandbox.

Amendment 2295
Renew - Renew Europe Group
Morten Løkkegaard
Article 53 - paragraph 1
1. AI regulatory sandboxes established by one or more Member States competent authorities or the European Data Protection Supervisor shall provide a controlled environment that facilitates the development, testing and validation of innovative AI systems for a limited time before their placement on the market or putting into service pursuant to a specific plan. This shall take place under the direct supervision and guidance by the competent authorities with a view to ensuring compliance with the requirements of this Regulation and, where relevant, other Union and Member States legislation supervised. Consultation with AI vendors on the technological feasibility of the guidance from the competent authorities should be possible as part of the proces.

Amendment 2296
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 53 - paragraph 1
1. National supervisory authorities or the European Data Protection Supervisor may establish AI regulatory sandboxes that shall provide a controlled environment facilitating the development, testing and validation of innovative AI systems for a limited time before their placement on the market or putting into service. This shall take place under the direct supervision and guidance by the competent authorities with a view to ensuring compliance with the requirements of this Regulation and, where relevant, other Union and Member States legislation.

Amendment 2297
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 53 - paragraph 1
1. AI regulatory sandboxes established by one or more Member States competent authorities or the European Data Protection Supervisor shall provide a controlled environment that facilitates the development, testing and validation of innovative AI systems before their placement on the market or putting into service pursuant to a specific plan. This shall take place under the direct supervision and guidance by the competent authorities with a view to ensuring compliance with the requirements of this Regulation and, where relevant, other Union and Member States legislation supervised within the sandbox.

Amendment 2298
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 53 - paragraph 1 a (new)
1 a. AI regulatory sandboxes established by one or more Member States, by local, regional, or national competent authorities, by the Commission or by the European Data Protection Supervisor shall provide a controlled environment that facilitates the development, testing and validation of innovative AI systems for a limited time before their placement on the market or putting into service pursuant to a specific plan. This shall take place under the direct supervision and guidance by the competent authorities with a view to ensuring compliance with the requirements of this Regulation and, where relevant, other Union and Member States legislation supervised within the sandbox.

Amendment 2299
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 53 - paragraph 1 a (new)
1 a. This article shall also apply to AI systems for which full compliance with the requirements of Title III Chapter 2 requires an initial phase of placing the systems on the market or putting them into service and using the experiences gained in such initial phase to further develop the AI system so as to fully fulfil the requirements of Title III Chapter 2, particularly for the case of general purpose AI Systems.

Amendment 2300
Renew - Renew Europe Group
Morten Løkkegaard
Article 53 - paragraph 1 a (new)
1 a. The AI regulatory sandbox shall allow and facilitate cooperation with the private sector on technical test environments aimed at risk assessment, AI use cases and the involvement of notified bodies, standardisation bodies, and other relevant stakeholders when relevant.

Amendment 2301
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 53 - paragraph 1 a (new)
1 a. National supervisory authorities may establish AI regulatory sandboxes jointly with other national supervisory authorities.

Amendment 2302
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 53 - paragraph 1 b (new)
1 b. The national competent authority or the European Data Protection Supervisor, as appropriate, may also supervise testing in real world conditions upon the request of participants in the sandbox.

Amendment 2303
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 53 - paragraph 1 c (new)
1 c. 1c.The establishment of AI regulatory sandboxes as defined in paragraph 1 shall aim to contribute to the following objectives:', '(a) foster innovation and competiveness and facilitate the development of an AI ecosystem;', '(b) facilitate and accelerate access to the Union market for AI systems, including provided by small and medium enterprises (SMEs) and start-ups;', '(c) improve legal certainty through cooperation with the authorities involved in the AI regulatory sandbox with a view to ensuring compliance with this Regulation and, where appropriate, with other Union and Member States legislation;', '(d) enhance authorities’ understanding of the opportunities and risks of AI systems as well as of the suitability and effectiveness of the measures for preventing and mitigating those risks;', '(e) contribute to the uniform and effective implementation of this Regulation and, where appropriate, its swift adaptation, notably as regards the techniques in Annex I, the high-risk AI systems in Annex III, the technical documentation in Annex IV;', '(f) contribute to the development or update of harmonised standards and common specifications referred to in Articles 40 and 41 and their uptake by providers.

Amendment 2304
EPP - Group of the European Peoples Party (Christian Democrats)
Tomislav Sokol
Article 53 - paragraph 2
2. Member States shall ensure that to the extent the innovative AI systems involve the processing of personal data or otherwise fall under the supervisory remit of other national authorities or competent authorities providing or supporting access to data, the national data protection authorities and those other national authorities are associated to the operation of the AI regulatory sandbox established by one or more Member States competent authorities or the European Data Protection Supervisor. Without prejudice to the Regulation (EU) 2016/679, start-ups, SMEs, enterprises and other innovators may request access to personal data from relevant national authorities to be used in their AI sandbox under the guidelines defined through Member State rules and regulations (e.g. Code of conduct).

Amendment 2305
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 53 - paragraph 2
2. Member States in collaboration with the Commission shall ensure that to the extent the innovative AI systems involve the processing of personal data or otherwise fall under the supervisory remit of other national authorities or competent authorities providing or supporting access to data, the national data protection authorities and those other national authorities are associated to the operation of the AI regulatory sandbox. As appropriate, national competent authorities may allow for the involvement in the AI regulatory sandbox of other actors within the AI ecosystem such as national or European standardisation organisations, notified bodies, testing and experimentation facilities, research and experimentation labs and innovation hubs.

Amendment 2306
EPP - Group of the European Peoples Party (Christian Democrats)
Karlo Ressler
Article 53 - paragraph 2
2. Member States shall ensure that to the extent the innovative AI systems involve the processing of personal data or otherwise fall under the supervisory remit of other national authorities or competent authorities providing or supporting access personal data, the national data protection authorities and those other national authorities are associated to the operation of the AI regulatory sandbox established by one or more Member States competent authorities or the European Data Protection Supervisor. Start-ups, SMEs, enterprises and other innovators may request access to personal data from relevant national authorities to be used in their AI sandbox under the guidelines defined through Member State rules and regulations.

Amendment 2307
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 53 - paragraph 2
2. The national supervisory authority shall ensure that to the extent the innovative AI systems involve the processing of personal data, the national data protection authorities are associated to the operation of the AI regulatory sandbox.

Amendment 2308
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 53 - paragraph 2
2. Member States shall ensure that to the extent the innovative AI systems involve the processing of personal data, or otherwise fall under the supervisory remit of other national authorities or competent authorities providing or supporting access to data, the national data protection authorities and those other national authorities are associated to the operation of the AI regulatory sandbox and involved in the control of those aspects of the sandbox it supervises to the full extent of its respective powers.

Amendment 2309
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz Körner, Jan-
Article 53 - paragraph 2
2. The European Commission in collaboration with Member States shall ensure that to the extent the innovative AI systems involve the processing of personal data or otherwise fall under the supervisory remit of other national authorities or competent authorities providing or supporting access to data, the national data protection authorities and those other national authorities are associated to the operation of the AI regulatory sandbox.

Amendment 2310
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 53 - paragraph 2
2. The Commission in collaboration with Member States shall ensure that to the extent the innovative AI systems involve the processing of personal data or otherwise fall under the supervisory remit of other national authorities or competent authorities providing or supporting access to data, the national data protection authorities and those other national authorities are associated to the operation of the AI regulatory sandbox.

Amendment 2311
Renew - Renew Europe Group
Morten Løkkegaard
Article 53 - paragraph 2
2. Member States shall ensure that to the extent the innovative AI systems involve the processing of personal data or otherwise fall under the supervisory remit of other national authorities or competent authorities providing or supporting access to personal data, the national data protection authorities and those other national authorities are associated to the operation of the AI regulatory sandbox.

Amendment 2312
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 53 - paragraph 2 a (new)
2 a. Access to the AI regulatory sandboxes and supervision and guidance by the relevant authorities shall be free of charge, without prejudice to exceptional costs that national competent authorities may recover in a fair and proportionate manner. It shall be open to any provider or prospective provider of an AI system who fulfils national eligibility and selection criteria and who has been selected by the national competent authorities or by the European Data Protection Supervisor. Participation in the AI regulatory sandbox shall be limited to a period that is appropriate to the complexity and scale of the project in any case not longer than a maximum period of 2 years, starting upon the notification of the selection decision. The participation may be extended for up to 1 more year.

Amendment 2313
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 53 - paragraph 3
3. The AI regulatory sandboxes shall not affect the supervisory and corrective powers of the competent authorities. Any significant risks to democracy, the environment, health and safety and fundamental rights identified during the development and testing of such systems shall result in immediate mitigation and, failing that, in the suspension of the development and testing process until such mitigation takes place, or, where mitigating measures cannot be identified that stop and remedy such significant risk or harm, Member States shall ensure that the competent authorities have the power to permanently suspend the development and testing process. In the case of abuse, competent authorities shall have the power to ban providers from applying for and participating in the regulatory sandbox for a limited amount of time or indefinitely. Decisions to suspend or ban providers from participating in regulatory sandboxes shall be submitted without delay to the European Artificial Intelligence Board. Applicants shall have access to remedies.

Amendment 2314
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 53 - paragraph 3
3. The AI regulatory sandboxes shall not affect the supervisory and corrective powers of the competent authorities. Regulatory sandboxes involving activities that may impact health, safety and fundamental rights, democracy and rule of law or the environment shall be developed in accordance with redress-by-design principles. Any significant risks identified during the development and testing of such systems shall result in immediate mitigation and, failing that, in the suspension of the development and testing process until such mitigation takes place.

Amendment 2315
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 53 - paragraph 3
3. The participation in the AI regulatory sandboxes shall not affect the supervisory and corrective powers of the competent authorities supervising the sandbox. However, provided that the participant(s) respect the sandbox plan and the terms and conditions for their participation and follow in good faith the guidance given by the authorities, no administrative enforcement action shall be taken by the authorities for infringement of applicable Union or Member State legislation.

Amendment 2316
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 53 - paragraph 3
3. The AI regulatory sandboxes shall not affect the supervisory and corrective powers of the competent authorities. Any significant risks to fundamental rights, health, safety or the environment identified during the development and testing of such systems shall result in immediate and adequate mitigation. Where such mitigation proves to be ineffective, the development and testing process shall be suspended without delay until such mitigation takes place.

Amendment 2317
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 53 - paragraph 3
3. The AI regulatory sandboxes shall not affect the supervisory and corrective powers of the competent authorities. Any significant risks to health and safety, fundamental rights and the environment identified during the development and testing of such systems shall result in immediate and adequate mitigation. Where such mitigation proves to be ineffective, the development and testing process shall be suspended without delay until such mitigation takes place.

Amendment 2318
Renew - Renew Europe Group
Morten Løkkegaard
Article 53 - paragraph 3
3. The AI regulatory sandboxes shall not affect the supervisory and corrective powers of the competent authorities. Any significant risks to health and safety and fundamental rights identified during the development and testing of such systems shall result in immediate and adequate mitigation. Where such mitigation proves to be ineffective, the development and testing process shall be suspended without delay until such mitigation takes place.

Amendment 2319
EPP - Group of the European Peoples Party (Christian Democrats)
Tomislav Sokol
Article 53 - paragraph 3
3. The AI regulatory sandboxes shall not affect the supervisory and corrective powers of the competent authorities. Any significant risks to health and safety and fundamental rights identified during the development and testing of AI systems shall result in immediate mitigation and, failing that, in the suspension of the development and testing process until such mitigation takes place.

Amendment 2320
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 53 - paragraph 4
4. Participants in the AI regulatory sandbox shall remain liable under applicable Union and Member States liability legislation for any harm intentionally inflicted on third parties as a result from the experimentation taking place in the sandbox, which was known or reasonably foreseeable at the time of experimentation and the risk of which the sandbox participants was not made aware of.

Amendment 2321
Renew - Renew Europe Group
Morten Løkkegaard
Article 53 - paragraph 4
4. Participants in the AI regulatory sandbox shall remain liable under applicable Union and Member States liability legislation for any harm inflicted on third parties as a result of the experimentation taking place in the sandbox.

Amendment 2322
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 53 - paragraph 4 a (new)
4 a. The AI regulatory sandboxes shall be designed and implemented in such a way that, where relevant, they facilitate cross-border cooperation between national competent authorities and synergies with relevant sectoral regulatory sandboxes. Cooperation may also be envisaged with third countries outside the Union establishing mechanisms to support AI innovation.

Amendment 2323
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 53 - paragraph 5
5. Member States’ competent authorities in collaboration with the Commission shall establish AI regulatory sandboxes, as much as possible through national and regional initiatives, in particular through European digital innovation hubs, and closely coordinate their activities as well as cooperate within the framework of the European Artificial Intelligence Board. They shall submit annual reports to the Board and the Commission on the results from the implementation of those schemes, including good practices, lessons learnt and recommendations on their setup and, where relevant, on the application of this Regulation and other Union legislation supervised within the sandbox. The annual reports or abstracts shall be made available to the public, online, in order to further enable innovation within the Union. Outcomes and learnings of the sandbox should be leveraged when monitoring the effectiveness and enforcement of this Regulation and taken into account when proceeding to amending it. The annual reports shall also be submitted to the AI Board which shall publish on its website a summary of all good practices, lessons learnt and recommendations.

Amendment 2324
Renew - Renew Europe Group
Morten Løkkegaard
Article 53 - paragraph 5
5. Member States’ competent authorities that have established AI regulatory sandboxes shall coordinate their activities and cooperate within the framework of the European Artificial Intelligence Board. They shall submit annual reports to the Board and the Commission on the results from the implementation of those scheme, including good practices, incidents, lessons learnt and recommendations on their setup and, where relevant, on the application of this Regulation and other Union legislation supervised within the sandbox. Those reports or abstracts thereof shall be made available to the public in order to further enable innovation in the Union, in respect of protecting trade secrets and innovative business and technical ideas.

Amendment 2325
EPP - Group of the European Peoples Party (Christian Democrats)
Karlo Ressler
Article 53 - paragraph 5
5. Member States’ competent authorities that have established AI regulatory sandboxes shall coordinate their activities and cooperate within the framework of the European Artificial Intelligence Board. They shall submit annual reports to the Board and the Commission on the results of the implementation of those schemes, including good practices, lessons learnt and recommendations on their setup and, where relevant, on the application of this Regulation and other Union legislation supervised within the sandbox. SMEs, start-ups, enterprises and other innovators shall submit annual reports to Member States’ competent authorities and share their good practices, lessons learnt and recommendations on their AI sandboxes.

Amendment 2326
EPP - Group of the European Peoples Party (Christian Democrats)
Tomislav Sokol
Article 53 - paragraph 5
5. Member States’ competent authorities that have established AI regulatory sandboxes shall coordinate their activities and cooperate within the framework of the European Artificial Intelligence Board. They shall submit annual reports to the Board and the Commission on the results from the implementation of those scheme, including good practices, lessons learnt and recommendations on their setup and, where relevant, on the application of this Regulation and other Union legislation supervised within the sandbox. SMEs, start-ups, enterprises and other innovators are invited to share their good practices, lessons learnt and recommendations on their AI sandboxes with Member State competent authorities.

Amendment 2327
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 53 - paragraph 5
5. Member States’ competent authorities that have established AI regulatory sandboxes shall coordinate their activities and cooperate within the framework of the European Artificial Intelligence Board. They shall submit annual reports to the Board and the Commission on the results from the implementation of those schemes, including good practices, lessons learnt and recommendations on their setup and, where relevant, on the application and possible revision of this Regulation and other Union legislation supervised within the sandbox, in particular with regards to easing burdens and introducing further regulation where additional risks and potential harms are identified.

Amendment 2328
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 53 - paragraph 5
5. The national supervisory authority that has established the AI regulatory sandboxes shall coordinate their activities and cooperate within the framework of the European Artificial Intelligence Board. They shall submit annual reports to the Board and the Commission on the results of the implementation of those schemes, including good practices, incidents, lessons learnt and recommendations on their setup and, where relevant, on the application of this Regulation and other Union legislation supervised within the sandbox. Those reports or abstracts thereof shall be made available to the public in order to further enable innovation in the Union.

Amendment 2329
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz Körner, Ondřej
Article 53 - paragraph 5
5. The European Commission, Member States’ competent authorities and other entities that have established AI regulatory sandboxes shall coordinate their activities and cooperate within the framework of the European Commission’s AI Regulatory Sandboxing programme. The European Commission shall submit annual reports to the European Artificial Intelligence Board on the results from the implementation of those scheme, including good practices, lessons learnt and recommendations on their setup and, where relevant, on the application of this Regulation and other Union legislation supervised within the sandbox.

Amendment 2330
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 53 - paragraph 5
5. National competent authorities shall coordinate their activities and cooperate within the framework of the AI Office. They shall submit annual reports to the AI Office and the Commission on the results of the implementation of those scheme, including good practices, incidents, lessons learnt and recommendations on their setup and, where relevant, on the application of this Regulation another Union legislation supervised within the sandbox. Those reports or abstracts thereof shall be made available to the public in order to further enable innovation in the Union.

Amendment 2331
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 53 - paragraph 5
5. The Commission, Member States’ competent authorities that have established AI regulatory sandboxes shall coordinate their activities and cooperate within the framework of the European Artificial Intelligence Board. They shall submit annual reports to the Board and the Commission on the results from the implementation of those scheme, including good practices, lessons learnt and recommendations on their setup and, where relevant, on the application of this Regulation and other Union legislation supervised within the sandbox.

Amendment 2332
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 53 - paragraph 5
5. Member States’ competent authorities that have established AI regulatory sandboxes shall cooperate within the framework of the European Artificial Intelligence Board. They shall submit annual reports to the Board and the Commission on the results from the implementation of those scheme, including good practices, lessons learnt and recommendations on their setup and, where relevant, on the application of this Regulation and other Union legislation supervised within the sandbox.

Amendment 2333
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 53 - paragraph 5 a (new)
5 a. Regulatory sandboxes shall allow and facilitate the testing of possible adaptations of the regulatory framework governing artificial intelligence in order to enhance innovation or reduce compliance costs, without prejudice to the provisions of this Regulation or to the health, safety, fundamental rights of natural persons or to the values of the Union as enshrined in Article 2 TEU. The results and lessons learned from such tests shall be submitted to the AI Office and the Commission.

Amendment 2334
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 53 - paragraph 6
6. The modalities and the conditions of the operation of the AI regulatory sandboxes, including the eligibility criteria and the procedure for the application, selection, participation and exiting from the sandbox, and the rights and obligations of the participants shall be set out in implementing acts. Those implementing acts shall be adopted in accordance with the examination procedure referred to in Article 74(2) no later than 12 months following the entry into force of this Regulation and shall ensure, inter alia:', '(a) that they allow start-ups to use their participation in the sandbox in order to fulfil, in a guided environment with significantly reduced costs, the conformity assessment obligations of this Regulation or the voluntary application of the codes of conduct referred to in Article 69;', '(b) that adequate resources are dedicated to the establishment and functioning of the regulatory sandboxes so that the regulatory sandboxes can ensure broad access and keep up with demand for participation without creating disincentivising backlogs or delays;', '(c)that procedures, processes, and bureaucratic requirements for application, selection, participation, and exiting the sandbox are simple, easily intelligible, clearly communicated, and streamlined so as to facilitate the participation of startups with limited legal and bureaucratic capacities;', '(d) that procedures, processes, and bureaucratic requirements for application, selection, participation, and exiting the sandbox are streamlined across the Union and that participation in a regulatory sandbox established by a Member State by virtue of its obligation in paragraph 1 or by the Commission is uniformly recognised and carries the same legal effects across the Union.

Amendment 2335
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 53 - paragraph 6
6. The modalities and the conditions of the operation of the AI regulatory sandboxes, including the eligibility criteria and the procedure for the application, selection, participation and exiting from the sandbox, and the rights and obligations of the participants shall be set out by the European Artificial Intelligence Board in close cooperation with the Member States’ and competent authorities. A list of planned and current sandboxes, including the modalities, conditions, eligibility criteria and application, selection, participation procedure shall be made publicly available by the European Artificial intelligence Board.

Amendment 2336
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Article 53 - paragraph 6
6. The modalities and the conditions of the operation of the AI regulatory sandboxes, including the eligibility criteria and the procedure for the application, selection, participation and exiting from the sandbox, and the rights and obligations of the participants shall be discussed with all the relevant actors of the AI value chain, such as research institutions and businesses, and set out in implementing acts. Those implementing acts shall be adopted in accordance with the examination procedure referred to in Article 74(2).

Amendment 2337
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 53 - paragraph 6
6. The modalities and the conditions of the operation of the AI regulatory sandboxes, including the eligibility criteria and the procedure for the application, selection, participation and exiting from the sandbox, and the rights and obligations of the participants shall be set out in implementing acts in accordance with the Council’s communication(11/2020) and in strong cooperation with relevant stakeholders. Those implementing acts shall be adopted in accordance with the examination procedure referred to in Article 74(2).

Amendment 2338
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 53 - paragraph 6 a (new)
6 a. The modalities referred to in Article 53(6) shall ensure at least the following: (a) participants in the regulatory sandboxing system, in particular small-scale providers, are granted access to pre-deployment services, such as preliminary registration of AI system, insurance, compliance and R&D support services, and to all the other relevant elements of the Union’s AI ecosystem and other Digital Single Market initiatives such as testing and experimentation facilities, digital hubs, centers of excellence, testing and experimentation facilities, and EU benchmarking capabilities; and to other value-adding services such as standardization and certification, community social platform and contact databases, tenders and grant making portal and lists of potential investors. (b) foreign providers, in particular small-scale providers, are eligible to take part in the regulatory sandboxes to incubate and refine their products in compliance with this Regulation. (c) individuals such as researchers, entrepreneurs, innovators and other pre-market ideas owners are eligible to take part in the regulatory sandboxes to incubate and refine their products in compliance with this Regulation. (d) there be as little fragmentation as possible of the regulatory sandboxes across Member States, notably through development of a single interface and contact point at the EU level to interact with the regulatory sandbox ecosystem and through the Commission facilitating the creation of transnational and EU-wide regulatory sandboxes

Amendment 2339
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 53 - paragraph 6 a (new)
6 a. Notwithstanding the modalities and conditions outlined in paragraph 6, Member States shall design regulatory sandboxes to provide access to as many providers as possible. There shall be aparticular focus on the use and application of general purpose AI systems. Member States may establish virtual sandboxing environments to ensure that sandboxes can meet the demand.

Amendment 2340
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz Körner, Ondřej
Article 53 - paragraph 6 a (new)
6 a. The Commission shall establish an EU AI Regulatory Sandboxing Programme whose modalities referred to in Article 53(6) shall cover the elements set out in Annex IXa. The Commission shall proactively coordinate with national, regional and also local authorities, as relevant.

Amendment 2341
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 53 - paragraph 6 a (new)
6 a. The Commission shall draw up guidelines for the proper establishment, development, implementation, functioning, and supervision of regulatory sandboxes.

Amendment 2342
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 53 - paragraph 6 b (new)
6 b. The Commission shall establish an EU AI Regulatory Sandboxing Work Programme whose modalities referred to in Article 53(6) shall cover the elements set out in Annex IXa. The Commission shall proactively coordinate with national and local authorities, where relevant.

Amendment 2343
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 54
deleted

Amendment 2344
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 54
deleted

Amendment 2345
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 54
deleted

Amendment 2346
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 54 - paragraph 1 - introductory part
1. In the AI regulatory sandbox personal data and data protected by intellectual property rights or trade secrets lawfully collected for other purposes shall be processed solely for the purposes of developing and testing certain AI systems in the sandbox under the following conditions:

Amendment 2347
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 54 - paragraph 1 - introductory part
1. In the AI regulatory sandbox personal data lawfully collected for other purposes shall be processed for the purposes of developing and testing certain innovative AI systems in the sandbox when all of the following conditions are met:

Amendment 2348
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Article 54 - paragraph 1 - introductory part
1. In the AI regulatory sandbox personal data lawfully collected for other purposes may be processed for the purposes of developing and testing certain innovative AI systems in the sandbox under the following conditions:

Amendment 2349
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 54 - paragraph 1 - point a - introductory part
(a) the AI systems shall be developed for safeguarding substantial public interest in one or more of the following areas:

Amendment 2350
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Article 54 - paragraph 1 - point a - introductory part
(a) the innovative AI systems shall be developed for safeguarding public interest in one or more of the following areas:

Amendment 2351
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 54 - paragraph 1 - point a - point i
deleted

Amendment 2352
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona Strugariu, Dragoş Pîslaru, Lucia Ďuriš Nicholsonová, Irena Joveva, Malik Azmani, Svenja Hahn, Alin Mituța
Article 54 - paragraph 1 - point a - point i
(i) the investigation, detection or prosecution of criminal offences or the execution of criminal penalties, including the safeguarding against threats to public security, under the control and responsibility of the competent authorities. The processing shall be based on Member State or Union law;

Amendment 2353
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 54 - paragraph 1 - point a - point iii
(iii) a high level of protection and improvement of the quality of the environment, and to counter and remedy the climate crisis;

Amendment 2354
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 54 - paragraph 1 - point a a (new)
(aa) natural persons whose personal data are used for the development and testing of certain innovative AI systems in the sandbox shall be informed of the collection and use of their data and shall have given their consent thereto;

Amendment 2355
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Article 54 - paragraph 1 - point c
(c) there are effective monitoring mechanisms to identify if any high risks to the rights and freedoms of the data subjects, as referred to in Art 35 Regulation (EU) 2016/679 and in Article 35 of Regulation (EU) 2018/1725 may arise during the sandbox experimentation as well as response mechanism to promptly mitigate those risks and, where necessary, stop the processing;

Amendment 2356
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 54 - paragraph 1 - point c
(c) there are effective monitoring mechanisms to identify if any risks to the fundamental rights of the data subjects and holders of intellectual property rights or trade secrets may arise during the sandbox experimentation as well as response mechanism to promptly mitigate those risks and, where necessary, stop the processing;

Amendment 2357
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 54 - paragraph 1 - point d
(d) any personal data or data protected by intellectual property rights or trade secrets to be processed in the context of the sandbox are in a functionally separate, isolated and protected data processing environment under the control of the participants and only authorised persons have access to those data;

Amendment 2358
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Article 54 - paragraph 1 - point e
(e) any personal data processed are not be transmitted, transferred or otherwise accessed by other parties that are not participants in the sandbox nor transferred to a third country outside the Union or an international organisation;

Amendment 2359
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 54 - paragraph 1 - point e
(e) any personal data or data protected by intellectual property rights or trade secrets processed are not be transmitted, transferred or otherwise accessed by other parties;

Amendment 2360
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Article 54 - paragraph 1 - point f
(f) any processing of personal data in the context of the sandbox shall not affect the application of the rights of the data subjects as provided for under Union law on the protection of personal data, in particular in Article 22 of Regulation (EU) 2016/679 and Article 24 of Regulation (EU) 2018/1725;

Amendment 2361
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Article 54 - paragraph 1 - point g
(g) any personal data processed in the context of the sandbox are protected by means of appropriate technical and organisational measures and deleted once the participation in the sandbox has terminated or the personal data has reached the end of its retention period;

Amendment 2362
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 54 - paragraph 1 - point g
(g) any personal data or data protected by intellectual property rights or trade secrets processed in the context of the sandbox are deleted once the participation in the sandbox has terminated or the personal data has reached the end of its retention period;

Amendment 2363
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Article 54 - paragraph 1 - point h
(h) the logs of the processing of personal data in the context of the sandbox are kept for the duration of the participation in the sandbox;

Amendment 2364
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 54 - paragraph 1 - point h
(h) the logs of the processing of personal data or data protected by intellectual property rights or trade secrets in the context of the sandbox are kept for the duration of the participation in the sandbox and 1 year after its termination, solely for the purpose of and only as long as necessary for fulfilling accountability and documentation obligations under this Article or other applicable Union or Member States legislation;

Amendment 2365
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 54 - paragraph 1 - point j
(j) a short summary of the AI project developed in the sandbox, its objectives, hypotheses and expected results, and non-confidential testing results, is published on the website of the competent authorities.

Amendment 2366
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 54 - paragraph 1 - point j
(j) a short summary of the AI system developed in the sandbox, its objectives and expected results published on the website of the competent authorities.

Amendment 2367
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 54 - paragraph 1 a (new)
1 a. Provided that the conditions of paragraph 1 are met, personal data processed for developing and testing innovative AI systems in the sandbox shall be considered compatible for the purposes of Article 6(4) GDPR.

Amendment 2368
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 54 - paragraph 2
2. Paragraph 1 further specifies Article 89 of Regulation (EU) 2016/679 and is without prejudice to Union or Member States legislation excluding processing for other purposes than those explicitly mentioned in that legislation or to Union or Member States legislation excluding the use of data protected by intellectual property or trade secrets under the conditions covered by Paragraph 1.

Amendment 2369
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 54 a (new)
Article 54 a', 'Promotion of AI research and development in support of socially and environmentally beneficial outcomes', '1. Member States shall promote research and development of AI solutions which support socially and environmentally beneficial outcomes, including but not limited to development of AI-based solutions to increase accessibility for persons with disabilities, tackle socio-economic inequalities, and meet sustainability and environmental targets, by:', '(a) providing relevant projects with priority access to the AI regulatory sandboxes to the extent that they fulfil the eligibility conditions;', '(b) earmarking public funding, including from relevant EU funds, for AI research and development in support of socially and environmentally beneficial outcomes;', '(c) organising specific awareness raising activities about the application of this Regulation, the availability of and application procedures for dedicated funding, tailored to the needs of those projects;', '(d) where appropriate, establishing accessible dedicated channels, including within the sandboxes, for communication with projects to provide guidance and respond to queries about the implementation of this Regulation.', '2. Without prejudice to Article 55 a (new)1(a), Member States shall ensure that relevant projects are led by civil society and social stakeholders that set the project priorities, goals, and outcomes.

Amendment 2370
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 55 - title
Measures for providers and users that are SME’s or start-ups

Amendment 2371
Greens/EFA - Group of the Greens/European Free Alliance
Sergey Lagodinsky, Kim Van Sparrentak, Alexandra Geese, Alviina Alametsä
Article 55 - title
Measures for small-scale providers and deployers', '(This amendment applies throughout the text. Adopting it will necessitate corresponding changes throughout.)

Amendment 2372
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 55 - title
Measures for SMEs, start-ups and users

Amendment 2373
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 55 - paragraph 1 - introductory part
1. The national supervisory authority shall undertake the following actions:

Amendment 2374
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 55 - paragraph 1 - point a
(a) provide SMEs and start-ups with priority access to and make AI regulatory sandboxes reusable as well as affordable to the extent that SMEs and start-ups fulfil the eligibility conditions;

Amendment 2375
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 55 - paragraph 1 - point a
(a) provide SMEs and start-ups with priority access to the AI regulatory sandboxes to the extent that they fulfil the eligibility conditions;

Amendment 2376
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 55 - paragraph 1 - point b
(b) organise specific awareness raising and training activities about the application of this Regulation tailored to the needs of SME’s and start-ups;

Amendment 2377
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 55 - paragraph 1 - point b
(b) organise specific awareness raising activities about the application of this Regulation tailored to the needs of SMEs, sart-ups and users;

Amendment 2378
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 55 - paragraph 1 - point c
(c) where appropriate, establish a dedicated channel for communication with SME’s and start-ups and user and other innovators to provide guidance and respond to queries about the implementation of this Regulation;

Amendment 2379
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 55 - paragraph 1 - point c a (new)
(c) where appropriate, establish a dedicated channel for communication with SMEs, start-ups, users and other innovators to provide guidance and respond to queries about the implementation of this Regulation.

Amendment 2380
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 55 - paragraph 1 - point c a (new)
(c a) consult representative organisations of SMEs and start ups and involve them in the development of relevant standards;

Amendment 2381
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 55 - paragraph 1 - point c a (new)
(c a) support SME's increased participation in the standardisation development process;

Amendment 2382
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 55 - paragraph 1 - point c b (new)
(c b) create development paths and services for SMEs and start ups, ensuring that government support is provided at all stages of their development, in particular by promoting digital tools and developing AI transition plans;

Amendment 2383
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 55 - paragraph 1 - point c c (new)
(c c) promote industry best practices and responsible approaches toAI development and use self-regulatory commitments as a criterion for public procurement projects or as a factor that allows more opportunities to use andshare data responsibly;

Amendment 2384
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 55 - paragraph 1 - point c d (new)
(c d) offer tax breaks for doing research, better access to computer capacities and datasets, an EU-Visa schema for tech-talents, temporary support in technology scouting or in paying salaries of AI specialists, and state aid exemptions in the area of AI education, training and reskilling of employees;

Amendment 2385
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 55 - paragraph 1 - point c e (new)
(c e) reduce extensive reporting, information or documentation obligations, establish a single EU online portal in different languages concerning all necessary procedures and formalities to operate in another EU country, a single point of contact in the home country that can certify the company’s eligibility to provide services in another EU country as well as a standardized EU-wide VAT declaration in the respective native language.

Amendment 2386
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 55 - paragraph 2
2. The specific interests and needs of the SME’s and start-ups shall be taken into account when setting the fees for conformity assessment under Article 43, reducing those fees proportionately to their size and market size, by granting subsidies or even exempting SMEs and start ups from paying.

Amendment 2387
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 55 - paragraph 2
2. The specific interests and needs of the SMEs and start-ups shall be taken into account when setting the fees for conformity assessment under Article 43, reducing those fees proportionately to their size and market size.

Amendment 2388
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 55 a (new)
Article 55 a', 'Promoting research and development of AI in support of socially and environmentally beneficial outcomes led by civil society', '1. Member States shall promote research and development of AI solutions which support socially and environmentally beneficial outcomes, including but not limited to development of AI-based solutions to increase accessibility for persons with disabilities, tackle socio-economic inequalities, and meet sustainability and environmental targets, by:', '(a) providing relevant projects with priority access to the AI regulatory sandboxes to the extent that they fulfil the eligibility conditions;', '(b) earmarking public funding, including from relevant EU funds, for AI research and development in support of socially and environmentally beneficial outcomes;', '(c) organising specific awareness raising activities about the application of this Regulation, the availability of and application procedures for dedicated funding, tailored to the needs of those projects;', '(d) where appropriate, establishing accessible dedicated channels for communication with projects to provide guidance and respond to queries about the implementation of this Regulation.', '2. Member States shall ensure that when conformity assessment is required under Article 43, cost of such assessment is covered by public, including EU, funds available for AI research and development.', '3. Without prejudice to Article 55 a (new)1(a), Member States shall ensure that relevant projects are led by civil society and social stakeholders that set the project priorities, goals, and outcomes.

Amendment 2389
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 55 a (new)
Article 55 a', 'Promoting research and development of AI in support of socially and environmentally beneficial outcomes', 'Member States shall promote research and development of AI solutions which support socially and environmentally beneficial outcomes, including but not limited to development of AI-based solutions to increase accessibility for persons with disabilities, tackle socio-economic inequalities, and meet sustainability and environmental targets, by:', '(a) providing relevant projects with priority access to the AI regulatory sandboxes to the extent that they fulfil the eligibility conditions;', '(b) earmarking public funding, including from relevant EU funds, for AI research and development in support of socially and environmentally beneficial outcomes;', '(c) organising specific awareness raising activities about the application of this Regulation, the availability of and application procedures for dedicated funding, tailored to the needs of those projects;', '(d) where appropriate, establishing accessible dedicated channels for communication with projects to provide guidance and respond toqueries about the implementation of this Regulation.

Amendment 2390
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 55 b (new)
Article 55 b', 'Right not to be subject to non-compliant AI systems', 'Natural persons shall have the right not to be subject to AI systems that:', '(a) pose an unacceptable risk pursuant to Article 5, or', '(b) otherwise do not comply with the requirements of this Regulation.

Amendment 2391
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 55 c (new)
Article 55 c', 'Right to information about the use and functioning of AI systems', '1. Natural persons shall have the right to be informed that they have been exposed to high-risk AI systems as defined in Article 6, and other AI systems as defined in Article 52.', '2. Natural persons shall have the right to be provided upon request, with an explanation for decisions producing legal effects or otherwise affecting them or outcomes related to them taken by or with the assistance of systems within the scope of this Regulation, pursuant to Article 52 paragraph (3b).', '3. The information outlined in paragraphs 1 and 2 shall be provided in a clear, easily understandable and intelligible way, in a manner that is accessible for persons with disabilities.

Amendment 2392
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona Strugariu, Dragoş Pîslaru, Lucia Ďuriš Nicholsonová, Irena Joveva, Alin Mituța
Title VI - Chapter 1 - title
1 European Artificial Intelligence Office

Amendment 2393
ECR - European Conservatives and Reformists Group
Jorge Buxadé Villalba
Article 56
deleted

Amendment 2394
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 56 - title
Establishment of the European Artificial Intelligence Office

Amendment 2395
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 56 - title
European Artificial Intelligence Board

Amendment 2396
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 56 - title
European Artificial Intelligence Board

Amendment 2397
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 56 - paragraph 1
deleted

Amendment 2398
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 56 - paragraph 1
1. A ‘European Artificial Intelligence Board’ (the ‘Board’) is established as an independent body with its own legal personality. The Board shall have a Secretariat, a strong mandate as well as sufficient resources and skilled personnel at its disposal for the assistance in the performance of its tasks laid down in Article 58.

Amendment 2399
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 56 - paragraph 1
1. An independent ‘European Artificial Intelligence Board’ (the ‘Board’) is hereby established as a body of the Union and shall have legal personality.

Amendment 2400
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,
Article 56 - paragraph 1
1. A ‘European Artificial Intelligence Board’ (the ‘Board’) is established as a body of the Union and shall have legal personality.

Amendment 2401
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 56 - paragraph 1 a (new)
1 a. The Board shall monitor and ensure the effective and consistent application, and contribute to the effective and consistent enforcement, of this Regulation throughout the Union, including with regard to cases involving two or more Member States as set out in Article 59b.

Amendment 2402
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 56 - paragraph 1 a (new)
1 a. The Board shall be independent in the fulfilment of its task. It shall have legal personality.

Amendment 2403
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 56 - paragraph 1 b (new)
1 b. The Board shall ensure the consistent application of this Regulation.

Amendment 2404
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 56 - paragraph 2
deleted

Amendment 2405
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 56 - paragraph 2 - introductory part
2. The Board shall provide advice and assistance to the Commission and to the national supervisory authorities in order to:

Amendment 2406
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 56 - paragraph 2 - introductory part
2. The Board shall provide advice and assistance to the Commission and the national authorities in order to:

Amendment 2407
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 56 - paragraph 2 - point b
(a) contribute to the effective cooperation of the national supervisory authorities and the Commission with regard to matters covered by this Regulation;

Amendment 2408
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 56 - paragraph 2 - point b
(b) coordinate and provide guidance and analysis by the Commission and the national supervisory authorities and other competent authorities on emerging issues across the internal market with regard to matters covered by this Regulation;

Amendment 2409
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 56 - paragraph 2 - point c
(c) assist the Commission, national supervisory authorities and other competent authorities in ensuring the consistent application of this Regulation, in particular in line with the consistency mechanism referred to in Article 59a(3);

Amendment 2410
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 56 - paragraph 2 - point c
(c) contribute to the effective and consistent application of this Regulation and assist the national supervisory authorities and the Commission in that regard.

Amendment 2411
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 56 - paragraph 2 - point c a (new)
(c a) carry out annual reviews and analyses of the complaints sent to and findings by national competent authorities, of the serious incidents and malfunctioning reports referred to in Article 62, and of the new registration in the EU Database referred to in Article 60 to identify trends and potential emerging issues threatening the future health and safety and fundamental rights of citizens and not adequately addressed by this Regulation; to carry out biannual horizon scanning and foresight exercises to extrapolate the impact these trends and emerging issues can have on the Union; and to annually publish recommendations to the Commission, including but not limited to recommendations on the categorization of prohibited practices, high-risk systems, and codes of conduct for AI systems that are not classified as high-risk.

Amendment 2412
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 56 - paragraph 2 - point c a (new)
(c a) provide particular oversight, monitoring and regular dialogue with the providers of general purpose AI systems about their compliance with the Regulation. Any such meeting shall be open to national supervisory authorities, notified bodies and market surveillance authorities to attend and contribute

Amendment 2413
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 56 - paragraph 2 - point c a (new)
(c a) contribute to the effective cooperation with the competent authorities of third countries and with international organisations.

Amendment 2414
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 56 - paragraph 2 - point c a (new)
(c a) contribute to the effective cooperation with the competent authorities of third countries and with international organisations.

Amendment 2415
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 56 - paragraph 2 - point c a (new)
(c a) propose amendments to Annexes I and III to the Commission.

Amendment 2416
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 56 - paragraph 2 - point c b (new)
(c b) bring together national metrology and benchmarking authorities to provide guidance to address the technical aspects of how to measure appropiate levels of accuracy and robustness.

Amendment 2417
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 56 - paragraph 2 - point c b (new)
(c b) represent and defend the interest of the broad cicil society, including Social Partners.

Amendment 2418
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 56 - paragraph 2 - point c c (new)
(c c) launch an evaluation procedure for an AI system

Amendment 2419
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 56 - paragraph 2 a (new)
2 a. The Board shall have a sufficient number of competent personnel at their disposal for assistance in the proper performance of their tasks.

Amendment 2420
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 56 - paragraph 2 b (new)
2 b. The Board shall be organised and operated so as to safeguard the independence, objectivity and impartiality of their activities. The Board shall document and implement a structure and procedures to safeguard impartiality and to promote and apply the principles of impartiality throughout its activities.

Amendment 2421
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 56 a (new)
Article 56 a', 'SECTION 1:General provisions', 'An independent ‘European Artificial Intelligence Office’ (the ‘AI Office’) is hereby established. The European Union Artificial Intelligence Office shall bean Office of the Union, shall have legal personality, and shall be adequately funded and staffed. The Office shall enjoy in all the Member States the most extensive legal capacity accorded to legal persons under their laws.

Amendment 2422
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 56 b (new)
Article 56 b', 'Mandate', '1. The AI Office shall carry out the tasks assigned to it under this Regulation for the purpose of achieving a high level of trustworthiness and of protection of health, safety, fundamental rights and the Union values enshrined in Article 2 TEU across the Union with regards to artificial intelligence systems, including by actively supporting Member States, Union institutions, bodies, offices and agencies in matters pertaining to this Regulation. The AI Office shall act as a reference point for advice and expertise on artificial intelligence for Union institutions, bodies, offices and agencies, for Member States and their national supervisory authorities, as well as for other relevant Union stakeholders.', '2. The AI Office shall contribute to reducing the fragmentation of the internal market and to increasing the uptake of artificial intelligence throughout the Union by carrying out the tasks assigned to it under this Regulation.', '3. When carrying out its tasks, the AI Office shall act independently while avoiding the duplication of Member State activities and taking into consideration Member State competences.', '4. The AI Office shall organise consultations with stakeholders twice a year to assess the evolution of trends in technology, issues related to the implementation and the effectiveness of this Regulation, regulatory gaps or loopholes observed in practice. Such stakeholders shall include representatives from industry, start-ups and SMEs, civil society organisations, such as NGOs, consumer associations, the social partners and academia.', '5. The AI Office may consult national authorities, such as national equality bodies, where the issues discussed are of relevance for them. The AI Office may also consult, where appropriate, external experts and observers and interested third parties, including stakeholders such as those referred to in paragraph 5, and may hold exchanges with them.', '6. The AI Office shall cooperate with Union institutions, bodies, offices, agencies and advisory groups and shall make the results of that cooperation publicly available.

Amendment 2423
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 56 c (new)
Article 56 c', 'Accountability, transparency, and independence', '1. The AI Office shall be accountable to the European Parliament and to the Council in accordance with this Regulation.', '2. The AI Office shall develop good administrative practices in order to ensure the highest possible level of transparency concerning its activities. Regulation (EC) No 1049/2001 shall apply to documents held by the AI Office.', '3. The AI Office shall fulfil its tasks in complete independence.

Amendment 2424
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 56 d (new)
Article 56 d', 'Administrative and management structure', '1. The administrative and management structure of the AI Office shall comprise:', '(a) a management board', '(b) an executive director', '(c) an advisory forum', '(d) where appropriate, other advisory bodies established by the management board to support the AI Office in technical or scientific matters related to this Regulation.

Amendment 2425
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 56 e (new)
Article 56 e', 'Objectives', '1. The AI Office shall:', '(a) contribute to the uptake of artificial intelligence in the Union, including through supporting innovation and the development of regulatory sandboxes provided for in this Regulation;', '(b) contribute to a high level of trustworthiness and of protection of health, safety, fundamental rights and the Union values enshrined in Article 2 TEU with regard to artificial intelligence systems in the Union;', '(c) contribute to the effective cooperation of the national supervisory authorities and the Commission with regard to matters covered by this Regulation;', '(d) provide forecasts, guidance, and analysis to the Commission, Member States, and to the national supervisory authorities and other competent authorities on emerging issues across the internal market with regard to matters covered by this Regulation and related issues;', '(e) contribute to the effective and consistent application of this Regulation and assist Member States, the national supervisory authorities, and the Commission in this regard;', '(f) contribute to the effective cooperation with the competent authorities of third countries and with international organisations;', '(g) contribute to the development, promotion, and adoption of harmonized standards, common specifications, common benchmarking standards, and voluntary codes of conduct;', '(h) contribute to the effective and consistent enforcement of this Regulation throughout the Union, including by issuing binding decisions with regard to cases involving two or more Member States asset out in Article 59b.

Amendment 2426
ECR - European Conservatives and Reformists Group
Jorge Buxadé Villalba
Article 57
deleted

Amendment 2427
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 57
deleted

Amendment 2428
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 57 - title
Structure and independence of the Board

Amendment 2429
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 57 - paragraph 1
1. The Board shall be composed of the national supervisory authorities, who shall be represented by the head or equivalent high-level official of that authority. Other national authorities may also be invited to the meetings, where the issues discussed are of relevance for them.', 'The European Data Protection Supervisor, the Chairperson of the EU Agency for Fundamental Rights, the Executive director of the EU Agency for Cybersecurity, the Chair of the High Level Expert Group on AI, the Director-General of the Joint Research Centre, and the presidents of the European Committee for Standardization, the European Committee for Electrotechnical Standardization, and the European Telecommunications Standards Institute shall be invited as permanent observers with the right to speak but without voting rights.

Amendment 2430
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 57 - paragraph 1
1. The Board shall be composed of the national supervisory authorities, who shall be represented by the head of that authority, and the European Data Protection Supervisor, the Chair of the European Data Protection Board, the Director of the Fundamental Rights Agency, the Executive Director of the European Union Agency for Cybersecurity or their respective representatives. Other national authorities or Union agencies and bodies may be invited to the meetings, where the issues discussed are of relevance for them.

Amendment 2431
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 57 - paragraph 1
1. The Board shall be composed of the national supervisory authorities, the European Data Protection Supervisor as the EU Agency for Fundamental Rights, the EU Agency for Cybersecurity, the Joint Research Centre, the European Committee for Standardization, the European Committee for Electrotechnical Standardization, and the European Telecommunications Standards Institute, each with one representative. Other national authorities may be invited to the meetings, where the issues discussed are of relevance for them.

Amendment 2432
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 57 - paragraph 1
1. The Board shall be composed of the national supervisory authorities, who shall be represented by the head or equivalent high-level official of that authority, and the European Data Protection Supervisor, the EU Agency for Fundamental Rights, ENISA, EIGE and social partners as well representratives of civil society. Other national authorities may be invited to the meetings, where the issues discussed are of relevance for them.

Amendment 2433
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 57 - paragraph 1
1. The Board shall be composed of the national supervisory authorities, who shall be represented by the head or equivalent high-level official of that authority, the European Data Protection Supervisor and the national data protection bodies. Other national authorities may be invited to the meetings, where the issues discussed are of relevance for them.

Amendment 2434
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 57 - paragraph 1
1. The Board shall be composed of the national supervisory authorities, who shall be represented by the head or equivalent high-level official of that authority, and the European Data Protection Supervisor, AI ethics experts and industry representatives. Other national authorities may be invited to the meetings, where the issues discussed are of relevance for them.

Amendment 2435
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 57 - paragraph 1
1. The Board shall be composed of the national supervisory authorities, who shall be represented by the head or equivalent high-level official of that authority, the European Data Protection Supervisor and the Fundamental Rights Agency. Other national authorities or EU agencies may be invited to the meetings, where the issues discussed are of relevance for them.

Amendment 2436
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Article 57 - paragraph 1
1. The Board shall be composed of the national supervisory authorities, who shall be represented by the head or equivalent high-level official of that authority, and the European Data Protection Supervisor and relevant stakeholders including SMEs. Other national authorities may be invited to the meetings, where the issues discussed are of relevance for them.

Amendment 2437
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 57 - paragraph 1
1. The Board shall be composed of the national supervisory authorities, who shall be represented by the head or equivalent high-level official of that authority, the European Data Protection Supervisor and the FRA. Other national authorities may be invited to the meetings, where the issues discussed are of relevance for them.

Amendment 2438
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 57 - paragraph 1 a (new)
1 a. The Commission shall have the right to participate in the activities and meetings of the Board without voting right. The Commission shall designate a representative. The Chair of the Board shall communicate to the Commission the activities of the Board.

Amendment 2439
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 57 - paragraph 1 a (new)
1 a. The Board shall act independently when performing its tasks or exercising its powers.

Amendment 2440
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 57 - paragraph 1 a (new)
1 a. The Board shall be represented by its Chair.

Amendment 2441
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 57 - paragraph 1 b (new)
1 b. The Board shall act independently when performing its tasks or exercising its powers pursuant to Articles 58.

Amendment 2442
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 57 - paragraph 1 c (new)
1 c. The Board shall take decisions by a simple majority of its voting members, unless otherwise provided for in this Regulation. Each national supervisory authority and the EDPS shall have one vote.

Amendment 2443
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 57 - paragraph 2
2. The Board shall adopt its rules of procedure by a simple two-thirds majority of its voting members and organise its own operational arrangements.

Amendment 2444
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 57 - paragraph 2
2. The Board shall adopt its rules of procedure by a simple majority of its members. The rules of procedure shall also contain the operational aspects related to the execution of the Board’s tasks as listed in Article 58. The Board may establish sub-groups as appropriate for the purpose of examining specific questions.

Amendment 2445
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 57 - paragraph 2
2. The Board shall adopt its rules of procedure by two-thirds majority and shall take decisions by a simple majority of its members. The rules of procedure shall also contain the operational aspects related to the execution of the Board’s tasks as listed in Article 58. The Board may establish sub-groups as appropriate for the purpose of examining specific questions.

Amendment 2446
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 57 - paragraph 2
2. The Board shall adopt its rules of procedure by a two-thirds majority of its members. The rules of procedure shall also contain the operational aspects related to the execution of the Board’s tasks as listed in Article 58. The Board may establish sub-groups as appropriate for the purpose of examining specific questions.

Amendment 2447
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 57 - paragraph 2
2. The Board shall adopt its rules of procedure by a simple majority of its members. The rules of procedure shall also contain the operational aspects related to the execution of the Board’s tasks as listed in Article 58. The Board may establish standing or temporary sub-groups as appropriate for the purpose of examining specific questions.

Amendment 2448
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 57 - paragraph 2 a (new)
2 a. The Board may establish sub-groups as appropriate for the purpose of examining specific questions. The Board shall establish a permanent sub-group for the purpose of examining the question of the proper governance of general purpose AI systems. The Board shall also establish a permanent sub-group for the purpose of examining the question of the proper governance of research and development activities on the topic of AI and to inform the development of the governance framework.

Amendment 2449
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 57 - paragraph 2 a (new)
2 a. The Board may establish sub-groups as appropriate for the purpose of examining specific questions.In any case, the Board shall establish the following permanent sub-groups:', 'a) for the purpose of examining the question of the proper governance of AI systems with indeterminate use;', 'b) for the purpose of examining the question of the proper governance of research and development activities on the topic of AI.

Amendment 2450
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 57 - paragraph 2 b (new)
2 b. The Board shall elect a Chair and two deputy Chairs from among its voting members by simple majority. The term of office of the Chair and of the deputy Chairs shall be three years, renewable once.

Amendment 2451
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 57 - paragraph 3
3. The Commission shall provide administrative and analytical support for the activities of the Board pursuant to this Regulation.

Amendment 2452
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 57 - paragraph 3
3. The Board shall be chaired by the national supervisory authority of the Member State holding the Presidency of the Council of the European Union. The latter shall convene the meetings and prepare the agenda in accordance the tasks of the Board pursuant to this Regulation and with its rules of procedure. The Commission shall provide administrative and analytical support for the activities of the Board pursuant to this Regulation.

Amendment 2453
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 57 - paragraph 3
3. The Board shall be co-chaired by the Commission and a representative chosen from among the delegates of the Member States. The Commission shall convene the meetings and prepare the agenda in accordance with the tasks of the Board pursuant to this Regulation and with its rules of procedure. The Commission shall provide administrative and analytical support for the activities of the Board pursuant to this Regulation.

Amendment 2454
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 57 - paragraph 3
3. The Chair shall have the following tasks:', '- convene the meetings of the Board and prepare its agenda;', '- ensure the timely performance of the tasks of the Board;', '- notify Member States and the Commission of any recommendations adopted by the Board.

Amendment 2455
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 57 - paragraph 3
3. The Board shall be chaired by the Commission. The Board’s Secretariat shall convene the meetings and prepare the agenda in accordance with the tasks of the Board pursuant to this Regulation and with its rules of procedure. The Board’s Secretariat shall also provide administrative and analytical support for the activities of the Board pursuant to this Regulation.

Amendment 2456
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 57 - paragraph 3
3. The Board shall elect a chair and two deputy chairs from among its members. Their term of office shall be five years and be renewable once. . The Chair shall convene the meetings and prepare the agenda in accordance with the tasks of the Board pursuant to this Regulation and with its rules of procedure.

Amendment 2457
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Article 57 - paragraph 3 a (new)
3 a. The Board shall establish a AI Advisory Council (Advisory Council). The Advisory Council shall be composed of relevant representatives from industry, research, academia, civil society, standardisation organisations, relevant common European data spaces and other relevant stakeholders or third parties appointed by the Board, representing all Member States to maintain geographical balance. The Advisory Council shall support the work of the Board by providing advice relating to the tasks of the Board. The Advisory Council shall nominate a relevant representative, depending on the configuration in which the Board meets, to attend meetings of the Board and to participate in its work. The composition of the Advisory Council and its recommendations to the Board shall be made public.

Amendment 2458
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 57 - paragraph 3 a (new)
3 a. The secretariat of the Board shall have the necessary human and financial resources to be able to perform its tasks pursuant to this Regulation.

Amendment 2459
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 57 - paragraph 3 a (new)
3 a. The Board shall elect a chair and two deputy chairs from amongst its members by simple majority.

Amendment 2460
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 57 - paragraph 3 b (new)
3 b. The Commission shall provide administrative and analytical support for the activities of the Board pursuant to this Regulation.

Amendment 2461
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 57 - paragraph 3 b (new)
3 b. The term of office of the Chair and of the deputy chairs shall be five years and be renewable once.

Amendment 2462
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 57 - paragraph 4
4. The Board shall regularly invite external experts, in particular from organisations representing the interests of the providers and users of AI systems, SMEs and start-ups, civil society organisations, representatives of affected persons, researchers, standardisation organisations, testing and experimentation facilities, to attend its meetings in order to ensure accountability and appropriate participation of external actors. The Commission may facilitate exchanges between the Board and other Union bodies, offices, agencies and advisory groups.

Amendment 2463
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 57 - paragraph 4
4. The Board may invite external experts and observers to attend its meetings and may hold exchanges with interested third parties to inform its activities to an appropriate extent. To that end the Chair shall facilitate exchanges between the Board and other Union bodies, offices, agencies and advisory groups. The Board shall ensure a balanced representation of stakeholders from academia, research, industry and civil society when it invites external experts and observers, and actively stimulate participation from underrepresented categories.

Amendment 2464
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 57 - paragraph 4
4. The Board may invite external experts and observers to attend its meetings and may hold exchanges with interested third parties to inform its activities to an appropriate extent, and hold consultations with relevant stakeholders and ensure appropriate participation. The Commission may facilitate exchanges between the Board and other Union bodies, offices, agencies and advisory. The Commission may facilitate exchanges between the Board and other Union bodies, offices, agencies and advisory groups.

Amendment 2465
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 57 - paragraph 4
4. The Board may invite external experts and observers. To that end the Commission may facilitate exchanges between the Board and other Union bodies, offices, agencies and specialised bodies. The composition of the specialised body shall ensure fair representation of consumer organisations, civil society organisations and academics specialised on AI. Its meetings and their minutes shall be published online.

Amendment 2466
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 57 - paragraph 4
4. The Board may invite national authorities, such as national equality bodies, to its meetings, where the issues discussed are of relevance for them. The Board may also invite, where appropriate, external experts, and observers and interested third parties, including stakeholders, such as those referred to in Article 58, paragraph 1c, to attend its meetings and may hold exchanges with them.

Amendment 2467
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 57 - paragraph 4 a (new)
4 a. Without prejudice to paragraph 4, the Board’s Secretariat shall organise four additional meetings between the Board and the High Level Expert Group on AI to allow them to share their practical and technical expertise every quarter of the year.

Amendment 2468
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 57 - paragraph 4 a (new)
4 a. The Board shall take into consideration advice provided by the EDPB, particularly on new or evolving risks of high-risk AI systems processing personal data.

Amendment 2469
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 57 a (new)
4 a. The Board shall cooperate with Union institutions, bodies, offices, agencies and advisory groups and shall make the results of that cooperation publicly available.

Amendment 2470
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 57 a (new)
Article 57 a', 'Secretariat', '1. The Board shall have a secretariat, which shall be provided by the European Data Protection Supervisor.', '2. The secretariat shall perform its tasks exclusively under the instructions of the Chair of the Board.', '3. The staff of the European Data Protection Supervisor involved in carrying out the tasks conferred on the Board by this Regulation shall be subject to separate reporting lines from the staff involved in carrying out tasks conferred on the European Data Protection Supervisor.', '4. Where appropriate, the Board and the European Data Protection Supervisor shall establish and publish a Memorandum of Understanding implementing this Article, determining the terms of their cooperation, and applicable to the staff of the European Data Protection Supervisor involved in carrying out the tasks conferred on the Board by this Regulation.', '5. The secretariat shall provide analytical, administrative and logistical support to the Board.', '6. The secretariat shall be responsible in particular for:', '(a) the day-to-day business of the Board;', '(b) communication between the members of the Board, its Chair and the Commission;', '(c) communication with other institutions and the public;', '(d) the use of electronic means for the internal and external communication;', '(e) the translation of relevant information;', '(f) the preparation and follow-up of the meetings of the Board;', '(g) the preparation, drafting and publication of opinions, guidelines, and other texts to be adopted by the Board.', '7. For the exercise of point (g) of paragraph 6, the secretariat shall, under the guidance of the Chair and the deputy Chairs, establish a European Centre of Excellence for Artificial Intelligence (ECE-AI, “the Centre”). The Centre shall be provided with sufficient resources and facilities to attract the highest level of expertise on artificial intelligence from technical and humanities sciences. In particular it shall have a sufficient number of personnel permanently available whose competences and expertise shall include an in-depth understanding of artificial intelligence technologies, data and data computing, fundamental rights, health and safety risks and environmental risks, and knowledge of existing standards and legal requirements, including competition law.

Amendment 2471
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 57 a (new)
Article 57 a', 'Composition of the management board', '1. The management board shall be composed of one representative of each Member State, the Commission, and the European Data Protection Supervisor, and the Fundamental Rights Agency. Each Member State and the Commission shall have one vote. The EDPS and the FRA shall not have voting rights.', '2. Each member of the management board shall have an alternate. That alternate shall represent the member in the member’s absence.', '3. The Commission and the Member States shall aim to achieve gender balance on the management board.', '4. The list of the members and alternate members of the management board shall be made public and shall be updated by the AI Office on its web site.', '5. The term of office of the members of the management board and their alternates shall be four years. That term shall be renewable once.

Amendment 2472
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 57 b (new)
Article 57 b', 'Functions of the management board', '1. The management board shall be responsible for taking the strategic decisions of the AI Office in accordance with this Regulation. In particular, the management board shall:', '(a) Establish the general direction of the operation of the AI Office and ensure that the AI Office operates in accordance with the rules and principles laid down in this Regulation;', "(b) Adopt, on the basis of the draft submitted by the Office's executive director and after the Commission has delivered an opinion, the single programming document of the AI Office containing, inter alia, the AI Office’s multiannual programming and its work programme for the following year. The single programming document shall be transmitted to the European Parliament, the Council and the Commission;", '(c) Appoint the executive director and, where relevant, extend his or her term of office or remove him or her from office;', '(d) Produce, on the basis of a draft drawn up by the executive director, the estimate budget of the AI Office for the following financial year. This estimate, which shall initially include a draft establishment plan by the date of entry into force of this Regulation, shall be transmitted by the management board to the Commission within the first quarter of each year;', '(e)Adopt the AI Office’s annual draft and final budgets;', '(f) Assess and adopt the consolidated annual report on the AI Office activities, including an evaluation based on performance indicators; submit both the annual report and the assessment thereof to the European Parliament, to the Council, to the Commission and to the Court of Auditors, and make the annual report public;', '(g) Adopt the AI Office’s rules of procedure on the basis of the draft submitted by the executive director after the Commission has delivered an opinion;', '(h) Take decisions, based on the executive director’s recommendation, concerning the establishment of the AI Office’s internal structures and, where necessary, the modification of those internal structures, taking into consideration technological developments that may create additional operational needs and having regard to sound budgetary management;

Amendment 2473
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 57 c (new)
Article 57 c', 'Meetings of the management board', '1. The meetings of the management board shall be convened by the Chair. The Chair shall prepare the agenda of the meetings in accordance with the tasks of the Board pursuant to this Regulation and with its rules of procedure.', '2. The meetings of the management board shall be considered to be quorate where at least two-thirds of its members are present.', '3. The management board shall hold at least two ordinary meetings a year. It shall also hold extraordinary meetings at the request of the Chair, at the request of the Commission, or at the request of at least one third of its members.', '4. The executive director shall take part in the meetings of the management board but shall not have the right to vote.', '5. Members of the advisory forum may take part in the meetings of the management board at the invitation of the Chair, but shall not have the right to vote.', '6. The members of the management board and their alternates may be assisted at the meetings of the management board by advisers or experts, subject to the rules of procedure of the management board.', '7. The AI Office shall provide the secretariat of the management board and support the management Board in its operations.

Amendment 2474
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 57 c (new)
Article 57 c', 'Chair of the management board', '1. The management board shall elect a Chair and a deputy Chair from among its voting members by simple majority. The term of office of the Chair and of the deputy Chair shall be three years. The terms of the Chair and of the deputy Chair may be renewed once. The Deputy Chair shall replace the Chair ex officio if the Chair is unable to attend to his or her duties.

Amendment 2475
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 57 d (new)
Article 57 d', 'Voting rules of the management board', '1. The management board shall take its decisions by a majority of its members, unless otherwise provided for in this Regulation.', '2. A majority of two-thirds of the members of the management board shall be required for the adoption of the single programming document and of the annual budget and for the appointment, extension of the term of office or removal of the executive director.', '3. Each member shall have one vote. In the absence of a member, their alternate shall be entitled to exercise the member’s right to vote.', '4. The Chair of the management board shall take part in the voting.', '5. The executive director shall not take part in the voting.', '6. The management board’s rules of procedure shall establish more detailed voting arrangements, in particular the circumstances in which a member may act on behalf of another member.

Amendment 2476
ECR - European Conservatives and Reformists Group
Jorge Buxadé Villalba
Article 58 - title
deleted

Amendment 2477
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 58 - title
Tasks

Amendment 2478
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 58 - paragraph -1 (new)
-1 The Board shall ensure the consistent application of this Regulation and shall the competent supervisory authority to enforce this Regulation where one of the following criteria is met:', '(a) The aggregate worldwide turnover of an undertaking or the undertaking to which another undertaking belongs is more than EUR 2 500 million;', '(b) in each of at least three Member States, the aggregate turnover of an undertaking or the undertaking to which another undertaking belongs is more than EUR 100 million;', '(c) in each of at least three Member States included for the purpose of point (b), the aggregate turnover of an undertaking or the undertaking to which another undertaking belongs is more than EUR 25 million;and', '(d) the aggregate Union-wide turnover of an undertaking or the undertaking to which another undertaking belongs is more than EUR 100 million, unless each of the undertakings concerned achieves more than two-thirds of its aggregate Community-wide turnover within one and the same Member State.

Amendment 2479
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 58 - paragraph -1 a (new)
-1 a In order to ensure consistent application of this Regulation, the Board shall, on its own initiative or, where relevant, at the request of the Commission, in particular:', '(a) monitor and ensure the correct application of Title III of this Regulation without prejudice to the tasks of national supervisory authorities;', '(b) advise the Commission on any issue related to the development and use of artificial intelligence in the in the Union, including on any proposed amendment of this Regulation;', '(c) issue guidelines, recommendations, and best practices on procedures, information and documentation as referred to in Titles III and VIII;', '(d) examine, on its own initiative, on request of one of its members or on request of the Commission, any question covering the application of this Regulation and issue guidelines, recommendations and best practices in order to encourage consistent application of this Regulation;', '(e) draw up guidelines for supervisory authorities concerning the application of this Regulation;', '(f) draw up guidelines for supervisory authorities concerning the setting of administrative fines pursuant to Article 72;', '(g) review the practical application of the guidelines, recommendations and best practices referred to in points (e) and (f);', '(h) encourage the drawing-up of codes of conduct pursuant to Article 69;', '(i) issue opinions on codes of conduct drawn up at Union level pursuant to Article 69(3a);', '(j) issue decisions pursuant to Articles 66 and 67;', '(k) promote the cooperation and the effective bilateral and multilateral exchange of information and best practices between the supervisory authorities;', '(l) promote common training programmes and facilitate personnel exchanges between the supervisory authorities and, where appropriate, with the supervisory authorities of third countries or with international organisations;', '(m) promote the exchange of knowledge and documentation on relevant legislation and practice with supervisory authorities whose scope includes artificial intelligence worldwide;', '(n) maintain a publicly accessible electronic register of decisions taken by supervisory authorities and courts on issues handled pursuant to Chapter 3 of Title VIII.

Amendment 2480
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese
Article 58 - paragraph -1 b (new)
-1 b Where the Commission requests advice from the Board, it may indicate a time limit, taking into account the urgency of the matter.

Amendment 2481
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 58 - paragraph -1 c (new)
-1 c The Board shall forward its opinions, guidelines, recommendations, and best practices to the Commission and to the committee referred to in Article 73 and make them public.

Amendment 2482
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 58 - paragraph -1 d (new)
-1 d The Board shall, where appropriate, consult interested parties and give them the opportunity to comment within a reasonable period. The Board shall make the results of the consultation procedure publicly available.

Amendment 2483
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 58 - paragraph -1 e (new)
-1 e When providing advice and assistance to the Commission in the context of Article 56(2), the Board shall in particular:', '(a) collect and share expertise and best practices among Member States;', '(b) contribute to uniform administrative practices in the Member States, including for the functioning of regulatory sandboxes referred to in Article 53;', '(c) issue opinions, recommendations or written contributions on matters related to the implementation of this Regulation, in particular on', '(i) technical specifications or existing standards regarding the requirements set out in Title III, Chapter 2,', '(ii) the use of harmonised standards or common specifications referred to in Articles 40 and 41,', '(iii) the preparation of guidance documents, including the guidelines concerning the setting of administrative fines referred to in Article 71,', '(iii a) amendments to the Annexes I and III.

Amendment 2484
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 58 - paragraph 1 - introductory part
When providing advice and assistance to the Commission and to the national supervisory authorities in the context of Article 56(2), the Board shall in particular:

Amendment 2485
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 58 - paragraph 1 - introductory part
When providing advice and assistance to the Commission and the national supervisory authorities in the context of Article 56(2), the Board shall in particular:

Amendment 2486
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 58 - paragraph 1 - introductory part
In fulfilling its objectives, the AI Office shall in particular:

Amendment 2487
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 58 - paragraph 1 - introductory part
1. When providing advice and assistance to the Commission in the context of Article 56(2), the Board shall in particular:

Amendment 2488
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 58 - paragraph 1 - introductory part
When ensuring the consistent application of this Regulation, the Board shall in particular:

Amendment 2489
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 58 - paragraph 1 - point -a (new)
(-a) issue opinions, recommendations or written contributions with a view to ensuring the consistent implementation of this Regulation;

Amendment 2490
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 58 - paragraph 1 - point -a a (new)
(-a a) examine, on its own initiative or on request of one of its members, any question covering the application of this Regulation and issue guidelines, recommendations and best practices with a view to ensuring the consistent implementation of this Regulation;

Amendment 2491
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 58 - paragraph 1 - point a
(a) collect and share expertise and best practices among Member States, including on the promotion of awareness raising initiatives on Artificial Intelligence and the Regulation;

Amendment 2492
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 58 - paragraph 1 - point a
(a) collect and share expertise and best practices in implementation of this Regulation;

Amendment 2493
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 58 - paragraph 1 - point a a (new)
(a a) issue opinions, recommendations or written contributions on matters related to the implementation of this Regulation;

Amendment 2494
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 58 - paragraph 1 - point a b (new)
(a b) examine, on its own initiative or on request of its management board, any question covering the application of this Regulation and issue guidelines, recommendations and best practices with a view to ensuring the consistent implementation of this Regulation;

Amendment 2495
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 58 - paragraph 1 - point a d (new)
(a c) provide the Commission, in the cases referred to in Article 68a (1)(a) and(1)(b), with all the available information at its disposal, including market studies, impact assessments, and analyses referred to in paragraph (f) of this article, to prepare the decision for triggering the Commission's intervention and opening of proceedings pursuant to Article 68a;

Amendment 2496
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 58 - paragraph 1 - point a d (new)
(a d) assist Member States in developing the organizational and technical expertise required for the implementation of this Regulation;

Amendment 2497
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 58 - paragraph 1 - point b
(b) contribute to uniform practices in the Member States, including by assisting Member States, the Commission, and, where applicable, other authorities in the establishment, development, and functioning of regulatory sandboxes referred to in Article 53, including by providing input and support in drafting the delegated acts referred to in Article 53(6);

Amendment 2498
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz
Article 58 - paragraph 1 - point b
(b) contribute to uniform administrative practices in the Member States, including for the assessment , establishing, managing with the meaning of fostering cooperation and guaranteeing consistency among regulatory sandboxes, and functioning of regulatory sandboxes referred to in Article 53, Article54 and Annex IXa;

Amendment 2499
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 58 - paragraph 1 - point b
(b) contribute to uniform administrative practices in the Member States, including for the assessment, establishing, managing with the meaning of fostering cooperation and guaranteeing consistency among regulatory sandboxes, and functioning of regulatory sandboxes referred to in Article 53;

Amendment 2500
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 58 - paragraph 1 - point b
(b) contribute to uniform administrative practices, including for the functioning of the regulatory sandboxes, as referred to in Article 53;

Amendment 2501
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 58 - paragraph 1 - point b a (new)
(b a) Support innovation by coordinating the exchange of information and good practices and by facilitating the cooperation among regulatory sandboxes established according to Article 53 and by making available on its website the information referred to in Article 53 (5).

Amendment 2502
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 58 - paragraph 1 - point c - introductory part
(c) issue opinions, recommendations, written contributions, or studies on matters related to the technical specifications or existing standards regarding the requirements set out in Title III, Chapter 2 and on the use of harmonised standards or common specifications referred to in Articles 40and 41;

Amendment 2503
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 58 - paragraph 1 - point c - introductory part
(c) issue opinions, recommendations or written contributions on matters related to the implementation of this Regulation, in consultation with relevant stakeholders, in particular

Amendment 2504
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 58 - paragraph 1 - point c - introductory part
(c) issue opinions, recommendations or written contributions on matters related to the implementation of this Regulation, after consulting relevant stakeholders, in particular

Amendment 2505
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 58 - paragraph 1 - point c - point i
deleted

Amendment 2506
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 58 - paragraph 1 - point c - point ii
deleted

Amendment 2507
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 58 - paragraph 1 - point c - point iii a (new)
deleted

Amendment 2508
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 58 - paragraph 1 - point c - point iii a (new)
(iii a) on the need for the amendment of each of the Annexes as referred to in Article 73 as well as all other provisions in this Regulation that the Commission can amend, in light of the available evidence.

Amendment 2509
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 58 - paragraph 1 - point c - point iii b (new)
(iii b) on activities and decisions of Member States regarding post-market monitoring, information sharing, market surveillance referred to in Title VIII;

Amendment 2510
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 58 - paragraph 1 - point c - point iii c (new)
(iii c) on developing common criteria for market operators and competent authorities having the same understanding of concepts such as the 'generally acknowledged state of the art' referred to in Article 9 (3), 'foreseeable risks' referred to in Articles 9 (2) (a), 'foreseeable misuse' referred to in Article 3 (13), Article 9 (2) (b), Article 9 (4), Article 13 (3)(b)(iii) and Article 14 (2), and the 'type and degree of transparency' referred in Article 13 (1);

Amendment 2511
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 58 - paragraph 1 - point c - point iii d (new)
(iii d) verify alignment with the legal acts listed in Annex II, including with the implementation matters related to those acts.

Amendment 2512
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 58 - paragraph 1 - point c a (new)
(c a) carry out annual reviews and analyses of the complaints sent to and findings made by national supervisory authorities, of the serious incidents reports referred to in Article 62, and of the new registration in the EU Database referred to in Article 60 to identify trends and potential emerging issues threatening the future health and safety and fundamental rights of citizens that are not adequately addressed by this Regulation;

Amendment 2513
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 58 - paragraph 1 - point c a (new)
(c a) carry out annual reviews and analyses of the complaints sent to and findings made by national competent authorities, of the serious incidents reports referred to in Article 62, and of the new registration in the EU Database referred to in Article 60 to identify trends and potential emerging issues threatening the future health and safety and fundamental rights of citizens that are not adequately addressed by this Regulation;

Amendment 2514
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 58 - paragraph 1 - point c a (new)
(c a) encourage, facilitate and support the drawing up of codes of conduct intended to foster the voluntary application to AI systems of those codes of conduct in close cooperation with relevant stakeholders in accordance with Article 69;

Amendment 2515
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 58 - paragraph 1 - point c a (new)
(c a) advise the Commission on the possible amendment of Article 5, to expand the prohibitions, based on national and cross-border cases that led to withdrawing or recalling AI systems from the market.

Amendment 2516
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 58 - paragraph 1 - point c a (new)
(c a) support the Commission and the Member States in the preparation of guidance documents, including the guidelines concerning the setting of administrative fines referred to in Article 71;

Amendment 2517
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 58 - paragraph 1 - point c a (new)
(c a) provide guidance in relation to governing general-purpose AI systems and their compliance with applicable requirements to meet the objectives of this Regulation.

Amendment 2518
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 58 - paragraph 1 - point c b (new)
(c b) cooperate with the European Data Protection Board and with the FRA to receive guidance in relation to the respect of fundamental rights, in particular the right to non-discrimination and to equal treatment, the right to privacy, confidentiality of communications and the protection of personal data;

Amendment 2519
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 58 - paragraph 1 - point c b (new)
(c b) encourage, facilitate and support the drawing up of risk-commensurate codes of conduct intended to foster the voluntary application to AI systems of those codes of conduct in close cooperation with industry and other relevant stakeholders in accordance with Article 69;

Amendment 2520
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 58 - paragraph 1 - point c b (new)
(c b) provide guidance in relation to governing research and development activities for creating new or improving existing AI systems, and the alignment of these activities with the objectives of this Regulation.

Amendment 2521
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 58 - paragraph 1 - point c b (new)
(c b) coordinate among national competent authorities; issue guidelines, recommendations and best practices with a view to ensuring the consistent implementation of this Regulation;

Amendment 2522
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 58 - paragraph 1 - point c b (new)
(c b) carry out biannual horizon scanning and foresight exercises to extrapolate the impact the trends and emerging issues can have on the Union;

Amendment 2523
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 58 - paragraph 1 - point c c (new)
(c c) carry out periodic in-depth horizon-scanning, foresight, and market monitoring exercises to analyse trends and emerging issues in respect of this Regulation, with a particular focus on emerging technologies and their interaction with artificial intelligence, European global competitiveness in artificial intelligence, the uptake of artificial intelligence technologies, the development of digital skills, and emerging systemic threats related to artificial intelligence, including those referred to in Article 68a (1)(a) and (1)(b);

Amendment 2524
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 58 - paragraph 1 - point c c (new)
(c c) The Board shall provide statutory guidance in relation to children’s rights, applicable law and minimum standards for the evaluation of automated decision-making systems to meet the objectives of this Regulation pertaining to children and to investigate the design goals, data inputs, model selection, implementation and outcomes of such systems.

Amendment 2525
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 58 - paragraph 1 - point c c (new)
(c c) annually publish recommendations to the Commission, in particular on the categorization of prohibited practices, high-risk systems, and codes of conduct for AI systems that are not classified as high-risk;

Amendment 2526
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 58 - paragraph 1 - point c c (new)
(c c) promote the cooperation and effective bilateral and multilateral exchange of information and best practices between the national supervisory authorities;

Amendment 2527
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 58 - paragraph 1 - point c c (new)
(c c) promote public awareness and understanding of the benefits, risks, rules and safeguards and rights in relation to the use of AI systems;

Amendment 2528
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 58 - paragraph 1 - point c d (new)
(c d) cooperate with the European Data Protection Board and with the FRA to provide guidance in relation to the respect of fundamental rights, in particular the right to non-discrimination and to equal treatment, the right to privacy and the protection of personal data;

Amendment 2529
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad- Marius Botoş, Moritz Körner, Jan-Christoph Oetjen
Article 58 - paragraph 1 - point c d (new)
(c d) annually publish recommendations to the Commission, in particular on the categorization of prohibited practices, high-risk systems, and codes of conduct for AI systems that are not classified as high-risk;

Amendment 2530
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 58 - paragraph 1 - point c d (new)
(c d) promote the cooperation and effective bilateral and multilateral exchange of information and best practices between the national supervisory authorities;

Amendment 2531
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 58 - paragraph 1 - point c d (new)
(c d) encourage and facilitate the drawing up of codes of conduct as referred to in Article 69;

Amendment 2532
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 58 - paragraph 1 - point c e (new)
(c e) promote common training programmes and facilitate personnel exchanges between the national supervisory authorities and, where appropriate, with the national supervisory authorities of third countries or with international organisations;

Amendment 2533
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 58 - paragraph 1 - point c e (new)
(c e) carry out biannual horizon scanning and foresight exercises to extrapolate the impact the trends and emerging issues can have on the Union;

Amendment 2534
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 58 - paragraph 1 - point c e (new)
(c e) promote public awareness and understanding of the benefits, risks, rules and safeguards and rights in relation to the use of AI systems;

Amendment 2535
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 58 - paragraph 1 - point c e (new)
(c e) coordinate among national supervisory authorities and make sure that the consistency mechanism in Article 59a(3) is observed;

Amendment 2536
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 58 - paragraph 1 - point c f (new)
(c f) adopt binding decisions for national supervisory authorities in case the consistency mechanism is not able to solve the conflict among national supervisory authorities as it is clarified in Article 59a(6);

Amendment 2537
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 58 - paragraph 1 - point c f (new)
(c f) advise the Commission on the possible amendment of the Annexes by means of delegated act in accordance with Article 73, in particular the annex listing high-risk AI systems;

Amendment 2538
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 58 - paragraph 1 - point c f (new)
(c f) promote the cooperation and effective bilateral and multilateral exchange of information and best practices between the national supervisory authorities;

Amendment 2539
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 58 - paragraph 1 - point c f (new)
(c f) promote public awareness and understanding of the benefits, rules and safeguards and rights in relation to the use of AI systems.

Amendment 2540
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 58 - paragraph 1 - point c g (new)
(c g) facilitate cooperation between the supervisory authorities of Member States and other supervisory authorities that might be responsible for the enforcement of this Regulation;

Amendment 2541
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 58 - paragraph 1 - point c g (new)
(c g) issue yearly reports on the implementation of the Regulation, including an assessment of the impact of the Regulation on economic operators.

Amendment 2542
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 58 - paragraph 1 - point c g (new)
(c g) ensure that the national supervisory authorities actively cooperate in the implementation of this Regulation;

Amendment 2543
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 58 - paragraph 1 - point c h (new)
(c h) support capacity and expertise building in supervisory authorities that are responsible for the enforcement of this Regulation;

Amendment 2544
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 58 - paragraph 1 - point c i (new)
(c i) advise the Commission on the possible amendment of the Annexes by means of delegated acts in accordance with Article 73, in particular the annex listing high-risk AI systems;

Amendment 2545
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 58 - paragraph 1 - point c j (new)
(c j) ensure that the national supervisory authorities actively cooperate in the implementation of this Regulation;

Amendment 2546
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 58 - paragraph 1 - point c k (new)
(c k) adopt binding decisions for national competent authorities in cases of serious disagreements pursuant to article 59a (5);

Amendment 2547
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 58 - paragraph 1 - point c l (new)
(c l) promote the development of a common European approach to benchmarking by cooperating with national metrology and benchmarking authorities and by issuing opinions, recommendations, written contributions, or studies with a view to ensure consistent and harmonised European benchmarking standards;

Amendment 2548
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 58 - paragraph 1 - point c m (new)
(c m) provide guidance in relation to children’s rights, applicable law and minimum standards to meet the objectives of this Regulation that pertain to children;

Amendment 2549
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 58 - paragraph 1 - point c n (new)
(c n) promote and support the accessible development and use of artificial intelligence systems, in accordance with the provisions of Directive (EU) 2019/882;

Amendment 2550
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 58 - paragraph 1 a (new)
When acting in the context of Article 59c on cases involving two or more Member States, the Board shall adopt binding decisions for national supervisory authorities.

Amendment 2551
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 58 - paragraph 1 b (new)
The Board shall organise consultations with stakeholders twice a year. Such stakeholders shall include representatives from industry, start-ups and SMEs ,organisations from the civil society organisations such as NGOs, consumer associations, the social partners and academia, to assess the evolution of trends in technology, issues related to the implementation and the effectiveness of this Regulation, regulatory gaps or loopholes observed in practice.

Amendment 2552
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 58 a (new)
Article 58 a', 'SECTION 3:the Executive Director', 'Functions and powers of the executive director', '1. The AI Office shall be managed by its executive director, who shall be completely independent in the performance of his or her duties. Without prejudice to the respective competencies of the Union institutions and the management board, the executive director shall neither seek nor take instructions from any government or from any other body.', "2. The executive director may be called upon at any time by the European Parliament or by the Council to attend a hearing on any matter linked to the AI Office's activities or to report on the carrying out of his or her tasks. This includes reporting on the activities of the AI Office, the implementation of its annual programming, the annual activity report for the previous year, and any other matter related to the activities of the AO Office. The executive director shall also make a statement before the European Parliament, if requested, and shall answer in writing any question put forward by a Member of the European Parliament within 15 calendar days from receipt of such question. The executive director shall report regularly to the appropriate bodies and committees of the European Parliament.", '3. Except where specific deadlines are provided for in this Regulation, the executive director shall ensure that reports are transmitted to the European Parliament, to the Council and to the Commission as soon as possible, and in any event within six months of the end of the reporting period, unless the executive director duly justifies a delay in writing.', '4. The executive director shall be responsible for the preparation and implementation of the strategic decisions taken by the management board and for the taking of decisions related to the operational activities of the AI Office in accordance with this Regulation. The executive director shall have the following functions and powers:', '(a) to propose, prepare and implement the strategic decisions and programmes and activities adopted by the management board within the limits set out in this Regulation, its implementing rules and any applicable law;', '(b) to take all necessary steps, including the adoption of internal administrative instructions and the publication of notices, to ensure the day-to-day administration and functioning of the AI Office in accordance with this Regulation;', '(c) to prepare each year the draft single programming document pursuant to Article 57a (b) and to submit it to the management board for endorsement before that draft is sent to the European Parliament, to the Council and to the Commission;', '(d) to draw up a draft statement of estimates of the revenues and expenditure of the AI Office as part of the single programming document pursuant to Article 57a (d) and to implement thebudget of the AI Office;', "(e) to prepare each year the annual activity report on the Agency's activities and submit it to the management board;", '(f) to coordinate all staff matters and all matters of day-to-day administration of the AI Office;', '(g) to prepare appropriate draft implementing rules to give effect to the Staff Regulations and the Conditions of Employment of Other Servants in accordance with Article 110 of the Staff Regulations;', '(h) to protect the values and interests of the Union by drawing up, submitting to the management board for approval, and implementing effective internal anti-fraud, anti-corruption, data protection and equal opportunity strategies, procedures, and safeguards;', '(i) to establish and implement effective monitoring and evaluation procedures relating to the performance of the AI Office against its objectives and to report annually to the management board on the results of the monitoring;', '(j) to consult the advisory forum and to facilitate its operations;', '(k) to develop and maintain contact with industry, standardization bodies, academia, and civil society, including organizations protecting fundamental and digital rights, consumers, workers, children, persons with disabilities, and other vulnerable categories, to ensure regular dialogue with relevant stakeholders;', '(l) to cooperate and to exchange views and information regularly with Union institutions, bodies, offices and agencies regarding artificial intelligence and related domains such as data, digital infrastructure, platform and internet governance, and cybersecurity, tonsure coherence in the development and the implementation of Union policy;', '(m) to represent the AI Office in international fora for cooperation on Artificial Intelligence;', '(n) To support the Chair of the management board in preparing and planning the management board meetings;', '(o) to perform other tasks pursuant to this Regulation.', '5. The executive director shall be accountable for his or her activities to the management board. 6. The executive director shall be the legal representative of the AI Office.

Amendment 2553
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 58 a (new)
Article 58 a', 'Guidelines from the Commission on the implementation of this Regulation', 'Upon the request of the Member States or the Board, or on its own initiative, the Commission shall issue guidelines on the practical implementation of this Regulation and in particular on:', '(i) the application of the requirements referred to in Articles 8 - 15;', '(ii) the prohibited practices referred to in Article 5;', '(iii) the practical implementation of the provisions related to substantial modification;', '(iv) the identification and application of criteria and use cases related to high risk AIsystems referred to in Annex III;', '(v) the practical implementation of transparency obligations laid down in Article 52;', '(vi) the relationship of this Regulation with other relevant Union legislation.', 'When issuing such guidelines, the Commission shall pay particular attention to the needs of SMEs and start-ups as well as sectors most likely to be affected by this Regulation.

Amendment 2554
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 58 a (new)
Article 58 a', 'Independence of the Board', '1. The Board shall act with complete independence in performing its tasks and exercising its powers in accordance with this Regulation.', '2. The members of the Board shall, in the performance of their tasks and exercise of their powers in accordance with this Regulation, remain free from external influence, whether direct or indirect, and shall neither seek nor take instructions from anybody.', '3. The members of the Board shall refrain from any action incompatible with their duties and shall not, during their term of office, engage in any incompatible occupation, whether gainful or not.

Amendment 2555
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 58 b (new)
Article 58 b', 'SECTION 4:the Advisory Forum', 'The advisory forum', '1. An advisory forum shall be established by the AI Office to advise it in the fulfilment of its tasks by providing stakeholder input in matters pertaining to this Regulation, in particular on:', '(a) technological developments and trends related to artificial intelligence;', '(b) potential updates of this Regulation, including prohibited practices, high-risk AI systems, AI systems requiring additional transparency obligations, and novel techniques used for the development of artificial intelligence;', '(c) best practices to optimise compliance and to reduce compliance costs and regulatory burden;', '(d) measures in support of innovation, start-ups, and SMEs, including improving participation in regulatory sandboxes;', '(e) the development, promotion, and uptake of harmonised standards, harmonised benchmarking standards, and common specifications;', '(f) emerging threats to health, safety, fundamental rights, or the values of the Union as enshrined in Article2 TEU related to artificial intelligence;', '2. The advisory forum shall have a balanced composition and represent the views of different stakeholders, with a third of its members representing industry, a third of its members representing start-ups, SMEs, and the innovation environment, and a third of its members representing civil society and academia.', '3. Stakeholders established outside the Union shall only participate in the advisory forum if they are established in third countries that are subject to a decision of the Commission adopted in accordance with Article 36 of Directive (EU) 2016/680 or Article 45 of Regulation 2016/679(‘adequacy decision’) or that are part of an international agreement concluded between the Union and that third country or international organisation pursuant to Article 218 TFEU adducing adequate safeguards with respect to the protection of privacy and fundamental rights and freedoms of individuals.', '4. Members of the advisory forum shall be appointed by the management board, based on a recommendation from the executive director, following a transparent call for applications and selection procedure.', '5. When drawing up the call for applications and the selection procedure, the executive director shall ensure that:', '(a) the composition criteria stet out in paragraph 2 are met;', '(b) the representation of industry, start-up, SMEs and the innovation environment is varied and includes stakeholders of different sizes and representing different industries;', '(c) the representation of civil society is varied and includes, at a minimum, organizations for the protection of democracy, fundamental rights, consumer rights, the rights of persons with disabilities, and children’s rights;', '(d) the advisory forum is balanced in terms of geographical distribution and gender.', '6. The term of office of the members of the advisory forum shall be two years. To ensure diversity and balanced representation, the term of office for members of the advisory forum shall not be renewable consecutively.', '7. The advisory forum shall draw up its rules of procedure and elect three co-Chairs from among its members according to there presentation criteria set out in paragraph 2. Their term of office shall be two years, non-renewable.', '8. The advisory forum shall hold regular meetings at least four times a year. The advisory forum can invite experts and other stakeholders to its meetings. The executive director can attend, ex officio, the meetings of the advisory forum.', '9. In fulfilling its role as set out in paragraph 1, the advisory forum can prepare opinions, recommendations or written contributions and forward these to the attention of the executive director.', '10. The advisory forum shall prepare an annual report of its activities. That report shall be made publicly available, including on the AI Office website.', '11. The AI Office shall provide secretarial assistance to the advisory forum to ensure its proper functioning.

Amendment 2556
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Title VI - Chapter 2 - title
2 National competent authorities and national supervisory authorities

Amendment 2557
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Title VI - Chapter 2 - title
2 national supervisory authorities

Amendment 2558
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 59 - title
Designation of national supervisory authorities

Amendment 2559
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 59 - paragraph 1
1. Each Member State shall establish or designate one national supervisory authority, which shall be organised so as to safeguard the objectivity and impartiality of its activities and tasks.

Amendment 2560
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 59 - paragraph 1
1. National competent authorities shall be established or designated by each Member State for the purpose of ensuring the application, implementation and enforcement of this Regulation. National competent authorities shall be organised so as to safeguard the objectivity and impartiality of their activities and tasks.

Amendment 2561
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 59 - paragraph 2
deleted

Amendment 2562
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 59 - paragraph 2
2. The national supervisory authority shall be in charge to ensure the application and implementation of this Regulation. With regard to high-risk AI systems, related to products to which legal acts listed in Annex II apply, the competent authorities designated under those legal acts shall continue to lead the administrative procedures. However, to the extent a case involves aspects covered by this Regulation, the competent authorities shall be bound by measures issued by the national supervisory authority designated under this Regulation. The national supervisory authority shall also act as notifying authority and market surveillance authority.

Amendment 2563
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 59 - paragraph 2
2. Each Member State shall designate a national supervisory authority among the national competent authorities. The national supervisory authority shall act as notifying authority and market surveillance authority.

Amendment 2564
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 59 - paragraph 2
2. 2. Each Member State shall designate the national data protection authority as tthe national supervisory authority among the national competent authorities. The national supervisory authority shall act as notifying authority and market surveillance authority unless a Member State has organisational and administrative reasons to designate more than one authority.

Amendment 2565
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte
Article 59 - paragraph 2
2. Each Member State shall designate one or more national supervisory authorities among the national competent authorities. The national supervisory authority or authorities shall act as notifying authorities and market surveillance authorities.

Amendment 2566
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 59 - paragraph 3
3. The national supervisory authority in each Member State shall be the lead authority, ensure adequate coordination and act as single point of contact for this Regulation. Member States shall inform the Commission of their designations.

Amendment 2567
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 59 - paragraph 3
3. Member States shall inform the Commission of their designation or designations

Amendment 2568
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 59 - paragraph 3
3. Member States shall inform the Board and the Commission of their designation or designations and, where applicable, the reasons for designating more than one authority.

Amendment 2569
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 59 - paragraph 4
4. Member States shall ensure that the national competent authorities are provided with adequate technical, financial and human resources, premises and infrastructure necessary to fulfil their tasks under this Regulation. In particular, national competent authorities shall have a sufficient number of personnel permanently available whose competences and expertise shall include an in-depth understanding of artificial intelligence technologies, data and data computing, personal data protection, fundamental rights, health and safety risks and knowledge of existing standards and legal requirements. Member States shall assess and update competence and resource requirements referred to in this paragraph on an annual basis.

Amendment 2570
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 59 - paragraph 4
4. Member States shall ensure that national supervisory authority is provided with adequate financial and human resources to fulfil its tasks under this Regulation. In particular, national supervisory authorities shall have a sufficient number of permanently available personnel, whose competences and expertise shall include an in-depth understanding of artificial intelligence technologies, data, data protection and data computing, cybersecurity, competition law, fundamental rights, health and safety risks as well as knowledge of existing standards and legal requirements.

Amendment 2571
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 59 - paragraph 4
4. Member States shall ensure that national competent authorities are provided with adequate financial and human and technical resources to fulfil their tasks effectively under this Regulation. In particular, national competent authorities shall have a sufficient number of personnel permanently available whose competences and expertise shall include an in-depth understanding of artificial intelligence technologies, data and data computing, fundamental rights, competition law, health and safety risks and knowledge of existing standards and other legal requirements.

Amendment 2572
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 59 - paragraph 4
4. Member States shall ensure that national competent authorities are provided with adequate financial, technical and human resources to fulfil their tasks under this Regulation. In particular, national competent authorities shall have a sufficient number of personnel permanently available whose competences and expertise shall include an in-depth understanding of artificial intelligence technologies, data and data computing, fundamental rights, health and safety risks and knowledge of existing standards and legal requirements.

Amendment 2573
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 59 - paragraph 4 a (new)
4 a. National supervisory authorities shall satisfy the minimum cybersecurity requirements set out for public administration entities identified as operators of essential services pursuant to Directive XXXX/XX on measures for a high common level of cybersecurity across the Union (NIS 2), repealing Directive (EU) 2016/1148.

Amendment 2574
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Vincenzo Sofo, Adam Bielan
Article 59 - paragraph 4 a (new)
4 a. National competent authorities shall satisfy the minimum cybersecurity requirements set out for public administration entities identified as operators of essential services pursuant to Directive (…) on measures for a high common level of cybersecurity across the Union, repealing Directive (EU) 2016/1148.

Amendment 2575
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Vincenzo Sofo, Adam Bielan
Article 59 - paragraph 4 b (new)
4 b. Any information and documentation obtained by the national competent authorities pursuant to the provisions of this Article shall be treated in compliance with the confidentiality obligations set out in Article 70.

Amendment 2576
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 59 - paragraph 4 b (new)
4 b. Any information and documentation obtained by the national supervisory authorities pursuant to the provisions of this Article shall be treated in compliance with the confidentiality obligations set out in Article 70.

Amendment 2577
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 59 - paragraph 5
5. Member States shall report to the Commission on an annual basis on the status of the financial and human resources of the national competent authorities with a qualified assessment of their adequacy. The Commission shall transmit that information to the Board for discussion and possible recommendations and formally accept or reject the assessments. Where an assessment is rejected, a new assessment shall be requested.

Amendment 2578
ECR - European Conservatives and Reformists Group
Jorge Buxadé Villalba
Article 59 - paragraph 5
5. Member States shall report to the Commission on an annual basis on the status of the financial and human resources of the national competent authorities with an assessment of their adequacy.

Amendment 2579
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 59 - paragraph 5
5. Member States shall report to the Commission on an annual basis on the status of the financial and human resources of the national competent authorities. The Commission shall transmit that information to the Board for discussion and possible recommendations.

Amendment 2580
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 59 - paragraph 5
5. Member States shall report to the Board and the Commission on an annual basis on the status of the financial and human resources of the national competent authorities with an assessment of their adequacy. The Commission shall transmit that information to the Board for discussion and possible recommendations.

Amendment 2581
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 59 - paragraph 5
5. Member States shall report to the Commission on an annual basis on the status of the financial and human resources of the national competent authorities with an assessment of their adequacy. The Commission shall transmit that information to the AI Office for discussion and possible recommendations.

Amendment 2582
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 59 - paragraph 5
5. Member States shall report to the Commission on an annual basis on the status of the financial and human resources of the national supervisory authority with an assessment of their adequacy. The Commission shall transmit that information to the Board for discussion and possible recommendations.

Amendment 2583
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 59 - paragraph 6
6. The Commission and the Board shall facilitate the exchange of experience between national competent authorities.

Amendment 2584
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 59 - paragraph 6
6. The Commission and the board shall facilitate the exchange of experience between national competent authorities.

Amendment 2585
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 59 - paragraph 6
6. The Commission and board shall facilitate the exchange of experience between national supervisory authorities.

Amendment 2586
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 59 - paragraph 6
6. The Board shall facilitate the exchange of experience between national competent authorities.

Amendment 2587
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 59 - paragraph 7
7. National competent authorities may provide guidance and advice on the implementation of this Regulation, including to small-scale providers. Whenever national competent authorities intend to provide guidance and advice with regard to an AI system in areas covered by other Union legislation, the competent national authorities under that Union legislation shall be consulted, as appropriate. Member States shall also establish one central contact point for communication with operators. In addition, the central contact point of each Member State should be contactable through electronic communications means.

Amendment 2588
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 59 - paragraph 7
7. National competent authorities may provide guidance and advice on the implementation of this Regulation, including to small-scale providers. Whenever national competent authorities intend to provide guidance and advice with regard to an AI system in areas covered by other Union legislation, the guidance shall be drafted in consultation with the competent national authorities under that Union legislation, as appropriate.

Amendment 2589
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 59 - paragraph 7
7. National competent authorities may provide guidance and advice on the implementation of this Regulation, including to SMEs and start-ups. Whenever national competent authorities intend to provide guidance and advice with regard to an AI system in areas covered by other Union legislation, the competent national authorities under that Union legislation shall be consulted,as appropriate. Member States shall also establish one central contact point for communication with operators and other stakeholders.

Amendment 2590
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 59 - paragraph 7
7. The Board may provide guidance and advice on the implementation of this Regulation, including to small-scale providers. Whenever the Board intends to provide guidance and advice with regard to an AI system in areas covered by other Union legislation, the competent national authorities under that Union legislation shall be consulted, as appropriate. Member States may also establish one central contact point for communication with operators.

Amendment 2591
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 59 - paragraph 7
7. National competent authorities may provide guidance and advice on the implementation of this Regulation, including to small-scale providers. Whenever national competent authorities intend to provide guidance and advice with regard to an AI system in areas covered by other Union legislation, the competent national authorities under that Union legislation shall be consulted, as appropriate. Member States shall also establish one central contact point for communication with operators.

Amendment 2592
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 59 - paragraph 7
7. National supervisory authorities may provide guidance and advice on the implementation of this Regulation, including to SMEs and start-ups, as long as it is not in contradiction with the Board’s or the Commission’s guidance and advice. Whenever national supervisory authorities intend to provide guidance and advice with regard to an AI system in areas covered by other Union legislation, the competent authorities under that Union legislation shall be consulted, as appropriate.

Amendment 2593
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 59 - paragraph 8
8. When Union institutions, agencies and bodies fall within the scope of this Regulation, the European Data Protection Supervisor shall act as the competent authority for their supervision and coordination.

Amendment 2594
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 59 - paragraph 8
8. The European Data Protection Supervisor shall act as the competent authority for the supervision of Union institutions, agencies and bodies.

Amendment 2595
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 59 a (new)
Article 59 a', 'Independent national superviosry authority', '1. Each Member State shall establish or designate a single national supervisory authority within 3 months after the entering into force of this Regulation.', '2. The national supervisory authority shall act as the lead authority and be responsible for ensuring the effective coordination between the national competent authorities regarding the implementation of this Regulation. It shall represent its Member State on the Board, in accordance with Article 57.', '3. Each national supervisory authority shall act with complete independence in performing its tasks and exercising its powers in accordance with this Regulation.', '4. The members of each national supervisory authority shall, in the performance of their tasks and exercise of their powers in accordance with this Regulation, remain free from external influence, whether direct or indirect, and shall neither seek nor take instructions from any other body.', '5. Members of each national supervisory authority shall refrain from any action incompatible with their duties and shall not, during their term of office, engage in any incompatible occupation, whether gainful or not.', '6. Each Member State shall ensure that each national supervisory authority is provided with the human, technical and financial resources, premises and infrastructure necessary for the effective performance of its tasks and exercise of its powers, including those to be carried out in the context of mutual assistance, cooperation and participation in the Board.', '7. Each Member State shall ensure that each national supervisory authority chooses and has its own staff which shall be subject to the exclusive direction of the member or members of the supervisory authority concerned.', '8. Each Member State shall ensure that each national supervisory authority is subject to financial control which does not affect its independence and that it has separate, public annual budgets, which may be part of the overall state or national budget.', '9. Each member of the national supervisory authority shall have the qualifications, experience and skills, in particular an in-depth understanding of artificial intelligence technologies, data and data computing, personal data protection, fundamental rights, health and safety risks and knowledge of existing standards and legal requirements, to perform their duties and exercise their powers.', '10. The duties of a member of the national supervisory authority shall end in the event of the expiry of the term of office, resignation or compulsory retirement, in accordance with the law of the Member State concerned.', '11. A member of the national supervisory authority shall be dismissed only in cases of serious misconduct or if the member no longer fulfils the conditions required for the performance of the duties.', '12. Member States shall make publicly available and communicate to the Commission and the Board, the national supervisory designation, and information on how it can be contacted, by [three months after the entry into force of this Regulation].', '13. For the purposes of the consistent application of the Regulation and for reasons of necessary cooperation with the market surveillance authorities, each national supervisory authority shall have at least one staff member from the market surveillance authority posted as a liaison officer to the national supervisory authority.

Amendment 2596
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 59 a (new)
Article 59 a', 'Consistency mechanism for cross-border cases', '1. Each national supervisory authority shall perform the tasks assigned to and the exercise of the powers conferred on it in accordance with this Regulation on the territory of its own Member State.', "2. The national supervisory authority of the Member State where the provider's place of central administration in the Union is present or established shall be competent to act as lead national supervisory authority for a cross-border case that involves an AI-system that falls under this Regulation and that is being placed on the market or put into service in two or more Member States.", '3. In order to contribute to the consistent application of this Regulation throughout the Union, national supervisory authorities shall cooperate with each other and, where relevant, with the Commission and the Board, through the consistency mechanism as set out in the following paragraphs.', '4. The lead national supervisory authority shall cooperate with the other supervisory authorities in an endeavour to reach consensus. The lead national supervisory authority and the other national supervisory authorities concerned shall exchange all relevant information with each other, provide mutual assistance and execute joint operations.', '5. The lead national supervisory authority shall, without delay, communicate the relevant information on the matter to the other national supervisory authorities concerned. It shall without delay submit a draft decision to the other national supervisory authorities concerned for their opinion and take due account of their views.', '6. In case the Board, after being notified by another national supervisory authority, finds that the lead national supervisory authority did not use its investigative, corrective or authorisation power despite being notified by another national supervisory authority or came to a decision that is clearly incompatible with provisions of this Regulation, other national supervisory authorities may address the case on their own, taking into account the procedure described in paragraph 3 or request that the Board issue a binding decision.

Amendment 2597
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 59 a (new)
Article 59 a', 'Cooperation mechanism between national supervisory authorities in cases involving two or more Member States', '1. Each national supervisory authority shall perform its tasks and powers conferred on in accordance with this Regulation on the territory of its own Member State.', '2. In the event of a case involving two or more national supervisory authorities, the national supervisory authority of the Member State where the provider or the user of the concerned AI system is established or where the authorised representative is appointed shall be considered to be the lead national supervisory authority.', '3. In the cases referred to in paragraph 2,the relevant national supervisory authorities shall cooperate and exchange all relevant information in due time. National supervisory authorities shall cooperate in order to reach a consensus.', '4. In the case of a serious disagreement between two or more national supervisory authorities, the national supervisory authorities shall notify the AI Office and communicate without delay all relevant information related to the case to the AI Office.', '5. The AI Office shall, within three months of receipt of the notification referred to in paragraph 4, issue a binding decision to the national supervisory authorities.

Amendment 2598
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 59 a (new)
Article 59 a', 'Independence', '1. Each supervisory authority shall act with complete independence in performing its tasks and exercising its powers in accordance with this Regulation.', '2. The member or members of each supervisory authority shall, in the performance of their tasks and exercise of their powers in accordance with this Regulation, remain free from external influence, whether direct or indirect, and shall neither seek nor take instructions from anybody.', '3. The member or members of each supervisory authority shall refrain from any action incompatible with their duties and shall not, during their term of office, engage in any incompatible occupation, whether gainful or not.', '4. Each Member State shall ensure that each supervisory authority chooses and has its own staff which shall be subject to the exclusive direction of the member or members of the supervisory authority concerned.', '5. Each Member State shall ensure that each supervisory authority is subject to financial control which does not affect its independence and that it has separate, public annual budgets, which may be part of the overall state or national budget.

Amendment 2599
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 59 b (new)
Article 59 b', 'Powers', '1. Each supervisory authority shall have all of the following investigative powers:', '(a) to order the provider or deployer of an AI system, and, where applicable, their representative, to provide any information it requires for the performance of its tasks;', '(b) to carry out investigations of providers or deployers of AI systems in the form of', '(i) audits;', '(ii) reviews of fundamental rights impact assessments;', '(iii) reviews of certifications of conformity;', '(iv) any other investigation to assess compliance with this Regulation;', '(c) to carry out a review on certifications issued pursuant to Article 44;', '(d) to notify the provider or deployer of an AI system of an alleged infringement of this Regulation;', '(e) to obtain, from the provider or deployer of an AI system, access to all data and to all information necessary for the performance of its tasks;', '(f) to obtain access to any premises of the provider or deployer of an AI system, including to any data processing equipment and means, in accordance with Union or Member State procedural law.', '2. Each supervisory authority shall have all of the following corrective powers:', '(a) to issue warnings to a provider or deployer of an AI system that the use or reasonably foreseeable misuse of that system is likely to infringe provisions of this Regulation;', '(b) to issue reprimands to a provider or deployer of an AI system where they have infringed provisions of this Regulation;', "(c) to order the provider or deployer of an AI system to comply with a subject's request to exercise his or her rights pursuant to this Regulation;", '(d) to order the provider or deployer of an AI system to bring operations into compliance with the provisions of this Regulation, where appropriate, in a specified manner and within a specified period;', '(e) to order the controller to communicate an infringement of this Regulation to the affected subject;', '(f) to impose a temporary or definitive limitation including a ban of the operation of an AI system;', '(g) to order the erasure of all data and of the related logic underlying automated processing, which had been generated as part of the development, training, or operation of an AI system that was subsequently found in breach of this Regulation;', '(h) to withdraw a certification or to order the certification body to withdraw a certification issued pursuant to Articles 44, or to order the certification body not to issue certification if the requirements for the certification are not or are no longer met;', '(i) to impose an administrative fine pursuant to Article 71, in addition to, or instead of measures referred to in this paragraph, depending on the circumstances of each individual case;', '(j) to order the suspension of the placing on the market of an AI system or of its export to a third country or to an international organisation.', '3. The exercise of the powers conferred on the supervisory authority pursuant to this Article shall be subject to appropriate safeguards, including effective judicial remedy and due process, set out in Union and Member State law in accordance with the Charter.', '4. Each Member State shall provide by law that its supervisory authority shall have the power to bring infringements of this Regulation to the attention of the judicial authorities and where appropriate, to commence or engage otherwise in legal proceedings, in order to enforce the provisions of this Regulation.', '5. Each Member State may provide by law that its supervisory authority shall have additional powers to those referred to in paragraphs 1, 2 and 3. The exercise of those powers shall not impair the effective operation of this Regulation.

Amendment 2600
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 59 b (new)
Article 59 b', 'Tasks of the national supervisory authority', '1. Without prejudice to other tasks set out under this Regulation, each national supervisory authority shall on the territory of its Member State:', '(a) monitor and enforce the application of this Regulation, in particular as to the upholding of the principles of article 4a, fundamental rights of individuals and the Union values, as enshrined in Article 2 TEU;', '(b) promote public awareness and understanding of the risks, rules, safeguards and rights in relation to use of AI systems;', '(c) promote the awareness of operators of their obligations under this Regulation;', '(d) monitor operators’ data governance and management practices, in particular in relation to training, validation and testing datasets;', '(e) upon request, provide information to affected persons concerning the exercise of their rights under this Regulation and, if appropriate, cooperate with the supervisory authorities in other Member States to that end;', '(f) handle complaints lodged by an affected person, organisation or association in accordance with Articles 68a and 68b, and investigate, to the extent appropriate, the subject matter of the complaint and inform the complainant of the progress and the outcome of the investigation within a reasonable period, in particular if further investigation or coordination with another national supervisory authority or national competent authority is necessary;', '(g) assist small-scale providers and users in accordance with Article 55;', '(h) cooperate with, including by sharing information and providing mutual assistance to, other national supervisory authorities and national competent authorities with a view to ensuring the consistency of application and enforcement of this Regulation;', '(i) conduct investigations on the application of this Regulation, including on the basis of information received from another national supervisory authority, national competent authority or other public authority;', '(j) cooperate with other competent authorities in their fields of competence, as necessary;', '(k) monitor relevant developments, insofar as they have an impact on the protection of fundamental rights and the values enshrined in Article 2 TEU, in particular the development of technologies and commercial practices;', '(l) contribute to the activities of the Board;', '2. National supervisory authorities may establish regulatory sandboxes in accordance with Article 53.', '3. Each national supervisory authority shall facilitate the submission of complaints referred to in point (f) of paragraph 1 by measures such as a complaint submission form which can also be completed electronically, without excluding other means of communication.', '4. The performance of the tasks of each national supervisory authority shall be free of charge for the affected person.

Amendment 2601
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 59 c (new)
Article 59 c', 'Cooperation and consistency', 'In order to contribute to the consistent application of this Regulation throughout the Union, the national supervisory authorities shall cooperate with each other and, where relevant, with the market surveillance authorities and the Commission, in order to reach consensus.

Amendment 2602
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 59 d (new)
Article 59 d', 'Cooperation mechanism in cases involving two or more Member States', '1. Each national supervisory authority shall perform its tasks and powers conferred to it in accordance with this Regulation, on the territory of its own Member State.', '2. In the event of a case involving two or more national supervisory authorities, the national supervisory authority of the Member State where the provider or the user of the concerned AI system is established, or where the legal representative resides, shall be considered to be the lead national supervisory authority.', '3. In case it is not clear which national supervisory authority should act as the lead authority pursuant to paragraph 2, the Board shall issue a binding decision according to Article 59e.', '4. In cases referred to in paragraph 2, the relevant national supervisory authorities shall cooperate and exchange all relevant information in due time.', '5. The national supervisory authorities shall, where appropriate, conduct joint operations, including joint investigations, in which members or staff of the national supervisory authorities of other Member States are involved.', '6. In case of a serious disagreement between two or more national supervisory authorities, the national supervisory authorities shall notify the Board and communicate without delay all relevant information related to the case to the Board for a binding decision.

Amendment 2603
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 59 e (new)
Article 59 e', 'Binding decisions by the Board', '1. In order to ensure the correct and consistent application of this Regulation in individual cases, the Board shall adopt a binding decision in the following cases:', '(a) where there are conflicting views on which of the national supervisory authorities concerned would be the lead authority pursuant to Article 59c;', '(b) where, in a case referred to in Article 59c(4), there is a serious disagreement between national supervisory authorities concerned regarding a matter involving two or more Member States;', '(c) where, in a case referred to in Article 67a, a national supervisory authority of a Member State finds that although an AI system is in compliance with this Regulation, it presents a risk to the compliance with obligations under Union or national law intended to protect fundamental rights, the principles of Article 4a, the values as enshrined in Article 2 TEU, the environment, or to other aspects of public interest protection;', '2. The decisions referred to in paragraph 1, point (a) shall be adopted within one week from the referral of the subject-matter, by a two-thirds majority of the members of the Board.', '3. The decisions referred to in paragraph 1, points (b) and (c) shall be adopted within one month from the referral of the subject-matter, by a two-thirds majority of the members of the Board. That period may be extended by a further month on account of the complexity of the subject-matter. The decision referred to in paragraph 1, points (b) and (c) shall be reasoned and addressed to the lead national supervisory authority and all the national supervisory authorities concerned and be binding on them.', '4. Where the Board has been unable to adopt a decision within the periods referred to in paragraph 3, it shall adopt its decision within two weeks following the expiration of the second month referred to in paragraph 2 by a simple majority of the members of the Board. Where the members of the Board are split, the decision shall by adopted by the vote of its Chair.', '5. The national supervisory authorities concerned shall not adopt a decision on the subject matter submitted to the Board under paragraph 1, points (b) and (c) during the periods referred to in paragraphs 3 and 4.', '6. The Chair of the Board shall notify, without undue delay, the decision referred to in paragraph 1 to the national supervisory authorities concerned. It shall also inform the Commission thereof. The decision shall be published on the website of the Board without delay after the national supervisory authorities have been notified.

Amendment 2604
ECR - European Conservatives and Reformists Group
Rob Rooken
Title VI - Chapter 2 a (new)
2 a Effective remedies', 'Create a comprehensive remedies framework for affected persons, including a right for individuals to bring complaints, a right to bring collective action; and a right to information.

Amendment 2605
ECR - European Conservatives and Reformists Group
Rob Rooken
Title VI - Chapter 2 b (new)
2 b The right to object to the use of automated decision-making in high-risk areas', 'Individuals shall have the right not to be subject to a decision based solely on automated processing by high-risk AI systems in Annex III which significantly affects them.

Amendment 2606
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Title VII
deleted

Amendment 2607
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Title VII
EU DATABASE FOR STAND-ALONE AI SYSTEMS

Amendment 2608
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Title VII
EU DATABASE FOR HIGH-RISK AI SYSTEMS

Amendment 2609
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Title VII
EU DATABASE FOR AI SYSTEMS

Amendment 2610
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 60 - title
60 EU database for stand-alone high-risk, general purpose and certain AI systems, uses thereof, and uses of AI systems by public authorities AI systems

Amendment 2611
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 60 - title
EU database for stand-alone AI systems

Amendment 2612
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 60 - title
EU database for high-risk AI systems

Amendment 2613
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 60 - title
EU database for AI systems

Amendment 2614
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 60 - paragraph 1
1. The Commission shall, in collaboration with the Member States, set up and maintain a EU database containing information referred to in paragraph 2 concerning AI systems which are registered in accordance with Article 51 and general purpose AI systems, in accordance with Article xx:', 'a. high-risk AI systems referred to in Article 6(2) which are registered in accordance with Article 51(1);', 'b. any AI systems referred to in Article 52 paragraphs 1b and 2 which are registered in accordance with Article 51(1);', 'c. any uses of high-risk AI systems referred to in Article 6(2) which are registered in accordance with Article 51(2);', 'd. any uses of AI systems referred to in Article 52 paragraph 1b and 2 which are registered in accordance with Article 51(2);', 'e. any uses of AI systems by or on behalf of public authorities registered in accordance with Article 51(3).

Amendment 2615
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 60 - paragraph 1
1. The Commission shall, in collaboration with the Member States, set up and maintain a EU database containing information referred to in paragraph 2 concerning high-risk AI systems in one of the areas listed in Annex III which are registered in accordance with Article 51 and their uses by public authorities and Union institutions, bodies, offices or agencies or on their behalf.

Amendment 2616
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 60 - paragraph 1
1. The Commission shall, in collaboration with the Member States and by building on the existing Business Registries in line with Directive 2012/17/EU, set up and maintain a EU database containing information referred to in paragraph 2 concerning high-risk AI systems listed in Annex III which are registered in accordance with Article 51.

Amendment 2617
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 60 - paragraph 1
1. The Commission shall, in collaboration with the Member States, set up and maintain a EU database containing information referred to in paragraph 2 and 2a concerning AI systems which are registered in accordance with Article 51, as well as users of any AI systems by public authorities and Union institutions, bodies, offices or agencies.

Amendment 2618
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 60 - paragraph 1
1. The Commission shall, in collaboration with the Member States, set up and maintain a public EU database containing information referred to in paragraph 2 concerning high-risk AI systems which are registered in accordance with Article 51.

Amendment 2619
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 60 - paragraph 2
2. The post-market monitoring system shall actively and systematically collect, document and analyse relevant data provided by users or collected through other sources, to the extent such data are readily accessible to the provider and taking into account the limits resulting from data protection, copyright and competition law, on the performance of high-risk AI systems throughout their lifetime, and allow the provider to evaluate the continuous compliance of AI systems with the requirements set out in Title III, Chapter 2.

Amendment 2620
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 60 - paragraph 2
2. The Commission shall provide providers and users entering data into the EU database with technical and administrative support.The following information should be included in the EU database:', '(a) For registrations according to paragraph 1(a) and 1(b), the data listed in Annex VIII point 1 shall be entered into the EU database by the providers.', '(b) For registrations according to paragraph 1(c) , 1(d) and 1(e), the data listed in Annex VIII point 2 shall be entered into the EU database by the users.

Amendment 2621
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 60 - paragraph 2
2. The data listed in Annex VIII shall be entered into the EU database by the providers, and, where relevant, deployers. The Commission shall provide them with technical and administrative support.

Amendment 2622
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 60 - paragraph 3
2 a. The data listed in Annex VIII, point (2), shall be entered into the EU database by the users, including those who are or who act on behalf of public authorities or Union institutions, bodies, offices or agencies. The Commission shall provide them with technical and administrative support.

Amendment 2623
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 60 - paragraph 3
3. Information contained in the EU database shall be freely available and accessible to the public, comply with the accessibility requirements of Annex I to Directive 2019/882, and be user-friendly, navigable, and machine-readable, containing structured digital data based on a standardised protocol.

Amendment 2624
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 60 - paragraph 3
3. The EU database and the information contained in it shall be freely available to the public, comply with the accessibility requirements of Annex I to Directive 2019/882, and be user-friendly, navigable, and machine-readable, containing structured digital data based on a standardised protocol.

Amendment 2625
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 60 - paragraph 3
3. Information contained in the EU database shall be accessible to the public, user-friendly and machine-readable.

Amendment 2626
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 60 - paragraph 3 a (new)
3 a. Users should register deployments of high-risk AI systems into the EU database before putting them into use. The users should include information in the database, not limited to, the identity of the provider and the user, the context of the purpose and of deployment, the designation of impacted persons, and the results of the impact assessment.

Amendment 2627
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş, Moritz Körner, Jan-Christoph Oetjen
Article 60 - paragraph 4
4. The EU database shall contain personal data only insofar as necessary for collecting and processing information in accordance with this Regulation. That information shall include the names and contact details of natural persons who are responsible for registering the system and have the legal authority to represent the provider or the user, if the user is a public authority or a Union institution, body, office or agency or a user acting on their behalf.

Amendment 2628
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 60 - paragraph 4
4. The EU database shall contain personal data only insofar as necessary for collecting and processing information in accordance with this Regulation. That information shall include the names and contact details of natural persons who are responsible for registering the system and have the legal authority to represent the provider, or the user.

Amendment 2629
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 60 - paragraph 4
4. The EU database shall contain personal data only insofar as necessary for collecting and processing information in accordance with this Regulation. That information shall include the names and contact details of natural persons who are responsible for registering the system and have the legal authority to represent the provider or the user.

Amendment 2630
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 60 - paragraph 4 a (new)
4 a. The EU database shall not contain any confidential business information or trade secrets of a natural or legal person, including source code.

Amendment 2631
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 60 - paragraph 4 a (new)
4 a. The EU database shall not contain any confidential business information or trade secrets of a natural or legal person, including source code.

Amendment 2632
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 60 - paragraph 5
5. The Commission shall be the controller of the EU database. It shall also ensure to providers and users adequate technical and administrative support, in particular in relation to registrations according to paragraph 1(e).

Amendment 2633
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 60 - paragraph 5
5. The Commission shall be the controller of the EU database.

Amendment 2634
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 60 - paragraph 5
5. The Commission shall be the controller of the EU database. It shall also ensure to providers and, where relevant, deployers, adequate technical and administrative support.

Amendment 2635
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Vincenzo Sofo, Adam Bielan
Article 60 - paragraph 5 a (new)
5 a. Any information and documentation obtained by the Commission and Member States pursuant to the provisions of this Article shall be treated in compliance with the confidentiality obligations set out in Article 70.

Amendment 2636
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 60 - paragraph 5 a (new)
5 a. Any information and documentation obtained by the Commission and Member States pursuant to the provisions of this Article shall be treated in compliance with the confidentiality obligations set out in Article 70.

Amendment 2637
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 60 - paragraph 5 a (new)
5 a. The database shall comply with the accessibility requirements of Annex I to Directive 2019/882.

Amendment 2638
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 60 a (new)
Article 60 a', 'Systemic transparency and monitoring of societal implications', '1. The Commission shall, in collaboration with the Member States, set up and maintain a relational database of digital and AI systems that interact with high-risk or general purpose AI systems or with AI systems with transparency obligations. Among others, the relational database shall include digital and AI systems whose input directly or indirectly come from a high-risk or general purpose AI system or whose output directly or indirectly is taken as input by a high-risk or general purpose AI system.', '2. For each entry in the EU database referred to in Article 60, the provider shall enter the upstream and downstream digital and AI systems into the relational database, as well as, to the extent it is possible, the digital and AI systems upstream of the upstream AI systems and the digital and AI systems downstream of the downstream AI systems.', '3. The European AI Board and the Commission shall regularly assess the relational map to facilitate incident response and to identify AI systems (‘Societally Significant AI systems’)whose output is used as input into many downstream digital and AI systems.4. The European AI Board and the Commission shall develop a Code of Conduct for Societally Significant AI Systems.

Amendment 2639
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 61 - paragraph 1
1. Providers shall establish and document a post-market monitoring system in a manner that is proportionate to the the risks of the high-risk AI system.

Amendment 2640
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 61 - paragraph 2
2. The post-market monitoring system shall actively and systematically collect, document and analyse relevant data provided by users or collected through other sources on the performance of high-risk AI systems throughout their lifetime, and allow the provider to evaluate the continuous compliance of AI systems with the requirements set out in Title III, Chapter 2.', 'Post-market monitoring must include continuous analysis of the AI environment, including other devices, software, and other AI systems that will interact with the AI system.

Amendment 2641
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 61 - paragraph 2
2. The post-market monitoring system shall actively and systematically collect, document and analyse relevant data provided by users or collected through other sources on the performance of high-risk AI systems throughout their lifetime, and allow the provider to evaluate the continuous compliance of AI systems with the requirements set out in Title III, Chapter 2. Post-market monitoring must include continuous analysis of the AI environment, including other devices, software, and other AI systems that will interact with the AI system.

Amendment 2642
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 61 - paragraph 2
2. The post-market monitoring system shall actively and systematically collect, document and analyse relevant data provided by deployers or collected through other sources on the performance of high-risk AI systems throughout their lifetime, and allow the provider to evaluate the continuous compliance of AI systems with the requirements set out in Title III, Chapter 2. Post-market monitoring shall include continuous analysis of the AI environment, including other devices, software, and other AI systems that interact with the AI system.

Amendment 2643
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Article 61 - paragraph 2
2. The post-market monitoring system shall actively and systematically collect, document and analyse relevant data provided by users or collected through other sources, to the extent such data are readily accessible to the provider and taking into account the limits resulting from data protection, copyright and competition law, on the performance of high-risk AI systems throughout their lifetime, and allow the provider to evaluate the continuous compliance of AI systems with the requirements set out in Title III, Chapter 2.

Amendment 2644
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 61 - paragraph 2
2. In order to allow the provider to evaluate the compliance of AI systems with the requirements set out in Title III, Chapter 2 throughout their lifetime, the post-market monitoring system shall actively and systematically collect, document and analyse relevant data provided by users or collected through other sources, to the extent such data are readily accessible to the provider and taking into account the limits resulting from data protection, copyright and competition law, on the performance of high-risk AI systems.

Amendment 2645
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 61 - paragraph 2
2. The post-market monitoring system shall actively and systematically collect, document and analyse relevant data provided by users or collected through other sources, not including the automated transmission of data, on the performance of high-risk AI systems throughout their lifetime, and allow the provider to evaluate the continuous compliance of AI systems with the requirements set out in Title III, Chapter 2.

Amendment 2646
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 61 - paragraph 2
2. The post-market monitoring system shall actively and systematically collect, document and analyse relevant data provided by users and end-users or collected through other sources on the performance of high-risk AI systems throughout their lifetime, and allow the provider to evaluate the continuous compliance of AI systems with the requirements set out in Title III, Chapter 2.

Amendment 2647
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 61 - paragraph 3
3. The post-market monitoring system shall be based on a post-market monitoring plan. The post-market monitoring plan shall be part of the technical documentation referred to in Annex IV. The Commission shall adopt an implementing act laying down detailed provisions establishing a template for the post-market monitoring plan and the list of elements to be included in the plan. These provisions shall not provide for the automated and systematic transmission of data.

Amendment 2648
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş, Moritz Körner, Ondřej Kovařík, Jan-Christoph Oetjen
Article 61 - paragraph 3
3. The post-market monitoring system shall be based on a post-market monitoring plan. The post-market monitoring plan shall be part of the technical documentation referred to in Annex IV. The Commission shall adopt an implementing act laying down detailed provisions establishing a template for the post-market monitoring plan and the list of elements to be included in the plan by ... [12 months following the entry into force of this Regulation].

Amendment 2649
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Title VIII - Chapter 2 - title
2 Sharing of information on incidents

Amendment 2650
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 62 - title
Reporting of serious incidents

Amendment 2651
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 62 - paragraph 1 - introductory part
1. Providers and, where users have identified a serious incident or malfunctioning, users of high-risk AI systems placed on the Union market shall report any serious incident or any malfunctioning of those systems which constitutes a breach of obligations under Union law to the market surveillance authorities of the Member States where that incident or breach occurred and to the affected persons and, where the incident or breach occurs or is likely to occur in at least two Member States, to the Commission.

Amendment 2652
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 62 - paragraph 1 - introductory part
1. Providers and, where users have identified a serious incident or malfunctioning, users of AI systems placed on the Union market shall report any serious incident or any malfunctioning, including near misses, of those systems which constitutes a breach of obligations under Union law to the national supervisory authorities and the market surveillance authorities of the Member States where that incident or breach occurred and, where relevant, to the Commission and to the affected persons.

Amendment 2653
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 62 - paragraph 1 - introductory part
1. Providers of high-risk AI systems placed on the Union market shall report any serious incident to the market surveillance authorities of the Member States where that incident occurred.

Amendment 2654
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 62 - paragraph 1 - introductory part
1. Providers and, where users have identified a serious incident or malfunctioning, including near misses, users of high-risk or general purpose systems which constitutes a breach of obligations under Union law intended to protect fundamental rights, health and safety to the market surveillance authorities of the Member States where that incident or breach occurred, and to the Commission..

Amendment 2655
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 62 - paragraph 1 - introductory part
1. Providers and, where applicable, users of high-risk AI systems placed on the Union market shall report any serious incident or any malfunctioning of those systems which constitutes a breach of obligations under Union law intended to protect fundamental rights to the market surveillance authorities of the Member States where that incident or breach occurred.

Amendment 2656
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 62 - paragraph 1 - introductory part
1. Providers and deployers of AI systems placed on the Union market shall report any serious incident or any malfunctioning of those systems which constitutes a breach of obligations under Union law or of fundamental rights to the market surveillance authorities of the Member States where that incident or breach occurred.

Amendment 2657
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 62 - paragraph 1 - subparagraph 1
Such notification shall be made without undue delay after the provider has established a causal link between the AI system and the incident or malfunctioning or the reasonable likelihood of such a link, and, in any event, not later than 72 hours after the providers becomes aware of the serious incident or of the malfunctioning.

Amendment 2658
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 62 - paragraph 1 - subparagraph 1
Such notification shall be made immediately after the provider has established a causal link between the AI system and the incident or malfunctioning or the reasonable likelihood of such a link, and, in any event, not later than 72 hours after the providers becomes aware of the serious incident or of the malfunctioning.

Amendment 2659
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 62 - paragraph 1 - subparagraph 1
Such notification shall be made immediately after the provider has established a causal link between the AI system and the incident or malfunctioning or the reasonable likelihood of such a link, and, in any event, not later than 72 hours after the providers becomes aware of the serious incident or of the malfunctioning.

Amendment 2660
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 62 - paragraph 1 - subparagraph 1
Such notification shall be made immediately when an AI system is involved in an incident or malfunctioning, including near misses, and, in any event, not later than 72 hours after the providers or, where applicable, the user becomes aware of the serious incident or of the malfunctioning.

Amendment 2661
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 62 - paragraph 1 - subparagraph 1
Such notification shall be made immediately when an AI system is involved in the incident or malfunctioning, including near misses, and, in any event, not later than 72 hours after the providers or, where applicable, the user becomes aware of the serious incident or of the malfunctioning.

Amendment 2662
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 62 - paragraph 1 - subparagraph 1
Such notification shall be made without undue delay after the provider has established a causal link between the AI system and the serious incident or the reasonable likelihood of such a link, and, in any event, not later than 72 hours after the providers becomes aware of the serious incident.

Amendment 2663
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 62 - paragraph 1 - subparagraph 1 a (new)
No report under this Article is required if the serious incident also leads to reporting requirements under other laws. In that case, the authorities competent under those laws shall forward the received report to the national competent authority.

Amendment 2664
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 62 - paragraph 1 - subparagraph 1 a (new)
No report under this Article is required if the serious incident also leads to reporting requirements under other laws. In that case, the authorities competent under those laws shall forward the received report to the national competent authority.

Amendment 2665
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 62 - paragraph 2
2. Upon receiving a notification related to a serious incident referred to in Article 3(44), the relevant market surveillance authority shall inform the national public authorities or bodies referred to in Article 64(3). The Commission shall develop dedicated guidance to facilitate compliance with the obligations set out in paragraph 1. That guidance shall be issued 12 months after the entry into force of this Regulation, at the latest.

Amendment 2666
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 62 - paragraph 2
2. Upon receiving a notification related to a breach of obligations under Union law or of fundamental rights, the market surveillance authority shall inform the national public authorities or bodies referred to in Article 64(3). The Commission shall develop dedicated guidance to facilitate compliance with the obligations set out in paragraph 1. That guidance shall be issued 3 months after the entry into force of this Regulation, at the latest.

Amendment 2667
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 62 - paragraph 2 a (new)
2 a. The market surveillance authorities shall take appropriate measures within 7 days from the date it received the notification referred to in paragraph 1. Where the infringement takes place or is likely to take place in other Member States, the market surveillance authority shall notify the Commission, the Board and the relevant national competent authorities of these Member States.

Amendment 2668
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 62 - paragraph 2 a (new)
2 a. Upon establishing a causal link between the AI system and the serious incident or malfunctioning or the reasonable likelihood of such a link, providers shall take appropriate corrective actions pursuant to Article 21.

Amendment 2669
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 62 - paragraph 3
3. For high-risk AI systems referred to in point 5(b) of Annex III which are placed on the market or put into service by providers that are subject to regulations that require solutions equivalent to those set out in this Regulation, the notification of serious incidents shall be limited to those referred to in Article 3(44).

Amendment 2670
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 62 - paragraph 3
3. For high-risk AI systems referred to in point 5(b) of Annex III which are placed on the market or put into service by providers that are credit institutions regulated by Directive 2013/36/EU and for high-risk AI systems which are safety components of devices, or are themselves devices, covered by Regulation (EU) 2017/745 and Regulation(EU) 2017/746, the notification of serious incidents or malfunctioning for the purposes of this Regulation shall be limited to those that that constitute a breach of obligations under Union law intended to protect fundamental rights and the environment.

Amendment 2671
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 62 - paragraph 3
3. For high-risk AI systems referred to in point 5(b) of Annex III which are placed on the market or put into service by providers that are credit institutions regulated by Directive 2013/36/EU and for high-risk AI systems which are safety components of devices, or are themselves devices, covered by Regulation (EU) 2017/745 and Regulation (EU) 2017/746, the notification of serious incidents or malfunctioning shall be limited to those that that constitute a breach of obligations under Union law or fundamental rights.

Amendment 2672
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Article 62 - paragraph 3 a (new)
3 a. Requirements in place in existing EU legislation shall be taken into account with regard to reporting of information of incidents, in view of avoiding duplications and harmonizing the provisions on incident and event reporting.

Amendment 2673
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 62 - paragraph 3 a (new)
3 a. National supervisory authorities shall on an annual basis notify the Board of the serious incidents and malfunctioning reported to them in accordance with this Article.

Amendment 2674
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 63 - paragraph 2
2. The national supervisory authority shall report annually to the Commission the outcomes of relevant market surveillance activities. The national supervisory authority shall report, without delay, to the Commission and relevant national competition authorities any information identified in the course of market surveillance activities that may be of potential interest for the application of Union law on competition rules.

Amendment 2675
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 63 - paragraph 3 a (new)
3 a. For the purpose of regulating high-risk AI systems, Market surveillance authorities may have the power to:', '(a) carry out unannounced on-site and remote inspections of high-risk AI systems;', '(b) acquire samples related to high-risk AI systems, including through remote inspections, to reverse-engineer the AI systems and to acquire evidence to identify non-compliance.

Amendment 2676
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 63 - paragraph 3 a (new)
3 a. The procedures referred to in Articles 65, 66, 67 and 68 of this Regulation shall not apply to AI systems related to products, to which legal acts listed in Annex II, section A apply, when such legal acts already provide for procedures having the same objective. In such a case, these sectoral procedures shall apply instead.

Amendment 2677
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 63 - paragraph 5
5. For AI systems that are used for law enforcement purposes, Member States shall designate as market surveillance authorities for the purposes of this Regulation the competent data protection supervisory authorities under Directive (EU) 2016/680, or Regulation 2016/679.

Amendment 2678
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 63 - paragraph 5
5. For AI systems listed in point 1(a) in so far as the systems are used for law enforcement purposes Member States shall designate as market surveillance authorities for the purposes of this Regulation the competent data protection supervisory authorities under Directive (EU) 2016/680 or Regulation 2016/679.

Amendment 2679
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Article 64 - paragraph 1
1. Without prejudice to powers provided under Regulation (EU) 2019/1020, and where relevant and limited to what is necessary to fulfil their tasks, market surveillance authorities may request access to data and documentation in the context of their activities, the market surveillance authorities shall be granted full access to the training, validation and testing datasets used by the provider that are strictly necessary for the purpose of its request., including, where appropriate and subject to security safeguards, through application programming interfaces (‘API’) or other appropriate technical means and tools enabling remote access.

Amendment 2680
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 64 - paragraph 1
1. When appropriate and proportionate, market surveillance authorities may request access to data and documentation in the context of their activities. The market surveillance authorities shall only be granted, access to those training, machine-learning validation and testing datasets used by the provider that are relevant and strictly necessary for the purpose of its request, after it has been clearly demonstrated that the data and documentation provided under paragraph 1 was not sufficient to assess conformity.

Amendment 2681
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 64 - paragraph 1
1. Access to data and documentation in the context of their activities, the market surveillance authorities shall be granted sufficient access to the training, validation and testing datasets used by the provider, including through application programming interfaces (‘API’) or other appropriate technical means and tools enabling remote access, taking into account the scope of access agreed with the relevant data subjects or data holders.

Amendment 2682
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 64 - paragraph 1
1. In the context of their activities, the national supervisory authorities, the market surveillance authorities, or the Commission, shall be granted full access to the training data sets, and where applicable, validation and testing datasets used by the provider or, where relevant, the user, including through application programming interfaces (‘API’) or other appropriate technical means and tools enabling remote access.

Amendment 2683
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Article 64 - paragraph 1
1. Upon a reasoned request the market surveillance authorities shall be granted access to the training, validation and testing datasets used by the provider, including through application programming interfaces (‘API’) or other appropriate technical means and tools enabling remote access.

Amendment 2684
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 64 - paragraph 1
1. Access to data and documentation in the context of their activities, the market surveillance authorities shall be granted access to the relevant training, validation and testing datasets used by the provider, including through application programming interfaces (‘API’) or other appropriate technical means and tools enabling remote access.

Amendment 2685
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 64 - paragraph 1
1. In the context of their activities, the market surveillance authorities shall be granted full access to the comprehensive training, validation and testing datasets used by the provider, including through application programming interfaces (‘API’) or other appropriate technical means and tools enabling remote access.

Amendment 2686
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 64 - paragraph 1 a (new)
1 a. Providers may challenge requests through an appeal procedure made available by Member States.

Amendment 2687
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 64 - paragraph 2
deleted

Amendment 2688
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 64 - paragraph 2
2. Where necessary to assess the conformity of the high-risk AI system with the requirements set out in Title III, Chapter 2, after all other reasonable ways to verify conformity have been exhausted and have proven to be insufficient, and upon a reasoned request, the market surveillance authorities or, where applicable, the Commission, shall be granted access to the source code of the AI system. Such access shall be subject to existing Union law on the protection of intellectual property and trade secrets.

Amendment 2689
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş,
Article 64 - paragraph 2
2. Market surveillance authorities shall be granted access to the source code of the high-risk AI system upon a reasoned request and only when the following cumulative conditions are fulfilled:', 'a) Access to source code is necessary to assess the conformity of a high-risk AI system with the requirements set out in Title III, Chapter 2, and', 'b) testing/auditing procedures and verifications based on the data and documentation provided by the provider have been exhausted or proved insufficient.

Amendment 2690
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 64 - paragraph 2
2. Where necessary to assess the conformity of the high-risk AI system with the requirements set out in Title III, Chapter 2 and upon a reasoned request, the national supervisory authority, the market surveillance authorities or, where applicable, the Commission shall be granted access to the source code of the AI system.

Amendment 2691
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 64 - paragraph 2
2. Where necessary to assess the conformity of the high-risk AI system with the requirements set out in Title III, Chapter 2 and upon a reasoned request. AI providers or deployers shall support market surveillance authorities with the necessary facilities to carry out testing to confirm compliance.

Amendment 2692
EPP - Group of the European Peoples Party (Christian Democrats)
Karlo Ressler
Article 64 - paragraph 2
2. Where necessary to assess the conformity of the high-risk uses of AI system with the requirements set out in Title III, Chapter 2 and upon a reasoned request, the market surveillance authorities shall ask for the explainability of the functioning of algorithms and criteria used by an AI system.

Amendment 2693
EPP - Group of the European Peoples Party (Christian Democrats)
Geoffroy Didier
Article 64 - paragraph 2
2. Where necessary to assess the conformity of the high-risk uses of AI system with the requirements set out in Title III, Chapter 2 and upon a reasoned request, the market surveillance authorities shall ask for the explainability of the functioning of algorithms and criteria used by an AI system.

Amendment 2694
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Article 64 - paragraph 2
2. Where necessary to assess the conformity of the high-risk AI system with the requirements set out in Title III, Chapter 2 and upon a reasoned request, the market surveillance authorities shall be granted access to other data if no confidential business information are at risk.

Amendment 2695
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 64 - paragraph 2
2. Where necessary to assess the conformity of the high-risk AI system with the requirements set out in Title III, Chapter 2 and upon request, the market surveillance authorities shall be granted access to the source code of the AI system.

Amendment 2696
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 64 - paragraph 3
3. National public authorities or bodies which supervise or enforce the respect of obligations under Union law protecting fundamental rights in relation to the use of high-risk AI systems referred to in Annex III shall have the power to request and access any documentation created or maintained under this Regulation, including data protection impact assessments and human rights impact assessments carried out by the users of such systems, when access to that documentation is necessary for the fulfilment of the competences under their mandate within the limits of their jurisdiction. The relevant public authority or body shall inform the market surveillance authority of the Member State concerned of any such request.

Amendment 2697
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 64 - paragraph 3
3. National public authorities or bodies, which supervise or enforce the respect of obligations under Union law protecting fundamental rights in relation to the use of high-risk AI systems referred to in Annex III shall have the power to request and access any documentation created or maintained under this Regulation when access to that documentation is necessary for the fulfilment of the competences under their mandate within the limits of their jurisdiction.

Amendment 2698
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 64 - paragraph 4
deleted

Amendment 2699
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 64 - paragraph 4
4. By 3 months after the entering into force of this Regulation, each Member State shall identify the public authorities or bodies referred to in paragraph 3 and make a list publicly available on the website of the national supervisory authority. Member States shall notify the list to the Commission and all other Member States and keep the list up to date. The European Commission shall publish in a dedicated website the list of all the Competent authorities designated by the Member States in accordance with this article.

Amendment 2700
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Article 64 - paragraph 5
5. Where the documentation referred to in paragraph 3 is insufficient to ascertain whether a breach of obligations under Union law intended to protect fundamental rights has occurred, the public authority or body referred to paragraph 3 may make a reasoned request to the national supervisory authority, the market surveillance authority, or where applicable the Commission, to organise testing of the high-risk AI system through technical means. The national supervisory authority, the market surveillance authority or where applicable the Commission shall organise the testing with the close involvement of the requesting public authority or body within reasonable time following the request.

Amendment 2701
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 64 - paragraph 5
5. Where the documentation referred to in paragraph 3 is insufficient to ascertain whether a breach of obligations under Union law or fundamental rights has occurred, the public authority or body referred to paragraph 3 may make a reasoned request to the market surveillance authority to organise testing of the high-risk AI system through technical means. The market surveillance authority shall organise the testing with the close involvement of the requesting public authority or body within reasonable time following the request.

Amendment 2702
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Article 64 a (new)
6. Any information and documentation obtained by the market surveillance authorities or the national public authorities or bodies referred to in paragraph 1, 2 and 3 pursuant to the provisions of this Article shall be treated in compliance with the confidentiality obligations set out in Article 70.

Amendment 2703
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 64 a (new)
Article 64 a', 'Market surveillance authorities', '1. Market surveillance authorities shall, at a minimum, have the power to', '(a) carry out unannounced on-site and remote inspections of AI systems.', '(b) acquire samples related to AI systems, including through remote inspections, to reverse-engineer the AI systems and to acquire evidence to identify non-compliance.', '2. Member States may authorise their market surveillance authorities to reclaim from the relevant operator the totality of the costs of their activities with respect to instances of non-compliance.', '3. The costs referred to in paragraph 2 of this Article may include the costs of carrying out testing, computation, hardware,storage, and the costs of activities relating to AI systems that are found to be non-compliant and are subject to corrective action prior to their placing on the market.

Amendment 2704
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 65 - title
Procedure for dealing with AI systems presenting a risk

Amendment 2705
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 65 - paragraph 1
1. AI systems presenting a risk means an AI system having the potential to affect adversely fundamental rights, health and safety of persons in general, including in the workplace, protection of consumers, the environment, public security, the values enshrined in Article 2 TEU and other public interests, that are protected by the applicable Union harmonisation legislation, to a degree which goes beyond that considered reasonable and acceptable in relation to its intended purpose or under the normal or reasonably foreseeable conditions of use of the system concerned, including the duration of use and, where applicable, its putting into service, installation and maintenance requirements.

Amendment 2706
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 65 - paragraph 1
1. AI systems presenting a risk shall be understood as a product presenting a risk defined in Article 3, point 19 of Regulation (EU) 2019/1020 insofar as risks to the health or safety in general, including safety in the workplace, protection of consumers, the environment, or to the protection of fundamental rights of persons are concerned, including autonomy of choice, access to goods and services, unfair discrimination and economic harm, privacy and data protection, as well as societal risks.

Amendment 2707
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte
Article 65 - paragraph 1
1. AI systems presenting a risk shall be understood as a product presenting a risk defined in Article 3, point 19 of Regulation (EU) 2019/1020 insofar as risks to the health or safety or to the protection of fundamental rights of persons, or of public order or the national security of the Member States are concerned.

Amendment 2708
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 65 - paragraph 1
1. AI systems presenting a risk shall be understood as AI systems having the potential to affect adversely the fundamental rights of persons, their health or safety, as well as AI systems having the potential to breach the principles defined in Art. 4a or the Union values as enshrined in Article 2 TEU.

Amendment 2709
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 65 - paragraph 1
1. AI systems presenting a risk shall be understood as a product presenting a risk defined in Article 3, point 19 of Regulation (EU) 2019/1020 insofar as risks to the health or safety or to fundamental rights of persons are concerned.

Amendment 2710
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Milan Brglez, Hilde Vautmans, Catharina Rinzema
Article 65 - paragraph 1 a (new)
1 a. When AI systems are likely to interact with or impact on children, the precautionary principle shall apply.

Amendment 2711
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 65 - paragraph 1 a (new)
1 a. When AI systems are likely to interact with or impact on children, the precautionary principle shall apply.

Amendment 2712
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Milan Brglez, Hilde Vautmans, Catharina Rinzema
Article 65 - paragraph 2 - introductory part
2. Where the market surveillance authority of a Member State has sufficient reasons to consider that an AI system presents a risk as referred to in paragraph 1, they shall carry out an evaluation of the AI system concerned in respect of its compliance with all the requirements and obligations laid down in this Regulation. When risks to the protection of fundamental rights are present, the market surveillance authority shall also inform the relevant national public authorities or bodies referred to in Article 64(3). Where there is sufficient reason to consider that that an AI system exploits the vulnerabilities of children or violates their rights intentionally or unintentionally, the market surveillance authority shall have the duty to investigate the design goals, data inputs, model selection, implementation and outcomes of the AI system and the burden of proof shall be on the operator or operators of that system to demonstrate compliance with the provisions of this Regulation. The relevant operators shall cooperate as necessary with the market surveillance authorities and the other national public authorities or bodies referred to in Article 64(3), including by providing access to personnel, documents, internal communications, code, data samples and on platform testing as necessary. Where, in the course of its evaluation, the market surveillance authority finds that the AI system does not comply with the requirements and obligations laid down in this Regulation, it shall without delay require the relevant operator to take all appropriate corrective actions to bring the AI system into compliance, to withdraw the AI system from the market, or to recall it within a reasonable period, commensurate with the nature of the risk, as it may prescribe. The corrective action can also be applied to AI systems in other products or services judged to be similar in their objectives, design or impact.

Amendment 2713
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 65 - paragraph 2 - introductory part
2. Where the market surveillance authority of a Member State has sufficient reasons to consider that an AI system presents a risk as referred to in paragraph 1, they shall carry out an evaluation of the AI system concerned in respect of its compliance with all the requirements and obligations laid down in this Regulation. When risks to the protection of fundamental rights are present, the market surveillance authority shall also inform the relevant national public authorities, Board or bodies referred to in Article 64(3). Where there is sufficient reason to consider that that an AI system exploits the vulnerabilities of children or violates their rights intentionally or unintentionally, the market surveillance authority shall have the duty to investigate the design goals, data inputs, model selection, implementation and outcomes of the AI system and the burden of proof shall be on the operator or operators of that system to demonstrate compliance with the provisions of this Regulation. The relevant operators shall cooperate as necessary with the market surveillance authorities and the other national public authorities or bodies referred to in Article 64(3), including by providing access to personnel, documents, internal communications, code, data samples and on platform testing as necessary.

Amendment 2714
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 65 - paragraph 2 - introductory part
2. Where the market surveillance authority of a Member State has sufficient reasons to consider that an AI system presents a risk to the health and safety of persons, they shall carry out an evaluation of the AI system concerned in respect of its compliance with all the requirements and obligations laid down in this Regulation.

Amendment 2715
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 65 - paragraph 2 - introductory part
2. Where the market surveillance authority of a Member State has sufficient reasons to consider that an AI system presents a risk as referred to in paragraph 1, they shall carry out an evaluation of the AI system concerned in respect of its compliance with all the requirements and obligations laid down in this Regulation. When risks to fundamental rights are present, the market surveillance authority shall also inform the relevant national public authorities or bodies referred to in Article 64(3). The relevant operators shall cooperate as necessary with the market surveillance authorities and the other national public authorities or bodies referred to in Article 64(3).

Amendment 2716
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 65 - paragraph 2 - subparagraph 1
Where, in the course of its evaluation, the market surveillance authority finds that the AI system does not comply with the requirements and obligations laid down in this Regulation, it shall without delay require the relevant operator to take all appropriate corrective actions to bring the AI system into compliance, to withdraw the AI system from the market, or to recall it within a reasonable period, commensurate with the nature of the risk, as it may prescribe. The corrective action can also be applied to AI systems in other products or services judged to be similar in their objectives, design or impact.

Amendment 2717
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 65 - paragraph 2 - subparagraph 1
Where, in the course of that evaluation, the market surveillance authority or, where relevant, the national public authority referred to in Article 64(3) finds that the AI system does not comply with the requirements and obligations laid down in this Regulation, it shall without delay require the relevant operator to take all appropriate corrective actions to bring the AI system into compliance, to withdraw the AI system from the market, or to recall it within a reasonable period, commensurate with the nature of the risk, as it may prescribe, and in any case no later than 15 working days.

Amendment 2718
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 65 - paragraph 2 - subparagraph 1
Where, in the course of that evaluation, the market surveillance authority finds that the AI system does not comply with the requirements and obligations laid down in this Regulation, it shall without delay require the relevant operator to take all appropriate corrective actions within a reasonable period, commensurate with the nature of the risk, and which it may prescribe, to withdraw the AI system from the market, or to recall it to bring it into compliance.

Amendment 2719
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 65 - paragraph 2 a (new)
2 a. Where the national supervisory authority has sufficient reasons to consider that an AI system presents a risk to the protection of fundamental rights, the principles as defined in Art 4a or the Union values, as enshrined in Article 2 TEU, they shall carry out an evaluation of the AI system concerned in respect of its compliance with all the requirements and obligations laid down in this Regulation.

Amendment 2720
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 65 - paragraph 2 b (new)
2 b. Where, in the course of that evaluation, the market surveillance authority or, where relevant, the national supervisory authority finds that the AI system does not comply with the requirements and obligations laid down in this Regulation, it shall without delay require the relevant operator to take all appropriate corrective actions to bring the AI system into compliance, to withdraw the AI system from the market, or to recall it within a reasonable period, commensurate with the nature of the risk, as it may prescribe, and in any case no later than 15 working days.', 'The market surveillance authority shall inform the relevant notified body accordingly. Article 18 of Regulation (EU) 2019/1020 shall apply to the measures referred to in the first subparagraph.

Amendment 2721
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 65 - paragraph 3
3. Where the market surveillance authority or, where relevant, the national supervisory authority, considers that non-compliance is not restricted to its national territory, it shall inform the Board, the Commission and the Member States’ competent authorities of the results of the evaluation and of the actions which it has required the operator to take.

Amendment 2722
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 65 - paragraph 3
3. Where the market surveillance authority considers that non-compliance is not restricted to its national territory, it shall inform the Commission and the other Member States without undue delay of the results of the evaluation and of the actions which it has required the operator to take.

Amendment 2723
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 65 - paragraph 3
3. Where the market surveillance authority considers that non-compliance is not restricted to its national territory, it shall inform the Commission, the AI Office and the other Member States of the results of the evaluation and of the actions which it has required the operator to take.

Amendment 2724
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 65 - paragraph 5
5. Where the operator of an AI system does not take adequate corrective action within the period referred to in paragraph 2b, the market surveillance authority or, where relevant, the national supervisory authority, shall take all appropriate provisional measures to prohibit or restrict the AI system's being made available on its national market or put into service, to withdraw the AI system from that market or to recall it. That authority shall immediately inform the Commission, the Board and the Member States’ market surveillance authorities, of those measures.

Amendment 2725
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 65 - paragraph 5
5. Where the operator of an AI system does not take adequate corrective action within the period referred to in paragraph 2, the market surveillance authority shall take all appropriate provisional measures to prohibit or restrict the AI system's being made available on its national market or put into service, to withdraw the AI system from that market or to recall it. That authority shall immediately inform the Commission, the Board and the other Member States, of those measures.

Amendment 2726
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 65 - paragraph 5
5. Where the operator of an AI system does not take adequate corrective action within the period referred to in paragraph 2, the market surveillance authority shall take all appropriate provisional measures to prohibit or restrict the AI system's being made available on its national market, to withdraw the product from that market or to recall it. That authority shall notify the Commission and the other Member States, without delay, of those measures.

Amendment 2727
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 65 - paragraph 6 - introductory part
6. The notification referred to in paragraph 5 shall include all available details, in particular the information necessary for the identification of the non-compliant AI system, the origin of the AI system, the nature of the non-compliance alleged and the risk involved, the nature and duration of the national measures taken and the arguments put forward by the relevant operator. In particular, the market surveillance authorities shall indicate whether the non-compliance is due to one or more of the following:

Amendment 2728
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 65 - paragraph 6 - point a
(a) a failure of the AI system to meet requirements and obligations set out in this Regulation;

Amendment 2729
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Article 65 - paragraph 6 - point a
(a) a failure of the high-risk AI system to meet requirements set out in Title III, Chapter 2;

Amendment 2730
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 65 - paragraph 6 - point b a (new)
(b a) non-compliance with the prohibition of the artificial intelligence practices referred to in Article 5;

Amendment 2731
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,
Article 65 - paragraph 6 - point b b (new)
(b b) non-compliance with provisions set out in Article 52;

Amendment 2732
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 65 - paragraph 7
7. The market surveillance authorities of the Member States other than the market surveillance authority of the Member State initiating the procedure shall without delay inform the Commission and the other Member States of any measures adopted and of any additional information at their disposal relating to the non-compliance of the AI system concerned.

Amendment 2733
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 65 - paragraph 7
7. The market surveillance authorities or, where applicable, the national supervisory authorities of the other Member States shall without delay inform the Commission, the Board and the authority initiating the procedure of any measures adopted and of any additional information at their disposal relating to the non-compliance of the AI system concerned, and, in the event of disagreement with the notified national measure, of their objections.

Amendment 2734
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 65 - paragraph 8
deleted

Amendment 2735
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 65 - paragraph 8
8. Where, within three months of receipt of the notification referred to in paragraph 5, no objection has been raised by either a Member State or the Commission in respect of a provisional measure taken by a Member State, that measure shall be deemed justified. This is without prejudice to the procedural rights of the concerned operator in accordance with Article 18 of Regulation (EU) 2019/1020. The period referred to in the first sentence of this paragraph shall be reduced to 30 days in the case of non-compliance with the prohibition of the artificial intelligence practices referred to in Article 5.

Amendment 2736
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 65 - paragraph 8
8. Where, within three months of receipt of the information referred to in paragraph 5, no objection has been raised by either a market surveillance authority, a national supervisory authority, or the Commission in respect of a provisional measure taken by a market surveillance authority or a national supervisory authority , that measure shall be deemed justified. This is without prejudice to the procedural rights of the concerned operator in accordance with Article 18 of Regulation (EU) 2019/1020.

Amendment 2737
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 65 - paragraph 9
9. The market surveillance authorities of all Member States shall ensure that appropriate restrictive measures are taken in respect of the AI system concerned, such as withdrawal of the product from their market, without delay.

Amendment 2738
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 66
deleted

Amendment 2739
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,
Article 66 - paragraph 1
1. Where, within three months of receipt of the notification referred to in Article 65(5), or 30 days in the case of non-compliance with the prohibition of the artificial intelligence practices referred to in Article 5, objections are raised by a Member State against a measure taken by another Member State, or where the Commission considers the measure to be contrary to Union law, the Commission shall without delay enter into consultation with the relevant Member State’s market surveillance authority and operator or operators and shall evaluate the national measure. On the basis of the results of that evaluation, the Commission shall decide whether the national measure is justified or not within 9 months, or 60 days in the case of non-compliance with the prohibition of the artificial intelligence practices referred to in Article 5, starting from the notification referred to in Article 65(5) and notify such decision to the Member State concerned. The Commission shall also inform all other Member States of such decision.

Amendment 2740
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 66 - paragraph 1
1. Where, within three months of receipt of the notification referred to in Article 65(5), objections are raised by the European Parliament or a Member State against a measure taken by another Member State, or where the Commission considers the measure to be contrary to Union law, or has sufficient reasons to believe that an AI system presents a risk or affects consumers in more than one Member State the Commission shall without delay enter into consultation with the relevant Member State and operator or operators and shall evaluate the national measure. On the basis of the results of that evaluation, the Commission shall decide whether the national measure is justified or not within 9 months from the notification referred to in Article 65(5) and notify such decision to the Member State concerned.

Amendment 2741
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 66 - paragraph 1
1. Where, within three months of receipt of the notification referred to in Article 65(5), objections are raised by a Member State against a measure taken by another Member State, or where the Board considers the measure to be contrary to Union law, the Board shall without delay enter into consultation with the relevant Member State and operator or operators and shall evaluate the national measure. On the basis of the results of that evaluation, the Board shall decide whether the national measure is justified or not within 9 months from the notification referred to in Article 65(5) and notify such decision to the Member State concerned.

Amendment 2742
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 66 - paragraph 2
2. If the national measure is considered justified, all Member States shall take the measures necessary to ensure that the non-compliant AI system is withdrawn from their market, and shall inform the Board accordingly. If the national measure is considered unjustified, the Member State concerned shall withdraw the measure.

Amendment 2743
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 66 - paragraph 3 a (new)
3. Where the national measure is considered justified and the non-compliance of the AI system is attributed to shortcomings in the harmonised standards or common specifications referred to in Articles 40 and 41 of this Regulation, the Commission shall apply the procedure provided for in Article 11 of Regulation (EU) No 1025/2012.The Commission shall also have the possibility to suggest alternative measures to the Member State concerned.

Amendment 2744
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 66 - paragraph 3 a (new)
3 a. If the national measure is found to be unjustified, the Member State concerned shall reimburse the operator for the costs and loss of revenue directly attributable to the measure found to be unjustified.

Amendment 2745
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 66 a (new)
Article 66 a', 'Requests for Commission intervention', '1. Where market surveillance authorities have reasons to suspect that the infringement of a provider or of a user of a high-risk AI system to this Regulation is liable to compromise the health or safety or fundamental of affected persons, the environment and the Union values enshrined in Article 2 TEU amount to a widespread infringement or a widespread infringement with a Uniondimension or affects or is likely affect at least 45 million citizens in the Union. The market surveillance authority may request the Commission to take the necessary investigatory and enforcement measures to ensure compliance with this Regulation. Such request shall set out the reasons for the Commission to intervene.', '2. Prior to requesting the Commission to intervene, the market surveillance authority shall notify the Board which shall issue within 7 days a non-binding opinion on the request for the Commission to intervene. The market surveillance authority shall take into account the non-binding opinion of the Board before sending its request to the Commission.

Amendment 2746
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 67
deleted

Amendment 2747
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 67 - title
Compliant AI systems which present a risk to the health and safety

Amendment 2748
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 67 - paragraph 1
1. Where, having performed an evaluation under Article 65, the market surveillance authority of a Member State finds that although an AI system is in compliance with this Regulation, it presents a risk to the health or safety of persons or to the compliance with obligations under Union or national law intended to protect fundamental rights, it shall require the relevant operator to take all appropriate measures to ensure that the AI system concerned, when placed on the market or put into service, no longer presents that risk

Amendment 2749
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 67 - paragraph 1
1. Where, having performed an evaluation under Article 65 in full cooperation with the relevant national public authority referred to in Article 64(3),the market surveillance authority of a Member State finds that although an AI system is in compliance with this Regulation, it presents a risk to the health or safety of persons, to the compliance with obligations under Union or national law intended to protect fundamental rights, environment, European values as enshrined in Article 2 TEU or to other aspects of public interest protection, it shall require the relevant operator to take all appropriate measures to ensure that the AI system concerned, when placed on the market or put into service, no longer presents that risk, to withdraw the AI system from the market or to recall it within a reasonable period, commensurate with the nature of the risk, as it may prescribe.

Amendment 2750
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 67 - paragraph 1
1. Where, having performed an evaluation under Article 65, the market surveillance authority of a Member State finds that although an AI system is in compliance with this Regulation, it presents a risk to the health or safety of persons, it shall require the relevant operator to take all appropriate measures to ensure that the AI system concerned, when placed on the market or put into service, no longer presents that risk, to withdraw the AI system from the market or to recall it within a reasonable period, commensurate with the nature of the risk, as it may prescribe.

Amendment 2751
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Article 67 - paragraph 1
1. Where, having performed an evaluation under Article 65, the market surveillance authority of a Member State finds that although an AI system is in compliance with this Regulation, it presents a risk to the health or safety of persons or to fundamental rights, it shall require the relevant operator to take all appropriate measures to ensure that the AI system concerned, when placed on the market or put into service, no longer presents that risk, to withdraw the AI system from the market or to recall it within a reasonable period, commensurate with the nature of the risk, as it may prescribe.

Amendment 2752
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Article 67 - paragraph 1
1. Where, having performed an evaluation under Article 65, the market surveillance authority of a Member State finds and demonstrates that although an AI system is in compliance with this Regulation, it presents a risk to the health or safety of persons, to the compliance with obligations under Union or national law intended to protect fundamental rights or to other aspects of public interest protection, it shall require the relevant operator to take all appropriate measures to ensure that the AI system concerned, when placed on the market or put into service, no longer presents that risk, to withdraw the AI system from the market or to recall it within a reasonable period, commensurate with the nature of the risk, as it may prescribe.

Amendment 2753
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 67 - paragraph 2 a (new)
2 a. Should the provider or other relevant operators fail to take corrective action as referred to in paragraph 2 and should the AI system continue to present a risk as referred to in paragraph 1, the market surveillance authority may require the relevant operator, as a measure of last resort, to withdraw the AI system from the market or to recall it within a reasonable period, commensurate with the nature of the risk.

Amendment 2754
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 67 - paragraph 3
3. The market surveillance authority shall immediately inform the Commission, the Board and the other Member States’ market surveillance authorities. That information shall include all available details, in particular the data necessary for the identification of the AI system concerned, the origin and the supply chain of the AI system, the nature of the risk involved and the nature and duration of the national measures taken.

Amendment 2755
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 67 - paragraph 3
3. The Member State shall immediately inform the Commission, the AI Office, and the other Member States. That information shall include all available details, in particular the data necessary for the identification of the AI system concerned, the origin and the supply chain of the AI system, the nature of the risk involved and the nature and duration of the national measures taken.

Amendment 2756
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 67 - paragraph 3
3. The Member State shall immediately inform the Board and the other Member States. That information shall include all available details, in particular the data necessary for the identification of the AI system concerned, the origin and the supply chain of the AI system, the nature of the risk involved and the nature and duration of the national measures taken.

Amendment 2757
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 67 - paragraph 4
4. The Commission shall without delay enter into consultation with the Member States and the relevant operator and shall evaluate the national measures taken. On the basis of the results of that evaluation, the Commission shall propose appropriate measures.

Amendment 2758
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 67 - paragraph 4
4. The Commission shall without delay enter into consultation with the Member States concerned and the relevant operator and shall evaluate the national measures taken. On the basis of the results of that evaluation, the Commission shall decide whether the measure is justified or not and, where necessary, propose appropriate measures.

Amendment 2759
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 67 - paragraph 4
4. The Commission shall without delay enter into consultation with the market surveillance authorities and the relevant operator and shall evaluate the national measures taken. On the basis of the results of that evaluation, the Commission shall decide whether the measure is justified or not and, where necessary, propose appropriate measures.

Amendment 2760
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 67 - paragraph 4
4. The Board shall without delay enter into consultation with the Member States and the relevant operator and shall evaluate the national measures taken. On the basis of the results of that evaluation, the Board shall decide whether the measure is justified or not and, where necessary, propose appropriate measures.

Amendment 2761
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 67 - paragraph 5
5. The Commission shall address its decision to the market surveillance authorities and communicate it to them and to the relevant operators.

Amendment 2762
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 67 - paragraph 5
5. The Commission shall address its decision to the Member States concerned, and inform all other Member States.

Amendment 2763
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 67 - paragraph 5
5. The Board shall address its decision to the Member States.

Amendment 2764
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 67 - paragraph 5 a (new)
5 a. The Board shall adopt guidelines to help national competent authorities to identify and rectify, where necessary, similar problems arising in other AI systems.

Amendment 2765
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 67 a (new)
Article 67 a', 'Compliant AI systems which present a risk to the fundamental rights', '1. Where, having performed an evaluation under Article 65, the national supervisory authority of a Member State finds that although an AI system is in compliance with this Regulation, it presents a risk to the compliance with obligations under Union or national law intended to protect fundamental rights, the principles of Article 4a, the values as enshrined in Article 2 TEU, the environment, or to other aspects of public interest protection, it shall require the relevant operator to take all appropriate measures to ensure that the AI system concerned, when placed on the market or put into service, no longer presents that risk, to withdraw the AI system from the market or to recall it within a reasonable period, commensurate with the nature of the risk, as it may prescribe.', '2. The provider or other relevant operators shall ensure that corrective action is taken in respect of all the AI systems concerned that they have made available on the market throughout the Union within the timeline prescribed by the national supervisory authority of the Member State referred to in paragraph 1.', '3. The national supervisory authority shall immediately inform the Board, the Commission and the market surveillance authority. That information shall include all available details, in particular the data necessary for the identification of the AI system concerned, the origin and the supply chain of the AI system, the nature of the risk involved and the nature and duration of the national measures taken.', '4. The Board shall without delay enter into consultation with the relevant operator and shall evaluate the national measures taken. On the basis of the results of that evaluation, the Board shall decide whether the measure is justified or not and, where necessary, propose appropriate measures.', '5. The Board shall address its decision to the national supervisory authority and to the relevant operators.

Amendment 2766
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 68 - paragraph 1 - point b
(b) the CE marking has not been affixed;

Amendment 2767
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 68 - paragraph 2
2. Where the non-compliance referred to in paragraph 1 persists for longer than one week following receipt of the relevant notice, the Member State concerned shall take all appropriate measures to restrict or prohibit the high-risk AI system being made available on the market or ensure that it is recalled or withdrawn from the market, imposing, where necessary, the penalties laid down in national law.

Amendment 2768
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 68 - paragraph 2
2. Where the non-compliance referred to in paragraph 1 persists, the Member State concerned shall take proportionate measures to restrict or prohibit the high-risk AI system being made available on the market.

Amendment 2769
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 68 - paragraph 2
2. Where the non-compliance referred to in paragraph 1 persists, the Member State concerned shall take all appropriate and proportionate measures to restrict or prohibit the high-risk AI system being made available on the market or ensure that it is recalled or withdrawn from the market.

Amendment 2770
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
René Repasi, Marc Angel, Andreas Schieder
Article 68 a (new)
Article 68 a', 'Insufficient application or non-application of Union law by the competent authority', '1. Where a competent authority has failed to ensure that an AI system is in compliance with the requirements laid down in this Regulation, or where a competent authority fails to require sufficient corrective action from an operator of an AI system that is incompliance with this Regulation but presents a risk to the health or safety of persons, to the compliance with obligations under Union or national law intended to protect fundamental rights or to other aspects of public interest protection, the Commission shall act in accordance with the powers set out in the following paragraphs of this Article.', '2. Upon request from one or more competent authorities, the European Parliament, the Council, the European Artificial Intelligence Board, or on its own initiative, including when this is based on well substantiated information from natural or legal persons, and after having informed the competent authority concerned, the Commission shall outline how it intends to proceed with the case and, where appropriate, investigate the alleged insufficient application or non-application of Union law.', 'The competent authority shall, without delay, provide the Commission with all information which the Commission considers necessary for its investigation.', 'The Commission may, after having informed the competent authority concerned, address a duly justified and reasoned request for information directly to other competent authorities whenever requesting information from the competent authority concerned has proven, or is deemed tobe, insufficient to obtain the information that is deemed necessary for the purpose of investigating an alleged insufficient application or non-application of Union law. The addressee of such a request shall provide the Commission with clear, accurate and complete information without undue delay.', 'Before issuing a recommendation as set out in paragraph 4, the Commission shall engage with the competent authority concerned where it considers such engagement appropriate in order to resolve the insufficient application or non-application of Union law, in an attempt to reach agreement on actions necessary for the competent authority to comply with Union law.', '3. Where necessary to issue a recommendation as set out in paragraph 4, the Commission shall have the rights granted to the market surveillance authorities under Article 64.', '4. The Commission may, not later than 2 months from initiating its investigation, address a recommendation to the competent authority concerned setting out the action necessary to comply with Union law. The competent authority shall, within ten working days of receipt of the recommendation, inform the Commission of the steps it has taken or intends to take to ensure compliance with Union law.', '5. Where the competent authority has not complied with Union law within 1 month from receipt of the Commission’s recommendation, the Commission may issue a formal opinion requiring the competent authority to take the action necessary to comply with Union law. The Commission shall issue such a formal opinion no later than 3 months after the adoption of the recommendation set out in paragraph 4. The Commission may extend this period by 1 month.', '6. The competent authority shall, within ten working days of receipt of the formal opinion referred to in paragraph 5,inform the Commission of the steps it has taken or intends to take to comply with that formal opinion.', '7. Without prejudice to the powers of the Commission pursuant to Article 258 TFEU, where a competent authority does not comply with the formal opinion referred to in paragraph 5 of this Article within the period specified therein, the Commission may adopt an individual decision addressed to the operator of an AI system requiring it to take all necessary action to comply with its obligations under Union law.', 'The decision of the Commission shall be in conformity with the formal opinion issued pursuant to paragraph 5.', '8. Decisions adopted in accordance with paragraph 7 shall prevail over any previous decision adopted by the competent authorities on the same matter. When taking action in relation to issues which are subject to a formal opinion pursuant to paragraph 5 or to a decision pursuant to paragraph 7, competent authorities shall comply with the formal opinion or the decision, as the case may be.

Amendment 2771
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 68 a (new)
Article 68 a', 'Right to lodge a complaint with a supervisory authority', '1. Without prejudice to any other administrative or judicial remedy, AI subjects and any natural or legal person affected by an AI system shall have the right to lodge a complaint with a supervisory authority, in particular in the Member State of his or her habitual residence, place of work or place of the alleged infringement if the subject considers that the use of a particular AI system, he or she is affected by, infringes this Regulation. Such a complaint may be lodged through a representative action for the protection of the collective interests of consumers as provided under Directive (EU) 2020/1828.', '2. Complainants shall have a right to be heard in the complaint handling procedure and in the context of any investigations or deliberations conducted by the competent authority as a result of their complaint.', '3. Supervisory authorities shall inform complainants or their representatives about the progress and outcome of their complaints. In particular, supervisory authorities shall take all the necessary actions to follow up on the complaints they receive and, within three months of the reception of a complaint, give the complainants a preliminary response indicating the measures they intend to take and the next steps in the procedure, if any.', '4. The supervisory authority shall take a decision on the complaint, including the possibility of a judicial remedy pursuant to Article 68b, without delay and no later than six months after the date on which the complaint was lodged.

Amendment 2772
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş, Samira Rafaela, Monica Semedo, Salima Yenbou, Moritz Körner, Ondřej Kovařík, Jan-Christoph Oetjen
Article 68 a (new)
Article 68 a', 'Right to lodge a complaint with a supervisory authority', '1. Without prejudice to any other administrative or judicial remedy, every natural or legal person shall have the right to lodge a complaint with a supervisory authority, in particular in the Member State of his or her habitual residence, place of work or place of the alleged infringement if the natural or legal person considers that their health, safety, or fundamental rights have been breached by an AI system falling within the scope of this Regulation.', '2. Natural or legal persons shall have a right to be heard in the complaint handling procedure and in the context of any investigations conducted by the national supervisory authority as a result of their complaint.', '3. The national supervisory authority with which the complaint has been lodged shall inform the complainants about the progress and outcome of their complaint. In particular, the national supervisory authority shall take all the necessary actions to follow up on the complaints it receives and, within three months of the reception of a complaint, give the complainant a preliminary response indicating the measures it intends to take and the next steps in the procedure, if any.', '4. The national supervisory authority shall take a decision on the complaint and inform the complainant on the progress and the outcome of the complaint, including the possibility of a judicial remedy pursuant to Article 68b, without delay and no later than six months after the date on which the complaint was lodged.

Amendment 2773
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 68 a (new)
Article 68 a', 'Right to lodge a complaint', '1. Affected persons, affected by an AI system falling within the scope of this Regulation, shall have the right to lodge a complaint against the providers or users of such AI system, with the national supervisory authority of the Member State where they have their habitual place of residence or place of work or where the alleged infringement took place, if they consider that their fundamental rights, health or safety have been breached.', '2. Affected persons shall have a right to be heard in the complaint handling procedure and in the context of any investigations conducted by the national supervisory authority as a result of their complaint.', '3. The national supervisory authority with which the complaint has been lodged shall inform the complainants about the progress and outcome of their complaint. In particular,the national supervisory authority shall take all the necessary actions to follow up on the complaints it receives and, within three months of the reception of a complaint, give the complainant a preliminary response indicating the measures it intends to take and the next steps in the procedure, if any.', '4. The national supervisory authority shall take a decision on the complaint, without delay and no later than six months after the date on which the complaint was lodged.

Amendment 2774
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Andrzej Halicki, Adam Jarubas, Jerzy Buzek, Janusz Lewandowski,
Article 68 a (new)
Article 68 a', 'Representation of affected persons and the right of public interest organisation to lodge complaints', '1. Without prejudice to Directive 2020/1828/EC, natural per-sons or groups of natural persons affected by an AI system shall have the right to mandate a body, organisation or association to lodge a complaint referred to in Article 68 on their behalf, to exercise the right to remedy referred to in Article 68 on their behalf, and to exercise on their behalf other rights under this Regulation, in particular the right to receive an explanation referred to in Article 4a', '2. Without prejudice to Directive 2020/1828/EC, the bodies, organisations or associations referred to in paragraph 1 shall have the right to lodge a complaint with national supervisory authorities, independently of the mandate of the natural per-son, if they consider that an AI system has been placed on the market, put into service, or used in a way that infringes this Regulation, or is otherwise in violation of fundamental rights or other aspects of public interest protection, pursuant to article 67.', '3. National supervisory authorities have the duty to investigate, in conjunction with relevant market surveillance authority if applicable, and respond within a reasonable period to all com-plaints referred to in paragraph 2.

Amendment 2775
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 68 a (new)
Article 68 a', 'Commission fees', '1. The Commission shall charge fees to market surveillance authorities when the Commission initiates proceedings in accordance with Article 68a(1)(c).', '2. The overall amount of the fee shall cover the estimated costs the Commission incurs in relation to proceedings carried out under this Regulation, in particular costs related to the investigation and enforcement measures pursuant to Chapter 4 of Title VIII.', '3. The Commission shall lay down in a delegated act, adopted pursuant to Article 73, the detailed methodology and procedures for:(a) the determination of the estimated costs referred to in paragraph 2and the necessary payment modalities.', '4. The fees charged pursuant to paragraph 1 shall constitute external assigned revenue in accordance with Article 21(5) of Regulation (EU, Euratom) No 2018/1046 of the European Parliament and of the Council.', '5. The Commission shall report annually to the European Parliament and to the Council on the overall amount of the costs incurred for the fulfilment of the tasks under this Regulation and the total amount of the fees charged in the preceding year.

Amendment 2776
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 68 a (new)
Article 68 a', 'Right to lodge a complaint with a supervisory authority', '1. Citizens have a right not to be subjected to prohibited AI systems.', '2. Citizens have a right not to be subjected to high-risk AI systems that fail to meet the requirements for high-risk systems.', '3. Without prejudice to any other administrative or judicial remedy, every citizen shall have the right to lodge a complaint with a supervisory authority, in particular in the Member State of his or her habitual residence, place of work or place of the alleged infringement if the citizen considers that he or she has been subjected to an AI system that infringes this Regulation.', '4. The supervisory authority with which the complaint has been lodged shall inform the complainant on the progress and the outcome of the complaint.', '5. Without prejudice to any other administrative or non-judicial remedy, each natural or legal person shall have the right to an effective judicial remedy against a legally binding decision

Amendment 2777
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 68 a (new)
Article 68 a', 'Right to lodge a complaint with a supervisory authority', '1. Every citizen who considers that his or her right to protection of personal data has been infringed by the use of a prohibited AI system or a high-risk AI system shall have the right to lodge a complaint with the authority in charge to handle complaints under Article 77 of Regulation (EU) 2016/679 in the Member State of his or her habitual residence, place of work or place of the alleged infringement.', '2. The supervisory authority with which the complaint has been lodged shall inform the complainant on the progress and the outcome of the complaint.

Amendment 2778
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 68 b (new)
Article 68 b', 'Representation of affected persons', '1. An affected person shall have the right to mandate a not-for-profit body, organisation or association that has been properly constituted in accordance with the law of a Member State, has statutory objectives which are in the public interest, and is active in the field of the protection of rights and freedoms of affected persons, with regard to the protection of their fundamental rights, to lodge the complaint on their behalf, to exercise the rights referred to in Article 68a on his or her behalf, and to exercise the right to receive compensation referred to in Article 70a and 71 on his or her behalf.', '2. Any body, organisation or association referred to in paragraph 1 of this Article, independently of an affected person’s mandate, has the right to lodge, in that Member State, a complaint with the national supervisory authority which is competent pursuant to Article 68a, if it considers that the rights of a affected persons under this Regulation have been infringed as a result of them being subject to AI systems.

Amendment 2779
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,
Article 68 b (new)
Article 68 b', 'Right to an effective judicial remedy against a national supervisory authority', '1. Without prejudice to any other administrative or non-judicial remedy, each natural or legal person shall have the right to an effective judicial remedy against a legally binding decision of a national supervisory authority concerning them.', '2. Without prejudice to any other administrative or non-judicial remedy, each data subject shall have the right to a an effective judicial remedy where the national supervisory authority does not handle a complaint, does not inform the complainant on the progress or preliminary outcome of the complaint lodged within three months pursuant to Article 68a(3) or does not comply with its obligation to reach a final decision on the complaint within six months pursuant to Article 68a(4) or its obligations under Article 65.', '3. Proceedings against a supervisory authority shall be brought before the courts of the Member State where the national supervisory authority is established.

Amendment 2780
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 68 b (new)
Article 68 b', 'Right to an effective judicial remedy against an authority', '1. Without prejudice to any other administrative or non-judicial remedy, individuals and their representatives shall have the right to an effective judicial remedy against any legally binding decision concerning them, whether by a market surveillance authority or a supervisory authority.', '2. Without prejudice to any other administrative or non-judicial remedy, individuals shall have the right to a an effective judicial remedy where the authority which is competent does not handle a complaint, does not inform the individual on the progress or preliminary outcome of the complaint lodged within three months pursuant to Article 68a (3), does not comply with its obligation to reach a final decision on the complaint within six months pursuant to Article 68a (3) or its obligations under Article 65.', '3. Proceedings against a market surveillance authority shall be brought before the courts of the Member State where the authority is established.

Amendment 2781
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 68 b (new)
Article 68 b', 'Representation of affected persons or groups of persons', '1. Without prejudice to Directive 2020/1828/EC, the person or groups of persons harmed by AI systems shall have the right to mandate a not-for-profit body, organisation or association which has been properly constituted in accordance with the law of a Member State, has statutory objectives which are in the public interest, and is active in the field of the protection of rights and freedoms impacted by AI to lodge the complaint on his, her or their behalf, to exercise the rights referred to in this Regulation on his, her or their behalf.', '2. Without prejudice to Directive 2020/1828/EC, the body, organisation or association referred to in paragraph 1 shall have the right to exercise the rights established in this Regulation independently of a mandate by a person or groups of person if it considers that a provider or a user has infringed any of the rights or obligations set out in this Regulation.

Amendment 2782
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 68 c (new)
Article 68 c', 'Remedies', '1. Without prejudice to any available administrative or non-judicial remedy and the right to lodge a complaint with a supervisory authority pursuant to Article 68a, any natural person shall have the right to an effective judicial remedy against a provider or deployer where they consider that their rights under this Regulation have been infringed or has been subject to an AI system otherwise in non-compliance with this Regulation.', '2. Any person who has suffered material or non-material harm, as a result of an infringement of this Regulation shall have the right to receive compensation from the provider or deployer for the damage suffered. Individuals and their representatives shall be able to seek judicial and non-judicial remedies against providers or deployers of AI systems, including repair, replacement, price reduction, contract termination, reimbursement of the price paid or compensation for material and immaterial damages, for breaches of the rights and obligations set out in this Regulation.', '3. Providers and deployers of AI systems which may affect individuals, including AI-subjects, or consumers must provide an effective complaint handling system which enables complaints to be lodged electronically and free of charge, and ensure that complaints submitted through this system are dealt with in an efficient and expedient manner.', '4. Providers and deployers of AI systems shall ensure that their internal complaint-handling systems are easy to access, user-friendly and enable and facilitate the submission of sufficiently precise and adequately substantiated complaints.', '5. Where an AI system infringes this Regulation, any natural or legal person affected by said AI system may ask the supervisory authority or judicial authorities to stop the use of this system.', '6. Member States shall ensure that where infringements of an AI system are imminent or likely, any affected natural or legal person may seek a prohibitory injunction under national law.

Amendment 2783
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 68 d (new)
Article 68 c', 'Amendment to Directive 2020/1828/EC on Representative Actions for the Protection of the Collective Interests of Consumers', 'The following is added to Annex I of Directive 2020/1828/EC on Representative actions for the protection of the collective interests of consumers: “Regulation xxxx/xxxx of the European Parliament and of the Council laying down harmonised rules on artificial intelligence (artificial intelligence act) and amending certain union legislative acts”.

Amendment 2784
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 68 d (new)
Article 68 d', 'Representation of individuals', '1. Without prejudice to Directive 2020/1828/EC, individuals shall have the right to mandate a body, organisation or association to exercise the rights referred to in Articles 68a, 68b and 68c and, where relevant, the rights of AI subjects, on their behalf, provided that the body, organisation or association meets all of the following conditions:', 'a) It operates on a not-for-profit basis;', 'b) It has been constituted in accordance of the law of a Member State;', 'c) Its statutory objectives include a legitimate interest in ensuring that this Regulation is complied with.', '2. Without prejudice to Directive 2020/1828/EC, the bodies, organisations or associations referred to in paragraph 1 shall have the right to exercise the rights established in Articles 68a, 68b and 68c independently of an individual’s mandate, if they consider that a provider or user of an AI system has infringed any of the rights or obligations set out in this Regulation.

Amendment 2785
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 68 d (new)
Article 68 d', 'Reporting of breaches and protection of reporting persons', 'Directive (EU) 2019/1937 of the European Parliament and of the Council shall apply to the reporting of breaches of this Regulation and the protection of persons reporting such breaches.

Amendment 2786
Renew - Renew Europe Group
Dragoş Tudorache
Article 69 - paragraph 1
1. The Commission, AI Office, and the Member States shall encourage and facilitate the drawing up of codes of conduct intended to foster the development and use of safe and trustworthy AI for AI systems other than high-risk AI systems. These codes of conduct should be voluntary and should be based on the requirements set out in Title III, Chapter 2 on the basis of technical specifications and solutions that are appropriate means of ensuring compliance with such requirements but be adapted in light of the intended purpose of the systems and of the lower risk involved

Amendment 2787
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz
Article 69 - paragraph 1
1. The Commission and the board shall encourage and facilitate the drawing up of codes of conduct intended to foster the voluntary application to AI systems other than high-risk AI systems of the requirements set out in Title III, Chapter 2 on the basis of technical specifications and solutions that are appropriate means of ensuring compliance with such requirements in light of the intended purpose of the systems.

Amendment 2788
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 69 - paragraph 1 a (new)
1 a. The Commission and the Board shall encourage and facilitate the drawing up of Codes of Conduct intended to foster the voluntary application of the concept of trustworthy AI set out in Article 4(a) to AI systems other than high-risk AI systems on the basis of technical specifications and solutions that are appropriate means of ensuring compliance with such requirements in light of the intended purpose of the system.

Amendment 2789
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 69 - paragraph 2
2. The Commission and the Board shall encourage and facilitate the drawing up of codes of conduct intended to foster the voluntary application to AI systems of requirements related for example to environmental sustainability, accessibility for persons with a disability and stakeholders’ participation in the design and development of the AI systems on the basis of clear objectives and key performance indicators to measure the achievement of those objectives.

Amendment 2790
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 69 - paragraph 3
2. The Commission and the AI Office shall encourage and facilitate the drawing up of codes of conduct intended to foster the voluntary application to AI systems of requirements related for example to environmental sustainability, accessibility for persons with a disability, stakeholders participation in the design and development of the AI systems and diversity of development teams on the basis of clear objectives and key performance indicators to measure the achievement of those objectives.

Amendment 2791
Renew - Renew Europe Group
Dragoş Tudorache
Article 69 - paragraph 3
3. Codes of conduct may be drawn up by individual providers of AI systems or by organisations representing them or by the Commission or the AI Office, including with the involvement of users and any interested stakeholders and their representative organisations. Codes of conduct may cover one or more AI systems taking into account the similarity of the intended purpose of the relevant systems.

Amendment 2792
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 69 - paragraph 4
4. The Commission and the AI Office shall take into account the specific interests and needs of the small-scale providers and start-ups when encouraging and facilitating the drawing up of codes of conduct.

Amendment 2793
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 69 - paragraph 4
4. The Commission and the Board shall take into account the specific interests and needs of SMEs and start-ups when encouraging and facilitating the drawing up of codes of conduct.

Amendment 2794
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 69 - paragraph 4
4. The Commission and the Board shall take into account the specific interests and needs of the SMEs and start-ups when encouraging and facilitating the drawing up of codes of conduct.

Amendment 2795
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 70 - paragraph 1 - introductory part
1. National competent authorities, market surveillance authorities and notified bodies involved in the application of this Regulation shall put effective cybersecurity, technical and organisational measures in place to ensure the confidentiality of information and data obtained in carrying out their tasks and activities in such a manner as to protect, in particular:

Amendment 2796
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 70 - paragraph 1 - introductory part
1. National competent authorities, notified bodies, the Commission, the Board, and any other natural or legal person involved in the application of this Regulation shall, in accordance with Union or national law, put appropriate technical and organisational measures in place to ensure the confidentiality of information and data obtained in carrying out their tasks and activities in such a manner as to protect, in particular:

Amendment 2797
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar
Article 70 - paragraph 1 - introductory part
1. National supervisory authorities, national competent authorities and notified bodies involved in the application of this Regulation shall respect the confidentiality of information and data obtained in carrying out their tasks and activities in such a manner as to protect, in particular:

Amendment 2798
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 70 - paragraph 1 - introductory part
1. The Commission, the AI Office, national competent authorities and notified bodies involved in the application of this Regulation shall respect the confidentiality of information and data obtained in carrying out their tasks and activities in such a manner as to protect, in particular:

Amendment 2799
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 70 - paragraph 1 - point a
(a) intellectual property rights, and confidential business information or trade secrets of a natural or legal person in line with the 2016 EU Trade Secrets Directive (Directive 2016/943) as well as the 2004 Directive on the enforcement of intellectual property rights (Directive 2004/48/EC), including source code, except the cases referred to in Article 5 of Directive 2016/943 on the protection of undisclosed know-how and business information (trade secrets) against their unlawful acquisition, use and disclosure apply.

Amendment 2800
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Article 70 - paragraph 1 - point a
(a) intellectual property rights, and confidential business information or professional secrecy or trade secrets of a natural or legal person, including source code, except the cases referred to in Article 5 of Directive 2016/943 on the protection of undisclosed know-how and business information (trade secrets) against their unlawful acquisition, use and disclosure apply.

Amendment 2801
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 70 - paragraph 1 - point a
(a) confidential business information or trade secrets of a natural or legal person, except the cases referred to in Article 5 of Directive 2016/943 on the protection of undisclosed know-how and business information (trade secrets) against their unlawful acquisition, use and disclosure apply.

Amendment 2802
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 70 - paragraph 1 - point c a (new)
(c a) the principles of purpose limitation and data minimization, meaning that national competent authorities minimize the quantity of data requested for disclosure in line with what is absolutely necessary for the perceived risk and its assessment, and they must not keep the data for any longer than absolutely necessary.

Amendment 2803
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Article 70 - paragraph 1 - point c a (new)
(c a) the principles of purpose limitation and data minimization, meaning that national competent authorities minimize the quantity of data requested for disclosure inline with what is absolutely necessary for the perceived risk and its assessment, and they must not keep the data for any longer than absolutely necessary;

Amendment 2804
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 70 - paragraph 1 a (new)
1 a. In cases where the activity of national competent authorities, market surveillance authorities and notified bodies pursuant to the provisions of this Article results in a breach of intellectual property rights, Member States shall provide for the measures, procedures and remedies necessary to ensure the enforcement of the intellectual property rights in full application of Directive 2004/48/EC on the enforcement of intellectual property rights.

Amendment 2805
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 70 - paragraph 1 a (new)
1 a. Where the activities of national competent authorities and bodies notified under the provisions of this Article infringe intellectual property rights, Member States shall provide for the measures, procedures and remedies necessary to ensure the enforcement of intellectual property rights in full application of Directive 2004/48/EC on the enforcement of intellectual property rights.

Amendment 2806
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 70 - paragraph 1 a (new)
1 a. The Commission, the Board, national supervisory authorities, national competent authorities and notified bodies involved in the application of this Regulation shall put in place adequate cybersecurity and organisational measures to protect the security and confidentiality of the information and data obtained in carrying out their tasks and activities.

Amendment 2807
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 70 - paragraph 1 b (new)
1 b. Information and data collected by national competent authorities and notified bodies and referred to in Paragraph 1 shall be:', 'a) collected for specified, explicit and legitimate purposes and not further processed in a way incompatible with those purposes;further processing for archiving purposes in the public interest, for scientific or historical research purposes or for statistical purposes shall not be considered incompatible with the original purposes ("purpose limitation");', 'b) adequate, relevant and limited to what is necessary in relation to the purposes for which they are processed (‘data minimisation’);

Amendment 2808
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 70 - paragraph 2 - introductory part
2. Without prejudice to paragraph 1, information exchanged on a confidential basis between the national competent authorities and between national competent authorities and the Commission shall not be disclosed without the prior consultation of the originating national competent authority and the deployer when high-risk AI systems referred to in points 1, 6 and 7 of Annex III are used by law enforcement, immigration or asylum authorities, when such disclosure would jeopardise public or national security.

Amendment 2809
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 70 - paragraph 2 - introductory part
2. Without prejudice to paragraphs 1 and 1a, information exchanged on a confidential basis among the national supervisory authorities, national competent authorities and the Commission shall not be disclosed without the prior consultation of the originating authority and the user when high-risk AI systems referred to in points 1, 6 and 7 of Annex III are used by law enforcement, immigration or asylum authorities, when such disclosure would jeopardise public and national security interests.

Amendment 2810
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Article 70 - paragraph 4
4. The Commission and Member States may exchange, where necessary and in compliance with trade agreements between the EU and third countries that may apply, confidential information with regulatory authorities of third countries with which they have concluded bilateral or multilateral confidentiality arrangements guaranteeing an adequate level of confidentiality.

Amendment 2811
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 70 - paragraph 4
4. The Commission and Member States may, if consistent with the provisions contained in EU trade agreements with third countries, exchange, where necessary, confidential information with regulatory authorities of third countries with which they have concluded bilateral or multilateral confidentiality arrangements guaranteeing an adequate level of confidentiality.

Amendment 2812
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 70 a (new)
Article 70 a', 'Administrative fines', '1. Each national supervisory authority shall ensure that the imposition of administrative fines pursuant to this Article in respect of infringements of this Regulation shall in each individual case be effective, proportionate and dissuasive.', '2. When deciding whether to impose an administrative fine and deciding on the amount of the administrative fine in each individual case due regard shall be given to the following:', '(a) the nature, gravity and duration of the infringement taking into account the nature, scope or purpose of the processing concerned as well as, where appropriate, the number of affected persons and the level of harm suffered by them;', '(b) the intentional or negligent character of the infringement;', '(c) any action taken by the operator to mitigate the harm suffered by the users or the affected persons;', '(d) the degree of responsibility of the operator taking into account the technical and organisational measures implemented by them;', '(e) any relevant previous infringements by the operator;', '(f) the degree of cooperation with the national supervisory authority, in order to remedy the infringement and mitigate the possible adverse effects of the infringement, including compliance with any of the measures previously ordered by the national supervisory authority with regard to the same subject matter', '(g) the manner in which the infringement became known to the national supervisory authority, in particular whether, and if so to what extent, the operator notified the infringement;', '(h) adherence to approved codes of conduct or approved certification mechanisms; and', '(i) any other aggravating or mitigating factor applicable to the circumstances of the case, such as financial benefits gained, or losses avoided, directly or indirectly, from the infringement.', '3. If an operator, intentionally or negligently, infringes several provisions of this Regulation, the total amount of the administrative fine shall not exceed the amount specified for the gravest infringement.', '4. The non-compliance of the AI system with the prohibition of the artificial intelligence practices referred to in Article 5 shall be subject to administrative fines of up to 50 000 000 or, if the offender is a company, up to 10% of its total worldwide annual turnover for the preceding financial year, whichever is higher.', '5. The non-compliance of the AI system with the requirements laid down in Article10 shall be subject to administrative fines of up to 40 000 000 EUR or, if the offender is company, up to 8 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.', '6. The non-compliance of the AI system with any requirements or obligations under this Regulation, other than those laid down in Articles 5 and 10, shall be subject to administrative fines of up to 30 000 000 EUR or, if the offender is a company, up to 6 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.', '7. The supply of incorrect, incomplete or misleading information to notified bodies and national competent authorities in reply to a request shall be subject to administrative fines of up to 20 000000 EUR or, if the offender is a company, up to 4 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.', '8. Without prejudice to the corrective powers of national supervisory authorities, each Member State may lay down the rules on whether and to what extent administrative fines may be imposed on public authorities and bodies established in that Member State.', '9. The exercise by the national supervisory authority of its powers under this Article shall be subject to appropriate procedural safeguards in accordance with Union and Member State law, including effective judicial remedy and due process.', '10. Where the legal system of the Member State does not provide for administrative fines, this Article may be applied in such a manner that the fine is initiated by the national supervisory authority and imposed by competent national courts, while ensuring that those legal remedies are effective and have an equivalent effect to the administrative fines imposed by national supervisory authorities. In any event, the fines imposed shall be effective, proportionate and dissuasive. Those Member States shall notify to the Commission the provisions of their laws which they adopt pursuant to this paragraph by [3 months after entry into force] and, without delay, any subsequent amendment law or amendment affecting them.

Amendment 2813
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 70 b (new)
Article 70 b', 'Right for removal and injunction', '1. If an AI system infringes this Regulation each natural or legal person affected by said AI system may require the user of this system to stop the use and to remove the infringement.', '2. If further infringements of an AI system are to be feared, each affected natural or legal person may seek a prohibitory injunction.

Amendment 2814
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 71 - paragraph 1
1. In compliance with the terms and conditions laid down in this Regulation, Member States shall lay down the rules on penalties, including administrative fines, applicable to infringements of this Regulation and shall take all measures necessary to ensure that they are properly and effectively implemented. The penalties provided for shall be effective, proportionate, and dissuasive. They shall take into particular account the interests of small-scale providers and start-ups and their economic viability, as well as the extent to which the infringement was intentionally committed and the extent of the harm sustained.

Amendment 2815
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Article 71 - paragraph 1
1. In compliance with the terms and conditions laid down in this Regulation, Member States shall lay down the rules on penalties, including administrative fines, applicable to infringements of this Regulation and shall take all measures necessary to ensure that they are properly and effectively implemented and aligned with the guidelines issued by the Board, as referred to in Article 58 (c) (iii). The penalties provided for shall be effective, proportionate, and dissuasive. They shall take into particular account the interests of small-scale providers and start-up and their economic viability.

Amendment 2816
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 71 - paragraph 1
1. In compliance with the terms and conditions laid down in this Regulation, Member States shall lay down the rules on penalties, including administrative fines, applicable to infringements of this Regulation and shall take all measures necessary to ensure that they are properly and effectively implemented. The penalties provided for shall be effective, proportionate, and dissuasive.

Amendment 2817
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Article 71 - paragraph 1
1. In compliance with the terms and conditions laid down in this Regulation, the Commission in consultation with Member States shall lay down the rules on penalties, including administrative fines, applicable to infringements of this Regulation and in cooperation with Member States shall take all measures necessary to ensure that they are properly and effectively implemented. The penalties provided for shall be effective, proportionate, and dissuasive. They shall take into particular account the size and the interests of SME providers including start-ups and their economic viability.

Amendment 2818
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 71 - paragraph 1
1. In compliance with the terms and conditions laid down in this Regulation, Member States shall lay down the rules on penalties, including administrative fines, applicable to infringements of this Regulation and shall take all measures necessary to ensure that they are properly and effectively implemented and aligned with the guidelines issued by the Board, as referred to in Article 58 (c) (iii). The penalties provided for shall be effective, proportionate, and dissuasive. They shall take into particular account the interests of SMEs and start-up and their economic viability.

Amendment 2819
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 71 - paragraph 1
1. In compliance with the terms and conditions laid down in this Regulation, Member States shall lay down the rules on penalties, applicable to infringements of this Regulation, in particular for infringements which are not subject to administrative fines pursuant to Article70a, and shall take all measures necessary to ensure that they are properly and effectively implemented. The penalties provided for shall be effective, proportionate, and dissuasive.

Amendment 2820
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 71 - paragraph 1
1. In compliance with the terms and conditions laid down in this Regulation, Member States shall lay down the rules on penalties, including administrative fines, applicable to infringements of this Regulation and shall take all measures necessary to ensure that they are properly and effectively implemented. The penalties provided for shall be effective, proportionate, and dissuasive. They shall take into particular account the interests and size of small-scale providers and start-ups and their economic viability.

Amendment 2821
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 71 - paragraph 1
1. In compliance with the terms and conditions laid down in this Regulation, Member States shall lay down the rules on penalties, including administrative fines, applicable to infringements of this Regulation and shall take all measures necessary to ensure that they are properly and effectively implemented. The penalties provided for shall be effective, proportionate, and dissuasive. They shall take into particular account the size and interests of SMEs and start-ups and their economic viability

Amendment 2822
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 71 - paragraph 1 a (new)
1 a. In cases where administrative fines have been imposed under Article 83 of Regulation 2016/679, no further penalties shall be imposed on operators under the AI Act.

Amendment 2823
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Article 71 - paragraph 2
deleted

Amendment 2824
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 71 - paragraph 2
2. The Member States shall notify [by 3 months following the date of entry into force of this Regulation] the Commission and the Board of those rules and of those measures and shall notify it, without delay, of any subsequent amendment affecting them.

Amendment 2825
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 71 - paragraph 2
2. Within [three months following the entry into force of this Regulation], the Member States shall notify the Commission of those rules and of those measures and shall notify it, without delay, of any subsequent amendment affecting them.

Amendment 2826
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 71 - paragraph 2
2. Member States shall notify the Commission of those rules and of those measures and shall notify it, without delay, of any subsequent amendment affecting them.

Amendment 2827
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 71 - paragraph 2
2. The Member States shall without delay notify the Commission of those rules and of those measures and of any subsequent amendment affecting them.

Amendment 2828
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 71 - paragraph 2 a (new)
2 a. The non-compliance of the AI system with the prohibition of the practices referred to in Article 5 shall be subject to administrative fines of up to 50 000 000 EUR or, if the offender is a company, up to 10% of its total worldwide annual turnover for the preceding financial year, whichever is higher.

Amendment 2829
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 71 - paragraph 3
deleted

Amendment 2830
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Article 71 - paragraph 3 - introductory part
3. Non-compliance with the prohibition of the artificial intelligence practices referred to in Article 5 shall be subject to administrative fines of up to 20 000 000 EUR or, if the offender is a company, up to 4 % of its total worldwide annual turnover for the preceding financial year, and in case of SMEs and start-ups, up to 3% of its worldwide annual turnover for the preceding financial year, whichever is higher.', '.

Amendment 2831
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 71 - paragraph 3 - introductory part
3. Non-compliance with the prohibition of the artificial intelligence practices referred to in Article 5 shall be subject to administrative fines of up to 30 000 000 EUR or, if the offender is a company, up to 6 % of its total worldwide annual turnover for the preceding financial year, whichever is higher;

Amendment 2832
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 71 - paragraph 3 - introductory part
3. The non-compliance of the AI system with the requirements laid down in Article 10 shall be subject to administrative fines of up to 40 000 000 EUR or, if the offender is a company, up to 8 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.

Amendment 2833
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 71 - paragraph 3 - introductory part
3. Non-compliance with the prohibition of the AI practices referred to in Article 5 shall be subject to administrative fines of up to 20 000 000 EUR or, if the offender is a company, up to 4% of its total worldwide annual turnover for the preceding financial year, whichever is higher.

Amendment 2834
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 71 - paragraph 3 - introductory part
3. The following infringements shall be subject to administrative fines of up to 1 000 000 000 EUR or, if the offender is a company, up to 10 % of its total worldwide annual turnover for the preceding financial year, whichever is higher:

Amendment 2835
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 71 - paragraph 3 - introductory part
3. The following infringements shall be subject to administrative fines of up to 30 000 000 EUR or, if the offender is a company, up to 10 % of its total worldwide annual turnover for the preceding financial year, whichever is higher:

Amendment 2836
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 71 - paragraph 3 - point a
deleted

Amendment 2837
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 71 - paragraph 3 - point a
deleted

Amendment 2838
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Article 71 - paragraph 3 - point a
deleted

Amendment 2839
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 71 - paragraph 3 - point a
deleted

Amendment 2840
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Article 71 - paragraph 3 - point b
deleted

Amendment 2841
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 71 - paragraph 3 - point b
deleted

Amendment 2842
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 71 - paragraph 3 - point b
deleted

Amendment 2843
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 71 - paragraph 3 - point b
deleted

Amendment 2844
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 71 - paragraph 3 - point b
deleted

Amendment 2845
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 71 - paragraph 3 a (new)
3 a. Non-compliance of the AI system with the requirements laid down in Article 10 shall be subject to administrative fines of up to 20 000 000 EUR or, if the offender is a company, up to 4 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.

Amendment 2846
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 71 - paragraph 4
deleted

Amendment 2847
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 71 - paragraph 4
4. The grossly negligent non-compliance by the provider or user of the AI system with the respective requirements or obligations under this Regulation, other than those laid down in Articles 5, shall be subject to administrative fines of up to 10 000 000 EUR or, if the offender is a company, up to 2 % of its total worldwide annual turnover for the preceding financial year, whichever is higher, and in case of SMEs and start-ups, up to 1% of its worldwide annual turnover for the preceding financial year, whichever is higher.

Amendment 2848
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Article 71 - paragraph 4
4. The grossly negligent non-compliance by the provider or the user of the AIs ystem with any requirements or obligations under this Regulation, other than those laid down in Article 5, shall be subject to administrative fines of up to 10 000 000 EUR or, if the offender is a company, up to 2 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.

Amendment 2849
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 71 - paragraph 4
4. The non-compliance of the AI system with any requirements or obligations under this Regulation, other than those laid down in Articles 5 and 10, shall be subject to administrative fines of up to 30 000 000 EUR or, if the offender is a company, up to 6 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.

Amendment 2850
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 71 - paragraph 4
4. The non-compliance of the AI system with any requirements or obligations under this Regulation, other than those laid down in Articles 5 and 10, shall be subject to administrative fines of up to 20 000 000 EUR or, if the offender is a company, up to 7 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.

Amendment 2851
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 71 - paragraph 4
4. The non-compliance of the AI system with any requirements or obligations under this Regulation, other than those laid down in Articles 5 and 10, shall be subject to administrative fines of up to 20 000 000 EUR or, if the offender is a company, up to 6 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.

Amendment 2852
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 71 - paragraph 4
4. The non-compliance of the AI system with any requirements or obligations under this Regulation, other than those laid down in Articles 5 and 10, shall be subject to administrative fines of up to 1 000 000 EUR or, if the offender is a company, up to 1 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.

Amendment 2853
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 71 - paragraph 4
4. Non-compliance of the AI system with any requirements or obligations under this Regulation, other than those laid down in Articles 5 and 10, shall be subject to administrative fines of up to 10 000 000 EUR or, if the offender is a company, up to 2 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.

Amendment 2854
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 71 - paragraph 5
deleted

Amendment 2855
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 71 - paragraph 5
5. The supply of incorrect, incomplete or misleading information to notified bodies and national competent authorities in reply to a request shall be subject to administrative fines of up to 10 000 000 EUR or, if the offender is a company, up to 2 % of its total worldwide annual turnover for the preceding financial year, whichever is higher and in case of SMEs and start-ups, up to 1% of its worldwide annual turnover for the preceding financial year, whichever is higher.

Amendment 2856
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 71 - paragraph 5
5. The supply of incorrect, incomplete or misleading information to notified bodies and national competent authorities in reply to a request shall be subject to administrative fines of up to 10 000 000 EUR or, if the offender is a company, up to 4 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.

Amendment 2857
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 71 - paragraph 5
5. The supply of incorrect, incomplete or misleading information to notified bodies and national competent authorities in reply to a request shall be subject to administrative fines of up to 10 000 000 EUR or, if the offender is a company, up to 4 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.

Amendment 2858
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 71 - paragraph 5
5. The supply of incorrect, incomplete or misleading information to notified bodies and national competent authorities in reply to a request shall be subject to administrative fines of up to 20 000 000 EUR or, if the offender is a company, up to 4 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.

Amendment 2859
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 71 - paragraph 5
5. The supply of incorrect or misleading information to notified bodies and national competent authorities in reply to a request shall be subject to administrative fines of up to 1 000 000 EUR or, if the offender is a company, up to 1 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.

Amendment 2860
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 71 - paragraph 5 a (new)
5 a. Where trade secrets, intellectual property rights or data protection rights have been infringed in the development of an AI system, competent authorities may order the definitive deletion of that system and all associated training data and outputs.

Amendment 2861
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 71 - paragraph 6
deleted

Amendment 2862
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 71 - paragraph 6 - introductory part
6. Fines may be imposed in addition to or instead of non-monetary measures such as orders or warnings. When deciding on whether to impose a fine or on the amount of the administrative fine in each individual case, all relevant circumstances of the specific situation shall be taken into account and due regard shall be given to the following:

Amendment 2863
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 71 - paragraph 6 - point a
(a) the nature, gravity and duration of the infringement and of its consequences taking into account the nature, scope or purpose of the AI system concerned, as well as the number of individuals affected, and the level of damage suffered by them;

Amendment 2864
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 71 - paragraph 6 - point b
(b) whether administrative fines have been already applied by other market surveillance authorities of one or more Member States to the same operator for the same infringement.

Amendment 2865
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 71 - paragraph 6 - point c
deleted

Amendment 2866
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 71 - paragraph 6 - point c
(c) the size, the annual turnover and market share of the operator committing the infringement;

Amendment 2867
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 71 - paragraph 6 - point c
(c) the size, the annual turnover and market share of the operator committing the infringement;

Amendment 2868
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 71 - paragraph 6 - point c a (new)
(c a) any action taken by the provider to mitigate the harm or damage suffered by the affected persons;

Amendment 2869
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 71 - paragraph 6 - point c a (new)
(c a) the intentional or negligent character of the infringement;

Amendment 2870
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 71 - paragraph 6 - point c c (new)
(c c) the degree of cooperation with the national competent authorities, in order to remedy the infringement and mitigate the possible adverse effects of the infringement;

Amendment 2871
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 71 - paragraph 6 - point c e (new)
(c c) any relevant previous infringements by the provider;

Amendment 2872
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 71 - paragraph 6 - point c e (new)
(c e) any other aggravating or mitigating factor applicable to the circumstances of the case, such as financial benefits gained, or losses avoided, directly or indirectly, from the infringement;

Amendment 2873
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 71 - paragraph 6 - point c e (new)
(c e) the manner in which the infringement became known to the national competent authority, in particular whether, and if so to what extent, the provider notified the infringement;

Amendment 2874
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 71 - paragraph 6 - point c g (new)
(c g) in the context of paragraph 5 of this Article, the intentional or unintentional nature of the infringement.

Amendment 2875
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 71 - paragraph 7
deleted

Amendment 2876
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 71 - paragraph 7
7. Each Member State shall lay down rules on administrative fines to be imposed on public authorities and bodies established in that Member State, with a view to ensure compliance with this Regulation.

Amendment 2877
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 71 - paragraph 8
deleted

Amendment 2878
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
René Repasi, Marc Angel, Andreas Schieder, Maria-Manuel Leitão-Marques
Article 71 - paragraph 8
8. Depending on the legal system of the Member States, the rules on administrative fines may be applied in such a manner that the fines are imposed by competent national courts of other bodies as applicable in those Member States. The application of such rules in those Member States shall have an equivalent effect. In any event, the fines imposed shall be effective, proportionate and dissuasive.

Amendment 2879
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
René Repasi, Marc Angel, Andreas Schieder, Maria-Manuel Leitão-Marques
Article 71 - paragraph 8 a (new)
8 a. In respect of adopting administrative fines and of deciding on the amount of the administrative fine the procedure as set out in Article 68a, paragraphs 2 to 6, applies mutatis mutandis.

Amendment 2880
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 71 - paragraph 8 a (new)
8 a. Administrative fines shall not be applied to a participant in a regulatory sandbox, who was acting in line with the recommendation issued by the supervisory authority.

Amendment 2881
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 71 - paragraph 8 a (new)
8 a. Administrative fines shall not be applied to a participant in a regulatory sandbox, who was acting in line with the recommendation issued by the supervisory authority;

Amendment 2882
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Article 71 - paragraph 8 b (new)
8 b. The penalties referred to in this article as well as the associated litigation costs and indemnification claims may not be the subject of contractual clauses or other form of burden-sharing agreements between the providers and distributors, importers, users, or any other third-parties.

Amendment 2883
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 71 - paragraph 8 c (new)
8 c. The exercise by the market surveillance authority of its powers under this Article shall be subject to appropriate procedural safeguards in accordance with Union and Member State law, including effective judicial remedy and due process.

Amendment 2884
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Article 72 - paragraph 1 - point a
1. The European Data Protection Supervisor may impose administrative fines on Union institutions, agencies and bodies developing, deploying or operating AI systems. When deciding whether to impose an administrative fine and deciding on the amount of the administrative fine in each individual case, all relevant circumstances of the specific situation shall be taken into account and due regard shall be given to the following:

Amendment 2885
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 72 - paragraph 1 - point a
(a) the nature, gravity and duration of the infringement and of its consequences, including to affected persons;

Amendment 2886
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 72 - paragraph 1 - point a a (new)
(a a) any action taken by the Union institution, agency or body to mitigate the harm;

Amendment 2887
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 72 - paragraph 1 - point a a (new)
(a a) the intentional or negligent character of the infringement;

Amendment 2888
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 72 - paragraph 1 - point a b (new)
(a b) any relevant previous infringement;

Amendment 2889
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte
Article 72 - paragraph 1 - point b
deleted

Amendment 2890
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 72 - paragraph 1 - point b a (new)
(b a) the degree of cooperation with the supervisory authority, in order to remedy the infringement and mitigate the possible adverse effects of the infringement;

Amendment 2891
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 72 - paragraph 1 - point b b (new)
(b b) any action taken by the provider to mitigate the damage suffered by subjects;

Amendment 2892
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 72 - paragraph 1 - point c a (new)
(c a) the manner in which the infringement became known to the European Data Protection Supervisor, in particular whether, and if so, to what extent, the Union institution, agency or body notified the infringement.

Amendment 2893
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 72 - paragraph 1 - point c a (new)
(c a) any other aggravating or mitigating factor applicable to the circumstances of the case, such as financial benefits gained, or losses avoided, directly or indirectly, from the infringement.

Amendment 2894
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 72 - paragraph 2 - introductory part
2. The non-compliance with the prohibition of the artificial intelligence practices referred to in Article 5 shall be subject to administrative fines of up to 1 000 000 EUR;', '2a. The non-compliance of the AI system with the requirements laid down in Article 10 shall be subject to administrative fines of up to 700 000 EUR.

Amendment 2895
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 72 - paragraph 2 - introductory part
2. Non-compliance with the prohibition of the artificial intelligence practices referred to in Article 5 shall be subject to administrative fines of up to 1.000 000 EUR;

Amendment 2896
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 72 - paragraph 2 - introductory part
2. The non-compliance with the prohibition of the artificial intelligence practices referred to in Article 5 shall be subject to administrative fines of up to 1 000 000 EUR:

Amendment 2897
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 72 - paragraph 2 - introductory part
2. The following infringements shall be subject to administrative fines of up to 30 000 000 EUR:

Amendment 2898
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 72 - paragraph 2 - introductory part
2. The following infringements shall be subject to administrative fines of up to 5 000 000 EUR:

Amendment 2899
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 72 - paragraph 2 - point a
deleted

Amendment 2900
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 72 - paragraph 2 - point a
deleted

Amendment 2901
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 72 - paragraph 2 - point a
deleted

Amendment 2902
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 72 - paragraph 2 - point b
deleted

Amendment 2903
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 72 - paragraph 2 - point b
deleted

Amendment 2904
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 72 - paragraph 2 - point b
deleted

Amendment 2905
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 72 - paragraph 2 a (new)
2 a. The non-compliance of the AI system with the requirements laid down in Article 10 shall be subject to administrative fines of up to 700 000 EUR.

Amendment 2906
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 72 - paragraph 2 a (new)
2 a. non-compliance of the AI system with the requirements laid down in Article 10 shall be subject to administrative fines of up to 500 000 EUR.

Amendment 2907
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 72 - paragraph 3
3. The non-compliance of the AI system with any requirements or obligations under this Regulation, other than those laid down in Articles 5 and 10, shall be subject to administrative fines of up to 20 000 000 EUR.

Amendment 2908
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Article 72 - paragraph 3
3. The non-compliance of the AI system with any requirements or obligations under this Regulation, other than those laid down in Articles 5 and 10, shall be subject to administrative fines of up to 2 500 000 EUR.

Amendment 2909
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 72 - paragraph 3
3. The non-compliance of the AI system with any requirements or obligations under this Regulation, other than those laid down in Articles 5 and 10, shall be subject to administrative fines of up to 500 000 EUR.

Amendment 2910
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 72 - paragraph 3
3. The non-compliance of the AI system with any requirements or obligations under this Regulation, other than those laid down in Articles 5 and 10, shall be subject to administrative fines of up to 300 000 EUR.

Amendment 2911
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 72 - paragraph 3
3. The non-compliance of the AI system with any requirements or obligations under this Regulation, other than those laid down in Articles 5 and 10, shall be subject to administrative fines of up to 500 000 EUR.

Amendment 2912
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 72 - paragraph 5
5. The rights of defense of the parties concerned shall be fully respected in the proceedings. They shall be entitled to have access to the European Data Protection Supervisor’s file, subject to the legitimate interest of individuals or undertakings in the protection of their personal data.

Amendment 2913
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 72 - paragraph 5
5. The rights of defense of the parties concerned shall be fully respected in the proceedings. They shall be entitled to have access to the European Data Protection Supervisor’s file, subject to the legitimate interest of individuals or undertakings in the protection of their personal data.

Amendment 2914
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte
Article 72 - paragraph 6
deleted

Amendment 2915
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 72 - paragraph 6 a (new)
6. Funds collected by imposition of fines in this Article shall contribute to the general budget of the Union.

Amendment 2916
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 72 - paragraph 6 a (new)
6 a. The European Data Protection Supervisor shall, on an annual basis, notify the Board of the fines it has imposed pursuant to this Article.

Amendment 2917
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 73 - paragraph 2
2. The delegation of power referred to in Article 7(1), Article 11(3), Article 43(5), Article 48(5) and Article 68a shall be conferred on the Commission for an indeterminate period of time from [entering into force of the Regulation].

Amendment 2918
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 73 - paragraph 2
2. The delegation of power referred to in Article 4, Article 5a, Article 7(1), Article 11(3), Article 43(5) and (6), Article 48(5) and Article 52a shall be conferred on the Commission for an indeterminate period of time from [entering into force of the Regulation].

Amendment 2919
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 73 - paragraph 2
2. The delegation of power referred to in Article 4 and Article 48(5) shall be conferred on the Commission for an indeterminate period of time from [entering into force of the Regulation].

Amendment 2920
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 73 - paragraph 2 a (new)
2 a. The delegation of power referred to in Article 4, Article 7(1), Article 11(3), Article 43(5) and (6) and Article 48(5) shall undergo due process, be proportionate and be based on a permanent and institutionalised exchange with the relevant stakeholders as well as the Board and the High Level Expert Group on AI.

Amendment 2921
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 73 - paragraph 3
3. The delegation of power referred to in Article 7(1), Article 11(3), Article 43(5), Article 48(5) and Article 68a may be revoked at any time by the European Parliament or by the Council. A decision of revocation shall put an end to the delegation of power specified in that decision. It shall take effect the day following that of its publication in the Official Journal of the European Union or at a later date specified therein. It shall not affect the validity of any delegated acts already in force.

Amendment 2922
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 73 - paragraph 3
3. The delegation of power referred to in Article 4, Article 5a, Article 7(1), Article 11(3), Article 43(5) and (6), Article 48(5) and Article 52a may be revoked at any time by a joint decision from the European Parliament and the Council.. A decision of revocation shall put an end to the delegation of power specified in that decision. It shall take effect the day following that of its publication in the Official Journal of the European Union or at a later date specified therein. It shall not affect the validity of any delegated acts already in force.

Amendment 2923
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 73 - paragraph 3
3. The delegation of power referred to in Article 4 and Article 48(5) may be revoked at any time by the European Parliament or by the Council. A decision of revocation shall put an end to the delegation of power specified in that decision. It shall take effect the day following that of its publication in the Official Journal of the European Union or at a later date specified therein. It shall not affect the validity of any delegated acts already in force.

Amendment 2924
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 73 - paragraph 3 a (new)
3 a. Before adopting a delegated act, the Commission shall consult with the relevant institutions and stakeholders in accordance with the principles laid down in the Interinstitutional Agreement of 13 April 2016 on Better Law-Making.

Amendment 2925
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 73 - paragraph 3 a (new)
3 a. Prior to adopting a delegated act pursuant to Article 4, Article 7(1), Article 11(3), Article 43(5) and (6), and Article48(5) the Commission shall consult the AI Office.

Amendment 2926
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 73 - paragraph 3 b (new)
3 b. Delegated acts that lead to the modification or the addition of obligations on operators shall foresee an adequate transition period of no less than 24 months before their entry into force.

Amendment 2927
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 73 - paragraph 4
4. Once the Commission decides to draft a delegated act, it shall notify the European Parliament of this fact. This notification does not place an obligation on the Commission to adopt the said act. I As soon as it adopts a delegated act, the Commission shall notify it simultaneously to the European Parliament and to the Council.

Amendment 2928
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 73 - paragraph 4
4. As soon as it adopts a delegated act, the Commission shall notify it simultaneously to the European Parliament, the Council, and the AI Office.

Amendment 2929
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 73 - paragraph 4
4. In preparation of a delegated act, the Commission shall notify it simultaneously to the European Parliament and to the Council.

Amendment 2930
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 73 - paragraph 5
5. Any delegated act adopted pursuant to Article 4, Article 5a, Article 7(1), Article 11(3), Article43(5) and (6), Article 48(5) and Article 52a shall enter into force only if no objection has been expressed by either the European Parliament or the Council within a period of three months of notification of that act to the European Parliament and the Council or if, before the expiry of that period, the European Parliament and the Council have both informed the Commission that they will not object. That period shall be extended by three months at the initiative of the European Parliament or of the Council.

Amendment 2931
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 73 - paragraph 5
5. Any delegated act adopted pursuant to Article 4 and Article 48(5) shall enter into force only if no objection has been expressed by either the European Parliament or the Council within a period of three months of notification of that act to the European Parliament and the Council or if, before the expiry of that period, the European Parliament and the Council have both informed the Commission that they will not object. That period shall be extended by three months at the initiative of the European Parliament or of the Council.

Amendment 2932
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 73 - paragraph 5
5. Any delegated act adopted pursuant to Article 7(1), Article 11(3), Article 43(5), Article 48(5) and 68d shall enter into force only if no objection has been expressed by either the European Parliament or the Council within a period of three months of notification of that act to the European Parliament and the Council or if, before the expiry of that period, the European Parliament and the Council have both informed the Commission that they will not object. That period shall be extended by three months at the initiative of the European Parliament or of the Council.

Amendment 2933
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 80 - paragraph 1 - introductory part
In Article 5 of Regulation (EU) 2018/858 the following paragraphs are added:

Amendment 2934
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 80 - paragraph 1 - introductory part
In Article 5 of Regulation (EU) 2018/858 the following paragraphs are added:

Amendment 2935
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 80 - paragraph 1
4 a. The Commission shall, prior to fulfilling the obligation pursuant to paragraph 4, provide a reasonable explanation based on a gap analysis of existing sectoral legislation in the automotive sector to determine the existence of potential gaps relating to Artificial Intelligence therein, and consult relevant stakeholders, in order to avoid duplications and overregulation, in line with the Better Regulation principles.

Amendment 2936
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 80 - paragraph 1
4 a. The Commission shall, prior to fulfilling the obligation pursuant to paragraph 4, provide a reasonable explanation based on a gap analysis of existing sectoral legislation in the automative sector to determine the existence of potential gaps relating to Artifical Intelligence therein, and consult relevant stakeholders, in order to avoid duplications and overregulation, in line with the Better Regulation principle.

Amendment 2937
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 81 a (new)
Article 81 a', 'Amendment to Regulation (EU) 2019/1020', 'In Article 14.4 of Regulation (EU) 2019/1020 the following paragraph is added:', '“(l) The power to implement the powers provided for in this Article remotely, where applicable.”

Amendment 2938
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 82 - paragraph 1 - introductory part
In Article 11 of Regulation (EU) 2019/2144, the following paragraphs are added:

Amendment 2939
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 82 - paragraph 1 - introductory part
In Article 11 of Regulation(EU) 2019/2144, the following paragraphs are added:

Amendment 2940
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 82 - paragraph 1
3 a. The Commission shall, prior to fulfilling the obligation pursuant to paragraph 3, provide a reasonable explanation based on a gap analysis of existing sectoral legislation in the automotive sector to determine the existence of potential gaps relating to Artificial Intelligence therein, and consult relevant stakeholders, in order to avoid duplications and overregulation, in line with the Better Regulation principles.

Amendment 2941
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 82 - paragraph 1
3 a. The Commission shall, prior to fulfilling the obligation pursuant to paragraph 3, provide a reasonable explanation based on a gap analysis of existing sectoral legislation in the automative sector to determine the existence of potential gaps relating to Artifical Intelligence therein, and consult relevant stakeholders, in order to avoid duplications and overregulation, in line with the Better Regulation principle.

Amendment 2942
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 82 a (new)
Article 82 a', 'Sound regulation', 'In taking into account the requirements of this Regulation pursuant to the Amendments in Articles 75, 76, 77, 78, 79, 80, 81, and 82, the Commission shall conduct an analysis and consult relevant stakeholders to determine potential gaps as well as overlaps between existing sectoral legislation and the provisions of this Regulation in order to avoid duplication, overregulation, and the creation of loopholes.

Amendment 2943
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 83
deleted

Amendment 2944
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 83 - paragraph 1 - introductory part
1. This Regulation shall apply to the AI systems which are components of the large-scale IT systems established by the legal acts listed in Annex IX that have been placed on the market or put into service before [12 months after the date of application of this Regulation referred to in Article 85(2)].

Amendment 2945
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 83 - paragraph 1 - introductory part
1. This Regulation shall apply to the AI systems which are components of the large-scale IT systems established by the legal acts listed in Annex IX that have been placed on the market or put into service before, with a transitional period of two years after the entry into force of this Regulation.

Amendment 2946
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 83 - paragraph 1 - introductory part
1. Operators of the AI systems which are components of the large-scale IT systems established by the legal acts listed in Annex IX that have been placed on the market or put into service before [the date of application of this Regulation referred to in Article 85(2)] shall take the necessary steps to comply with the requirements of the present Regulation within 4 years of its entry into force.

Amendment 2947
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 83 - paragraph 1 - introductory part
1. This Regulation shall apply to the AI systems which are components of the large-scale IT systems established by the legal acts listed in Annex IX that have been placed on the market or put into service before [12 months after the date of application of this Regulation referred to in Article 85(2)] and the requirements laid down in this Regulation shall be taken into account in the evaluation of each large-scale IT systems established by the legal acts listed in Annex IX.

Amendment 2948
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 83 - paragraph 1 - introductory part
1. This Regulation shall apply to the AI systems which are components of the large-scale IT systems established by the legal acts listed in Annex IX starting [ on the date of application of this Regulation referred to in Article 85(2)], or as soon as there is a significant change in the design or intended purpose of the AI system or AI systems concerned in which case it shall apply from [the date of application of this Regulation]

Amendment 2949
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 83 - paragraph 1 - introductory part
1. This Regulation shall not apply to the AI systems which are components of the large-scale IT systems established by the legal acts listed in Annex IX that have been placed on the market or put into service before [24 months after the date of application of this Regulation referred to in Article 85(2)], unless the replacement or amendment of those legal acts leads to a significant change in the design or intended purpose of the AI system or AI systems concerned.

Amendment 2950
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka, Róża Thun und Hohenstein
Article 83 - paragraph 1 - subparagraph 1
deleted

Amendment 2951
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 83 - paragraph 1 - subparagraph 1
deleted

Amendment 2952
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 83 - paragraph 1 - subparagraph 1
The requirements laid down in this Regulation shall be taken into account, where applicable, in the evaluation of each large-scale IT systems established by the legal acts listed in Annex IX to be undertaken as provided for in those respective acts and whenever those legal acts are replaced or amended.

Amendment 2953
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 83 - paragraph 1 - subparagraph 1
The requirements laid down in this Regulation shall apply in the evaluation of each large-scale IT systems established by the legal acts listed in Annex IX to be undertaken as provided for in those respective acts.

Amendment 2954
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 83 - paragraph 1 - subparagraph 1
The requirements laid down in this Regulation shall be taken into account in the evaluation of each large-scale IT systems established by the legal acts listed in Annex IX to be undertaken as provided for in those respective acts.

Amendment 2955
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 83 - paragraph 2
2. This Regulation shall apply to the high-risk AI systems, other than the ones referred to in paragraph 1, that have been placed on the market or put into service before [date of application of this Regulation referred to in Article 85(2)], only if, from that date, those systems are subject to significant changes as defined in Article 3(23) in their design or intended purpose, and those changes are not needed to comply with applicable existing or new legislation, or to provide security fixes.

Amendment 2956
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 83 - paragraph 2
2. This Regulation shall apply to the high-risk AI systems that have been placed on the market or put into service before [date of application of this Regulation referred to in Article 85(2)].

Amendment 2957
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 83 - paragraph 2
2. Operators of high-risk AI systems, other than the ones referred to in paragraph 1, that have been placed on the market or put into service before [date of application of this Regulation referred to in Article 85(2)] shall take the necessary steps to comply with the requirements of the present Regulation within 2 years of its entry into force or at the time when such systems are subject to a substantial modification in their design or intended purpose.

Amendment 2958
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Article 83 - paragraph 2
2. This Regulation shall apply to the high-risk AI systems, other than the ones referred to in paragraph 1, that have been placed on the market or put into service before [date of application of this Regulation referred to in Article 85(2)].

Amendment 2959
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 83 - paragraph 2
2. This Regulation shall apply to the high-risk AI systems, other than the ones referred to in paragraph 1, that have been placed on the market or put into service from [date of application of this Regulation referred to in Article 85(2)].

Amendment 2960
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 83 - paragraph 2
2. This Regulation shall apply to the high-risk AI systems, other than the ones referred to in paragraph 1, that have been placed on the market or put into service before [date of application of this Regulation referred to in Article 85(2)].

Amendment 2961
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka, Róża Thun und Hohenstein
Article 83 - paragraph 2
2. This Regulation shall apply to the high-risk AI systems that have been placed on the market or put into service before [date of application of this Regulation referred to in Article 85(2)], with a transitional period of two years after the application of this Regulation.

Amendment 2962
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 83 - paragraph 2
2. This Regulation shall apply to the high-risk AI systems, other than the ones referred to in paragraph 1, that have been placed on the market or put into service before [date of application of this Regulation referred to in Article 85(2)], only if, from that date, those systems are subject to substantial modification in their design or intended purpose as defined in Article 3(23) .

Amendment 2963
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 83 a (new)
Article 83 a', 'AI systems deployed in the context of employment', "Member States may, by law or by collective agreements, decide to prohibit or limit the use of certain AI systems in the employment context or provide for more specific rules for AI systems in employment, in particular for the purposes of the recruitment, the performance of the contract of employment, including discharge of obligations laid down by law or by collective agreements, management, planning and organisation of work, equality and diversity in the workplace, health and safety at work, protection of employer's or customer's property and for the purposes of the exercise and enjoyment, on an individual or collective basis, of rights and benefits related to employment, and for the purpose of the termination of the employment relationship.

Amendment 2964
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 84 - paragraph 1
1. The Commission shall assess the need for amendment of the list in Annex III, including the extension of existing area headings or addition of new area headings; ,Article 5’s list of prohibited AI practices, and Article 52’s list of AI systems requiring additional transparency measures, once a year following the entry into force of this Regulation.

Amendment 2965
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 84 - paragraph 1
1. The Commission shall assess the need for amendment of the list in Annex III, including the extension of existing area headings or addition of new area headings, the list of prohibited practices in Article 5, and the list of AI systems requiring additional transparency measures, once a year following the entry into force of this Regulation.

Amendment 2966
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 84 - paragraph 1
1. The Commission shall assess the need for amendment of the list in Annex III every 24 months following the entry into force of this Regulation and until the end of the period of the delegation of power. The findings of that assessment shall be presented to the European Parliament and the Council.

Amendment 2967
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 84 - paragraph 1
1. The Commission shall assess the need for amendment of the list in Annex III once a year following the entry into force of this Regulation, and when necessary, table to the European Parliament and the Council a legislative proposal in this regard.

Amendment 2968
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 84 - paragraph 1
1. The Commission shall assess the need for amendment of the list in Annex I once a year following the entry into force of this Regulation. The findings of that assessment shall be presented to the European Parliament and the Council.

Amendment 2969
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 84 - paragraph 1
1. The Commission shall assess the need for amendment of the list in Annex III , including the extension of existing area headings or addition of new area headings, once a year following the entry into force of this Regulation.

Amendment 2970
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 84 - paragraph 1
1. In consultation with the AI Office, the Commissions shall assess the need for amendment of the list in Annex III once a year following the entry into force of this Regulation.

Amendment 2971
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 84 - paragraph 1
1. The Commission shall assess the need for amendment of the list in Annex III annually following the entry into force of this Regulation and following a recommendation of the Board.

Amendment 2972
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 84 - paragraph 1 a (new)
1 a. The Commission shall assess the need for amendment of the list in Annex III once a year following the entry into force of this Regulation. The findings of that assessment shall be presented to the European Parliament and the Council.

Amendment 2973
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Article 84 - paragraph 2
2. By [two years after the date of application of this Regulation referred to in Article 85(2)] and every three years thereafter, the Commission shall submit a report on the evaluation and review of this Regulation to the European Parliament and to the Council. The reports shall be made public.

Amendment 2974
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Article 84 - paragraph 3 - point a
(a) the status of the financial, technical and human resources of the national competent authorities in order to effectively perform the tasks assigned to them under this Regulation;

Amendment 2975
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Article 84 - paragraph 3 - point b
(b) the state of penalties, and notably administrative fines as referred to in Articles 70a and 71 applied by national supervisory authoritites and Member States to infringements of the provisions of this Regulation.

Amendment 2976
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 84 - paragraph 3 - point b
(b) the state of penalties, and notably administrative fines as referred to in Article 71, applied by Member States to infringements of the provisions of this Regulation.

Amendment 2977
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 84 - paragraph 3 - point b a (new)
(b a) the state of the development of harmonised standards and common specifications for Artificial Intelligence;

Amendment 2978
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 84 - paragraph 3 - point b a (new)
(b a) the levels of investments in research, development and application of AI systems throughout the Union,

Amendment 2979
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 84 - paragraph 3 - point b b (new)
(b b) the competitiveness of the aggregated European AI ecosystem compared to AI ecosystems in third countries.

Amendment 2980
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 84 - paragraph 3 a (new)
3 a. Within [two years after the date of application of this Regulation referred to in Article 85(2)] and every two years thereafter, the Commission shall evaluate the impact and effectiveness of the Regulation with regards to the resource and energy use, waste production and other environmental impact of AI systems and evaluate the need for proposing legislation to regulate the resource and energy efficiency of AI systems and related ICT systems in order for the sector to contribute to EU climate strategy and targets.

Amendment 2981
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 84 - paragraph 4
4. Within [one year after the date of application of this Regulation referred to in Article 85(2)] and every two years thereafter, the Commission shall evaluate the impact and effectiveness of codes of conduct to foster the application of the requirements set out in Title III, Chapter 2 and possibly other additional requirements for AI systems other than high-risk AI systems.

Amendment 2982
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 84 - paragraph 5
5. For the purpose of paragraphs 1 to 4 the Board, the Member States and national competent authorities shall provide the Commission with information on its request without undue delay.

Amendment 2983
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 84 - paragraph 5
5. For the purpose of paragraphs 1 to 4 the AI Office, the Member States and national competent authorities shall provide the Commission with information on its request.

Amendment 2984
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 84 - paragraph 6
6. In carrying out the evaluations and reviews referred to in paragraphs 1 to 4 the Commission shall take into account the positions and findings of the Board, of the European Parliament, of the Council, and of equality bodies and other relevant bodies or sources, and shall consult relevant external stakeholders, in particular those potentially affected by the AI system, as well as stakeholders from academia and civil society.

Amendment 2985
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 84 - paragraph 6
6. In carrying out the evaluations and reviews referred to in paragraphs 1 to 4 the Commission shall take into account the positions and findings of the Board, of the European Parliament, of the Council, and of equality bodies and other relevant bodies or sources, and shall consult relevant external stakeholders, in particular those potentially affected by the AI system, as well as stakeholders from academia and civil society.

Amendment 2986
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Article 84 - paragraph 6
6. In carrying out the evaluations and reviews referred to in paragraphs 1 to 4 the Commission shall take into account the positions and findings of the Board, of the European Parliament, of the Council, and of other relevant bodies or sources, including stakeholders, and in particular civil society.

Amendment 2987
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 84 - paragraph 6
6. In carrying out the evaluations and reviews referred to in paragraphs 1 to 4 the Commission shall take into account the positions and findings of the Board, of the European Parliament, of the Council, and of other relevant bodies or sources, including from academia and civil society.

Amendment 2988
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 84 - paragraph 6
6. In carrying out the evaluations and reviews referred to in paragraphs 1 to 4 the Commission shall take into account the positions and findings of the Board, of the European Parliament, of the Council, and of other relevant bodies or sources, which shall be attached to the report.

Amendment 2989
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Article 84 - paragraph 6
6. In carrying out the evaluations and reviews referred to in paragraphs 1 to 4 the Commission shall take into account the positions and findings of the AI Office, of the European Parliament, of the Council, and of other relevant bodies or sources.

Amendment 2990
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 84 - paragraph 7
7. The Commission shall, if necessary, submit appropriate proposals to amend this Regulation, in particular taking into account developments in technology, the effect of AI systems on health and safety, fundamental rights, the environment, equality, and accessibility for persons with disabilities, and in the light of the state of progress in the information society.

Amendment 2991
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 84 - paragraph 7
7. The Commission shall, if necessary, submit appropriate proposals to amend this Regulation, in particular taking into account developments in technology, the effect of AI systems on health and safety, fundamental rights, equality, and accessibility for persons with disabilities, and in the light of the state of progress in the information society.

Amendment 2992
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 84 - paragraph 7
7. The Commission shall, if necessary, submit appropriate proposals to amend this Regulation, in particular taking into account the effect of AI systems on fundamental rights, equality, and accessibility for persons with disabilities, developments in technology and in the light of the state of progress in the information society.

Amendment 2993
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Article 84 - paragraph 7
7. The Commission shall, if necessary, submit appropriate proposals to amend this Regulation, in particular taking into account developments in technology and new potential or realised risks to fundamental rights, and in the light of the state of progress in the information society.

Amendment 2994
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Article 84 - paragraph 7
7. The Commission shall, if necessary, submit appropriate proposals to amend this Regulation, in particular taking into account the impact of this Regulation on fundamental rights, developments in technology and in the light of the state of progress in the information society.

Amendment 2995
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 84 - paragraph 7 a (new)
7 a. By three years from the date of application of this Regulation at the latest, the Commission shall carry out an assessment of the enforcement of this Regulation and shall report it to the European Parliament, the Council and the European Economic and Social Committee, taking into account the first years of application of the Regulation. On the basis of the findings that report shall, where appropriate, be accompanied by a proposal for amendment of this Regulation with regard to the structure of enforcement and the need for an EU agency to resolve any identified shortcomings.

Amendment 2996
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Article 84 - paragraph 7 a (new)
7 a. To guide the evaluations and reviews referred to in paragraphs 1 to 4, the Board shall undertake to develop an objective and participative methodology for the evaluation of risk level based on the criteria outlined in the relevant articles and inclusion of new systems in: the list in Annex III, including the extension of existing area headings or addition of new area headings; Article 5’s list of prohibited AI practices; and Article 52’s list of AI systems requiring additional transparency measures.

Amendment 2997
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Article 84 - paragraph 7 a (new)
7 a. To guide the evaluations and reviews referred to in paragraphs 1 to 4, the Board shall undertake to develop an objective and participative methodology for the evaluation of risk level based on the criteria outlined in the relevant articles and inclusion of new systems in: the list in Annex III, including the extension of existing area headings or addition of new area headings; the list of prohibited practices in Article 5; and the list of AI systems requiring additional transparency measures.

Amendment 2998
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 84 - paragraph 7 a (new)
7 a. Any amendment to this Regulation pursuant to paragraph 7, or relevant future delegated or implementing acts, which concern sectoral legislation listed in annex II section B, shall take into account the regulatory specificities of each sector, and should not interfere with existing governance, conformity assessment and enforcement mechanisms and authorities established therein.

Amendment 2999
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
René Repasi, Marc Angel, Andreas Schieder, Maria-Manuel Leitão-Marques
Article 84 a (new)
Article 84 a', 'New Article 84a', 'Amendments to Directive (EU) 2020/1828 on Representative Actions for the Protection of the Collective Interests of Consumers', 'The following is added to Annex I:', '"(X) Regulation laying down harmonised rules on artificial intelligence (Artificial Intelligence Act). Artificial Intelligence (AI)

Amendment 3000
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Article 85 - paragraph 2
2. This Regulation shall apply from [36 months following the entering into force of the Regulation].

Amendment 3001
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Article 85 - paragraph 2
2. This Regulation shall apply from [48 months following the entering into force of the Regulation].

Amendment 3002
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 85 - paragraph 2
2. This Regulation shall apply from [48 months following the entering into force of the Regulation].

Amendment 3003
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Article 85 - paragraph 2
2. This Regulation shall apply from [6 months following the entering into force of the Regulation].

Amendment 3004
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Article 85 - paragraph 3 - point b
(b) Article 71 shall apply from [24 months following the entry into force of this Regulation].

Amendment 3005
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 85 - paragraph 3 - point b a (new)
(b a) Title II shall apply from [24 months following the entry into force of this Regulation].

Amendment 3006
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 85 - paragraph 3 a (new)
3 a. Member States shall not until ... [24 months after the date of application of this Regulation] impede the making available of AI systems and products which were placed on the market in conformity with Union harmonisation legislation before [the date of application of this Regulation].

Amendment 3007
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Article 85 - paragraph 3 a (new)
3 a. Member States shall not until... [24 months after the date of application of this Regulation] impede the making available of AI systems and products which were placed on the market inconformity with Union harmonisation legislation before [the date of application of this Regulation].

Amendment 3008
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz
Article 85 - paragraph 3 b (new)
3 b. At the latest by six months after entry into force of this Regulation, the European Commission shall submit a standardization request to the European Standardisation Organisations in order to ensure the timely provision of all relevant harmonised standards that cover the essential requirements of this regulation. Any delay in submitting the standardisation request shall add to the transitional period of 24 months as stipulated in paragraph 3a.

Amendment 3009
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Article 85 - paragraph 3 b (new)
3 b. At the latest by six months after entry into force of this Regulation, the European Commission shall submit a standardization request to the European Standardisation Organisations in order to ensure the timely provision of all relevant harmonised standards that cover the essential requirements of this regulation. Any delay in submitting the standardisation request shall add to the transitional period of 24 months as stipulated in paragraph 4

Amendment 3010
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Annex I
deleted

Amendment 3011
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Annex I
deleted

Amendment 3012
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Annex I
deleted

Amendment 3013
ECR - European Conservatives and Reformists Group
Carlo Fidanza
Annex I - point b
deleted

Amendment 3014
EPP - Group of the European Peoples Party (Christian Democrats)
Geoffroy Didier
Annex I - point b
deleted

Amendment 3015
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Annex I - point b
deleted

Amendment 3016
EPP - Group of the European Peoples Party (Christian Democrats)
Karlo Ressler
Annex I - point b
deleted

Amendment 3017
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Annex I - point b
deleted

Amendment 3018
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Annex I - point b
(b) Other data-driven approaches, including search and optimization methods.

Amendment 3019
ECR - European Conservatives and Reformists Group
Carlo Fidanza
Annex I - point c
deleted

Amendment 3020
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Annex I - point c
deleted

Amendment 3021
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Annex I - point c
deleted

Amendment 3022
EPP - Group of the European Peoples Party (Christian Democrats)
Karlo Ressler
Annex I - point c
deleted

Amendment 3023
EPP - Group of the European Peoples Party (Christian Democrats)
Geoffroy Didier
Annex I - point c
deleted

Amendment 3024
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Annex I - point c
deleted

Amendment 3025
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Annex I - point c a (new)
(c) Statistical approaches, Bayesian estimation, if they are used to extract decisions from data in an automated way and search.

Amendment 3026
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Annex I - point c a (new)
(c a) Approaches based on neural network imitation and neuro-robotic networks;

Amendment 3027
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Annex I - point c b (new)
(c b) Machine learning tasks on graphs for repetition tasks or pattern recognition;

Amendment 3028
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Annex I - point c c (new)
(c c) Natural language programming techniques, including emotion detection and recognition systems, using interactions between human language and computer language;

Amendment 3029
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Annex I - point c d (new)
(c d) Artificial vision for pattern recognition, including graphical analysis or digital signature identification;

Amendment 3030
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Annex I - point c e (new)
(c e) Interactive systems related to mechatronics, robotics and automation systems.

Amendment 3031
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex II - Part A - point 6
deleted

Amendment 3032
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex II - Part A - point 11
deleted

Amendment 3033
EPP - Group of the European Peoples Party (Christian Democrats)
Deirdre Clune, Axel Voss, Andreas Schwab
Annex II - Part A - point 11
deleted

Amendment 3034
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex II - Part A - point 12
deleted

Amendment 3035
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex II - Part A - point 12 a (new)
12 a. Directive 2014/35/EU of the European Parliament and of the Council of 26 February 2014 on the harmonisation of the laws of the Member States relating to the making available on the market of electrical equipment designed for use within certain voltage limits (OJ L96/357, 29.3.2014).

Amendment 3036
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Annex II - Part A - point 12 a (new)
12a. [REGULATION OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL on a Single Market For Digital Services (Digital Services Act) and amending Directive 2000/31/EC]

Amendment 3037
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Annex II - Part A - point 12 b (new)
12b. [REGULATION OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL on contestable and fair markets in the digital sector (Digital Markets Act)].

Amendment 3038
EPP - Group of the European Peoples Party (Christian Democrats)
Deirdre Clune, Axel Voss, Andreas Schwab
Annex II - Part B - point 7 a (new)
7 a. Regulation (EU) 2017/745 of the European Parliament and of the Council of 5 April 2017 on medical devices, amending Directive 2001/83/EC, Regulation (EC) No 178/2002 and Regulation (EC) No1223/2009 and repealing Council Directives 90/385/EEC and 93/42/EEC (OJ L 117,5.5.2017, p. 1;

Amendment 3039
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex II - Part B - point 7 a (new)
7 a. Regulation (EU) 2017/745 of the European Parliament and of the Council of 5 April 2017 on medical devices, amending Directive 2001/83/EC, Regulation (EC) No 178/2002 and Regulation (EC) No 1223/2009 and repealing Council Directives 90/385/EEC and 93/42/EEC (OJ L 117, 5.5.2017, p. 1;

Amendment 3040
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex II - Part B - point 7 a (new)
7 a. Directive 2009/125/EC of the European Parliament and of the Council of 21 October 2009 establishing a framework for the setting of ecodesign requirements for energy-related products.

Amendment 3041
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex II - Part B - point 7 b (new)
7 b. Regulation (EU) 2017/746 of the European Parliament and of the Council of 5 April 2017 on in vitro diagnostic medical devices and repealing Directive 98/79/EC and Commission Decision 2010/227/EU (OJ L 117, 5.5.2017, p. 176).

Amendment 3042
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Annex III - title
INDICATIVE LIST OF HIGH-RISK AI SYSTEMS REFERRED TO IN ARTICLE 6(2)

Amendment 3043
EPP - Group of the European Peoples Party (Christian Democrats)
Geoffroy Didier
Annex III - title
HIGH-RISK USES OF AI SYSTEMS REFERRED TO IN ARTICLE 6(2)

Amendment 3044
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex III - title
CRITICAL USE CASES REFERRED TO IN ARTICLE 6(2)

Amendment 3045
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Annex III - title
CRITICAL AREAS REFERRED TO IN ARTICLE 6(2)

Amendment 3046
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex III - paragraph 1 - introductory part
The AI systems specifically mentioned under points 1-8 stand for critical use cases and are each considered to be high-risk AI systems pursuant to Article 6(2), when - according to their instructions to use - their intended purpose and specific use pose a significant risk of harm to the health and safety or a risk of adverse impact on fundamental rights:

Amendment 3047
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Annex III - paragraph 1 - point 1 - introductory part
1. 1.Biometric and biometrics-based systems:', '(a) AI systems intended to be used for the ‘real-time’ and ‘post’ remote biometric identification of natural persons;', '(b) AI systems intended to be used for the remote biometric categorisation of natural persons in publicly-accessible spaces;', '(c) AI systems intended to be used for emotion recognition in natural persons;

Amendment 3048
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Annex III - paragraph 1 - point 1 - introductory part
1. Biometric identification systems, excluding biometric authentication or verification, intended to be used for the ‘real-time’ and ‘post’ remote biometric identification or categorisation of natural persons (i.e., revealing their identity or tracking their behaviour) without their expressed or implied consent and causing legal effects or discrimination against the affected person;

Amendment 3049
ECR - European Conservatives and Reformists Group
Rob Rooken
Annex III - paragraph 1 - point 1 - introductory part
1. Biometric or biometrics-based profiling, including identification and categorisation of natural persons:

Amendment 3050
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 1 - introductory part
1. Biometric identification, biometrics-based data and categorisation of natural persons:

Amendment 3051
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Patryk Jaki, Eugen Jurzyca, Adam Bielan
Annex III - paragraph 1 - point 1 - introductory part
1. Biometrics systems identification and categorisation of natural persons

Amendment 3052
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 1 - introductory part
1. AI systems which use biometric or biometrics-based data:

Amendment 3053
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Annex III - paragraph 1 - point 1 - introductory part
1. AI systems which use biometric or biometrics-based data:

Amendment 3054
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Annex III - paragraph 1 - point 1 - introductory part
1. Biometric identification of natural persons:

Amendment 3055
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Annex III - paragraph 1 - point 1 - point a
deleted

Amendment 3056
Renew - Renew Europe Group
Dragoş Tudorache
Annex III - paragraph 1 - point 1 - point a
deleted

Amendment 3057
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 1 - point a
deleted

Amendment 3058
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Annex III - paragraph 1 - point 1 - point a
deleted

Amendment 3059
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş, Moritz Körner,
Annex III - paragraph 1 - point 1 - point a
(a) AI systems intended to be used for the ‘real-time’ and ‘post’ remote biometric identification of natural persons, excluding verification/authentification systems whose sole purpose is to confirm that a specific natural person is the person he or she claims to be, and systems that are used to confirm the identity of a natural person for the sole purpose of having access to a service, a device or premises;

Amendment 3060
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Annex III - paragraph 1 - point 1 - point a
(a) AI systems that are or may be used for the biometric identification of natural persons, including in workplaces, in educational settings and in border surveillance, or for the provision of public or essential services;

Amendment 3061
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Annex III - paragraph 1 - point 1 - point a
(a) AI systems intended to be used for the ‘real-time’ and ‘post’ remote biometric identification of natural persons, within the strict limits of the exemption from the general prohibition on their use laid down in Article 5;

Amendment 3062
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Annex III - paragraph 1 - point 1 - point a
(a) AI systems intended to be used for the ‘real-time’ and ‘post’ remote biometric identification of natural persons without their agreement, including remote biometric identification;

Amendment 3063
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Patryk Jaki, Eugen Jurzyca
Annex III - paragraph 1 - point 1 - point a
(a) AI biometric identification systems intended to be used for the ‘real time’ and ‘post’ remote biometric identification of natural persons without their agreement;

Amendment 3064
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 1 - point a
(a) AI systems that are or may be used for the ‘real-time’ and ‘post’ remote biometric identification of natural persons;

Amendment 3065
ECR - European Conservatives and Reformists Group
Rob Rooken
Annex III - paragraph 1 - point 1 - point a
(a) AI systems used for the ‘real-time’ and ‘post’ biometric identification of natural persons;

Amendment 3066
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Karen Melchior, Vlad-Marius Botoş, Abir Al-Sahlani, Moritz
Annex III - paragraph 1 - point 1 - point a a (new)
(a a) AI systems intended to be used to make inferences on the basis of biometric data, including emotion recognition systems, or biometrics-based data, including speech patterns, tone of voice, lip-reading and body language analysis, that produces legal effects or affects the rights and freedoms of natural persons.

Amendment 3067
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Annex III - paragraph 1 - point 1 - point a a (new)
(a a) AI systems that are or may be used for the detection of a person’s presence, in workplaces, in educational settings, and in border surveillance, including in the virtual / online version of these spaces, on the basis of their biometric or biometrics-based data;

Amendment 3068
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 1 - point a a (new)
(a a) AI systems that are or may be used for the biometric identification of natural persons in publicly accessible spaces, as well as in workplaces, in educational settings and in border surveillance, or in the provision of public or essential services;

Amendment 3069
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 1 - point a a (new)
(a a) AI systems that may be or are intended to be used for the ‘real-time’ and ‘post’ non-remote biometric identification of natural persons in publicly accessible spaces, as well as in workplaces, in educational settings and in border surveillance;

Amendment 3070
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Annex III - paragraph 1 - point 1 - point a a (new)
(a a) AI systems intended to be used by autonomous devices, drones or vehicles to transport or collect natural persons;

Amendment 3071
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 1 - point a a (new)
(a a) AI systems that are or may be used for biometric verification in publicly accessible spaces, as well as in workplaces and in educational settings;

Amendment 3072
ECR - European Conservatives and Reformists Group
Rob Rooken
Annex III - paragraph 1 - point 1 - point a a (new)
(a a) AI categorisation systems using biometric or biometrics-based data;

Amendment 3073
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 1 - point a b (new)
(a b) AI systems that are or may be used for the detection of a person’s presence, in workplaces, in educational settings, and in border surveillance, including in the virtual / online version of these spaces, on the basis of their biometric or biometrics-based data;

Amendment 3074
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 1 - point a b (new)
(a b) AI systems that may be or are intended to be used for the ‘real-time’ and ‘post’ non-remote biometric identification of natural persons in publicly accessible spaces, as well as in workplaces, in educational settings and in border surveillance;

Amendment 3075
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Annex III - paragraph 1 - point 1 - point a b (new)
(a b) AI systems that are or may be used for monitoring compliance with health and safety measures or inferring alertness /attentiveness for safety purposes, on the basis of biometric or biometrics-based data;

Amendment 3076
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 1 - point a b (new)
(a b) AI systems that are or may be used for biometric verification in publicly accessible spaces, as well as in workplaces and in educational settings;

Amendment 3077
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 1 - point a b (new)
(a b) AI systems that are or may be used for categorisation on the basis of biometric or biometrics-based data;

Amendment 3078
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 1 - point a c (new)
(a c) AI systems that are or may be used for monitoring compliance with health and safety measures or inferring alertness / attentiveness for safety purposes, on the basis of biometric or biometrics-based data;

Amendment 3079
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 1 - point a c (new)
(a c) AI systems that are or may be used for ‘real-time’ and ‘post’ biometric verification in publicly accessible spaces, as well as in workplaces and in educational settings;

Amendment 3080
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Annex III - paragraph 1 - point 1 - point a c (new)
(a c) AI systems that are or may be used to diagnose or support diagnosis of medical conditions or medical emergencies on the basis of biometric or biometrics-based data;

Amendment 3081
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 1 - point a c (new)
(a c) AI systems that are or may be used to diagnose or support diagnosis of medical conditions or medical emergencies on the basis of biometric or biometrics-based data;

Amendment 3082
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 1 - point a c (new)
(a c) AI systems that are or may be used for categorisation on the basis of biometric or biometrics-based data;

Amendment 3083
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 1 - point a d (new)
(a d) AI systems that are or may be used for the ‘real-time’ and ‘post’ detection of a person’s presence, in workplaces, in educational settings, and in border surveillance, including in the virtual or online version of these spaces, on the basis of their physical, physiological or behavioural data, including biometric data;

Amendment 3084
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 1 - point a d (new)
(a d) AI systems that are or may be used for the detection of a person’s presence, in workplaces, in educational settings, and in border surveillance, including in the virtual / online version of these spaces, on the basis of their biometric or biometrics-based data;

Amendment 3085
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 1 - point a e (new)
(a e) AI systems intended to be used by or on behalf of competent authorities in ‘real-time’ and ‘post’ migration, asylum and border control management for the forecasting or prediction of trends related to migration, movement and border crossings.

Amendment 3086
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 1 - point a e (new)
(a e) AI systems that are or may be used for monitoring compliance with health and safety measures or inferring alertness / attentiveness for safety purposes, on the basis of biometric or biometrics-based data;

Amendment 3087
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 2 - introductory part
2. Management, operation, generation and supply of critical infrastructure, technology and energy:

Amendment 3088
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Annex III - paragraph 1 - point 2 - point a
2. Critical infrastructure and protection of environment:

Amendment 3089
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Annex III - paragraph 1 - point 2 - point a
(a) AI systems intended to be used as a component, the failure or malfunctioning of which endangers the health, safety or fundamental rights of persons or the safety of property, in the management, operation, generation and/or supply of the telecom, internet, and financial infrastructure, road, rail, air and water traffic, and the operation, management an/or supply of water, gas, heating, and electricity and energy (including nuclear power).

Amendment 3090
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan, Vincenzo Sofo
Annex III - paragraph 1 - point 2 - point a
(a) AI systems intended to be used as safety components in the management and operation of road traffic and the supply of water, gas, heating and electricity, whose failure or malfunctioning would directly cause significant harm to the health, natural environment or safety of natural persons.

Amendment 3091
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 2 - point a
(a) AI systems that may be or are intended to be used as safety components in the management and operation of road traffic and the supply of water, gas, heating and electricity and entities falling under [Directive XXXX/XXX/EU (‘NIS 2 Directive’)].

Amendment 3092
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Annex III - paragraph 1 - point 2 - point a
(a) AI systems intended to be used as safety components in the management and operation of road traffic and the supply of water, gas, heating and electricity, unless these are regulated in harmonisation legislation or sectorial regulation.

Amendment 3093
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Annex III - paragraph 1 - point 2 - point a
(a) AI systems intended to be used as safety components in the management and operation of road traffic, digital infrastructure and the supply of water, gas, heating and electricity.

Amendment 3094
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex III - paragraph 1 - point 2 - point a
(a) AI systems used as safety or security components in the management and operation of road traffic to the extent that they are not embedded in a vehicle;

Amendment 3095
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex III - paragraph 1 - point 2 - point a a (new)
(a a) AI systems intended to be used as safety or security components in the management and operation of the supply of water, gas, heating and electricity, provided the failure of the AI system is highly likely to lead to an imminent threat to such supply.

Amendment 3096
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
René Repasi, Marc Angel, Andreas Schieder, Paul Tang, Maria-Manuel Leitão- Marques
Annex III - paragraph 1 - point 2 a (new)
2 a. Vulnerable groups:', 'a) AI systems intended to be used by children in a way that may seriously affect a child’s personal development, such as by educating the child in a broad range of areas not limited to areas which parents or guardians can reasonably foresee at the time of the purchase;', 'b) AI systems, such as virtual assistants, intended to be used by natural persons for taking decisions with regard to their private lives that have legal effects or similarly significantly affect the natural persons;

Amendment 3097
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex III - paragraph 1 - point 3 - point a
(a) AI systems intended to be used for the purpose of determining or materially influence decision on the admission of natural persons to educational and vocational training institutions;

Amendment 3098
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 3 - point a
(a) AI systems that may be or are intended to be used for the purpose of determining access or assigning natural persons to educational and vocational training institutions;

Amendment 3099
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Annex III - paragraph 1 - point 3 - point b
(b) AI systems intended to be used for the purpose of assessing students in educational and vocational training institutions and for assessing participants in tests commonly required for admission to educational institutions or monitoring of students during exams, for determining learning objectives, and for allocating personalised learning tasks to students;

Amendment 3100
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 3 - point b
(b) AI systems that may be or are intended to be used for the purpose of assessing students in educational and vocational training institutions or for assessing participants in tests commonly required for admission to educational institutions.

Amendment 3101
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex III - paragraph 1 - point 3 - point b
(b) AI systems intended to be used for the purpose of assessing the learning outcome of students in educational and vocational training institutions and for assessing participants in tests commonly required for admission to these institutions.

Amendment 3102
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Annex III - paragraph 1 - point 3 - point b
(b) AI systems intended to be used for the purpose of assessing students in educational and vocational training institutions and for assessing participants in tests commonly required for admission to those institutions.

Amendment 3103
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 3 - point b a (new)
(b a) AI systems that may be or are intended to be used for the purpose of assessing the appropriate level of education for an individual with potential effects for the methods or level of education that individual will recieve or will be able to access.

Amendment 3104
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 3 - point b a (new)
(b a) AI systems intended to be used for the optimization of individual learning processes based on a student's learning data.

Amendment 3105
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex III - paragraph 1 - point 4 - introductory part
4. Employment and work-related contractual relationships', 'AI systems intended to be used to make or materially influence decisions on:', '(i) recruitment or selection of natural persons, specifically for screening or filtering applications, evaluating candidates in the course of interviews or tests;', '(ii) promotion and termination of work-related contractual relationships;', '(iii) task allocation based on individual behaviour or personal traits or characteristics;or', '(iv) monitoring and evaluating the performance and behaviour of persons.', 'where those decisions are likely to pose a significant risk of adversely impacting fundamental rights or threatening harm to health and safety.

Amendment 3106
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex III - paragraph 1 - point 4 - point a
deleted

Amendment 3107
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Annex III - paragraph 1 - point 4 - point a
(a) AI systems intended to be used to make final decisions for recruitment or selection of natural persons.

Amendment 3108
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Karen Melchior, Morten Løkkegaard, Sandro Gozi, Vlad-
Annex III - paragraph 1 - point 4 - point a
(a) AI systems intended to make autonomous decisions or materially influence decisions about recruitment or selection of natural persons, notably for screening or filtering applications, evaluating candidates in the course of interviews or tests;

Amendment 3109
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 4 - point a
(a) AI systems that may be or are intended intended to be used for recruitment or selection of natural persons, notably for advertising vacancies, screening or filtering applications, evaluating candidates in the course of interviews or tests;

Amendment 3110
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Annex III - paragraph 1 - point 4 - point a
(a) AI systems intended to be used in recruitment for advertising vacancies, screening or filtering applications, or evaluating candidates in the course of interviews or tests;

Amendment 3111
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Annex III - paragraph 1 - point 4 - point a
(a) AI systems intended to be used for recruitment or selection of natural persons, screening or filtering applications, evaluating candidates in the course of interviews or tests;

Amendment 3112
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex III - paragraph 1 - point 4 - point b
deleted

Amendment 3113
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Patryk Jaki, Adam Bielan, Vincenzo Sofo
Annex III - paragraph 1 - point 4 - point b
(b) AI systems intended to be used to make decisions on promotion and termination of work-related contractual relationships, based on individual behaviour or personal traits or characteristics, and for monitoring and evaluating performance and behaviour of persons in such relationships that have a likelihood of causing harm to the physical health and safety or adversely impact on the fundamental rights or have given rise to significant concerns in relation to the materialisation of such harm or adverse impact.

Amendment 3114
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 4 - point b
(b) AI that may be or are intended to be used to assist decision-making affecting the initiation, establishment, implementation and termination of an employment relationship, including AI systems intended to support collective legal and regulatory matters, particularly work-related relationships, for task allocation and for monitoring, measuring and evaluating performance and behavior of persons in such relationships.

Amendment 3115
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Annex III - paragraph 1 - point 4 - point b
(b) AI intended to be used for making decisions affecting the initiation, establishment, implementation, promotion and termination of an employment relationship, including AI systems intended to support collective legal and regulatory matters, particularly for task allocation and for monitoring and evaluating performance and behavior of persons or in matters of training or further education in such relationships.

Amendment 3116
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 4 - point b
(b) AI intended to be used for making decisions affecting the initiation, establishment, implementation and termination of an employment relationship, including AI systems intended to support collective legal and regulatory matters, particularly for task allocation and for monitoring and evaluating performance and behavior of persons in such relationships

Amendment 3117
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Annex III - paragraph 1 - point 4 - point b
(b) AI systems intended to be used for making decisions or to assist in making decisions on promotion and termination of work-related contractual relationships; for personalized task allocation based on biometrics, biometrics-based, or personal data; and for monitoring and evaluating performance and behaviour of natural persons in such relationships.

Amendment 3118
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Karen Melchior, Morten Løkkegaard, Sandro Gozi, Vlad- Marius Botoş, Moritz Körner, Ondřej Kovařík, Jan-Christoph Oetjen
Annex III - paragraph 1 - point 4 - point b
(b) AI intended to make autonomous decisions or materially influence decisions on promotion and termination of work-related contractual relationships, for monitoring and evaluating performance and behavior of persons in such relationships.

Amendment 3119
EPP - Group of the European Peoples Party (Christian Democrats)
Nathalie Colin-Oesterlé
Annex III - paragraph 1 - point 4 - point b
(b) AI intended to be used for making decisions on promotion and termination of work-related contractual relationships, and for monitoring and evaluating performance and behavior of persons in such relationships.

Amendment 3120
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
René Repasi, Marc Angel, Andreas Schieder, Maria-Manuel Leitão-Marques
Annex III - paragraph 1 - point 5 - introductory part
5. Access to and enjoyment of essential private services and public services and benefits, including access to products:

Amendment 3121
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Annex III - paragraph 1 - point 5 - point a
deleted

Amendment 3122
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 5 - point a
(a) AI systems intended to be used by or on behalf of (semi-)public authorities or private parties to evaluate or predict the lawful use by, or the eligibility of, natural persons, including the self employed and micro-enterprises, for public assistance, benefits and services and essential private services including but not limited to housing, electricity, heating/cooling, finance, insurance and internet, as well as to grant reduce, revoke, or reclaim such benefits and services or set payment obligations related to these services;

Amendment 3123
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 5 - point a
(a) AI systems that may be or are intended to be used by public authorities or on behalf of public authorities to evaluate the eligibility of natural persons for public assistance benefits and services, as well as to grant, reduce, revoke, or reclaim such benefits and services;

Amendment 3124
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex III - paragraph 1 - point 5 - point a
(a) AI systems intended to be used by public authorities or on behalf of public authorities to evaluate and decide on the eligibility of natural persons for public assistance benefits and services, as well as to grant, reduce, revoke, or reclaim such benefits and services;

Amendment 3125
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Annex III - paragraph 1 - point 5 - point a
(a) AI systems intended to be used by public authorities or on behalf of public authorities to evaluate the eligibility of natural persons for public assistance benefits and services, as well as to grant, reduce, revoke, increase, or reclaim such benefits and services;

Amendment 3126
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex III - paragraph 1 - point 5 - point b
deleted

Amendment 3127
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 5 - point b
deleted

Amendment 3128
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Annex III - paragraph 1 - point 5 - point b
(b) AI systems intended to be used to evaluate the creditworthiness of natural persons or establish their credit score in order to determine their access to credit or to other essential services. Ancillary applications such as AI applications used for the acceleration of the credit disbursement process, in the valuation of collateral, or for the internal process efficiency, as well as other subsequent applications based on the credit scoring which do not create high risks for individuals are not included in those systems;

Amendment 3129
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
René Repasi, Marc Angel, Andreas Schieder, Maria-Manuel Leitão-Marques
Annex III - paragraph 1 - point 5 - point b
(b) AI systems intended to be used

Amendment 3130
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Patryk Jaki
Annex III - paragraph 1 - point 5 - point b
(b) AI systems intended to be used to evaluate the creditworthiness of natural persons or assessment of insurance risk, with the exception of AI systems put into service by small scale providers for their own use or AI systems related to low-value credits for the purchase of moveables;

Amendment 3131
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Annex III - paragraph 1 - point 5 - point b
(b) AI systems intended to be used to evaluate the creditworthiness of natural persons or establish their credit score, with the exception of AI systems put into service by small scale providers for their own use; or AI systems related to low-value credits for the purchase of movables;

Amendment 3132
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 5 - point b
(b) AI systems intended to be used to evaluate the creditworthiness of natural persons or establish their credit score;

Amendment 3133
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 5 - point b
(b) AI systems that may be or are intended to be used to evaluate the creditworthiness of natural persons or establish their credit score, with the exception of AI systems put into service by small scale providers for their own use;

Amendment 3134
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 5 - point b
(b) AI systems that may be or are intended to be used to evaluate the creditworthiness of natural persons or establish their credit score, with the exception of AI systems put into service by small scale providers for their own use;

Amendment 3135
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Maria-Manuel Leitão-Marques, Eva Kaili
Annex III - paragraph 1 - point 5 - point b
(b) AI systems intended to be used to evaluate the creditworthiness of natural persons, establish their credit score, or predict human medical conditions and health-related outcomes

Amendment 3136
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş,
Annex III - paragraph 1 - point 5 - point b
(b) AI systems intended to be used to evaluate the creditworthiness of natural persons or establish their credit score, with the exception of AI systems put into service by SMEs and start-ups for their own use;

Amendment 3137
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
René Repasi, Marc Angel, Andreas Schieder, Maria-Manuel Leitão-Marques
Annex III - paragraph 1 - point 5 - point b - point i (new)
i) to evaluate the creditworthiness of natural persons or establish their credit score,

Amendment 3138
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
René Repasi, Marc Angel, Andreas Schieder, Maria-Manuel Leitão-Marques
Annex III - paragraph 1 - point 5 - point b - point ii (new)
ii) to evaluate the behaviour of natural persons such as with regard to complaints or the exercise of statutory or contractual rights in order to draw conclusions for their future access to private or public services,

Amendment 3139
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
René Repasi, Marc Angel, Andreas Schieder, Maria-Manuel Leitão-Marques
Annex III - paragraph 1 - point 5 - point b - point iii (new)
iii) for making individual risk assessments of natural persons in the context of access to essential private and public services, including insurance contracts, or

Amendment 3140
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
René Repasi, Marc Angel, Andreas Schieder, Maria-Manuel Leitão-Marques
Annex III - paragraph 1 - point 5 - point b - point iv (new)
iv) for personalized pricing within the meaning of Article 6 (1) (ea) of Directive 2011/83/EU, with the exception of AI systems put into service by small scale providers of AI systems for their own use;

Amendment 3141
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Annex III - paragraph 1 - point 5 - point c
(c) AI systems intended to be used, without taking any decisions on the matter, to dispatch, or to establish priority in the dispatching of emergency first response services, including by firefighters and medical aid.

Amendment 3142
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 5 - point c
(c) AI systems that may be or are intended to be used to dispatch, or to establish priority in the dispatching of emergency first response services, including by firefighters and medical aid.

Amendment 3143
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 5 - point c a (new)
(c a) AI systems that may be used or are intended to be used for making individual risk assessments of natural persons in the context of access to private and public services, including determining the amounts of insurance premiums.

Amendment 3144
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Patryk Jaki
Annex III - paragraph 1 - point 5 - point c a (new)
(c a) AI systems intended to be used for insurance premium setting, underwritings and claims assessments, with the exception of AI systems related to low-value property insurance.

Amendment 3145
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Annex III - paragraph 1 - point 5 - point c a (new)
(c a) AI systems intended to be used for insurance premium setting, underwritings and claims assessments, with the exception of AI systems related to low-value property insurance.

Amendment 3146
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 5 - point c b (new)
(c b) AI systems that may be used or are intended to be used in the context of payment and debt collection services.

Amendment 3147
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 5 a (new)
5 a. Use by vulnerable groups or in situations that imply vulnerability', '(a) AI systems intended to be used by children in a way that may seriously affect a child’s personal development, such as by educating the child in a broad range of areas not limited to areas which parents or guardians can reasonably foresee at the time of the purchase;', '(b) AI systems, such as virtual assistants, intended to be used by natural persons for taking decisions with regard to their private lives that have legal effects or similarly significantly affect the natural persons;', '(c) AI systems intended to be used for personalised pricing within the meaning of Article 6 (1) (ea) of Directive 2011/83/EU.

Amendment 3148
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Annex III - paragraph 1 - point 6 - point a
deleted

Amendment 3149
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Annex III - paragraph 1 - point 6 - point a
deleted

Amendment 3150
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 6 - point a
deleted

Amendment 3151
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 6 - point a
deleted

Amendment 3152
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 6 - point a
deleted

Amendment 3153
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex III - paragraph 1 - point 6 - point a
(a) AI systems intended to be used by law enforcement authorities or on their behalf for making individual risk assessments of natural persons in order to assess the risk for a natural person for offending or reoffending or the risk for a natural person to become a potential victim of criminal offences;

Amendment 3154
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Abir
Annex III - paragraph 1 - point 6 - point a
(a) AI systems intended to be used by law enforcement authorities or on their behalf for making individual risk assessments of natural persons in order to assess the risk of a natural person for offending or reoffending or the risk for potential victims of criminal offences;

Amendment 3155
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Annex III - paragraph 1 - point 6 - point a a (new)
(a a) AI systems designed for real-time remote biometric identification in publicly accessible locations for law enforcement purposes.

Amendment 3156
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Annex III - paragraph 1 - point 6 - point b
deleted

Amendment 3157
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Annex III - paragraph 1 - point 6 - point b
deleted

Amendment 3158
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Annex III - paragraph 1 - point 6 - point b
deleted

Amendment 3159
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 6 - point b
deleted

Amendment 3160
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Annex III - paragraph 1 - point 6 - point b
deleted

Amendment 3161
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 6 - point b
deleted

Amendment 3162
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 6 - point b
deleted

Amendment 3163
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Annex III - paragraph 1 - point 6 - point b
(b) AI systems intended to be used by law enforcement authorities or on behalf of law enforcement authorities as polygraphs and similar tools or to detect the emotional state of a natural person;

Amendment 3164
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Sandro Gozi, Vlad-
Annex III - paragraph 1 - point 6 - point b
(b) AI systems intended to be used by law enforcement authorities or on their behalf as polygraphs and similar tools or to detect the emotional state of a natural person;

Amendment 3165
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Annex III - paragraph 1 - point 6 - point c
(c) AI systems intended to be used by law enforcement authorities or on their behalf to detect deep fakes as referred to in article 52(3) and in point 8a(a) and (b) of this Annex;

Amendment 3166
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Annex III - paragraph 1 - point 6 - point c
(c) AI systems intended to be used by law enforcement authorities or on behalf of law enforcement authorities to detect deep fakes as referred to in article 52(3);

Amendment 3167
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 6 - point c
(c) AI systems that may be or are intended to be used by law enforcement authorities to detect deep fakes as referred to in article 52(3);

Amendment 3168
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Sandro Gozi, Vlad-
Annex III - paragraph 1 - point 6 - point c
(c) AI systems intended to be used by law enforcement authorities or on their behalf to detect deep fakes as referred to in article 52(3);

Amendment 3169
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Annex III - paragraph 1 - point 6 - point d
(d) AI systems intended to be used by law enforcement authorities or on behalf of law enforcement authorities for evaluation of the reliability of evidence in the course of investigation or prosecution of criminal offences;

Amendment 3170
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Annex III - paragraph 1 - point 6 - point d
(d) AI systems intended to be used by law enforcement authorities or on their behalf for evaluation of the reliability of evidence in the course of investigation or prosecution of criminal offences;

Amendment 3171
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 6 - point d
(d) AI systems that may be or are intended to be used by law enforcement authorities for evaluation of the reliability of evidence in the course of investigation or prosecution of criminal offences;

Amendment 3172
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Sandro Gozi, Vlad-
Annex III - paragraph 1 - point 6 - point d
(d) AI systems intended to be used by law enforcement authorities or on their behalf for evaluation of the reliability of evidence in the course of investigation or prosecution of criminal offences;

Amendment 3173
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Annex III - paragraph 1 - point 6 - point e
deleted

Amendment 3174
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 6 - point e
deleted

Amendment 3175
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 6 - point e
deleted

Amendment 3176
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 6 - point e
deleted

Amendment 3177
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Vlad-Marius Botoş,
Annex III - paragraph 1 - point 6 - point e
deleted

Amendment 3178
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Annex III - paragraph 1 - point 6 - point e
deleted

Amendment 3179
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex III - paragraph 1 - point 6 - point e
(e) AI systems intended to be used by law enforcement authorities for predicting the occurrence or reoccurrence of an actual or potential criminal offence based on profiling of natural persons as referred to in Article 3(4) of Directive (EU) 2016/680 or assessing personality traits and characteristics or past criminal behaviour of natural persons or groups, with the exception of AI systems used for compliance with applicable counterterrorism and anti-money laundering legislation;

Amendment 3180
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Annex III - paragraph 1 - point 6 - point f
deleted

Amendment 3181
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 6 - point f
deleted

Amendment 3182
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Annex III - paragraph 1 - point 6 - point f
(f) AI systems intended to be used by law enforcement authorities or on behalf of law enforcement authorities for profiling of natural persons as referred to in Article 3(4) of Directive (EU)2016/680 in the course of detection, investigation or prosecution of criminal offences;

Amendment 3183
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 6 - point f
(f) AI systems that may be or are intended to be used by law enforcement authorities for profiling of natural persons as referred to in Article 3(4) of Directive (EU) 2016/680 in the course of detection, investigation or prosecution of criminal offences;

Amendment 3184
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Sandro Gozi, Vlad-
Annex III - paragraph 1 - point 6 - point f
(f) AI systems intended to be used by law enforcement authorities or on their behalf for profiling of natural persons as referred to in Article 3(4) of Directive (EU) 2016/680 in the course of detection, investigation or prosecution of criminal offences;

Amendment 3185
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 6 - point g
deleted

Amendment 3186
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex III - paragraph 1 - point 6 - point g
deleted

Amendment 3187
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 6 - point g
deleted

Amendment 3188
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Sandro Gozi, Vlad-
Annex III - paragraph 1 - point 6 - point g
(g) AI systems intended to be used by law enforcement authorities or on their behalf for crime analytics regarding natural persons, allowing to search complex related and unrelated large data sets available in different data sources or in different data formats in order to identify unknown patterns or discover hidden relationships in the data.

Amendment 3189
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 7 - point a
deleted

Amendment 3190
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Annex III - paragraph 1 - point 7 - point a
deleted

Amendment 3191
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 7 - point a
deleted

Amendment 3192
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 7 - point a
deleted

Amendment 3193
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Annex III - paragraph 1 - point 7 - point a
deleted

Amendment 3194
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Annex III - paragraph 1 - point 7 - point a
deleted

Amendment 3195
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Sandro Gozi, Vlad-
Annex III - paragraph 1 - point 7 - point a
(a) AI systems intended to be used by competent public authorities or on their behalf as polygraphs and similar tools or to detect the emotional state of a natural person;

Amendment 3196
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Annex III - paragraph 1 - point 7 - point a
(a) AI systems intended to be used by competent public authorities or on their behalf as polygraphs and similar tools or to detect the emotional state of a natural person;

Amendment 3197
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Annex III - paragraph 1 - point 7 - point b
deleted

Amendment 3198
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 7 - point b
deleted

Amendment 3199
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Annex III - paragraph 1 - point 7 - point b
deleted

Amendment 3200
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Annex III - paragraph 1 - point 7 - point b
deleted

Amendment 3201
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 7 - point b
(b) AI systems that may be or are intended to be used by competent public authorities, or third parties on their behalf, to assess a risk, including, but not limited to, a security risk, a risk of irregular immigration, or a health risk, posed by a natural person who intends to enter or has entered into the territory of a Member State;

Amendment 3202
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 7 - point b
(b) AI systems intended to be used by competent public authorities, or by third parties acting on their behalf, to assess a risk, including but not limited to a security risk, a risk of irregular immigration, or a health risk, posed by a natural person who intends to enter or has entered into the territory of a Member State;

Amendment 3203
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Annex III - paragraph 1 - point 7 - point b
(b) AI systems intended to be used by competent public authorities or by third parties acting on their behalf to assess a risk, including but not limited to a security risk, a risk of irregular immigration, or a health risk, posed by a natural person who intends to enter or has entered into the territory of a Member State;

Amendment 3204
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Annex III - paragraph 1 - point 7 - point b
(b) AI systems intended to be used by competent public authorities or on their behalf to assess a risk, including a security risk, a risk of irregular immigration, or a health risk, posed by a natural person who intends to enter or has entered into the territory of a Member State;

Amendment 3205
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Sandro Gozi, Vlad-
Annex III - paragraph 1 - point 7 - point b
(b) AI systems intended to be used by competent public authorities or on their behalf to assess a risk, including a security risk, a risk of irregular immigration, or a health risk, posed by a natural person who intends to enter or has entered into the territory of a Member State;

Amendment 3206
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 7 - point c
(c) AI systems that may be or are intended to be used by competent public authorities for the verification of the authenticity of travel documents and supporting documentation of natural persons and detect non-authentic documents by checking their security features;

Amendment 3207
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Sandro Gozi, Vlad-
Annex III - paragraph 1 - point 7 - point c
(c) AI systems intended to be used by competent public authorities or on their behalf for the verification of the authenticity of travel documents and supporting documentation of natural persons and detect non-authentic documents by checking their security features;

Amendment 3208
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Annex III - paragraph 1 - point 7 - point c
(c) AI systems intended to be used by competent public authorities or on their behalf for the verification of the authenticity of travel documents and supporting documentation of natural persons and detect non-authentic documents by checking their security features;

Amendment 3209
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Annex III - paragraph 1 - point 7 - point d
deleted

Amendment 3210
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Annex III - paragraph 1 - point 7 - point d
deleted

Amendment 3211
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Annex III - paragraph 1 - point 7 - point d
(d) AI systems intended to assist competent public authorities for the examination and assessment of the veracity of evidence and claims in relation to applications for asylum, visa and residence permits and associated complaints with regard to the eligibility of the natural persons applying for a status.

Amendment 3212
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 7 - point d
(d) AI systems intended to assist competent public authorities for the examination and assessment of the veracity of evidence and claims in relation to applications for asylum, visa and residence permits and associated complaints with regard to the eligibility of the natural persons applying for a status.

Amendment 3213
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Annex III - paragraph 1 - point 7 - point d
(d) AI systems intended to be used by competent public authorities or on their behalf or to assist competent public authorities in the examination of applications for asylum, visa and residence permits and associated complaints with regard to the eligibility of the natural persons applying for a status.

Amendment 3214
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Sandro Gozi, Vlad-
Annex III - paragraph 1 - point 7 - point d
(d) AI systems intended to assist competent public authorities or on their behalf for the examination of applications for asylum, visa and residence permits and associated complaints with regard to the eligibility of the natural persons applying for a status.

Amendment 3215
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 7 - point d
(d) AI systems that may be or are intended to assist competent public authorities for the examination of applications for asylum, visa and residence permits and associated complaints with regard to the eligibility of the natural persons applying for a status.

Amendment 3216
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Abir
Annex III - paragraph 1 - point 7 - point d
(d) AI systems intended to be used by competent public authorities for the examination of applications for asylum, visa and residence permits and associated complaints with regard to the eligibility of the natural persons applying for a status.

Amendment 3217
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 7 - point d a (new)
(d a) AI systems that may be or are intended to be used by competent public authorities for border management and immigration authorities to monitor, surveil or process data for the purpose of detecting, verifying or identifying natural persons.

Amendment 3218
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Annex III - paragraph 1 - point 7 - point d a (new)
(d a) AI systems intended to be used by or on behalf of competent authorities in migration, asylum and border control management for the forecasting or prediction of trends related to migration, movement and border crossings;

Amendment 3219
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 7 - point d a (new)
(d a) AI systems intended to be used by or on behalf of competent authorities in migration, asylum and border control management for the forecasting or prediction of trends related to migration, movement and border crossings;

Amendment 3220
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Annex III - paragraph 1 - point 7 - point d a (new)
(d a) AI systems intended to be used by or on behalf of competent authorities in migration, asylum and border control management for the forecasting or prediction of trends related to migration, movement and border crossings;

Amendment 3221
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 7 - point d a (new)
(d a) AI systems that are or may be used by or on behalf of competent authorities in law enforcement, migration, asylum and border control management for the biometric identification of natural persons;

Amendment 3222
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 7 - point d b (new)
(d b) AI systems that may be or are intended to be used for migration analytics regarding natural persons or groups, allowing immigration authorities or related entities to search complex related and unrelated large data sets available in different data sources or in different data formats in order to identify unknown patterns or discover hidden relationships in the data.

Amendment 3223
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 7 - point d b (new)
(d b) AI systems intended to be used by, or on behalf of, competent authorities in migration, asylum and border control management to monitor, surveil, or process data in the context of border management activities for the purpose of recognizing or detecting objects and natural persons;

Amendment 3224
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Annex III - paragraph 1 - point 7 - point d b (new)
(d b) AI systems that are or may be used by or on behalf of competent authorities in law enforcement, migration, asylum and border control management for the biometric identification of natural persons;

Amendment 3225
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 7 - point d b (new)
(d b) AI systems that are or may be used by or on behalf of competent authorities in law enforcement, migration, asylum and border control management for the biometric identification of natural persons;

Amendment 3226
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Annex III - paragraph 1 - point 7 - point d c (new)
(d c) AI systems intended to be used by or on behalf of competent authorities in migration, asylum and border control management to monitor, surveil or process data in the context of border management activities for the purpose of recognising or detecting objects and natural persons;

Amendment 3227
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Annex III - paragraph 1 - point 7 - point d c (new)
(d c) AI systems intended to be used by, or on behalf of, competent authorities in migration, asylum and border control management to monitor, surveil or process data in the context of border management activities for the purpose of recognizing or detecting objects and natural persons;

Amendment 3228
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Annex III - paragraph 1 - point 8 - introductory part
deleted

Amendment 3229
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Annex III - paragraph 1 - point 8 - introductory part
8. Administration of justice:

Amendment 3230
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Annex III - paragraph 1 - point 8 - point a
(a) AI systems intended to be used by a judicial authority or administrative body or on their behalf or to assist a judicial authority or administrative body in researching and interpreting facts or the law and in applying the law to a concrete set of facts.

Amendment 3231
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 8 - point a
(a) AI systems which may be or are intended to assist a judicial authority in researching and interpreting facts and the law and in applying the law or used in a similar way in alternative dispute resolution.

Amendment 3232
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex III - paragraph 1 - point 8 - point a
(a) AI systems intended to be used by a judicial authority, administrative body or on their behalf for in researching and interpreting facts and the law and for applying the law to a concrete set of facts.

Amendment 3233
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Sandro Gozi, Vlad-
Annex III - paragraph 1 - point 8 - point a a (new)
(a) AI systems intended to be used by judicial authorities or on their behalf in interpreting facts or the law for applying the law to a concrete set of facts.

Amendment 3234
Renew - Renew Europe Group
Sophia in t Veld
Annex III - paragraph 1 - point 8 - point a a (new)
(a a) AI systems intended to be used by electoral constituencies for the purpose of protecting democracy and predicting the risk of a candidate for political office, in particular the position of head of government, being homophobic, sexist, dictatorial, kleptocratic and/or having other toxic personality traits;

Amendment 3235
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Annex III - paragraph 1 - point 8 - point a a (new)
(a a) AI systems used by political parties, political candidates, public authorities, or on their behalf for influencing natural persons in the exercise of their vote in local, national, or European Parliament elections;

Amendment 3236
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 8 - point a a (new)
(a a) AI systems that may or are intended to assist in democratic processes, the casting or counting of votes, such as in elections.

Amendment 3237
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Annex III - paragraph 1 - point 8 a (new)
8 a. Other applications:', '(a) AI systems intended to be used to generate, on the basis of limited human input, complex text content that would falsely appear to a person to be human generated and authentic, such as news articles, opinion articles, novels, scripts, and scientific articles, with the exception of AI systems used exclusively for content that undergoes human review and for the publication of which a natural or legal person established in the Union is liable or holds editorial responsibility;', '(b) AI systems intended to be used to generate or manipulate audio or video content that features existing natural persons appearing to say or do something they have never said or done, with the exception of AI systems used exclusively for content that forms part of an evidently artistic, creative or fictional cinematographic and analogous work;', '(c)AI systems that deploy subliminal techniques for scientific research and for therapeutical purposes;

Amendment 3238
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Annex III - paragraph 1 - point 8 a (new)
8 a. Other applications:', '(a) AI systems intended to be used to generate, on the basis of limited human input, complex text content that would falsely appear to a person to be human-generated and authentic, such as news articles, opinion articles, novels, scripts, and scientific articles, except where the content forms part of an evidently artistic, creative or fictional and analogous work;', '(b) AI systems intended to be used to generate or manipulate audio or video content that appreciably resembles existing natural persons, in a manner that significantly distorts or fabricates the original situation, meaning, content, or context and would falsely appear to a person to be authentic, except where the content forms part of an evidently artistic, creative or fictional cinematographic and analogous work.

Amendment 3239
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Annex III - paragraph 1 - point 8 a (new)
8 a. Use in online platforms such as social media and search engines:', 'a) AI systems intended to recommend content to users of online intermediaries such as social media platforms and search engines', 'b) AI systems intended to assist the moderation of content produced by users of online intermediaries such as social media platforms.

Amendment 3240
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 8 a (new)
8 a. Media', '(a). Recommender systems, meaning AI systems used by an online platform to suggest in its online interface specific information to recipients of the service, including as a result of a search initiated by the recipient or otherwise determining the relative order or prominence of information displayed.

Amendment 3241
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Maria-Manuel Leitão-Marques, Paul Tang, Tiemo Wölken, Biljana Borzan, Lina Gálvez Muñoz, Birgit Sippel, Martin Schirdewan, Christel Schaldemose, Alex Agius Saliba, Karen Melchior, René Repasi, Eva Kaili, Sylvie Guillaume
Annex III - paragraph 1 - point 8 a (new)
8 a. Others', 'a) AI systems intended to be used for the delivery of online advertising to internet users

Amendment 3242
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex III - paragraph 1 - point 8 b (new)
8 b. Health and Healthcare', '(a) AI systems intended to be used inside or outside of the national healthcare system the outputs of which can influence individuals’ health, for example through impacting health diagnostics, treatments or medical prescriptions.', '(b) AI systems intended to be used to facilitate administrative, planning, and health insurance processes within the healthcare system which could influence the distribution of healthcare resources, health insurance or access to healthcare.', '(c) AI systems intended to be used by pharmaceutical companies and medical technology companies to facilitate research and development, as well as for pharmacovigilance, market optimisation and pharmaceutical marketing.

Amendment 3243
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex IV - paragraph 1 - point 1 - point a
(a) its intended purpose, the person/s developing the system the date and the version of the system, reflecting its relation to previous and, where applicable, more recent, versions in the succession of revisions;

Amendment 3244
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Annex IV - paragraph 1 - point 1 - point a
(a) its intended purpose or reasonably foreseeable use, the person/s developing the system, the date and the version of the system;

Amendment 3245
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Annex IV - paragraph 1 - point 1 - point a
(a) its intended purpose or reasonably foreseeable use , the person/s developing the system the date and the version of the system;

Amendment 3246
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Annex IV - paragraph 1 - point 1 - point a
(a) its intended purpose or reasonably foreseeable use, the person/s developing the system the date and the version of the system;

Amendment 3247
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex IV - paragraph 1 - point 1 - point a a (new)
(a) its intended purpose, the name of the provider and the version of the system;

Amendment 3248
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex IV - paragraph 1 - point 1 - point a a (new)
(a a) the categories of natural persons and groups likely or foreseen to be affected;

Amendment 3249
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex IV - paragraph 1 - point 1 - point a b (new)
(a b) the categories and nature of data likely or foreseen to be processed;

Amendment 3250
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex IV - paragraph 1 - point 1 - point b
(b) how the AI system interacts or can be used to interact with hardware or software, including other AI systems that are not part of the AI system itself, where applicable;

Amendment 3251
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Annex IV - paragraph 1 - point 1 - point b
(b) how the AI system interacts or can be used to interact with hardware or software, including other AI systems, that are not part of the AI system itself, where applicable;

Amendment 3252
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex IV - paragraph 1 - point 1 - point b
(b) how the AI system is intended to be used with hardware or software that is not part of the AI system itself, where applicable;

Amendment 3253
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex IV - paragraph 1 - point 1 - point c
(c) the versions of relevant software or firmware and any requirement related to development, maintenance and version update;

Amendment 3254
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex IV - paragraph 1 - point 1 - point c
(c) the versions of relevant software or firmware and version update information for the user, where applicable;

Amendment 3255
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex IV - paragraph 1 - point 1 - point d
(d) the description or list of the various configurations and variants of the AI system which are intended to be made available on the market or put into service;

Amendment 3256
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex IV - paragraph 1 - point 1 - point f
(f) descriptions and, if applicable, photographs or illustrations of the user interface;

Amendment 3257
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex IV - paragraph 1 - point 1 - point g
(g) instructions of use for the deployer and, where applicable installation instructions;

Amendment 3258
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex IV - paragraph 1 - point 1 - point g a (new)
(g a) instructions on the intervention in case of emergency, interrupting the system through a “stop” button or a similar procedure that allows the system to come to a halt in a safe state;

Amendment 3259
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex IV - paragraph 1 - point 2 - introductory part
2. Provided that no confidential information or trade secrets are disclosed, a detailed description of the AI system and of the process for its development, including:

Amendment 3260
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Annex IV - paragraph 1 - point 2 - point a
(a) provided that no confidential information or trade secrets are disclosed, the methods and steps performed for the development of the AI system, including, where relevant, recourse to pre-trained systems or tools provided by third parties and how these have been used, integrated or modified by the provider;

Amendment 3261
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex IV - paragraph 1 - point 2 - point b
(b) the architecture and design specifications: a description of the AI system architecture, with a decomposition of its components and interfaces, how they relate to one another and how they provide for the overall processing or logic of the AI system; the key design choices including the rationale and assumptions made, also with regard to persons or groups of persons on which the system is intended to be used; the main classification choices; what the system is designed to optimise for and the relevance of the different parameters; the decisions about any possible trade-off made regarding the technical solutions adopted to comply with the requirements set out in Title III, Chapter 2;

Amendment 3262
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Annex IV - paragraph 1 - point 2 - point b
(b) provided that no confidential information or trade secrets are disclosed, the design specifications of the system, namely the general logic of the AI system and of the algorithms; the key design choices including the rationale and assumptions made, also with regard to persons or groups of persons on which the system is intended to be used; the main classification choices; what the system is designed to optimise for and the relevance of the different parameters; the decisions about any possible trade-off made regarding the technical solutions adopted to comply with the requirements set out in Title III, Chapter 2;

Amendment 3263
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex IV - paragraph 1 - point 2 - point b
(b) the design specifications of the system, namely the general logic of the AI system, of the algorithms and of data structures; the key design choices including the rationale and assumptions made, also with regard to persons or groups of persons on which the system is intended to be used; the main classification choices; what the system is designed to optimise for and the relevance of the different parameters; the decisions about any possible trade-off made regarding the technical solutions adopted to comply with the requirements set out in Title III, Chapter 2;

Amendment 3264
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex IV - paragraph 1 - point 2 - point c
deleted

Amendment 3265
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex IV - paragraph 1 - point 2 - point d
deleted

Amendment 3266
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex IV - paragraph 1 - point 2 - point d
(d) where relevant, the data requirements in terms of datasheets describing the training methodologies and techniques and the training data sets used, including information about the provenance of those data sets, their scope and main characteristics; how the data was obtained, selected and prepared; labelling procedures (e.g. for supervised learning), data cleaning methodologies (e.g. outliers detection), and methods applied to prevent bias;

Amendment 3267
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex IV - paragraph 1 - point 2 - point e
(e) assessment of the human oversight measures needed in accordance with Article 14, including an assessment of the technical measures needed to facilitate the interpretation of the outputs of AI systems by the deployers, in accordance with Articles 13(3)(d);

Amendment 3268
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex IV - paragraph 1 - point 2 - point g
(g) the validation and testing procedures used, including information about the machine-learning validation and testing data used and their main characteristics; information used to measure accuracy, robustness, and compliance with other relevant requirements set out in Title III, Chapter 2 as well as potentially discriminatory impacts; test logs and all test reports dated and signed by the responsible persons, including with regard to pre-determined changes as referred to under point (f);

Amendment 3269
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Annex IV - paragraph 1 - point 2 - point g
(g) the validation and testing procedures used, including information about the validation and testing data used and their main characteristics; metrics used to measure performance, robustness, cybersecurity and compliance with other relevant requirements set out in Title III, Chapter 2 as well as potentially discriminatory impacts; test logs and all test reports dated and signed by the responsible persons, including with regard to pre-determined changes as referred to under point (f).

Amendment 3270
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Annex IV - paragraph 1 - point 2 - point g
(g) the validation and testing procedures used, including information about the validation and testing data used and their main characteristics; metrics used to measure performance, robustness, cybersecurity and compliance with other relevant requirements set out in Title III, Chapter 2 as well as potentially discriminatory impacts; test logs and all test reports dated and signed by the responsible persons, including with regard to pre-determined changes as referred to under point (f).

Amendment 3271
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex IV - paragraph 1 - point 2 - point g a (new)
(g a) cybersecurity measures put in place.

Amendment 3272
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Annex IV - paragraph 1 - point 3
3. Detailed information about the monitoring, functioning and control of the AI system, in particular with regard to: its capabilities and limitations in performance, including the degrees of accuracy for specific persons or groups of persons on which the system is intended to be used and the overall expected level of accuracy in relation to its intended purpose or reasonably foreseeable use ; the foreseeable unintended outcomes and sources of risks to health and safety, fundamental rights and discrimination in view of the intended purpose or reasonably foreseeable use of the AI system; the human oversight measures needed in accordance with Article 14, including the technical measures put in place to facilitate the interpretation of the outputs of AI systems by the users; specifications on input data, as appropriate;

Amendment 3273
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Annex IV - paragraph 1 - point 3 a (new)
3 a. A description of the appropriateness of the performance metrics for the specific AI system;

Amendment 3274
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Annex IV - paragraph 1 - point 3 a (new)
3 a. A description of the appropriateness of the performance metrics for the specific AI system.

Amendment 3275
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina Penkova, Petar Vitanov, René Repasi, Birgit Sippel, Maria Grapini, Adriana Maldonado López, Maria-Manuel Leitão-Marques, Marc Angel
Annex IV - paragraph 1 - point 3 b (new)
3 b. Detailed information about the carbon footprint and the energy efficiency of the AI system, in particular with regard to the development of hardware, computational resources, as well as algorithm design and training processes;

Amendment 3276
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Annex IV - paragraph 1 - point 3 c (new)
3 c. Information about the computational resources required for the functioning of the AI system and its expected energy consumption during its use;

Amendment 3277
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex IV - paragraph 1 - point 4 a (new)
4 a. A detailed description of the system’s environmental impact in accordance with Article 10a.

Amendment 3278
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex IV - paragraph 1 - point 5
deleted

Amendment 3279
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Vlad-Marius Botoş,
Annex IV - paragraph 1 - point 5
5. A description of relevant changes made by providers to the system through its lifecycle;

Amendment 3280
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Annex IV - paragraph 1 - point 6
5. A description of any relevant change made to the system through its lifecycle;

Amendment 3281
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Annex IV - paragraph 1 - point 6
6. A list of the harmonised standards applied in full or in part the references of which have been published in the Official Journal of the European Union; where no such harmonised standards have been applied, a detailed description of the solutions adopted to meet the requirements set out in Title III, Chapter 2, including a list of common specifications or other relevant standards and technical specifications applied;

Amendment 3282
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Annex IV - paragraph 1 - point 8 a (new)
8 a. Without prejudice to Article 9(2), a detailed description of the economic and social implications and potential risks for health, and in particular mental health, safety and fundamental rights arising from the hypothetical widespread usage of the AI system or of similar systems in society, with reference to past incidents that occurred using similar systems and associated mitigating measures.

Amendment 3283
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Annex VI
deleted

Amendment 3284
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex VII - point 4 - point 4.3
4.3. The technical documentation shall be examined by the notified body. To this purpose, the notified body shall be granted full access to the testing datasets used by the provider, including through application programming interfaces (API) or other appropriate means and tools enabling remote access.

Amendment 3285
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex VII - point 4 - point 4.4
4.4. In examining the technical documentation, the notified body may require that the provider supplies further evidence or carries out further tests so as to enable a proper assessment of conformity of the AI system with the requirements set out in Title III, Chapter 2.

Amendment 3286
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Annex VII - point 4 - point 4.5
4.5. Where necessary to assess the conformity of the high-risk AI system with the requirements set out in Title III, Chapter 2, after all other reasonable ways to verify conformity have been exhausted and have proven to be insufficient, and upon a reasoned request, the notified body shall also be granted access to the source code of the AI system. Such access shall be subject to existing Union law on the protection of intellectual property and trade secrets.

Amendment 3287
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Annex VII - point 4 - point 4.7
4.7. Any change to the AI system that could affect the compliance of the AI system with the requirements or its intended purpose or reasonably foreseeable use shall be approved by the notified body which issued the EU technical documentation assessment certificate. The provider shall inform such notified body of its intention to introduce any of the above-mentioned changes or if it becomes otherwise aware of the occurrence of such changes. The intended changes shall be assessed by the notified body which shall decide whether those changes require a new conformity assessment in accordance with Article 43(4) or whether they could be addressed by means of a supplement to the EU technical documentation assessment certificate. In the latter case, the notified body shall assess the changes, notify the provider of its decision and, where the changes are approved, issue to the provider a supplement to the EU technical documentation assessment certificate.

Amendment 3288
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Annex VIII - title
INFORMATION TO BE SUBMITTED UPON THE REGISTRATION OF HIGH-RISK AI SYSTEMS AND OF CERTAIN AI SYSTEMS, USES THEREOF, AND USES OF AI SYSTEMS BY PUBLIC AUTHORITIES IN ACCORDANCE WITH ARTICLE 51

Amendment 3289
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Annex VIII - title
INFORMATION TO BE SUBMITTED UPON THE REGISTRATION OF AI SYSTEMS IN ACCORDANCE WITH ARTICLE 60

Amendment 3290
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Annex VIII - paragraph 1
The following information shall be provided and thereafter kept up to date by the provider with regard to high-risk AI systems referred to in Article 6(2) and to any AI system referred to in Article 52 1(b) and (2) to be registered in accordance with Article 51(1).

Amendment 3291
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex VIII - paragraph 1
The following information shall be provided and thereafter kept up to date with regard to AI systems to be registered in accordance with Article 51.

Amendment 3292
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Annex VIII - paragraph 1
The following information shall be provided and thereafter kept up to date with regard to AI systems to be registered in accordance with Article 60.

Amendment 3293
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Annex VIII - paragraph 1 a (new)
The following information shall be provided and thereafter kept up to date by the user with regard to uses of high-risk AI systems referred to in Article 6(2) and any AI system referred to in Article 52 1(b) and (2) to be registered in accordance with Article 51(2).', '(a) Name, address and contact details of the user;', '(b) Where submission of information is carried out by another person on behalf of the user, the name, address and contact details of that person;', '(c) Name, address and contact details of the authorised representative, where applicable;', '(d) URL of the entry of the AI system in the EU database by its provider, or, where unavailable, AI system trade name and any additional unambiguous reference allowing identification and traceability of the AI system;', '(e) Description of the intended purpose of the intended use of the AI system;', '(f) Description of the context and the geographical and temporal scope of application, geographic and temporal, of the intended use of the AI system;', '(g) Basic explanation of design specifications of the system, namely the general logic of the AI system and of the algorithms;the key design choices including the rationale and assumptions made, also with regard to categories persons or groups of persons on which the system is intended to be used;the main classification choices;and what the system is designed to optimise for and the relevance of the different parameters.', '(h) For high-risk AI systems and for systems referred to in Article 52 1(b) and (2), designation of persons foreseeably impacted by the intended use of the AI system as required by Article X;', '(i) For high-risk AI systems, results of the impact assessment on the use of the AI system that is conducted under obligations imposed by Article XX of this Regulation.Where full public disclosure of these results cannot be granted for reasons of privacy and data protection, disclosure must be granted to the national supervisory authority, which in turn must be indicated in the EU database.', '(j) A description of how the relevant accessibility requirements set out in Annex I to Directive 2019/882 are met by the use of the AI system.

Amendment 3294
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Annex VIII - paragraph 1 a (new)
1a.The following information shall be provided and updated with regard to high risk AI systems to be registered in accordance with Article 51(2) by users who are or act on behalf of public authorities or Union institutions, bodies, offices or agencies:', '1. the name, address and contact details of the user;', '2. the name, address and contact details of any person submitting information on behalf of the user;', '3. the high-risk AI system trade name and any additional unambiguous reference allowing identification and traceability of the AI system used;', '4. description of the intended use of the AI system, including the specific outcomes sought through the use of the system;', '5. a summary of the findings of the fundamental rights impact assessment conducted in accordance with the obligation of public authorities or Union institutions, agencies, offices or bodies set out in this Regulation;', '6. a summary of the data protection impact assessment carried out in accordance with Article 35 of Regulation (EU) 2016/679 or Article 27 of Directive (EU) 2016/680 as specified in paragraph 6 of Article 29 of this Regulation, where applicable; 6. a declaration of conformity with the applicable data protection rules.

Amendment 3295
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Annex VIII - paragraph 1 b (new)
The following information shall be provided and thereafter kept up to date by the user with regard to uses of AI systems by public authorities to be registered in accordance with Article 51(3).', '(a) Name, address and contact details of the user;(b) Where submission of information is carried out by another person on behalf of the user, the name, address and contact details of that person;', '(c) Name, address and contact details of the authorised representative, where applicable;', '(d) For high-risk AI systems, URL of the entry of the AI system in the EU database by its provider, or, for non-high risk systems, AI system trade name and any additional unambiguous reference allowing identification and traceability of the AI system;', '(e) Description of the intended purpose of the intended use of the AI system;', '(f) Description of the context and the geographical and temporal scope of application, geographic and temporal, of the intended use of the AI system;', '(g) Basic explanation of design specifications of the system, namely the general logic of the AI system and of the algorithms;the key design choices including the rationale and assumptions made, also with regard to categories persons or groups of persons on which the system is intended to be used;the main classification choices;and what the system is designed to optimise for and the relevance of the different parameters.', '(h) Designation of persons foreseeably impacted by the intended use of the AI system;', '(i) If available, results of any impact assessment or due diligence process regarding the use of the AI system that the user has conducted;', '(j) Assessment of the foreseeable impact on the environment, including but not limited to energy consumption, resulting from the use of the AI system over its entire lifecycle, and of the methods to reduce such impact;', '(k) A description of how the relevant accessibility requirements set out in Annex I to Directive 2019/882 are met by the use of the AI system.

Amendment 3296
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex VIII - point 1
1. Name, address and contact details of the provider or deployer;

Amendment 3297
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex VIII - point 2
2. Where submission of information is carried out by another person on behalf of the provider or deployer, the name, address and contact details of that person;

Amendment 3298
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Annex VIII - point 5
3. Name, address and contact details of the legal representative, where applicable;

Amendment 3299
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex VIII - point 5
5. Descriptions of:', '(a) the intended purpose of the AI system;', '(b) the components and functions supported through AI;', '(c) the main parameters the AI system takes into account;', '(d) arrangements for human oversight and responsible natural persons for decisions made or influenced by the AI system;

Amendment 3300
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Annex VIII - point 5
5. Description of the intended purpose or reasonably foreseeable use of the AI system;

Amendment 3301
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex VIII - point 5 a (new)
5 a. Where applicable, the categories of natural persons and groups likely or foreseen to be affected;

Amendment 3302
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex VIII - point 5 b (new)
5 b. Where applicable, the categories and nature of data likely or foreseen to be processed by the AI system;

Amendment 3303
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex VIII - point 5 c (new)
5 c. For each deployment, the deployer’s assessments of the assessment of the systems’ impact in the context of use throughout the entire lifecycle as conducted by the deployer under Article 9a;

Amendment 3304
Renew - Renew Europe Group
Sophia in t Veld, Michal Šimečka
Annex VIII - point 6 a (new)
6 a. where the user is obliged to register an AI system under Article 29, the human rights impact assessment must also be registered and publicly available;

Amendment 3305
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex VIII - point 11
deleted

Amendment 3306
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky
Annex VIII - point 11
11. Electronic instructions for use.

Amendment 3307
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Annex VIII - point 11
11. Electronic instructions for use as listed in Article 13(3) and basic explanation of the general logic and key design as listed in Annex IV point 2(b) and of optimization choices as listed in Annex IV point (3).

Amendment 3308
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Annex VIII - point 11 a (new)
11 a. Assessment of the environmental impact, including but not limited to resource consumption, resulting from the design, data management and training, and underlying infrastructures of the AI system, and of the methods to reduce such impact;

Amendment 3309
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Annex VIII - point 11 b (new)
11 b. A description of how the system meets the relevant accessibility requirements of Annex I to Directive 2019/882.

Amendment 3310
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Annex VIII - point 12 a (new)
12 a. The list of users of the AI systems

Amendment 3311
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Annex IX - title
4. The sandboxing programme shall, in a later development phase, look at helping Member States develop and manage two types of regulatory sandboxes: Physical Regulatory Sandboxes for AI systems embedded in physical products or services and Cyber Regulatory Sandboxes for AI systems operated and used on a stand-alone basis, not embedded in physical products or services.

Amendment 3312
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz Körner, Ondřej
Annex IX a (new)
ANNEX IXa:  MODALITIES FOR AN EU AI REGULATORY SANDBOXING PROGRAMME', '1.The European Commission shall establish the EU AI Regulatory Sandboxing Programme (‘sandboxing programme’) in collaboration with Member States and other competent entities such as regions or universities.', '2.The Commission shall play a complementary role, allowing those entities with demonstrated experience with sandboxing to build on their expertise and, on the other hand, assisting and providing technical understanding and resources to those Member States and regions that seek guidance on the set-up of these regulatory sandboxes.', '3.Participants in the sandboxing programme, in particular start-ups and SMEs, are granted access to pre-deployment services, such as preliminary registration of their AI system, compliance R&D support services, and to all the other relevant elements of the Union’s AI ecosystem and other Digital Single Market initiatives such as Testing &Experimentation Facilities, Digital Hubs, Centres of Excellence, and EU benchmarking capabilities;and to other value-adding services such as standardisation documents and certification, an online social platform for the community, contact databases, existing portal for tenders and grant making and lists of EU investors.', '4.Foreign providers, in particular start-ups and SMEs, are eligible to take part in the sandboxes to incubate and refine their products incompliance with this Regulation.', '5.Individuals such as researchers, entrepreneurs, innovators and other pre-market ideas owners are eligible to pre-register into the sandboxing programme to incubate and refine their products in compliance with this Regulation.', '6.The sandboxing programme and its benefits shall be available from a single portal established by the European Commission.', '7.The sandboxing programme shall develop and manage two types of regulatory sandboxes:Physical Regulatory Sandboxes for AI systems embedded in physical products or services and Cyber Regulatory Sandboxes for AI systems operated and used on a stand-alone basis, not embedded in physical products or services.', '8.The sandboxing programme shall work with the already established Digital Innovation Hubs in Member States to provide a dedicated point of contact for entrepreneurs to raise enquiries with competent authorities and to seek non-binding guidance on the conformity of innovative products, services or business models embedding AI technologies.', '9.One of the objectives of the sandboxing programme is to enable firms’ compliance with this Regulation at the design stage of the AI system (‘compliance-by-design’).To do so, the programme shall facilitate the development of software tools and infrastructure for testing, benchmarking, assessing and explaining dimensions of AI systems relevant to sandboxes, such as accuracy, robustness and cybersecurity.', '10.The sandboxing programme shall include a Reg Tech lab, to help authorities experiment and develop enforcement tools and protocols for enforcing this Regulation.', '11. The sandboxing programme shall be rolled out in a phased fashion, with the various phases launched by the Commission upon success of the previous phase. The sandboxing programme will have a built-in impact assessment procedure to facilitate the review of cost-effectiveness against the agreed-upon objectives. This assessment shall be drafted with input from Member States based on their experiences and shall be included as part of the Annual Report submitted by the Commission to the European Artificial Intelligence Board.

