Amendment 313
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 1
(1) The purpose of this Regulation is to improve the functioning of the internal market by laying down a uniform minimum legal framework in particular for the development, marketing and use of artificial intelligence in conformity with Union values. This Regulation pursues a number of overriding reasons of public interest, such as a high level of protection of health, safety and fundamental rights, as well as the environment, society, rule of law and democracy, economic interests and consumer protection. It also ensures the free movement of AI-based goods and services cross-border, thus preventing Member States from imposing restrictions on the development, marketing and use of AI systems, unless explicitly authorised by this Regulation, or justified by the need to ensure the protection of the rights and freedoms of natural persons, or the ethical principles advocated by this Regulation

Amendment 314
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 1
(1) The purpose of this Regulation is to ensure a high level of protection of fundamental rights, health, safety and the environment, as well as the Union values enshrined in Article 2 of the Treaty on European Union (TEU), from harmful effects of the use of artificial intelligence systems in the Union while enhancing innovation and improving the functioning of the internal market. This Regulation lays down a uniform legal framework in particular for the development, the placing on the market, the putting into service and the use of artificial intelligence in conformity with Union values and it ensures the free movement of AI-based goods and services cross-border, thus preventing Member States from imposing restrictions on the development, marketing and use of AI systems, unless explicitly authorised by this Regulation.

Amendment 315
ECR - European Conservatives and Reformists Group
Vincenzo Sofo, Kosma Złotowski
Recital 1
(1) The purpose of this Regulation is to improve the functioning of the internal market by laying down a uniform legal framework in particular for the development, marketing and use of artificial intelligence in conformity with Union values, the Universal Declaration of Human Rights, the European Convention on Human Rights and the Charter of Fundamental Rights of the EU. This Regulation pursues a number of overriding reasons of public interest, such as a high level of protection of health, safety and fundamental rights, and it ensures the free movement of AI-based goods and services cross-border, thus preventing Member States from imposing restrictions on the development, marketing and use of AI systems, unless explicitly authorised by this Regulation.

Amendment 316
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 1
(1) The purpose of this Regulation is to improve the functioning of the internal market by laying down a uniform legal framework in particular for the development, the placing on the market, the putting into service and the marketing and use of artificial intelligence in conformity with Union values. This Regulation pursues a number of overriding reasons of public interest, such as a high level of protection of health, safety, fundamental rights, the environment and the Union values enshrined in Article 2 of the Treaty on European Union (TEU), and it ensures the free movement of AI-based goods and services cross-border, thus preventing Member States from imposing restrictions on the development, marketing and use of AI systems, unless explicitly authorised by this Regulation.

Amendment 317
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 1
(1) The purpose of this Regulation is to improve the functioning of the internal market by laying down a uniform legal framework in particular for the development, marketing and use of artificial intelligence in conformity with Union values. This Regulation pursues a number of overriding reasons of public interest, such as a high level of protection of health, safety and fundamental rights, and it ensures the free movement of AI-based goods and services cross-border, thus preventing Member States from imposing restrictions on the development, marketing and use of AI systems, unless explicitly authorised by this Regulation and without prejudice to stricter national legislation governing the protection of fundamental rights.

Amendment 318
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 1
(1) The purpose of this Regulation is to improve the functioning of the internal market by laying down a uniform legal framework in particular for the development, marketing and use of artificial intelligence in conformity with Union values. This Regulation pursues a number of overriding reasons of public interest, such as a high level of protection of health, safety, environment and fundamental rights, as well as consumer protection and it ensures the free movement of AI-based goods and services cross-border, thus preventing Member States from imposing restrictions on the development, marketing and use of AI systems, unless explicitly authorised by this Regulation.

Amendment 319
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 1 a (new)
(1 a) The term “artificial intelligence” (AI) refers to systems developed by humans that can, using different techniques and approaches, generate outputs such as content, predictions, recommendations and decisions. The context they are used in is decisive for how much and what kind of influence they can have, and whether they are perceived by an observer as “intelligent”. The term “automated decision-making” (ADM) has been proposed as it could avoid the possible ambiguity of the term AI. ADM involves a user delegating initially a decision, partly or completely, to an entity by way of using a system or a service. That entity then uses automatically executed decision-making models to perform an action on behalf of a user, or to inform the user’s decisions in performing an action

Amendment 320
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 2
(2) Artificial intelligence systems (AI systems) can be easily deployed in multiple sectors of the economy and society, including cross border, and circulate throughout the Union. Certain Member States have already explored the adoption of national rules to ensure that artificial intelligence is safe and is developed and used in compliance with fundamental rights obligations. A consistent and high level of protection throughout the Union should therefore be ensured, while divergences hampering the free circulation of AI systems and related products and services within the internal market should be prevented, by laying down uniform obligations for operators and guaranteeing the uniform protection of overriding reasons of public interest and of rights of persons throughout the internal market based on Article 114 of the Treaty on the Functioning of the European Union (TFEU). To the extent that this Regulation contains specific rules on the protection of individuals with regard to the processing of personal data concerning restrictions of the use of AI systems biometric identification in publicly accessible spaces, it is appropriate to base this Regulation, in as far as those specific rules are concerned, on Article 16 of the TFEU. In light of those specific rules and the recourse to Article 16 TFEU, it is appropriate to consult the European Data Protection Board.

Amendment 321
ECR - European Conservatives and Reformists Group
Vincenzo Sofo, Kosma Złotowski
Recital 2
(2) Artificial intelligence systems (AI systems) can be easily deployed in multiple sectors of the economy and society, including cross border, and circulate throughout the Union. Certain Member States have already explored the adoption of national rules to ensure that artificial intelligence is safe and is developed and used in compliance with fundamental rights obligations. Differing national rules may lead to fragmentation of the internal market and decrease legal certainty for operators that develop or use AI systems. A consistent and high level of protection throughout the Union should therefore be ensured, while divergences hampering the free circulation of AI systems and related products and services within the internal market should be prevented, by laying down uniform obligations for operators and guaranteeing the uniform protection of overriding reasons of public interest and of rights of persons throughout the internal market based on Article 114 of the Treaty on the Functioning of the European Union (TFEU). To the extent that this Regulation contains specific rules on the protection of individuals with regard to the processing of personal data concerning restrictions of the use of AI systems for ‘real-time’ remote biometric identification in publicly accessible spaces for the purpose of law enforcement, it is appropriate to base this Regulation, in as far as those specific rules are concerned, on Article 16 of the TFEU and to align it with relevant EU legislation such as the GDPR and the EUDPR. In light of those specific rules and the recourse to Article 16 TFEU, it is appropriate to consult the European Data Protection Board and to take into consideration the EDPB-EDPS Joint Opinion 5/2021.

Amendment 322
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 2
(2) Artificial intelligence systems (AI systems) can be easily deployed in multiple sectors of the economy and society, including cross border, and circulate throughout the Union. Certain Member States have already explored the adoption of national rules to ensure that artificial intelligence is safe and is developed and used in compliance with fundamental rights obligations. Differing national rules may lead to fragmentation of the internal market and decrease legal certainty for operators that develop or use AI systems. A consistent and high level of protection throughout the Union should therefore be ensured, while divergences hampering the free circulation of AI systems and related products and services within the internal market should be prevented, by laying down uniform obligations for operators and guaranteeing the uniform protection of overriding reasons of public interest and of rights of persons throughout the internal market based on Article 114 of the Treaty on the Functioning of the European Union (TFEU). To the extent that this Regulation contains specific rules on the protection of individuals with regard to the processing of personal data concerning restrictions of the use of AI systems for ‘real-time’ remote biometric identification in publicly accessible and online spaces for the purpose of law enforcement, it is appropriate to base this Regulation, in as far as those specific rules are concerned, on Article 16 of the TFEU. In light of those specific rules and the recourse to Article 16 TFEU, it is appropriate to consult the European Data Protection Board.

Amendment 323
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 2
(2) Artificial intelligence systems (AI systems) can be easily deployed in multiple sectors of the economy and society, including cross border, and circulate throughout the Union. Certain Member States have already explored the adoption of national rules to ensure that artificial intelligence is safe and is developed and used in compliance with fundamental rights obligations. Differing national rules may lead to fragmentation of the internal market and decrease legal certainty for operators that develop or use AI systems. A minimum, consistent and high level of protection throughout the Union should therefore be ensured, while divergences hampering the free circulation of AI systems and related products and services within the internal market should be prevented, by laying down uniform obligations for operators and guaranteeing the uniform protection of overriding reasons of public interest and of rights of persons throughout the internal market based on Article 114 of the Treaty on the Functioning of the European Union (TFEU). To the extent that this Regulation contains specific rules on the protection of individuals with regard to the processing of personal data concerning restrictions of the use of AI systems for ‘real-time’ remote biometric identification in publicly accessible spaces for the purpose of law enforcement, it is appropriate to base this Regulation, in as far as those specific rules are concerned, on Article 16 of the TFEU. In light of those specific rules and the recourse to Article 16 TFEU, it is appropriate to consult the European Data Protection Board.

Amendment 324
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 2
(2) Artificial intelligence systems (AI systems) can be easily deployed in multiple sectors of the economy and society, including cross border, and circulate throughout the Union. Certain Member States have already explored the adoption of national rules to ensure that artificial intelligence is safe and is developed and used in compliance with fundamental rights obligations. Differing national rules may lead to fragmentation of the internal market and decrease legal certainty for operators that develop or use AI systems. A consistent and high level of protection throughout the Union should therefore be ensured, while divergences hampering the free circulation of AI systems and related products and services within the internal market should be prevented, by laying down uniform obligations for operators and guaranteeing the uniform protection of overriding reasons of public interest and of rights of persons throughout the internal market based on Article 114 of the Treaty on the Functioning of the European Union (TFEU). As AI systems rely on the processing of large volumes of data, including personal data, it is appropriate to base this Regulation on Article 16 of the TFEU, which enshrines the right of everyone to the protection of personal data concerning them and provides for the adoption of rules on the protection of individuals with regard to the processing of personal data. In light of the recourse to Article 16 TFEU, it is appropriate to consult the European Data Protection Board.

Amendment 325
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 2 a (new)
(2 a) However, in line with Article 114(2) TFEU, this Regulation does not affect the rights and interests of employed persons. This Regulation should therefore not affect Community law on social policy and national labour law and practice, that is any legal and contractual provision concerning employment conditions, working conditions, including health and safety at work and the relationship between employers and workers, including information, consultation and participation. This Regulation should not affect the exercise of fundamental rights as recognized in the Member States and at Union level, including the right or freedom to strike or to take other action covered by the specific industrial relations systems in Member States, in accordance with national law and/or practice. Nor should it affect concertation practices, the right to negotiate, to conclude and enforce collective agreement or to take collective action in accordance with national law and/or practice. It should in any case not prevent the Commission from proposing specific legislation on the rights and freedoms of workers affected by AI systems.

Amendment 326
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Maria-Manuel Leitão-Marques, Eva Kaili
Recital 2 a (new)
(2 a) The deployment of artificial intelligence applications across sectors will only accelerate in the years to come. The European Union should therefore consider, in separate legislation, the creation of an Artificial Intelligence Adjustment Fund, which could be beneficial for Member States to cover the accustoming of their labour markets to the new conditions arising from the rapid mass introduction of artificial intelligence systems that could affect specific job sectors.

Amendment 327
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 2 a (new)
(2 a) This Regulation should not affect the restrictions, prohibitions or enforcement that apply where an artificial intelligence practice infringes another EU law, including EU acquis on data protection, privacy, or the confidentiality of communications, on non discrimination, consumer protection or on competition.

Amendment 328
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Recital 3 a (new)
(3 a) The development of AI applications might bring down the costs and increase the volume of services available, e.g. health services, public transport, Farming 4.0, making them more affordable to a wider spectrum of society; that AI applications may also result in the rise of unemployment, pressure on social care systems, and an increase of poverty; in accordance with the values enshrined in Article 3 of the Treaty on European Union, there might be a need to adapt the Union AI transformation to socioeconomic capacities, to create adequate social shielding, support education and incentives to create alternative jobs; the establishment of a Union AI Adjustment Fund building upon the experience of The European Globalisation Adjustment Fund (EGF) or the currently developed Just Transition Fund should be considered;

Amendment 329
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Tomas Tobé, Arba Kokalari
Recital 3 a (new)
(3 a) The deployment of artificial intelligence is critical for European competitiveness and in particular for the success of small and medium-sized enterprises in industrial sectors. AI solutions can support European companies to optimise production processes, predict machinery failures and develop more efficient and smart services. The potential of AI can however only fully materialise if European industry, and in particular SMEs, are provided with a permissive legislative framework which avoids any overregulation that would funnel resources away from R&D towards unnecessary compliance costs.

Amendment 330
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 3 a (new)
(3 a) To ensure that Artificial Intelligence leads to socially and environmentally beneficial outcomes, Member States should support such measures through allocating sufficient resources, including public funding, and giving priority access to regulatory sandboxes to projects led by civil society and social stakeholders. Such projects should be based on the principle of interdisciplinary cooperation between AI developers, experts in equality and non-discrimination, accessibility, and consumer, environmental, and digital rights, and the academic community.

Amendment 331
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 3 a (new)
(3 a) In order for Member States to reach the carbon neutrality targets, European companies should seek to utilise all available technological advancements that can assist in realising this goal. AI is a well-developed and ready-to-use technology that can be used to process the ever-growing amount of data created during industrial, environmental, health and other processes. To facilitate investments in AI-based analysis and optimisation solutions, this Regulation should provide a predictable and proportionate environment for low-risk industrial solutions.

Amendment 332
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 3 a (new)
(3 a) To ensure that Artificial Intelligence leads to socially and environmentally beneficial outcomes, Member States should support such measures through allocating sufficient resources, including public funding, and giving priority access to regulatory sandboxes to projects led by civil society and social stakeholders. Such projects should be based on the principle of interdisciplinary cooperation between AI developers, experts in equality and non-discrimination, accessibility, and consumer, environmental, and digital rights, and the academic community.

Amendment 333
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 3 b (new)
(3 b) Furthermore, in order for Member States to fight against climate change, to achieve climate-neutrality and to meet the Sustainable Development Goals (SDGs), the European companies should ensure the sustainable design of AI systems to reduce resource usage and energy consumption, thereby limiting the risks to the environment; AI systems have the potential to automatically provide businesses with detailed insight into their emissions, including value chains, and forecast future emissions, thus helping to adjust and achieve the Union's emission targets.

Amendment 334
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 4
(4) At the same time, depending on the circumstances regarding its specific application and use, artificial intelligence may generate risks and cause harm to public interests and rights that are protected by Union law, whether individual, societal, environmental, economic, or to the rule of law and democracy. Such harm might be material or immaterial. Harm should be understood as injury or damage to the life, health, physical integrity and the property of a natural or legal person, economic harm to individuals, damage to their environment, security and other aspects defined in the scope of New Approach directives, complemented by collective harms such as harm to society, the democratic process and the environment, or going against core ethical principles. Immaterial harms should be understood as meaning harm as a result of which the affected person suffers considerable detriment, an objective and demonstrable impairment of his or her personal interests and an economic loss calculated having regard, for example, to annual average figures of past revenues and other relevant circumstances. Such immaterial harm can therefore consist of psychological harm, reputational harm or change in legal status. Harm can be caused (i) by single events and (ii) through exposure over time to harmful algorithmic practices, as well as (iii) through action distributed among a number of actors where the entity causing the harm is not necessarily that which uses the AI or (iv) through uses of AI which are different than intended for the given system.

Amendment 335
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 4
(4) At the same time, depending on the circumstances regarding its specific application and use, as well as the level of technological development, artificial intelligence may generate risks and cause harm to public interests and rights that are protected by Union law. Such harm might be material or immaterial, including physical, psychological, societal or economic harm.

Amendment 336
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 4
(4) At the same time, depending on the circumstances regarding its specific application and use, artificial intelligence may generate risks and cause harm to public interests and rights that are protected by Union law. Such harm might be material or immaterial and might affect one or more persons, a groups of persons or society as a whole, as well as the environment.

Amendment 337
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 4
(4) At the same time, depending on the circumstances regarding its specific application and use, artificial intelligence may generate risks and cause harm to public and private interests and rights that are protected by Union law. Such harm might be material or immaterial.

Amendment 338
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 4 a (new)
(4 a) In order to ensure the dual green and digital transition, and secure the technological resilience of the EU, to reduce the carbon footprint of artificial intelligence and achieve the objectives of the new European Green Deal, this Regulation should contribute to the promotion of a green and sustainable artificial intelligence and to the consideration of the environmental impact of AI systems throughout their lifecycle. Sustainability should be at the core at the European artificial intelligence framework to guarantee that the development of artificial intelligence is compatible with sustainable development of environmental resources for current and future generations, at all stages of the lifecycle of artificial intelligence products; sustainability of artificial intelligence should encompass sustainable data sources, data centres, resource use, power supplies and infrastructure;

Amendment 339
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Bettina Vollath
Recital 4 a (new)
(4 a) AI available in the Union market or otherwise affecting people in the Union should be designed human centered, so that people can trust that the technology is used in a way that is safe and compliant with the law, including the respect of fundamental rights what requires a shift towards a Human Centered AI Engineering, also in research and education.

Amendment 340
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 4 a (new)
(4 a) The concept of decision autonomy for machines is at its core in conflict with fundamental notions of our societies, such as human dignity, autonomy, and the rights to private life and the protection of personal data. This Regulation should reconcile the potential benefits to society offered by AI with the primacy of humans over machines;

Amendment 341
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 4 b (new)
(4 a) Given the major impact that artificial intelligence can have on society and the need to build trust, it is vital for artificial intelligence systems to respect the principles of fairness, accountability, transparency and accountability, privacy and security, and social benefit.

Amendment 342
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 4 b (new)
(4 b) Despite the high potential of solutions to the environmental and climate crisis offered by artificial intelligence, the design, training and execution of algorithms imply a high energy consumption and, consequently, high levels of carbon emissions. Artificial intelligence technologies and data centres have a high carbon footprint due to increased computational energy consumption, and high energy costs due to the volume of data stored and the amount of heat, electric and electronic waste generated, thus resulting in increased pollution. These environmental and carbon footprints are expected to increase overtime as the volume of data transferred and stored and the increasing development of artificial intelligence applications will continue to grow exponentially in the years to come. It is therefore important to minimise the climate and environmental footprint of artificial intelligence and related technologies and that AI systems and associated machinery are designed sustainably to reduce resource usage and energy consumption, thereby limiting the risks to the environment.

Amendment 343
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 4 c (new)
(4 c) To promote the sustainable development of AI systems and in particular to prioritise the need for sustainable, energy efficient data centres, requirements for efficient heating and cooling of data centres should be consistent with the long-term climate and environmental standards and priorities of the Union and comply with the principle of 'do no significant harm' within the meaning of Article 17 of Regulation (EU) 2020/852 on the establishment of a framework to facilitate sustainable investment, and should be fully decarbonised by January 2050. In this regard, Member States and telecommunications providers should collect and publish information relating to the energy performance and environmental footprint for artificial intelligence technologies and date centres including information on the energy efficiency of algorithms to establish a sustainability indicator for artificial intelligence technologies. A European code of conduct for datacentre energy efficiency can establish key sustainability indicators to measure four basic dimensions of a sustainable data centre, namely, how efficiently it uses energy, the proportion of energy generated from renewable energy sources, the reuse of any waste and heat, and the usage of fresh water.

Amendment 344
EPP - Group of the European Peoples Party (Christian Democrats)
Karlo Ressler
Recital 5
(5) A Union legal framework laying down harmonised rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time meets a high level of protection of public interests, such as health and safety and the protection of fundamental rights, as recognised and protected by Union law. To achieve that objective, rules regulating the placing on the market and putting into service of certain AI systems should be laid down, thus ensuring the smooth functioning of the internal market and allowing those systems to benefit from the principle of free movement of goods and services. These rules should be supportive to new innovative solutions and robust in protecting fundamental rights of all the actors. By laying down those rules, this Regulation supports the objective of the Union of being a global leader in the development of secure, trustworthy and ethical artificial intelligence, as stated by the European Council, and it ensures the protection of ethical principles, as specifically requested. One of the fundamental principles of this legislative framework is that there is no doubt between the protection of fundamental rights or the support of innovation, since this Regulation provides rules that adequately address both of mentioned priorities.

Amendment 345
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 5
(5) A Union legal framework laying down harmonised rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time meets a high level of protection of public interests, such as health and safety, the protection of fundamental rights, as recognised and protected by Union law, the environment and the Union values enshrined in Article 2 TEU. To achieve that objective, rules regulating the development, the placing on the market, and the putting into service and the use of certain AI systems should be laid down, thus ensuring the smooth functioning of the internal market and allowing those systems to benefit from the principle of free movement of goods and services. By laying down those rules, this Regulation supports the objective of the Union of being a global leader in the development of secure, trustworthy and ethical artificial intelligence, as stated by the European Council33, and it ensures the protection of ethical principles, as specifically requested by the European Parliament34.' '33 European Council, Special meeting of the European Council (1 and 2 October 2020) - Conclusions, EUCO 13/20, 2020, p. 6.', '34 European Parliament resolution of 20 October 2020 with recommendations to the Commission on a framework of ethical aspects of artificial intelligence, robotics and related technologies, 2020/2012(INL).

Amendment 346
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 5
(5) A Union legal framework laying down harmonised rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time meets a high level of protection of public interests, such as health and safety and the protection of fundamental rights, as recognised and protected by Union law. To achieve that objective, rules regulating the placing on the market and putting into service of certain AI systems should be laid down, thus ensuring the smooth functioning of the internal market and allowing those systems to benefit from the principle of free movement of goods and services. Furthermore, clear rules supporting the application and design of AI systems should be laid down, thus enabling a European ecosystem of public and private actors creating AI systems in line with European values. By laying down those rules, this Regulation supports the objective of the Union of being a global leader in the development of secure, trustworthy and ethical artificial intelligence, as stated by the European Council33, and it ensures the protection of ethical principles, as specifically requested by the European Parliament34.' '33 European Council, Special meeting of the European Council (1 and 2 October 2020) - Conclusions, EUCO 13/20, 2020, p. 6.', '34 European Parliament resolution of 20 October 2020 with recommendations to the Commission on a framework of ethical aspects of artificial intelligence, robotics and related technologies, 2020/2012(INL).

Amendment 347
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 5
(5) A Union legal framework laying down harmonised rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time guarantees a high level of protection of public interests, such as health and safety and the protection of fundamental rights, as recognised and protected by Union law as well as the environment, society, rule of law and democracy, economic interests and consumer protection. To achieve that objective, rules regulating the placing on the market and putting into service of certain AI systems should be laid down, thus ensuring the smooth functioning of the internal market and allowing those systems to benefit from the principle of free movement of goods and services. By laying down those rules, this Regulation supports the objective of the Union of being a global leader in the development of secure, trustworthy and ethical artificial intelligence, as stated by the European Council33 , and it ensures the protection of ethical principles, as specifically requested by the European Parliament34 .' '33 European Council, Special meeting of the European Council (1 and 2 October 2020) - Conclusions, EUCO 13/20, 2020, p. 6.', '34 European Parliament resolution of 20 October 2020 with recommendations to the Commission on a framework of ethical aspects of artificial intelligence, robotics and related technologies, 2020/2012(INL).

Amendment 348
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Dita Charanzová, Andrus Ansip, Morten
Recital 5
(5) A Union legal framework laying down harmonised rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time meets a high level of protection of public interests, such as health and safety and the protection of fundamental rights, as recognised and protected by Union law. To achieve that objective, rules regulating the placing on the market and putting into service of certain AI systems should be laid down, thus ensuring the smooth functioning of the internal market and allowing those systems to benefit from the principle of free movement of goods and services. By laying down those rules as well as measures in support of innovation with a particular focus on SMEs and start-ups, this Regulation supports the objective of the Union of being a global leader in the development of secure, trustworthy and ethical artificial intelligence, as stated by the European Council33 , and it ensures the protection of ethical principles, as specifically requested by the European Parliament34 .' '33 European Council, Special meeting of the European Council (1 and 2 October 2020) - Conclusions, EUCO 13/20, 2020, p. 6.', '34 European Parliament resolution of 20 October 2020 with recommendations to the Commission on a framework of ethical aspects of artificial intelligence, robotics and related technologies, 2020/2012(INL).

Amendment 349
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Recital 5
(5) A Union legal framework laying down harmonised rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time meets a high level of protection of public interests, such as health and safety and the protection of fundamental rights, as recognised and protected by Union law. To achieve that objective, rules regulating the placing on the market and putting into service of certain AI systems should be laid down, thus ensuring the smooth functioning of the internal market and allowing those systems to benefit from the principle of free movement of goods and services. By laying down those rules, this Regulation supports the objective of the Union of promoting the "AI made in Europe" and being a global leader in the development of secure, trustworthy and ethical artificial intelligence, as stated by the European Council33 , and it ensures the protection of ethical principles, as specifically requested by the European Parliament34 .' '33 European Council, Special meeting of the European Council (1 and 2 October 2020) - Conclusions, EUCO 13/20, 2020, p. 6.', '34 European Parliament resolution of 20 October 2020 with recommendations to the Commission on a framework of ethical aspects of artificial intelligence, robotics and related technologies, 2020/2012(INL).

Amendment 350
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Recital 5
(5) A Union legal framework laying down harmonised rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time meets a high level of protection of public interests, such as the protection of fundamental rights, health and safety, as recognised and protected by Union law. To achieve that objective, rules regulating the development, the placing on the market, putting into service and the use of certain AI systems should be laid down, thus ensuring the smooth functioning of the internal market and allowing those systems to benefit from the principle of free movement of goods and services. By laying down those rules, this Regulation supports the objective of the Union of being a global leader in the development of secure, trustworthy and ethical artificial intelligence, as stated by the European Council33 , and it ensures the protection of ethical principles, as specifically requested by the European Parliament34 .' '33 European Council, Special meeting of the European Council (1 and 2 October 2020) - Conclusions, EUCO 13/20, 2020, p. 6.', '34 European Parliament resolution of 20 October 2020 with recommendations to the Commission on a framework of ethical aspects of artificial intelligence, robotics and related technologies, 2020/2012(INL).

Amendment 351
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 5
(5) A Union legal framework laying down harmonised rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time meets a high level of protection of public interests, such as health and the environment and the protection of fundamental rights and values, as recognised and protected by Union law. To achieve that objective, rules regulating the placing on the market and putting into service of certain AI systems should be laid down, thus ensuring the smooth functioning of the internal market and allowing those systems to benefit from the principle of free movement of goods and services. By laying down those rules, this Regulation supports the objective of the Union of being a global leader in the development of secure, trustworthy and ethical artificial intelligence, as stated by the European Council33 , and it ensures the protection of ethical principles, as specifically requested by the European Parliament34 .' '33 European Council, Special meeting of the European Council (1 and 2 October 2020) - Conclusions, EUCO 13/20, 2020, p. 6.', '34 European Parliament resolution of 20 October 2020 with recommendations to the Commission on a framework of ethical aspects of artificial intelligence, robotics and related technologies, 2020/2012(INL).

Amendment 352
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 5 a (new)
(5) A Union legal framework laying down harmonised rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time meets a high level of protection of public and private interests, such as health and safety and the protection of fundamental rights, as recognised and protected by Union law. To achieve that objective, rules regulating the placing on the market and putting into service of certain AI systems should be laid down, thus ensuring the smooth functioning of the internal market and allowing those systems to benefit from the principle of free movement of goods and services. By laying down those rules, this Regulation supports the objective of the Union of being a global leader in the development of secure, trustworthy and ethical artificial intelligence, as stated by the European Council33 , and it ensures the protection of ethical principles, as specifically requested by the European Parliament34 .' '33 European Council, Special meeting of the European Council (1 and 2 October 2020) - Conclusions, EUCO 13/20, 2020, p. 6.', '34 European Parliament resolution of 20 October 2020 with recommendations to the Commission on a framework of ethical aspects of artificial intelligence, robotics and related technologies, 2020/2012(INL).

Amendment 353
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 5 a (new)
(5 a) Furthermore, in order to foster the development of artificial intelligence in line with Union values, the Union needs to address the main gaps and barriers blocking the potential of the digital transformation including the shortage of digitally skilled workers, cybersecurity concerns, lack of investment and access to investment, and existing and potential gaps between large companies, SME’s and start-ups. Special attention should be paid to ensuring that the benefits of AI and innovation in new technologies are felt across all regions of the Union and that sufficient investment and resources are provided especially to those regions that may be lagging behind in some digital indicators.

Amendment 354
ECR - European Conservatives and Reformists Group
Vincenzo Sofo, Kosma Złotowski
Recital 5 a (new)
(5 a) The regulatory framework addressing artificial intelligence should be without prejudice to existing and future Union laws concerning data protection, privacy, and protection of fundamental rights. In this regard, requirements of this Regulation should be consistent with the aims and objectives of, among others, the GDPR and the EUDPR. Where this Regulation addresses automated processing within the context of article 22 of the GDPR, the requirements contained in that article should continue to apply, ensuring the highest levels of protection for European citizens over the use of their personal data.

Amendment 355
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Recital 5 a (new)
(5 a) The Union legal framework for AI should respect existing sector specific legislations and create legal certainty by avoiding duplication and additional administrative burden;

Amendment 356
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 5 b (new)
(5 b) To ensure the development of secure, trustworthy and ethical AI, the European Commission established the High-Level Expert Group on Artificial Intelligence. In formulating both Ethics guidelines for Trustworthy AI and a corresponding Assessment List for Trustworthy Artificial Intelligence, this independent group solidified the foundational ambition for ‘Trustworthy AI’. As noted by the group, Trustworthiness is a prerequisite for people, societies and companies to develop, deploy and use AI systems. Without AI systems - and the human beings behind them - being demonstrably worthy of trust, serious and unwanted consequences may ensue and the uptake of AI might be hindered, preventing the realisation of the potentially vast social and economic benefits that trustworthy AI systems can bring. This approach should be seen as the basis of a European approach to both ensure and scale AI that is innovative and ethical.

Amendment 357
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 6
(6) The notion of AI system should be clearly defined to ensure legal certainty, while providing the flexibility to accommodate future technological developments. This definition should be in line with definitions that have found international acceptance. Moreover, it should be based on the key functional characteristics of artificial intelligence distinguishing it from more classic software systems and modelling approaches such as logistic regression and other techniques that are similarly transparent, explainable and interpretable. For the purposes of this Regulation, the definition should be based on the key functional characteristics of the AI system, in particular its ability, for a given set of human-defined objectives, to make predictions, recommendations, or decisions that influence real or virtual environments, whereby it uses machine and/or human-based data and inputs to (i) perceive real and/or virtual environments; (ii) abstract these perceptions into models through analysis in an automated manner (e.g. with machine learning), or manually; and (iii) use model inference to formulate options for outcomes. AI systems are designed to operate with varying levels of autonomy and can be used on a stand-alone software system, integrated into a physical product (embedded), used to serve the functionality of a physical product without being integrated therein (non-embedded) or used as a subsystem of a software/physical/hybrid system of systems. If an AI system is used as a subsystem of a system of systems, then all parts including their interfaces to other parts of the system of systems that would be obsolete if the AI functionality were turned off or removed are essential parts of the AI system thus fall directly under this regulation. Any parts of the system of systems to which this does not hold true are not covered by this regulation and the obligations listed in this regulation do not apply to them. This is to ensure that the integration of AI systems into existing systems is not blocked by this regulation.

Amendment 358
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Dita Charanzová, Andrus Ansip, Morten Løkkegaard, Vlad-
Recital 6
(6) The notion of AI system should be clearly defined to ensure legal certainty, while providing the flexibility to accommodate future technological developments. Therefore, the term AI system should be defined in line with internationally accepted definitions. The definition should be based on the key functional characteristics of AI systems, in particular the ability, for a given set of human-defined objectives, to generate outputs such as content, predictions, recommendations, or decisions which influence their physical or digital environment. AI systems can be designed to operate with varying levels of autonomy and be used on a stand-alone basis or as a component of a product, irrespective of whether the system is physically integrated into the product (embedded) or serve the functionality of the product without being integrated therein (non-embedded). The definition of AI system should be complemented by a list of specific techniques and approaches used for its development, which should be kept up-to-date in the light of market and technological developments through the adoption of delegated acts by the Commission to amend that list. In order to ensure alignment of definitions on an international level, the European Commission should engage in a dialogue with international organisations such as the Organisation for Economic Cooperation and Development (OECD), should their definitions of the term ‘AI system’ be adjusted.

Amendment 359
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Recital 6
(6) The notion of AI system should be clearly defined to ensure legal certainty, while providing the flexibility to accommodate future technological developments. The definition should be based on the key functional characteristics of the software, in particular the ability to perceive, reason and act on machine and/or human-based inputs, to generate outputs such as content, hypotheses, predictions, recommendations, or decisions which influence the environment with which the system interacts, be it in a physical or digital dimension. AI systems can be designed to operate with varying levels of autonomy and be used on a stand-alone basis or as a component of a product, irrespective of whether the system is physically integrated into the product (embedded) or serve the functionality of the product without being integrated therein (non-embedded).

Amendment 360
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 6
(6) The notion of AI system should be clearly defined to ensure legal certainty, while providing the flexibility to accommodate future technological developments. The definition should be based on the key functional characteristics of the software, in particular the ability to generate outputs such as content, predictions, recommendations, or decisions which influence the environment with which the system interacts, be it in a physical or digital dimension. AI systems can be designed to operate with varying levels of autonomy and be used on a stand-alone basis or as a component of a product, irrespective of whether the system is physically integrated into the product (embedded) or serve the functionality of the product without being integrated therein (non-embedded). AI systems can be developed through various techniques using learning, reasoning or modelling, such as: machine learning approaches, including supervised, unsupervised and reinforcement learning, using a wide variety of methods including deep learning; logic- and knowledge-based approaches, including knowledge representation, inductive (logic) programming, knowledge bases, inference and deductive engines, (symbolic) reasoning and expert systems; statistical approaches, Bayesian estimation, search and optimization methods.

Amendment 361
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 6
(6) The notion of AI system should be clearly defined to ensure legal certainty, while providing the flexibility to accommodate future technological developments. The definition should be based on the key functional characteristics of the software, in particular the ability, for a given set of objectives or parameters which have human control at their origin, to generate outputs such as content, predictions, recommendations, or decisions which influence the environment with which the system interacts, be it in a physical or digital dimension. AI systems can be designed to operate with varying levels of autonomy and be used on a stand-alone basis or as a component of a product, irrespective of whether the system is physically integrated into the product (embedded) or serve the functionality of the product without being integrated therein (non-embedded). The definition of AI system should be complemented by a list of specific techniques and approaches used for its development, which should be kept up-to-date in the light of market and technological developments through the adoption of delegated acts by the Commission to amend that list. These delegated acts should consist only of additions to the list of techniques used.

Amendment 362
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 6
(6) The notion of AI system should be clearly defined to ensure legal certainty, while providing the flexibility to accommodate future technological developments. The definition should be based on the key functional characteristics of the system, in particular the ability, for a given set of objectives, to generate outputs such as content, predictions, recommendations, or decisions. AI systems can be designed to operate with varying levels of autonomy and be used on a stand-alone basis or as a component of a product, irrespective of whether the system is physically integrated into the product (embedded) or serve the functionality of the product without being integrated therein (non-embedded). The definition of AI system should be complemented by a list of specific techniques and approaches used for its development, which should be kept up-to-date in the light of market and technological developments through the adoption of delegated acts by the Commission to amend that list.

Amendment 363
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Recital 6
(6) The notion of AI system should be clearly defined to ensure legal certainty, while providing the flexibility to accommodate existing harmless applications and future technological developments. The definition should be based on the key functional characteristics of the software, in particular the ability, for a given set of human-defined objectives, to generate outputs such as content, predictions, recommendations, or decisions which influence the environment with which the system interacts, be it in a physical or digital dimension. AI systems can be designed to operate with varying levels of autonomy and be used on a stand-alone basis or as a component of a product, irrespective of whether the system is physically integrated into the product (embedded) or serve the functionality of the product without being integrated therein (non-embedded). The definition of AI system should be complemented by a list of specific techniques and approaches used for its development, which should be kept up-to-date in the light of market and technological developments through the adoption of delegated acts by the Commission to amend that list.

Amendment 364
EPP - Group of the European Peoples Party (Christian Democrats)
Karlo Ressler
Recital 6
(6) The notion of AI system should be clearly defined to ensure legal certainty, while providing the flexibility to accommodate future technological developments. The definition should be aligned with internationally accepted approach. AI systems can be designed to operate with varying levels of autonomy and be used on a stand-alone basis or as a component of a product, irrespective of whether the system is physically integrated into the product (embedded) or serve the functionality of the product without being integrated therein (non-embedded). The definition of AI system should be complemented by a list of specific techniques and approaches used for its development, which should be kept up-to-date in the light of market and technological developments through the adoption of delegated acts by the Commission to amend that list. The Commission should engage in dialogue with key international organizations, so that the common international standards could be achieved to the highest possible extent.

Amendment 365
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 6 a (new)
(6 a) Defining AI systems is an ongoing process that should take into account the context in which AI operates, keep pace with societal developments in this field and not lose sight of the link between the ecosystem of excellence and the ecosystem of trust. The definition of AI system should be complemented by a list of specific techniques and approaches used for its development, which should be kept up-to-date in the light of market and technological developments through the adoption of delegated acts by the Commission to amend that list. In the drafting process of these delegated acts, the Commission shall insure the input of all relevant stakeholders including the technical experts and developers of AI systems. This consultation can take place through existing bodies such as the High Level Expert Group on AI or a newly established similar advisory body that is closely included in the work of the European Artificial Intelligence Board. Should the definition of ‘AI system’ from the OECD be adjusted in the coming years, the European Commission should engage in dialogue with these organisations to ensure alignment between the two definitions. Should the AI Act still be undergoing legislative procedure, the co-legislators should consider these latest developments during the legislative process, so as to ensure alignment, legal clarity and broad international acceptance of the AI Act Definition of ‘AI Systems’.

Amendment 366
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 6 b (new)
(6 b) Taking into account the work of International Standardisation Organisations, it is important to highlight the differences as well as the connection between Automation, Heteronomy and Autonomy. Experts speak of an automated system with different levels of automation instead of levels of autonomy. Autonomy is understood as the highest level of automation. An autonomous AI system would be capable to change its scope or its goals independently. However, today's AI technologies do not allow full autonomy yet and are not self-governing. Instead, they operate based on algorithms and otherwise obey the commands of operators. A fully autonomous AI system would be a genuine General or Super AI. Despite these restrictions, this Regulation will use the term “autonomy” as it is a key element of international accepted definitions.

Amendment 367
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 7
(7) The notion of biometric data used in this Regulation is in line with and should be interpreted consistently with the notion of biometric data as defined in Article 4(14) of Regulation (EU) 2016/679 of the European Parliament and of the Council35 , Article 3(18) of Regulation (EU) 2018/1725 of the European Parliament and of the Council36 and Article 3(13) of Directive (EU) 2016/680 of the European Parliament and of the Council37 . An additional definition has been added for ‘biometrics-based data’ to cover physical, physiological or behavioural data that may not meet the criteria to be defined as biometric data (i.e. would not allow or confirm the unique identification of a natural person) but which may be used for purposes such as emotion recognition or biometric categorisation. The addition of this definition does not narrow the scope of, nor exclude anything from, the definition of biometric data, but rather provides for a comprehensive scope for additional forms of data which may be used for purposes such as biometric categorisation but which would not allow or confirm unique identification.' '35 Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation) (OJ L 119, 4.5.2016, p. 1).', '36 Regulation (EU) 2018/1725 of the European Parliament and of the Council of 23 October 2018 on the protection of natural persons with regard to the processing of personal data by the Union institutions, bodies, offices and agencies and on the free movement of such data, and repealing Regulation (EC) No 45/2001 and Decision No 1247/2002/EC (OJ L 295, 21.11.2018, p. 39)', '37 Directive (EU) 2016/680 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data by competent authorities for the purposes of the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, and on the free movement of such data, and repealing Council Framework Decision 2008/977/JHA (Law Enforcement Directive) (OJ L 119, 4.5.2016, p. 89).

Amendment 368
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 7
(7) The notion of biometric data used in this Regulation is in line with and should be interpreted consistently with the notion of biometric data as defined in Article 4(14) of Regulation (EU) 2016/679 of the European Parliament and of the Council35 , Article 3(18) of Regulation (EU) 2018/1725 of the European Parliament and of the Council36 and Article 3(13) of Directive (EU) 2016/680 of the European Parliament and of the Council37 . An additional definition has been added for ‘biometrics-based data’ to cover physical, physiological or behavioural data that may not meet the criteria to be defined as biometric data (i.e. would not allow or confirm the unique identification of a natural person) but which may be used for purposes such as emotion recognition or biometric categorisation. The addition of this definition does not narrow the scope of, nor exclude anything from, the definition of biometric data, but rather provides for a comprehensive scope for additional forms of data which may be used for purposes such as biometric categorisation but which would not allow or confirm unique identification.' '35 Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation) (OJ L 119, 4.5.2016, p. 1).', '36 Regulation (EU) 2018/1725 of the European Parliament and of the Council of 23 October 2018 on the protection of natural persons with regard to the processing of personal data by the Union institutions, bodies, offices and agencies and on the free movement of such data, and repealing Regulation (EC) No 45/2001 and Decision No 1247/2002/EC (OJ L 295, 21.11.2018, p. 39)', '37 Directive (EU) 2016/680 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data by competent authorities for the purposes of the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, and on the free movement of such data, and repealing Council Framework Decision 2008/977/JHA (Law Enforcement Directive) (OJ L 119, 4.5.2016, p. 89).

Amendment 369
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 7
(7) The notion of biometric data used in this Regulation is the same as that defined in Article 4(14) of Regulation (EU) 2016/679 of the European Parliament and of the Council35.' '35 Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation) (OJ L 119, 4.5.2016, p. 1).

Amendment 370
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 7
(7) The notion of biometric data used in this Regulation is in line with and should be interpreted consistently with the notion of biometric data as defined in Article 4(14) of Regulation (EU) 2016/679 of the European Parliament and of the Council35 , Article 3(18) of Regulation (EU) 2018/1725 of the European Parliament and of the Council36 and Article 3(13) of Directive (EU) 2016/680 of the European Parliament and of the Council37 . The notion of “biometrics-based data” is broader, covering situations where the data in question may not, of itself, confirm the unique identification of an individual.' '35 Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation) (OJ L 119, 4.5.2016, p. 1).', '36 Regulation (EU) 2018/1725 of the European Parliament and of the Council of 23 October 2018 on the protection of natural persons with regard to the processing of personal data by the Union institutions, bodies, offices and agencies and on the free movement of such data, and repealing Regulation (EC) No 45/2001 and Decision No 1247/2002/EC (OJ L 295, 21.11.2018, p. 39)', '37 Directive (EU) 2016/680 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data by competent authorities for the purposes of the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, and on the free movement of such data, and repealing Council Framework Decision 2008/977/JHA (Law Enforcement Directive) (OJ L 119, 4.5.2016, p. 89).

Amendment 371
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 8
(8) The notion of biometric identification system as used in this Regulation should be defined functionally, as an AI system performing automated recognition of physical, physiological, behavioural, and psychological human features, for the purpose of identification of natural persons through the comparison of a person’s biometric data with the biometric data contained in a reference database, irrespectively of the particular technology, processes or types of biometric data used.

Amendment 372
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Recital 8
(8) The notion of remote biometric identification system as used in this Regulation should be defined functionally, as an AI system intended for the identification of natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database, and without prior knowledge whether the targeted person will be present and can be identified, irrespectively of the particular technology, processes or types of biometric data used.

Amendment 373
Greens/EFA - Group of the Greens/European Free Alliance
Patrick Breyer
Recital 8
(8) The notion of remote biometric identification system as used in this Regulation should be defined functionally, as an AI system intended for the identification of natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database, and without prior knowledge whether the targeted person will be present and can be identified, irrespectively of the particular technology, processes or types of biometric data used. Because remote biometric identification relates to how a system is designed and installed, and not solely to whether or not data subjects have consented, this definition applies even when warning notices are placed in the location that is under the surveillance of the remote biometric identification system, and is not de facto annulled by pre-enrolment.

Amendment 374
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,
Recital 8
(8) The notion of remote biometric identification system as used in this Regulation should be defined functionally, as an AI system intended for the identification of natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database, and without prior knowledge whether the targeted person will be present and can be identified, irrespectively of the particular technology, processes or types of biometric data used. Considering their different characteristics and manners in which they are used, as well as the different risks involved, a distinction should be made between ‘real-time’ and ‘post’ remote biometric identification systems. In the case of ‘real-time’ systems, the capturing of the biometric data, the comparison and the identification occur all instantaneously, near-instantaneously or in any event without a significant delay. In this regard, there should be no scope for circumventing the rules of this Regulation on the ‘real-time’ use of the AI systems in question by providing for minor delays. ‘Real-time’ systems involve the use of ‘live’ or ‘near-‘live’ material, such as video footage, generated by a camera or other device with similar functionality. In the case of ‘post’ systems, in contrast, the biometric data have already been captured and the comparison and identification occur only after a significant delay. This involves material, such as pictures or video footage generated by closed circuit television cameras or private devices, which has been generated before the use of the system in respect of the natural persons concerned. The notion of remote biometric identification system shall not include verification or authentification systems whose sole purpose is to confirm that a specific natural person is the person he or she claims to be, and systems that are used to confirm the identity of a natural person for the sole purpose of having access to a service, a device or premises.

Amendment 375
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 8
(8) The notion of remote biometric identification system as used in this Regulation should be defined functionally, as an AI system intended for the identification of natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database, and without prior knowledge whether the targeted person will be present and can be identified, irrespectively of the particular technology, processes or types of biometric data used. Considering their different characteristics and manners in which they are used, as well as the different risks involved, a distinction should be made between ‘real-time’ and ‘post’ remote biometric identification systems. In the case of ‘real-time’ systems, the capturing of the biometric data, the comparison and the identification occur all instantaneously, near-instantaneously or in any event without a significant delay. In this regard, there should be no scope for circumventing the rules of this Regulation on the ‘real-time’ use of the AI systems in question by providing for minor delays. ‘Real-time’ systems involve the use of ‘live’ or ‘near-‘live’ material, such as video footage, generated by a camera or other device with similar functionality. In the case of ‘post’ systems, in contrast, the biometric data have already been captured and the comparison and identification occur only after a significant delay. This involves material, such as pictures or video footage generated by closed circuit television cameras or private devices, which has been generated before the use of the system in respect of the natural persons concerned. The notion of remote biometric identification system shall not include authentification and verification systems whose purpose is to confirm, based on prior consent, that a specific natural person is the person he or she claims to be or to confirm the identity of a natural person for the purpose of having access to a service, a device or premises.

Amendment 376
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Recital 8
(8) The notion of biometric identification system, including remote biometric identification system as used in this Regulation, should be defined functionally, as an AI system intended for the identification of natural persons including at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference data repository, excluding verification/ authentication systems whose sole purpose is to confirm that a specific natural person is the person he or she claims to be, and systems that are used to confirm the identity of a natural person for the sole purpose of having access to a service, a device or premises, and without prior knowledge whether the targeted person will be present and can be identified, irrespectively of the particular technology, processes or types of biometric data used. Considering their different characteristics and manners in which they are used, as well as the different risks involved, a distinction should be made between ‘real-time’ and ‘post’ biometric identification systems. In the case of ‘real-time’ systems, the capturing of the biometric data, the comparison and the identification occur all instantaneously, near-instantaneously or in any event without a significant delay. In this regard, there should be no scope for circumventing the rules of this Regulation on the ‘real-time’ use of the AI systems in question by providing for minor delays. ‘Real-time’ systems involve the use of ‘live’ or ‘near-‘live’ material, such as video footage, generated by a camera or other device with similar functionality. In the case of ‘post’ systems, in contrast, the biometric data have already been captured and the comparison and identification occur only after a significant delay. This involves material, such as pictures or video footage generated by closed circuit television cameras or private devices, which has been generated before the use of the system in respect of the natural persons concerned.

Amendment 377
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Patryk Jaki, Eugen Jurzyca, Adam Bielan
Recital 8
(8) The notion of remote biometric identification system as used in this Regulation should be defined functionally, as an AI system intended for the identification of natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a database data repository, excluding verification/authentication systems whose sole purpose is to confirm that a specific natural person is the person he or she claims to be, and systems that are used to confirm the identity of a natural person for the sole purpose of having access to a service, a device or premises, and without prior knowledge whether the targeted person will be present and can be identified, irrespectively of the particular technology, processes or types of biometric data used. Considering their different characteristics and manners in which they are used, as well as the different risks involved, a distinction should be made between ‘real-time’ and ‘post’ remote biometric identification systems. In the case of ‘real-time’ systems, the capturing of the biometric data, the comparison and the identification occur all instantaneously, near-instantaneously or in any event without a significant delay. In this regard, there should be no scope for circumventing the rules of this Regulation on the ‘real-time’ use of the AI systems in question by providing for minor delays. ‘Real-time’ systems involve the use of ‘live’ or ‘near-‘live’ material, such as video footage, generated by a camera or other device with similar functionality. In the case of ‘post’ systems, in contrast, the biometric data have already been captured and the comparison and identification occur only after a significant delay. This involves material, such as pictures or video footage generated by closed circuit television cameras or private devices, which has been generated before the use of the system in respect of the natural persons concerned.

Amendment 378
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 8
(8) The notion of remote biometric identification system as used in this Regulation should be defined functionally, as an AI system intended for the identification of natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference database, irrespectively of the particular technology, processes or types of biometric data used. The notion of ‘at a distance’ in Remote Biometric Identification (RBI) means the use of systems as described in Article 3(36), at a distance great enough that the system has the capacity to scan multiple persons in its field of view (or the equivalent generalised scanning of online / virtual spaces), which would mean that the identification could happen without one or more of the data subjects’ knowledge. Because RBI relates to how a system is designed and installed, and not solely to whether or not data subjects have consented, this definition applies even when warning notices are placed in the location that is under the surveillance of the RBI system, and is not de facto annulled by pre-enrolment.

Amendment 379
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Recital 8
(8) The notion of remote biometric identification system as used in this Regulation should be defined functionally, as an AI system intended for the identification of natural persons at a distance through the comparison of a person’s biometric data with the biometric data contained in a reference data repository, and without prior knowledge whether the targeted person will be present and can be identified, irrespectively of the particular technology, processes or types of biometric data used. Considering their different characteristics and manners in which they are used, as well as the different risks involved, a distinction should be made between ‘real-time’ and ‘post’ remote biometric identification systems. In the case of ‘real-time’ systems, the capturing of the biometric data, the comparison and the identification occur all instantaneously, near-instantaneously or in any event without a significant delay. In this regard, there should be no scope for circumventing the rules of this Regulation on the ‘real-time’ use of the AI systems in question by providing for minor delays. ‘Real-time’ systems involve the use of ‘live’ or ‘near-‘live’ material, such as video footage, generated by a camera or other device with similar functionality. In the case of ‘post’ systems, in contrast, the biometric data have already been captured and the comparison and identification occur only after a significant delay. This involves material, such as pictures or video footage generated by closed circuit television cameras or private devices, which has been generated before the use of the system in respect of the natural persons concerned.

Amendment 380
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 9
(9) For the purposes of this Regulation the notion of publicly accessible physical or virtual space should be understood as referring to any physical or virtual place that is accessible to the public, on a temporary or permanent basis, irrespective of whether the place in question is privately or publicly owned. Therefore, the notion covers places that are both private in nature, used for private purposes only, accessed completely voluntarily and normally not freely accessible for third parties, including law enforcement authorities, unless those parties have been specifically invited or authorised, such as homes and private clubs. However, the mere fact that certain conditions for accessing a particular space may apply, such as admission tickets or age restrictions, does not mean that the space is not publicly accessible within the meaning of this Regulation. Consequently, in addition to public spaces such as streets, relevant parts of government buildings and most transport infrastructure, spaces such as cinemas, theatres, sports grounds, virtual gaming environments, schools, universities, hospitals, amusement parks, festivals, shops and shopping centres, offices, warehouses and factories are normally also publicly accessible. Whether a given space is accessible to the public should however be determined on a case-by-case basis, having regard to the specificities of the individual situation at hand.

Amendment 381
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 9
(9) For the purposes of this Regulation the notion of publicly accessible space should be understood as referring to any physical place that is accessible to the public, irrespective of whether the place in question is privately or publicly owned. Therefore, the notion does not cover places that are private in nature and normally not freely accessible for third parties, including law enforcement authorities, unless those parties have been specifically invited or authorised, such as homes, private clubs, offices, warehouses and factories. Online spaces are not covered either, as they are not physical spaces. However, the mere fact that certain conditions for accessing a particular space may apply, such as admission tickets or age restrictions, does not mean that the space is not publicly accessible within the meaning of this Regulation. Consequently, in addition to public spaces such as streets, relevant parts of government buildings and most transport infrastructure, spaces such as cinemas, theatres, shops and shopping centres are normally also publicly accessible. Whether a given space is accessible to the public should however be determined on a case-by-case basis by the competent judicial or administrative authority, having regard to the specificities of the individual situation at hand.

Amendment 382
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 9
(9) For the purposes of this Regulation the notion of publicly accessible space should be understood as referring to any physical place that is accessible to the public, irrespective of whether the place in question is privately or publicly owned. Therefore, the notion does not cover places that are private in nature and normally not freely accessible for third parties, including law enforcement authorities, unless those parties have been specifically invited or authorised, such as homes, private clubs, offices, warehouses and factories. However, the mere fact that certain conditions for accessing a particular space may apply, such as admission tickets or age restrictions, does not mean that the space is not publicly accessible within the meaning of this Regulation. Consequently, in addition to public spaces such as streets, relevant parts of government buildings and most transport infrastructure, spaces such as cinemas, theatres, shops and shopping centres are normally also publicly accessible. Whether a given space is accessible to the public should however be determined on a case-by-case basis, having regard to the specificities of the individual situation at hand.

Amendment 383
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López Aguilar,
Recital 9
(9) For the purposes of this Regulation the notion of publicly accessible space should be understood as referring to any physical place that is accessible to the public, irrespective of whether the place in question is privately or publicly owned. Therefore, the notion does not cover places that are private in nature and normally not freely accessible for third parties, including law enforcement authorities, unless those parties have been specifically invited or authorised, such as homes, private clubs, offices, warehouses and factories. However, the mere fact that certain conditions for accessing a particular space may apply, such as admission tickets or age restrictions, does not mean that the space is not publicly accessible within the meaning of this Regulation. Consequently, in addition to public spaces such as streets, relevant parts of government buildings and most transport infrastructure, spaces such as cinemas, theatres, shops and shopping centres are normally also publicly accessible. Whether a given space is accessible to the public should however be determined on a case-by-case basis, having regard to the specificities of the individual situation at hand.

Amendment 384
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 9
(9) For the purposes of this Regulation the notion of publicly accessible space should be understood as referring to any physical place that is accessible to the public, irrespective of whether the place in question is privately or publicly owned. Therefore, the notion does not cover places that are private in nature and normally not freely accessible for third parties, including law enforcement authorities, unless those parties have been specifically invited or authorised, such as homes, private clubs, offices, warehouses and factories. However, the mere fact that certain conditions for accessing a particular space may apply, such as admission tickets or age restrictions, does not mean that the space is not publicly accessible within the meaning of this Regulation. Consequently, in addition to online and public spaces such as streets, relevant parts of government buildings and most transport infrastructure, spaces such as cinemas, theatres, shops and shopping centres are normally also publicly accessible. Whether a given space is accessible to the public should however be determined on a case-by-case basis, having regard to the specificities of the individual situation at hand.

Amendment 385
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 9 a (new)
(9 a) In order to ensure the rights of individuals and groups, and the growth of trustworthy AI, certain principles should be guaranteed across all AI systems, such as transparency, the right to an explanation and the right to object to a decision. This requires that discrimination, and detrimental power and information imbalances be prevented, control and oversight guaranteed, and that compliance is demonstrable and subject to ongoing monitoring. Decision-making by, or supported by, AI systems, should be subject to specific transparency rules, as regards the logic and parameters on which decisions are made.

Amendment 386
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 9 b (new)
(9 b) Requirements on transparency and on the explicability of AI decision-making should contribute to countering the deterrent effects of digital asymmetry, power and information imbalance, and so-called ‘dark patterns’ targeting individuals and their informed consent.

Amendment 387
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 10
(10) In order to ensure a level playing field and an effective protection of rights and freedoms of individuals across the Union, the rules established by this Regulation should apply to providers of AI systems in a non-discriminatory manner, irrespective of whether they are established within the Union or in a third country, and to deployers of AI systems established within the Union. This Regulation and the rules it establishes should take into account different development and business models and the fact that standard implementations, or Free and Open Source software development and licensing models might entail less knowledge about and little to no control over further use, modification, and deployment within an AI system.

Amendment 388
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Recital 10
(10) In order to ensure a level playing field and an effective protection of rights and freedoms of individuals across the Union and on international level, the rules established by this Regulation should apply to providers of AI systems in a non-discriminatory manner, irrespective of whether they are established within the Union or in a third country, and to users of AI systems established within the Union.

Amendment 389
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte
Recital 11
(11) In light of their digital nature, certain AI systems should fall within the scope of this Regulation even when they are neither placed on the market, nor put into service, nor used in the Union. This is the case for example of an operator established in the Union that contracts certain services to an operator established outside the Union in relation to an activity to be performed by an AI system that would qualify as high-risk and whose effects impact natural persons located in the Union. In those circumstances, the AI system used by the operator outside the Union could process data lawfully collected in and transferred from the Union, and provide to the contracting operator in the Union the output of that AI system resulting from that processing, without that AI system being placed on the market, put into service or used in the Union. To prevent the circumvention of this Regulation and to ensure an effective protection of natural persons located in the Union, this Regulation should also apply to providers and users of AI systems that are established in a third country, to the extent the output produced by those systems is used in the Union.

Amendment 390
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 11
(11) In light of their digital nature, certain AI systems should fall within the scope of this Regulation even when they are neither placed on the market, nor put into service, nor used in the Union. This is the case for example of an operator established in the Union that contracts certain services to an operator established outside the Union in relation to an activity to be performed by an AI system that would qualify as high-risk and whose effects impact natural persons located in the Union. In those circumstances, the AI system used by the operator outside the Union could process data lawfully collected in and transferred from the Union, and provide to the contracting operator in the Union the output of that AI system resulting from that processing, without that AI system being placed on the market, put into service or used in the Union. To prevent the circumvention of this Regulation and to ensure an effective protection of natural persons located in the Union, this Regulation should also apply to providers and users of AI systems that are established in a third country, to the extent the output produced by those systems is used in the Union.

Amendment 391
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 11
(11) In light of their digital nature, certain AI systems should fall within the scope of this Regulation even when they are neither placed on the market, nor put into service, nor used in the Union. This is the case for example of an operator established in the Union that contracts certain services to an operator established outside the Union in relation to an activity to be performed by an AI system whose effects impact natural persons located in the Union. In those circumstances, the AI system used by the operator outside the Union could process data lawfully collected in and transferred from the Union, and provide to the contracting operator in the Union the output of that AI system resulting from that processing, without that AI system being placed on the market, put into service or used in the Union. To prevent the circumvention of this Regulation and to ensure an effective protection of natural persons located in the Union, this Regulation should also apply to providers and users of AI systems that are established in a third country, to the extent the output produced by those systems is used in the Union or it affects natural persons within the Union.

Amendment 392
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 11
(11) In light of their digital nature, certain AI systems should fall within the scope of this Regulation even when they are neither placed on the market, nor put into service, nor used in the Union. This is the case for example of an operator established in the Union that contracts certain services to an operator established outside the Union in relation to an activity to be performed by an AI system that would qualify as high-risk and whose effects impact natural persons located in the Union. In those circumstances, the AI system used by the operator outside the Union could process data lawfully collected in and transferred from the Union, and provide to the contracting operator in the Union the output of that AI system resulting from that processing, without that AI system being placed on the market, put into service or used in the Union. To prevent the circumvention of this Regulation and to ensure an effective protection of natural persons located in the Union, this Regulation should also apply to providers and deployers of AI systems that are established in a third country, to the extent the output produced by those systems is used in the Union or affects people in the Union.

Amendment 393
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 11
(11) In light of their digital nature, certain AI systems should fall within the scope of this Regulation even when they are neither placed on the market, nor put into service, nor used in the Union. This is the case for example of an operator established in the Union that contracts certain services to an operator established outside the Union in relation to an activity to be performed by an AI system that would qualify as high-risk and whose effects impact natural persons located in the Union. In those circumstances, the AI system used by the operator outside the Union could process data lawfully collected in and transferred from the Union, and provide to the contracting operator in the Union the output of that AI system resulting from that processing, without that AI system being placed on the market, put into service or used in the Union. To prevent the circumvention of this Regulation and to ensure an effective protection of natural persons located in the Union, this Regulation should also apply to providers and users of AI systems that are established in a third country, to the extent the output produced by those systems is used in the Union. Nonetheless, to take into account existing arrangements and special needs for cooperation with foreign partners with whom information and evidence is exchanged, this Regulation should not apply to public authorities of a third country and international organisations when acting in the framework of international agreements concluded at national or European level for law enforcement and judicial cooperation with the Union or with its Member States. Such agreements have been concluded bilaterally between Member States and third countries or between the European Union, Europol and other EU agencies and third countries and international organisations. This exception should nevertheless be limited to trusted countries and international organizations that share the Union’s values.

Amendment 394
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 11
(11) In light of their digital nature, certain AI systems should fall within the scope of this Regulation even when they are neither placed on the market, nor put into service, nor used in the Union. This is the case for example of an operator established in the Union that contracts certain services to an operator established outside the Union in relation to an activity to be performed by an AI system that would qualify as high-risk. In those circumstances, the AI system used by the operator outside the Union could process data lawfully collected in and transferred from the Union, and provide to the contracting operator in the Union the output of that AI system resulting from that processing, without that AI system being placed on the market, put into service or used in the Union. To prevent the circumvention of this Regulation and to ensure an effective protection of natural persons located in the Union, this Regulation should also apply to providers and users of AI systems that are established in a third country, to the extent the output produced by those systems is intended for use in the Union. Nonetheless, to take into account existing arrangements and special needs for future cooperation with foreign partners with whom information and evidence is exchanged, this Regulation should not apply to public authorities of a third country and international organisations when acting in the framework of international agreements concluded at national or European level for law enforcement and judicial cooperation with the Union or with its Member States. Such agreements have been concluded bilaterally between Member States and third countries or between the European Union, Europol and other EU agencies and third countries and international organisations.

Amendment 395
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 12
(12) This Regulation should also apply to Union institutions, offices, bodies and agencies when acting as a provider or user of an AI system. This Regulation should be without prejudice to the provisions regarding the liability of intermediary service providers set out in Directive 2000/31/EC of the European Parliament and of the Council [as amended by the Digital Services Act].

Amendment 396
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst
Recital 12
(12) This Regulation should also apply to Union institutions, offices, bodies and agencies when acting as a provider or user of an AI system. This Regulation should be without prejudice to the provisions regarding the liability of intermediary service providers set out in Directive 2000/31/EC of the European Parliament and of the Council [as amended by the Digital Services Act].

Amendment 397
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 12
(12) This Regulation should also apply to Union institutions, offices, bodies and agencies when acting as a provider or deployer of an AI system. This Regulation should be without prejudice to the provisions regarding the liability of intermediary service providers set out in Directive 2000/31/EC of the European Parliament and of the Council [as amended by the Digital Services Act].

Amendment 398
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul Garraud
Recital 12
(12) This Regulation should also apply to the institutions, bodies, offices and agencies of the Union. AI systems exclusively developed or used for military purposes should be excluded from the scope of this Regulation. This Regulation should be without prejudice to the provisions regarding the liability of intermediary service providers set out in Directive 2000/31/EC of the European Parliament and of the Council [as amended by the Digital Services Act].

Amendment 399
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Karen Melchior, Dita Charanzová, Andrus Ansip, Morten
Recital 12 a (new)
(12 a) This Regulation should not undermine research and development activity and should respect freedom of science. It is therefore necessary to exclude from its scope AI systems specifically developed and put into service for the sole purpose of scientific research and development and to ensure that the Regulation does not otherwise affect scientific research and development activity on AI systems. As regards product oriented research activity by providers, the provisions of this Regulation should apply insofar as such research leads to or entails placing of an AI system on the market or putting it into service. Under all circumstances, any research and development activity should be carried out in accordance with recognised ethical standards for scientific research.

Amendment 400
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Recital 12 a (new)
(12 a) This Regulation should also ensure harmonisation and consistency in definitions and terminology as biometric techniques can, in the light of their primary function, be divided into techniques of biometric identification, authentication and verification. Biometric authentication means the process of matching an identifier to a specific stored identifier in order to grant access to a device or service, whilst biometric verification refers to the process of confirming that an individual is who they claim to be. As they do not involve any “one-to-many” comparison of biometric data that is the distinctive trait of identification, both biometric verification and authentication should be excluded from the scope of this Regulation.

Amendment 401
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Recital 12 a (new)
(12 a) This Regulation should also ensure harmonisation consistency in definitions and terminology as biometric techniques can, in the light of their primary function, be divided into techniques of biometric identification, authentication and verification. Biometric authentication means the process of matching an identifier to a specific stored identifier in order to grant access to a device or service, whilst biometric verification refers to the process of confirming that an individual is who they claim to be. As they do not involve any “one-to-many” comparison of biometric data that is the distinctive trait of identification, both biometric verification and authentication should be excluded from the scope of this Regulation.

Amendment 402
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 12 a (new)
(12 a) AI systems developed or used exclusively for military purposes should be excluded from the scope of this Regulation where that use falls under the exclusive remit of the Common Foreign and Security Policy regulated under Title V TEU. However, AI systems which are developed or used for military purposes but can also be used for civil purposes, falling under the definition of “dual use items” pursuant to Regulation (EU) 2021/821 of the European Parliament and of the Council1ashould fall into the scope of this Regulation.' '1a Regulation (EU) 2021/821 of the European Parliament and of the Council of 20 May 2021 setting up a Union regime for the control of exports, brokering, technical assistance, transit and transfer of dual-use items (OJ L 206 11.6.2021, p. 1).

Amendment 403
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 12 a (new)
(12 a) In order to ensure a minimum level of transparency on the ecological sustainability aspects of an AI system, providers and users should document parameters including but not limited to resource consumption, resulting from the design, data management and training, the underlying infrastructures of the AI system, and of the methods to reduce such impact for any AI system.

Amendment 404
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Dita Charanzová, Andrus Ansip, Vlad-Marius Botoş, Moritz
Recital 12 b (new)
(12 b) Given the complexity of the value chain for AI systems, it is essential to clarify the role of persons who may contribute to the development of AI systems covered by this Regulation, without being providers and thus being obliged to comply with the obligations and requirements established herein. It is necessary to clarify that general purpose AI systems - understood as AI systems that are able to perform generally applicable functions such as image/speech recognition, audio/video generation, pattern detection, question answering, translation etc. - should not be considered as having an intended purpose within the meaning of this Regulation, unless those systems have been adapted to a specific intended purpose that falls within the scope of this Regulation. Initial providers of general purpose AI systems should therefore only have to comply with the provisions on accuracy, robustness and cybersecurity as laid down in Art. 15 of this Regulation. If a person adapts a general purpose AI application to a specific intended purpose and places it on the market or puts it into service, it shall be considered the provider and be subject to the obligations laid down in this Regulation. The initial provider of a general purpose AI application shall, after placing it on the market or putting it to service, and without compromising its own intellectual property rights or trade secrets, provide the new provider with all essential, relevant and reasonably expected information that is necessary to comply with the obligations set out in this Regulation.

Amendment 405
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 12 b (new)
(12 b) This Regulation should not affect the provisions aimed at improving working conditions in platform work set out in Directive 2021/762/EC.

Amendment 406
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 13
(13) In order to ensure a consistent and high level of protection of public interests as regards health, safety and fundamental rights, common normative standards for all high-risk AI systems should be established. Those standards should be consistent with the Charter of fundamental rights of the European Union (the Charter) and should be non-discriminatory and in line with the Union’s international trade commitments. In order to ensure a minimum level of transparency on the ecological sustainability aspects of an AI system, providers and users should document (i) parameters including, but not limited to, resource consumption resulting from the design, data management, training and from the underlying infrastructures of the AI system; as well as (ii) the methods to reduce such impact.

Amendment 407
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 13
(13) In order to ensure a consistent and high level of protection of public interests as regards health, safety, the environment and fundamental rights, and values, common normative standards for AI systems should be established. Those standards should be consistent with the Charter of fundamental rights of the European Union (the Charter), the European Green Deal (The Green Deal), the Joint Declaration on Digital Rights of the Union (the Declaration) and the Ethics Guidelines for Trustworthy Artificial Intelligence (AI) of the High-Level Expert Group on Artificial Intelligence (AI HLEG), and should be non-discriminatory and in line with the Union’s international commitments.

Amendment 408
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 13
(13) In order to ensure a consistent and high level of protection of public interests as regards health, safety, and fundamental rights, as well as the environment, society, rule of law and democracy, economic interests and consumer protection, common normative standards for all high-risk AI systems should be established. Those standards should be consistent with the Charter of Fundamental Rights of the European Union (the Charter) and should be non-discriminatory and in line with the Union’s international trade commitments.

Amendment 409
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 13
(13) In order to ensure a consistent and high level of protection of public interests as regards health, safety and fundamental rights, the environment and the Union values enshrined in Article 2 TEU, common normative standards for all high-risk AI systems should be established. Those standards should be consistent with the Charter of fundamental rights of the European Union (the Charter) and should be non-discriminatory and in line with the Union’s international trade commitments.

Amendment 410
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 13
(13) In order to ensure a consistent and high level of protection of public interests as regards health, safety and fundamental rights, minimum common normative standards for all high-risk AI systems should be established. Those standards should be consistent with the Charter of fundamental rights of the European Union (the Charter) and should be non-discriminatory and in line with the Union’s international commitments.

Amendment 411
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 13 a (new)
(13 a) AI systems and related ICT technology require significant natural resources, contribute to waste production, and have a significant overall impact on the environment. It is appropriate to design and develop in particular high-risk AI systems with methods and capabilities that measure, record, and reduce resource use and waste production, as well as energy use, and that increase their overall efficiency throughout their entire lifecycle. The Commission, the Member States and the European AI Board should contribute to these efforts by issuing guidelines and providing support to providers and deployers.

Amendment 412
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 14
(14) In order to introduce a proportionate and effective set of binding rules for AI systems, a clearly defined risk-based approach should be followed. That approach should tailor the type and content of such rules to the intensity and scope of the risks that AI systems can generate. It is therefore necessary to prohibit certain artificial intelligence practices, to lay down requirements for high-risk AI systems and obligations for the relevant operators, and to lay down transparency obligations for certain AI systems. It is also necessary to establish the criteria and conditions which determinine the category to which an AI system belongs.

Amendment 413
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Recital 14
(14) In order to introduce a proportionate and effective set of binding rules for AI systems, a clearly defined risk-based approach should be followed. That approach should tailor the type and content of such rules to the intensity and scope of the risks that AI systems can generate for individuals and society, rather than depend on the type of technology. It is therefore necessary to prohibit certain artificial intelligence practices, to lay down requirements for high-risk AI systems and obligations for the relevant operators, and to lay down transparency obligations for certain AI systems.

Amendment 414
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 14
(14) In order to introduce a proportionate and effective set of binding rules for AI systems, a clearly defined risk-based approach should be followed. That approach should tailor the type and content of such rules to the intensity and scope of the risks that AI systems can generate. It is therefore necessary to prohibit certain unacceptable artificial intelligence practices, to lay down requirements for high-risk AI systems and obligations for the relevant operators, and to lay down transparency obligations for certain AI systems.

Amendment 415
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 15
(15) AI systems can also be misused and provide novel and powerful tools for manipulative, exploitative and social control practices. Such practices are particularly harmful and should be prohibited because they contradict Union values of respect for human dignity, freedom, equality, democracy and the rule of law and Union fundamental rights, including the right to non-discrimination, data protection and privacy and the rights of the child. All uses of AI systems which interfere with the essence of the fundamental rights of individuals should in any case be prohibited. The prohibitions listed in this Regulation should apply notwithstanding existing Union law and do not provide a new legal basis for the development placing on the market, deployment or use of AI systems. To keep up with rapid technological development and to ensure future-proof regulation, the Commission should keep the list of prohibited and high-risk AI systems under constant review.

Amendment 416
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 15
(15) Aside from the many beneficial uses of artificial intelligence, that technology can also be misused and provide novel and powerful tools for manipulative, exploitative and social control practices. Such practices are particularly harmful and should be prohibited because they contradict the values of respect for human dignity, freedom, equality, democracy and the rule of law, which are protected values under EU law, and Union fundamental rights, including the right to non-discrimination, data protection and privacy and the rights of the child.

Amendment 417
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 15 a (new)
(15 a) As signatories to the United Nations Convention on the Rights of Persons with Disabilities (CRPD), the European Union and all Member States are legally obliged to protect persons with disabilities from discrimination and promote their equality, to ensure that persons with disabilities have access, on an equal basis with others, to information and communications technologies and systems, and to ensure respect for privacy of persons with disabilities. Given the growing importance and use of AI systems, the strict application of universal design principles to all new technologies and services should ensure full, equal, and unrestricted access for everyone potentially affected by or using AI technologies, including persons with disabilities, in a way that takes full account of their inherent dignity and diversity. It is essential to ensure that providers of AI systems design them, and users use them, in accordance with the accessibility requirements set out in Directive (EU) 2019/882.

Amendment 418
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 15 a (new)
(15 a) As signatories to the United Nations Convention on the Rights of Persons with Disabilities (CRPD), the European Union and all Member States are legally obliged to protect persons with disabilities from discrimination and promote their equality (Article 5). They are also obliged to ensure that persons with disabilities have access, on an equal basis with others, to information and communications technologies and systems. (Article 9). Finally, they are obliged to ensure respect for privacy of persons with disabilities (Article 22).

Amendment 419
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 15 a (new)
(15 a) As signatories to the United Nations Convention on the Rights of Persons with Disabilities (CRPD), the European Union and all Member States are legally obliged to protect persons with disabilities from discrimination and promote their equality (Article 5). They are also obliged to ensure that persons with disabilities have access, on an equal basis with others, to information and communications technologies and systems. (Article 9). Finally, they are obliged to ensure respect for privacy of persons with disabilities (Article 22).

Amendment 420
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Sylwia
Recital 15 a (new)
(15 a) The European Union and its Member States as signatories to the United Nations Convention on the Rights of Persons with Disabilities (CRPD) are obliged to protect persons with disabilities from discrimination and to promote their equality. They are obliged to ensure that persons with disabilities have access, on an equal basis with others, to information and communications technologies and systems and to ensure respect for the fundamental rights, including that of privacy, of persons with disabilities.

Amendment 421
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 15 a (new)
(15 a) As signatories to the United Nations Convention on the Rights of Persons with Disabilities (UNCRPD), the European Union and all Member States should protect persons with disabilities from discrimination and promote their equality, ensure that persons with disabilities have access, on an equal basis with others, to information and communications technologies and systems and ensure respect for privacy of persons with disabilities.

Amendment 422
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 15 b (new)
(15 b) Given the growing importance and use of AI systems, the strict application of universal design principles to all new technologies and services should ensure full, equal, and unrestricted access for everyone potentially affected by or using AI technologies, including persons with disabilities, in a way that takes full account of their inherent dignity and diversity. It is essential to ensure that providers of AI systems design them, and users use them, in accordance with the accessibility requirements set out in Directive (EU) 2019/882. Union law should be further developed, including through this Regulation, so that no one is left behind as result of digital innovation.

Amendment 423
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Sylwia
Recital 15 b (new)
(15 b) Providers of AI systems should ensure that these systems are designed in accordance with the accessibility requirements set out in Directive (EU) 2019/882 and guarantee full, equal, and unrestricted access for everyone potentially affected by or using AI systems, including persons with disabilities.

Amendment 424
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 16
(16) The placing on the market, putting into service or use of certain AI systems materially distorting human behaviour, whereby physical or psychological harms are likely to occur, should be forbidden. Such AI systems deploy subliminal components that persons cannot perceive or those systems otherwise exploit vulnerabilities of a specific group of persons due to their age, disability within the meaning of Directive (EU) 2019/882, or social or economic situation. Such systems can be placed on the market, put into service or used with the objective to or the effect of materially distorting the behaviour of a person and in a manner that causes or is reasonably likely to cause physical or psychological harm to that or another person or groups of persons, including harms that may be accumulated over time. The intention to distort the behaviour may not be presumed if the distortion results from factors external to the AI system which are outside of the control of the provider or the user meaning factors that may not be reasonably foreseen and mitigated by the provider or the user of the AI system. In any case, it is not necessary for the provider or the user to have the intention to cause the physical or psychological harm, as long as such harm results from the manipulative or exploitative AI-enabled practices. The prohibitions for such AI practices is complementary to the provisions contained in Directive [Unfair Commercial Practice Directive 2005/29/EC, as amended by Directive (EU) 2019/216], notably that unfair commercial practices leading to economic or financial harms to consumers are prohibited under all circumstances, irrespective of whether they are put in place through AI systems or otherwise.

Amendment 425
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 16
(16) The placing on the market, putting into service or use of certain AI systems with the effect or likely effect of distorting human behaviour, whereby physical, economic or psychological harms to individuals or society are likely to occur, should be forbidden. This includes AI systems that deploy subliminal components that individuals may not be able to perceive or understand, or exploit vulnerabilities of individuals. They materially distort the behaviour of a person, including in a manner that causes or is likely to cause physical, psychological or economic harm to that or another person, or to society, or lead them to make decisions they would not otherwise have taken. Manipulation may not be presumed if the distortion of human behaviour clearly results from factors external to the AI system which are outside of the control of the provider or the user and are not reasonably foreseeable at or during the deployment of the AI system. Research for legitimate purposes in relation to such AI systems should not be unduly limited by the prohibition, if such research does not amount to use of the AI system in non-supervised human-machine relations that exposes natural persons to harm and such research is carried out in accordance with recognised ethical standards for scientific research. If necessary, further flexibilities in order to foster research, and thereby European innovation capacities, should be introduced by Member States under controlled circumstances only and with all relevant safeguards to protect health and safety, fundamental rights, environment, society, rule of law and democracy.

Amendment 426
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 16
(16) The placing on the market, putting into service or use of certain AI systems intended to distort human behaviour should be forbidden. Such AI systems deploy subliminal components individuals cannot perceive or exploit vulnerabilities of people such as children or people who are vulnerable due to their age, physical or mental incapacities, or other traits. Research for legitimate purposes in relation to such AI systems should not be stifled by the prohibition, if such research does not amount to use of the AI system in human-machine relations with uninformed or non-consenting third parties that exposes natural persons to harm and such research is carried out in accordance with recognised ethical standards for scientific research.

Amendment 427
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Recital 16
(16) The placing on the market, putting into service or use of certain AI systems with the effect or likely effect of distorting human behaviour, whereby material or non-material harm, including physical, psychological or economic harms are likely to occur, should be forbidden. This limitation should be understood to include neuro-technologies assisted by AI systems that are used to monitor, use, or influence neural data gathered through brain-computer interfaces. Such AI systems deploy subliminal components individuals cannot perceive or exploit vulnerabilities of children and people due to their age, physical or mental incapacities. They do so with the effect of materially distorting the behaviour of a person and in a manner that causes or is likely to cause harm to that or another person. Research for legitimate purposes in relation to such AI systems should not be stifled by the prohibition, if such research does not amount to use of the AI system in human-machine relations that exposes natural persons to harm and such research is carried out in accordance with recognised ethical standards for scientific research.

Amendment 428
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 16
(16) The placing on the market, putting into service or use of certain AI systems intended to distort human behaviour, whereby physical or psychological harms are likely to occur, should be forbidden. In particular, AI systems that deploy subliminal components that natural persons cannot perceive, that exploit the vulnerabilities of any groups,or that use purposefully manipulative techniques with the intention to materially distort the behaviour of a person and in a manner that causes or is likely to cause harm to that or another person or to their rights or to the values of the Union should be prohibited. The intention may not be presumed if the distortion of human behaviour results from factors external to the AI system which are outside of the control of the provider or the user. Research for legitimate purposes in relation to such AI systems should not be stifled by the prohibition, if such research does not amount to use of the AI system inhuman-machine relations that exposes natural persons to harm and such research is carried out in accordance with recognised ethical standards for scientific research.

Amendment 429
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Maria-Manuel Leitão-Marques, Eva Kaili
Recital 16
(16) The placing on the market, putting into service or use of certain AI systems intended to distort human behaviour, whereby physical or psychological harms are likely to occur, should be forbidden. Such AI systems deploy subliminal components individuals cannot perceive, access brain or brain-generated data without consent, or exploit vulnerabilities of children and people due to their age, physical or mental incapacities. They do so with the intention to materially distort the behaviour of a person and in a manner that causes or is likely to cause harm to that or another person. The intention may not be presumed if the distortion of human behaviour results from factors external to the AI system which are outside of the control of the provider or the user. Research for legitimate purposes in relation to such AI systems should not be stifled by the prohibition, if such research does not amount to use of the AI system in human-machine relations that exposes natural persons to harm and such research is carried out in accordance with recognised ethical standards for scientific research.

Amendment 430
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Dita Charanzová, Andrus Ansip, Morten Løkkegaard, Sandro Gozi, Vlad-Marius Botoş, Abir Al-Sahlani, Moritz Körner, Ondřej Kovařík, Jan-Christoph Oetjen
Recital 16
(16) The placing on the market, putting into service or use of certain AI systems with the objective to or the effect of distorting human behaviour, whereby physical or psychological harms are reasonably likely to occur, should be forbidden. Such AI systems deploy subliminal components individuals cannot perceive or exploit vulnerabilities of specific groups of persons due to their age, disabilities, social or economic situation. They do so with the intention to materially distort the behaviour of a person and in a manner that causes or is likely to cause harm to that or another person. The intention may not be presumed if the distortion of human behaviour results from factors external to the AI system which are outside of the control of the provider or the user. Research for legitimate purposes in relation to such AI systems should not be stifled by the prohibition, if such research does not amount to use of the AI system inhuman-machine relations that exposes natural persons to harm and such research is carried out in accordance with recognised ethical standards for scientific research.

Amendment 431
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Recital 16
(16) The placing on the market, putting into service or use of certain AI systems intended to distort human behaviour, whereby with due diligence it could be predicted that physical or psychological harms are likely to occur, should be forbidden. Such AI systems deploy subliminal components individuals cannot perceive or exploit vulnerabilities of children and people due to their age, physical or mental incapacities. They do so with the intention to materially distort the behaviour of a person and in a manner that causes or is likely to cause harm to that or another person. The intention may not be presumed if the distortion of human behaviour results from factors external to the AI system which are outside of the control of the provider or the user. Research for legitimate purposes in relation to such AI systems should not be stifled by the prohibition, if such research does not amount to use of the AI system in human-machine relations that exposes natural persons to harm and such research is carried out in accordance with recognised ethical standards for scientific research.

Amendment 432
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 17
(17) AI systems providing social scoring of natural persons are, by definition, discriminatory.  They violate the right to dignity and non-discrimination and the values of equality and justice. Such AI systems evaluate or classify the trustworthiness of natural persons based on their social behaviour in multiple contexts or known or predicted personal or personality characteristics. The social score obtained from such AI systems leads to the detrimental or unfavourable treatment of natural persons or whole groups. Such AI systems should be therefore prohibited.

Amendment 433
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 17
(17) AI systems providing social scoring of natural persons for general purpose by private or public authorities or on their behalf may lead to discriminatory outcomes and the exclusion of certain groups. They may violate the right to dignity and non-discrimination and the values of equality and justice. Such AI systems evaluate or classify the trustworthiness of natural persons based on their social behaviour in multiple contexts or known or predicted personal or personality characteristics. Such AI systems should be therefore prohibited.

Amendment 434
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 17
(17) AI systems providing social scoring of natural persons for general purpose by public authorities or on their behalf may lead to discriminatory outcomes and the exclusion of certain groups. They may violate the right to dignity and non-discrimination and the values of equality and justice. Such AI systems evaluate or classify natural persons based on their social behaviour in multiple contexts or known or predicted personal or personality characteristics using trustworthiness, good citizenship, patriotism, deviancy, or any other such metric as a proxi. The social score obtained from such AI systems may lead to the detrimental or unfavourable treatment of natural persons or whole groups thereof in social contexts, which are unrelated to the context in which the data was originally generated or collected or to a detrimental treatment that is disproportionate or unjustified to the gravity of their social behaviour. This detrimental treatment can also be effected by providing undue and unjustified privileges to groups of people based on their social score. Such AI systems should be therefore prohibited.

Amendment 435
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 17
(17) AI systems that evaluate, classify, rate or score the trustworthiness or social standing of natural persons may lead to discriminatory outcomes and the exclusion of certain groups. They may violate the right to dignity and non-discrimination and the values of equality and justice. Such AI systems evaluate or classify the trustworthiness or social standing of natural persons based on multiple data points related to their social behaviour in multiple contexts or known, inferred or predicted personal or personality characteristics. The social score obtained from such AI systems may lead to the detrimental or unfavourable treatment of natural persons or whole groups thereof, which are unrelated to the context in which the data was originally generated or collected or to a detrimental treatment that is disproportionate or unjustified to the gravity of their social behaviour. Such AI systems should be therefore prohibited.

Amendment 436
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 17
(17) AI systems providing social scoring of natural persons for general purpose may lead to discriminatory outcomes and the exclusion of certain groups. They may violate the right to dignity and non-discrimination and the values of equality and justice. Such AI systems evaluate or classify the trustworthiness of natural persons based on their social behaviour in multiple contexts or known or predicted personal or personality characteristics. The social score obtained from such AI systems may lead to the detrimental or unfavourable treatment of natural persons or whole groups thereof in social contexts, which are unrelated to the context in which the data was originally generated or collected or to a detrimental treatment that is disproportionate or unjustified to the gravity of their social behaviour. Such AI systems should be therefore prohibited.

Amendment 437
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 17
(17) AI systems providing social scoring of natural persons for general purpose by public authorities or on their behalf may lead to discriminatory outcomes and the exclusion of certain groups. They violate the right to dignity and non-discrimination and the values of equality and justice. Such AI systems evaluate or classify natural persons based on their social behaviour in multiple contexts or known or predicted personal or personality characteristics. The social score obtained from such AI systems lead to the detrimental or unfavourable treatment of natural persons or whole groups thereof in social contexts, which are unrelated to the context in which the data was originally generated or collected or to a detrimental treatment that is disproportionate or unjustified to the gravity of their social behaviour. Such AI systems should be therefore prohibited.

Amendment 438
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 17 a (new)
(17 a) The placing on the market, putting into service or use of certain AI systems that can be used or foreseeably misused for intrusive monitoring and flagging to identify or deter rule-breaking or fraud should be forbidden. The use of such intrusive monitoring and flagging in a relationship of power, such as the use of e-proctoring software by education institutions to monitor students and pupils, or the use of surveillance- or monitoring software by employers on workers poses an unacceptable risk to the fundamental rights of workers, students and pupils, including minors. Notably, these practices affect the right to private life, data protection and human dignity of students and pupils, including minors.

Amendment 439
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 17 a (new)
(17 a) AI systems that are intended for use to protect consumers and prevent fraudulent activities should not necessarily be considered high-risk under this Regulation. As set by Article 94 of the Directive (EU) 2015/2366, payment systems and payment service providers should be allowed to process data to safeguard the prevention, investigation and detection of payment fraud. Therefore AI systems used to process data to safeguard the prevention, investigation and detection of fraud may not be considered as high-risk AI systems for the purpose of this Regulation.

Amendment 440
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 17 a (new)
(17 a) AI systems used by law enforcement authorities or on their behalf to make predictions, profiles or risk assessments based on data analysis or profiling of natural groups or locations, for the purpose of predicting the occurrence or reoccurrence of an actual or potential criminal offence(s) or other criminalised social behaviour, hold a particular risk of discrimination against certain persons or groups of persons, as they violate human dignity as well as the key legal principle of presumption of innocence. Such AI systems should therefore be prohibited.

Amendment 441
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Recital 17 a (new)
(17 a) AI systems used in law enforcement and criminal justice contexts based on predictive methods, profiling and risk assessment pose an unacceptable risk to fundamental rights and in particular to the right of non-discrimination, insofar as they contradict the fundamental right to be presumed innocent and are reflective of historical, systemic, institutional and societal discrimination and other discriminatory practices. These AI systems should therefore be prohibited;

Amendment 442
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 17 a (new)
(17 a) AI systems used by law enforcement authorities or on their behalf to predict the probability of a natural person to offend or to reoffend, based on profiling and individual or place-based risk-assessment hold a particular risk of discrimination against certain persons or groups of persons, as they violate human dignity as well as the key legal principle of presumption of innocence. Such AI systems should therefore be prohibited.

Amendment 443
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Sandro Gozi, Vlad-
Recital 17 a (new)
(17 a) AI systems used by law enforcement authorities or on their behalf to predict the probability of a natural person to offend or to reoffend, based on profiling and individual risk-assessment hold a particular risk of discrimination against certain persons or groups of persons, as they violate human dignity as well as the key legal principle of presumption of innocence. Such AI systems should therefore be prohibited.

Amendment 444
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 17 b (new)
(17 b) Insofar as such systems could ever function as intended, AI-based emotion recognition systems carry unacceptable risk for the essence of fundamental rights, such as human dignity and freedom of expression and must be prohibited. Exceptions for therapeutic tools or assistive technologies for personal use only could, nonetheless, be envisaged. However, this should only be permitted if the scientific basis and clinical validity of such systems have been demonstrated, where it can be shown that affected groups were active participants in the development process, and where the rights of everyone that is likely to be affected by the system, and not just the deployer , are clearly respected. Such systems should always be subject to careful oversight and transparency.

Amendment 445
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 17 c (new)
(17 c) Similarly, ostensible truth-detection technologies, such as polygraphs, have a long and unsuccessful history of abuse, misselling, miscarriages of justice and failure. The problems underlying these failures are exacerbated in the field of migration, which thusfar has been tarnished by new failings due to, inter alia to incorrect cultural assumptions. Such technologies therefore cannot be used while protecting the essence of all relevant fundamental rights.

Amendment 446
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 18
deleted

Amendment 447
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 18
(18) The use of AI systems for remote biometric identification of natural persons in publicly or privately accessible spaces, as well as online spaces, for the purpose of law enforcement is considered particularly intrusive in the rights and freedoms of the concerned persons, to the extent that it may affect the private life of a large part of the population, evoke a feeling of constant surveillance and indirectly dissuade the exercise of the freedom of assembly and other fundamental rights. Technical inaccuracies of AI systems intended for the remote biometric identification of natural persons can lead to biased results and entail discriminatory effects. This is particularly relevant when it comes to age, ethnicity, sex or disabilities. In addition, whether such systems are used in 'real-time' or post factum, there is little difference on the impact and the heightened risks for the rights and freedoms of the persons that are concerned by law enforcement activities. The placing or making available on the market, the putting into service or use of those systems should therefore be prohibited.

Amendment 448
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Recital 18
(18) The use of AI systems for remote biometric identification of natural persons in publicly or privately accessible spaces is particularly intrusive in the rights and freedoms of the concerned persons, to the extent that it may affect the private life of a large part of the population, evoke a feeling of constant surveillance and indirectly dissuade the exercise of the freedom of assembly and other fundamental rights. Such systems should therefore be prohibited.

Amendment 449
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Patrick
Recital 18
(18) The use of AI systems for biometric identification of natural persons in publicly accessible spaces is particularly corrosive to the rights and freedoms of the concerned persons and can ultimately affect the private life of a large part of the population, leave society with a justifiable feeling of constant surveillance, give parties deploying biometric identification in publicly accessible spaces a position of uncontrollable power and indirectly dissuade individuals from the exercise of their freedom of assembly and other fundamental rights  the core to the Rule of Law. Biometric identification not carried out in real time carries different but equally problematic risks. Due to the increase in pervasiveness, functionality and memory capacities of relevant devices, this would amount to a "surveillance time machine", which could be used to track movements and social interactions stretching back an indeterminate period into the past.

Amendment 450
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und Hohenstein, Vlad-Marius Botoş, Samira Rafaela, Monica Semedo, Salima Yenbou, Sophia in t Veld, Moritz Körner, Jan-Christoph Oetjen
Recital 18
(18) The use of AI systems for ‘real-time’ remote biometric identification of natural persons in publicly accessible spaces is considered particularly intrusive in the rights and freedoms of the concerned persons, to the extent that it may affect the private life of a large part of the population, evoke a feeling of constant surveillance and indirectly dissuade the exercise of the freedom of assembly and other fundamental rights. In addition, the immediacy of the impact and the limited opportunities for further checks or corrections in relation to the use of such systems operating in ‘real-time’ carry heightened risks for the rights and freedoms of the persons that are concerned by law enforcement activities. The use of those systems in publicly accessible places should therefore be prohibited.

Amendment 451
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 18
(18) The use of AI systems for ‘real-time’ remote biometric identification of natural persons in publicly accessible spaces is considered particularly intrusive in the rights and freedoms of the concerned persons, to the extent that it may affect the private life of a large part of the population, evoke a feeling of constant surveillance and indirectly dissuade the exercise of the freedom of assembly and other fundamental rights. In addition, the immediacy of the impact and the limited opportunities for further checks or corrections in relation to the use of such systems operating in ‘real-time’ carry heightened risks for the rights and freedoms of the persons that are concerned by law enforcement activities. The use of those systems in publicly accessible places should therefore be prohibited.

Amendment 452
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 18
(18) The use of AI systems for ‘real-time’ remote biometric identification of natural persons in publicly accessible spaces for the purpose of law enforcement is considered particularly intrusive in the rights and freedoms of the concerned persons, to the extent that it may affect the private life of a large part of the population, evoke a feeling of constant surveillance and indirectly dissuade the exercise of the freedom of assembly and other fundamental rights. In addition, the immediacy of the impact and the limited opportunities for further checks or corrections in relation to the use of such systems operating in ‘real-time’ carry heightened risks for the rights and freedoms of the persons that are concerned by law enforcement activities. Such AI systems should be therefore prohibited.

Amendment 453
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 18
(18) The use of AI systems for ‘real-time’ remote biometric identification of natural persons in publicly accessible or online spaces for the purpose of law enforcement is considered particularly intrusive in the rights and freedoms of the concerned persons, to the extent that it may affect the private life of a large part of the population, evoke a feeling of constant surveillance and indirectly dissuade the exercise of the freedom of assembly and other fundamental rights. In addition, the immediacy of the impact and the limited opportunities for further checks or corrections in relation to the use of such systems operating in ‘real-time’ carry heightened risks for the rights and freedoms of the persons that are concerned by law enforcement activities.

Amendment 454
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Recital 18
(18) The use of AI systems for ‘real-time’ remote biometric identification of natural persons in publicly accessible spaces is considered particularly intrusive in the rights and freedoms of the concerned persons, to the extent that it may affect the private life of a large part of the population, evoke a feeling of constant surveillance and indirectly dissuade the exercise of the freedom of assembly and other fundamental rights. In addition, the immediacy of the impact and the limited opportunities for further checks or corrections in relation to the use of such systems operating in ‘real-time’ carry heightened risks for the rights and freedoms of the persons that are concerned by law enforcement activities.

Amendment 455
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 18
(18) The use of AI systems for ‘real-time’ remote biometric identification of natural persons in publicly accessible spaces for the purpose of law enforcement is considered particularly intrusive in the rights and freedoms of the concerned persons, to the extent that it affects the private life of a large part of the population, constitutes constant surveillance and indirectly dissuades the exercise of the freedom of assembly and other fundamental rights. In addition, the immediacy of the impact and the limited opportunities for further checks or corrections in relation to the use of such systems operating in ‘real-time’ carry heightened risks for the rights and freedoms of the persons that are concerned by law enforcement activities.

Amendment 456
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 18 a (new)
(18 a) Despite progress regarding biometric identification technologies, the accuracy of the results still varies across technologies and depends on contextual factors. Even the relatively well-established fingerprint identification applications face challenges, in particular at the stage of the collection of biometric data (related to, for example, subject's age). The reliability of face recognition technologies in 'real world' settings is highly dependent on the quality of the images captured and on the quality of the algorithms used for biometric matching. During enrolment, poor quality images taken at e-gates or through a CCTV camera under variable environmental conditions may result in less accurate results. As in the case of automated fingerprint identification, changes in a person's physical characteristics over time may also affect the accuracy of facial recognition technologies. Research has found a considerable degradation in performance for face recognition algorithms on children as compared to the performance obtained on adults. In light of this, the placing or making available on the market, the putting into service or use of remote biometric identification systems should be prohibited.

Amendment 457
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 18 a (new)
(18 a) The notion of ‘at a distance’ in Remote Biometric Identification (RBI) means the use of systems as described in Article 3(36), at a distance great enough that the system has the capacity to scan multiple persons in its field of view (or the equivalent generalised scanning of online / virtual spaces), which would mean that the identification could happen without one or more of the data subjects’ knowledge. Because RBI relates to how a system is designed and installed, and not solely to whether or not data subjects have consented, this definition applies even when warning notices are placed in the location that is under the surveillance of the RBI system, and is not de facto annulled by pre-enrolment.

Amendment 458
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 18 a (new)
(18 a) The notion of ‘at a distance’ in Remote Biometric Identification (RBI) means the use of systems as described in Article 3(36), at a distance great enough that the system has the capacity to scanmultiple persons in its field of view (or the equivalent generalised scanning of online / virtual spaces), which would mean that the identification could happen without one or more of the data subjects’ knowledge. Because RBI relates to how a system is designed and installed, and not solely to whether or not data subjects have consented, this definition applies even when warning notices are placed in the location that is under the surveillance of the RBI system, and is not defacto annulled by pre-enrollment.

Amendment 459
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 18 a (new)
(18 a) The use of data collected or generated by practices prohibited under this Regulation should also be prohibited. Within the framework of judicial and administrative proceedings, the responsible authorities should establish that data collected or generated by practices prohibited under this regulation should not be admissible.

Amendment 460
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 18 b (new)
(18 b) There are serious concerns about the scientific basis of AI systems aiming to detect emotions from facial expressions. Facial expressions and perceptions thereof vary considerably across cultures and situations, and even within a single person. Among the key shortcomings of such technologies are the limited reliability (emotion categories are neither reliably expressed through, nor unequivocally associated with, a common set of facial movements), the lack of specificity (facial expressions do not perfectly match emotion categories) and the limited generalisability (the effects of context and culture are not sufficiently considered). Reliability issues may also arise when deploying the system in real-life situations, for example, when dealing with subjects who actively seek (and train themselves) to fool the system. Therefore, the placing on the market, putting into service, or use of AI systems intended to be used as polygraphs and similar tools to detect the emotional state, trustworthiness or related characteristics of a natural person, should be prohibited.

Amendment 461
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 18 b (new)
(18 b) ‘Biometric categorisation systems’ are defined as AI systems that assign natural persons to specific categories, or infer their characteristics or attributes. ‘Categorisation’ shall include any sorting of natural persons, whether into discrete categories (e.g. male/female, suspicious/not-suspicious), on a numerical scale (e.g. using the Fitzpatrick scale for skin type) or any other form of assigning labels or values to people. ‘Inferring an attribute or characteristic’ shall include any situation in which an AI system uses one type of data about a natural person (e.g. hair colour) to ascribe a different attribute or characteristic to that person (e.g. ethnic origin).

Amendment 462
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 19
deleted

Amendment 463
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 19
deleted

Amendment 464
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und
Recital 19
deleted

Amendment 465
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Recital 19
deleted

Amendment 466
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Recital 19
deleted

Amendment 467
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 19
deleted

Amendment 468
ECR - European Conservatives and Reformists Group
Jorge Buxadé Villalba
Recital 19
(19) The use of those systems for the purpose of law enforcement must therefore be prohibited, with the exception of border control and in the context of the fight against terrorism.

Amendment 469
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 19
(19) The use of those systems for the purpose of law enforcement should therefore be prohibited.

Amendment 470
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Patrick
Recital 19
(19) The use of AI systems for remote biometric identification of individuals should therefore be prohibited

Amendment 471
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte
Recital 19
(19) The use of those systems for the purpose of law enforcement should therefore be prohibited, except in three exhaustively listed and narrowly defined situations, where the use is ad hoc and strictly necessary to achieve a substantial public interest, the importance of which outweighs the risks. Those situations involve the search for potential victims of crime, including missing children; certain threats to the life or physical safety of natural persons or of a terrorist attack; and the detection, localisation, identification or prosecution of perpetrators or suspects of criminal offences if they are punishable by a custodial sentence or a detention order for a maximum period of at least ten years in the Member State concerned. Such threshold for the custodial sentence or detention order in accordance with national law contributes to ensure that the offence should be serious enough to potentially justify the use of ‘real-time’ remote biometric identification systems. The nature of the offences deemed sufficiently serious to justify a penalty up to this threshold is a matter for the national legislation of each Member State in accordance with its own criminal law.

Amendment 472
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Recital 20
deleted

Amendment 473
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 20
deleted

Amendment 474
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Recital 20
deleted

Amendment 475
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 20
deleted

Amendment 476
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Patrick
Recital 20
deleted

Amendment 477
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und
Recital 20
deleted

Amendment 478
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 20
deleted

Amendment 479
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 20
(20) In order to ensure that those systems are used in a responsible and proportionate manner, it is also important to establish that, in exhaustively listed and narrowly defined situations, certain elements should be taken into account, in particular as regards the nature of the situation giving rise to the request and the consequences of the use for the rights and freedoms of all persons concerned and the safeguards and conditions provided for with the use.

Amendment 480
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 20
(20) In order to ensure that those systems are used in a responsible and proportionate manner, it is also important to establish that, in each of those three exhaustively listed and narrowly defined situations, certain elements should be taken into account, in particular as regards the nature of the situation giving rise to the request and the consequences of the use for the rights and freedoms of all persons concerned and the safeguards and conditions provided for with the use. In addition, the use of ‘real-time’ remote biometric identification systems in publicly accessible or online spaces for the purpose of law enforcement should be subject to appropriate limits in time and space, having regard in particular to the evidence or indications regarding the threats, the victims or perpetrator. The reference database of persons should be appropriate for each use case in each of the three situations mentioned above.

Amendment 481
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Recital 21
deleted

Amendment 482
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 21
deleted

Amendment 483
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 21
deleted

Amendment 484
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Patrick
Recital 21
deleted

Amendment 485
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 21
deleted

Amendment 486
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und
Recital 21
deleted

Amendment 487
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Recital 21
deleted

Amendment 488
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 21
(21) Each use of a ‘real-time’ remote biometric identification system in publicly accessible or online spaces for the purpose of law enforcement should be subject to an express and specific authorisation by a judicial authority or by an independent administrative authority of a Member State. Such authorisation should in principle be obtained prior to the use, except in duly justified situations of urgency, that is, situations where the need to use the systems in question is such as to make it effectively and objectively impossible to obtain an authorisation before commencing the use. In such situations of urgency, the use should be restricted to the absolute minimum necessary and be subject to appropriate safeguards and conditions, as determined in national law and specified in the context of each individual urgent use case by the law enforcement authority itself. In addition, the law enforcement authority should in such situations seek to obtain an authorisation as soon as possible, whilst providing the reasons for not having been able to request it earlier.

Amendment 489
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 21
(21) Use of a ‘real-time’ remote biometric identification system in publicly accessible spaces for the purpose of law enforcement should be subject to authorisation by a judicial authority or by an independent administrative authority of a Member State. Such authorisation should in principle be obtained prior to the use, except in duly justified situations of urgency, that is, situations where the need to use the systems in question is such as to make it effectively and objectively impossible to obtain an authorisation before commencing the use. In such situations of urgency, the use should be restricted to the absolute minimum necessary and be subject to appropriate safeguards and conditions, as determined in national law and specified in the context of each individual urgent use case by the law enforcement authority itself. In addition, the law enforcement authority should in such situations seek to obtain an authorisation as soon as possible, whilst providing the reasons for not having been able to request it earlier.

Amendment 490
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 22
deleted

Amendment 491
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Recital 22
deleted

Amendment 492
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Patrick
Recital 22
deleted

Amendment 493
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 22
deleted

Amendment 494
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und
Recital 22
deleted

Amendment 495
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Recital 22
deleted

Amendment 496
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 22
(22) Furthermore, it is appropriate to provide that such use in the territory of a Member State in accordance with this Regulation should only be possible where and in as far as the Member State in question has decided to expressly provide for the possibility to authorise such use in its detailed rules of national law. Consequently, Member States remain free under this Regulation not to provide for such a possibility at all or to only provide limited possibilities in this regard.

Amendment 497
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und
Recital 23
deleted

Amendment 498
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Recital 23
deleted

Amendment 499
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 23
deleted

Amendment 500
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 23
deleted

Amendment 501
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Recital 23
deleted

Amendment 502
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Patrick
Recital 23
(23) The use of AI systems for biometric identification of natural persons in publicly accessible spaces necessarily involves the processing of biometric and biometrics-based data. The rules of this Regulation that prohibit, subject to certain exceptions, such use, which are based on Article 16 TFEU, should apply as lex specialis in respect of the rules on the processing of biometric data contained in Article 10 of Directive (EU) 2016/680 and Article 9 of Regulation 2016/679, thus regulating such use and the processing of biometric data involved in an exhaustive manner.

Amendment 503
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 23
(23) The use of AI systems for ‘real-time’ remote biometric identification of natural persons in publicly accessible spaces for the purpose of law enforcement necessarily involves the processing of biometric data. The rules of this Regulation that prohibit such use, which are based on Article 16 TFEU, should apply as lex specialis in respect of the rules on the processing of biometric data contained in Article 10 of Directive (EU) 2016/680. However, the use of ‘real-time’ remote biometric identification systems in publicly accessible spaces for purposes, including by competent authorities, should not be covered by the specific framework regarding such use for the purpose of law enforcement set by this Regulation. Such use for purposes other than law enforcement should therefore not be subject to the requirement of an authorisation under this Regulation and the applicable detailed rules of national law that may give effect to it. The lex specialis nature of the prohibition on RBI does not provide a legal basis for law enforcement uses of RBI, nor does it weaken existing protections of biometric data under the Data Protection Law Enforcement Directive (LED) or national implementations of the LED.

Amendment 504
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 23
(23) The use of AI systems for ‘real-time’ remote biometric identification of natural persons in publicly accessible or online spaces for the purpose of law enforcement necessarily involves the processing of biometric data. Therefore, such use and processing should only be possible in as far as it is compatible with the framework set by this Regulation, without there being scope, outside that framework, for the competent authorities, where they act for purpose of law enforcement, to use such systems and process such data in connection thereto on the grounds listed in Article 10 of Directive (EU) 2016/680. In this context, this Regulation is not intended to provide the legal basis for the processing of personal data under Article 8 of Directive 2016/680. However, the use of ‘real-time’ remote biometric identification systems in publicly accessible or online spaces for purposes other than law enforcement, including by competent authorities, should not be covered by the specific framework regarding such use for the purpose of law enforcement set by this Regulation. Such use for purposes other than law enforcement should therefore not be subject to the requirement of an authorisation under this Regulation and the applicable detailed rules of national law that may give effect to it.

Amendment 505
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte
Recital 23
(23) The use of AI systems for ‘real-time’ remote biometric identification of natural persons in publicly accessible spaces for the purpose of law enforcement necessarily involves the processing of biometric data. The rules of this Regulation that prohibit, subject to certain exceptions, such use, which are based on Article 16 TFEU, should apply as lex specialis in respect of the rules on the processing of biometric data contained in Article 10 of Directive (EU) 2016/680, thus regulating such use and the processing of biometric data involved in an exhaustive manner. Therefore, such use and processing should only be possible in as far as it is compatible with the framework set by this Regulation, without there being scope, outside that framework, for the competent authorities, where they act for purpose of law enforcement, to use such systems and process such data in connection thereto on the grounds listed in Article 10 of Directive (EU) 2016/680. In this context, this Regulation is not intended to provide the legal basis for the processing of personal data under Article 8 of Directive 2016/680. The use of biometric identification systems, including ‘real-time’ remote biometric identification systems in publicly accessible spaces for purposes other than law enforcement, including by competent authorities, should be covered by the framework set by this Regulation, with the exception of customs formalities and individual authentication.

Amendment 506
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 23
(23) The use of AI systems for ‘real-time’ remote biometric identification of natural persons in publicly accessible spaces for the purpose of law enforcement necessarily involves the processing of biometric data. The rules of this Regulation which are based on Article 16 TFEU, should apply as lex specialis in respect of the rules on the processing of biometric data contained in Article 10 of Directive (EU) 2016/680, thus regulating such use and the processing of biometric data involved in an exhaustive manner. Therefore, such use and processing should only be possible in as far as it is compatible with the framework set by this Regulation, without there being scope, outside that framework, for the competent authorities, where they act for purpose of law enforcement, to use such systems and process such data in connection thereto on the grounds listed in Article 10 of Directive (EU) 2016/680. In this context, this Regulation is not intended to provide the legal basis for the processing of personal data under Article 8 of Directive 2016/680. However, the use of ‘real-time’ remote biometric identification systems in publicly accessible spaces for purposes other than law enforcement, including by competent authorities, should not be covered by the specific framework regarding such use for the purpose of law enforcement set by this Regulation. Such use for purposes other than law enforcement should therefore not be subject to the requirement of an authorisation under this Regulation and the applicable detailed rules of national law that may give effect to it.

Amendment 507
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 23 a (new)
(23 a) ‘Biometric categorisation systems’ are defined as AI systems that assign natural persons to specific categories, or infer their characteristics or attributes. ‘Categorisation’ shall include any sorting of natural persons, whether into discrete categories (e.g. male/female, suspicious/not-suspicious), on a numerical scale (e.g. using the Fitzpatrick scale for skin type) or any other form of assigning labels or values to people. ‘Inferring an attribute or characteristic’ shall include any situation in which an AI system uses one type of data about a natural person (e.g. hair colour) to ascribe a different attribute or characteristic to that person (e.g. ethnic origin).

Amendment 508
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Recital 24
deleted

Amendment 509
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Recital 24
deleted

Amendment 510
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 24
(24) Any processing of biometric data and other personal data involved in the use of AI systems for biometric identification should continue to comply with all requirements resulting from Article 9(1) of Regulation (EU) 2016/679, Article 10(1) of Regulation (EU) 2018/1725 and Article 10 of Directive (EU) 2016/680, as applicable.

Amendment 511
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Róża Thun und
Recital 24
(24) Any processing of biometric data and other personal data involved in the use of AI systems for biometric identification, including where those systems are used by competent authorities in publicly accessible spaces for other purposes than law enforcement, should continue to comply with all requirements resulting from Article 9(1) of Regulation (EU) 2016/679, Article 10(1) of Regulation (EU) 2018/1725 and Article 10 of Directive (EU) 2016/680, as applicable.

Amendment 512
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 24
(24) Any processing of biometric data and other personal data involved in the use of AI systems for biometric identification, including where those systems are used by competent authorities in publicly accessible spaces for other purposes than law enforcement, should continue to comply with all requirements resulting from Article 9(1) of Regulation (EU) 2016/679, Article 10(1) of Regulation (EU) 2018/1725 and Article 10 of Directive (EU) 2016/680, as applicable.

Amendment 513
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Patrick
Recital 24
(24) Any processing of biometric data, biometrics-based data and other personal data involved in the use of AI systems for biometric identification, other than in connection to the use of biometric identification systems in publicly accessible spaces as regulated by this Regulation, should continue to comply with all requirements resulting from Article 9(1) of Regulation (EU) 2016/679, Article 10(1) of Regulation (EU) 2018/1725 and Article 10 of Directive (EU) 2016/680, as applicable.

Amendment 514
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 24
(24) Any processing of biometric data and other personal data involved in the use of AI systems for biometric identification, other than in connection to the use of ‘real-time’ remote biometric identification systems in publicly accessible or online spaces for the purpose of law enforcement as regulated by this Regulation, including where those systems are used by competent authorities in publicly accessible or online spaces for other purposes than law enforcement, should continue to comply with all requirements resulting from Article 9(1) of Regulation (EU) 2016/679, Article 10(1) of Regulation (EU) 2018/1725 and Article 10 of Directive (EU) 2016/680, as applicable.

Amendment 515
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Karen Melchior, Dita Charanzová, Andrus Ansip, Morten
Recital 24 a (new)
(24 a) Fundamental rights in the digital sphere have to be guaranteed to the same extent as in the offline world. The right to privacy needs to be ensured, amongst others through end-to-end encryption in private online communication and the protection of private content against any kind of general or targeted surveillance, be it by public or private actors. Therefore, the use of AI systems violating the right to privacy in online communication services should be prohibited.

Amendment 516
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Recital 25
(25) In accordance with Article 6a of Protocol No 21 on the position of the United Kingdom and Ireland in respect of the area of freedom, security and justice, as annexed to the TEU and to the TFEU, Ireland is not bound by the rules laid down in Article 5(1), point (d) of this Regulation adopted on the basis of Article 16 of the TFEU which relate to the processing of personal data by the Member States when carrying out activities falling within the scope of Chapter 4 or Chapter 5 of Title V of Part Three of the TFEU, where Ireland is not bound by the rules governing the forms of judicial cooperation in criminal matters or police cooperation which require compliance with the provisions laid down on the basis of Article 16 of the TFEU.

Amendment 517
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Recital 26
(26) In accordance with Articles 2 and 2a of Protocol No 22 on the position of Denmark, annexed to the TEU and TFEU, Denmark is not bound by rules laid down in Article 5(1), point (d) of this Regulation adopted on the basis of Article 16 of the TFEU, or subject to their application, which relate to the processing of personal data by the Member States when carrying out activities falling within the scope of Chapter 4 or Chapter 5 of Title V of Part Three of the TFEU.

Amendment 518
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 27
(26 a) AI systems capable of reading facial expressions to infer emotional states hold no scientific basis, while at the same time running a high risk of inaccuracy, in particular for certain groups of individuals whose facial traits are not easily readable by such systems, as several examples have shown. Therefore, due to the particular risk of discrimination, these systems should be prohibited.

Amendment 519
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 27
(27) High-risk AI systems should only be placed on the Union market or put into service if they comply with certain mandatory requirements. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as recognised and protected by Union law. AI systems identified as high-risk should be classified as such when they have a significant harmful impact on the health, safety, economic status and fundamental rights of individuals in the Union, and also on the environment, society, rule of law, democracy or consumer protection. Given the rapid path of technological development, but also given the potential changes in the use and the aim of authorised AI systems, regardless of whether they are high-risk or lower risk, the limited list of high-risk systems and areas of high risk systems in Annex III should nonetheless be subject to permanent review through the exercise of regular assessment as provided in Title III of this Regulation.

Amendment 520
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Recital 27
(27) High-risk AI systems should only be placed on the Union market or put into service if they comply with certain mandatory requirements. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as recognised and protected by Union law. AI systems identified as high-risk should be limited to those that have a significant harmful impact on the health, safety and fundamental rights of persons in the Union and such limitation minimises any potential restriction to international trade, if any. In particular, the classification as high-risk according to Article 6 should not apply to AI systems whose intended purpose demonstrates that the generated output is a recommendation, provided it is delivered with the information on its accuracy or other relevant methodical aspects necessary for the decision making. A human intervention is required to convert this recommendation into an action.

Amendment 521
EPP - Group of the European Peoples Party (Christian Democrats)
Deirdre Clune, Axel Voss, Andreas Schwab
Recital 27
(27) High-risk AI systems should only be placed on the Union market or put into service if they comply with certain mandatory requirements. To ensure alignment with sectoral legislation, requirements for certain high-risk AI systems and uses will take account of sectoral legislation which already lay out sufficient requirements for high-risk AI systems included within this Act, such as Regulation (EU) 2017/745 on Medical Devices and Regulation (EU) 2017/746 on In Vitro Diagnostic Devices and Directive 2006/42/EC on Machinery. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as recognised and protected by Union law. AI systems identified as high-risk should be limited to those that have a significant harmful impact on the health, safety and fundamental rights of persons in the Union and such limitation minimises any potential restriction to international trade, if any.

Amendment 522
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 27
(27) High-risk AI systems should only be placed on the Union market or put into service if they comply with certain mandatory requirements. To ensure alignment with sectoral legislation, requirements for certain high-risk AI systems and uses will take account of sectoral legislation which already lay out sufficient requirements for high-risk AI systems included within this Act, such as Regulation (EU) 2017/745 on Medical Devices and Regulation (EU) 2017/746 on In Vitro Diagnostic Devices and Directive 2006/42/EC on Machinery. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as recognised and protected by Union law. AI systems identified as high-risk should be limited to those that have a significant harmful impact on the health, safety and fundamental rights of persons in the Union and such limitation minimises any potential restriction to international trade, if any.

Amendment 523
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Recital 27
(27) High-risk AI systems should only be placed on the Union market or put into service if they comply with certain mandatory requirements. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as recognised and protected by Union law. AI systems identified as high-risk should be limited to those that have a significant harmful impact on the health, safety and fundamental rights of persons in the Union and such limitation minimises any potential restriction to international trade, if any. In particular, the classification as high-risk according to Article 6 should not apply to AI systems whose intended purpose demonstrates that the generated output is a recommendation and a human intervention is required to convert this recommendation into an action.

Amendment 524
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 27
(27) High-risk AI systems should only be placed on the Union market or put into service if they comply with certain mandatory requirements. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as recognised and protected by Union law and do not breach the Union values enshrined in Article 2 TEU or the principles applicable to all AI systems as per this Regulation. AI systems identified as high-risk should be limited to those that have a significant harmful impact on the fundamental rights of persons, their health and safety and such limitation minimises any potential restriction to international trade, if any.

Amendment 525
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina Penkova, René Repasi, Birgit Sippel, Maria Grapini, Adriana Maldonado López, Maria-Manuel Leitão-Marques, Marc Angel
Recital 27
(27) High-risk AI systems should only be placed on the Union market or put into service or used if they comply with certain mandatory requirements. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as recognised and protected by Union law and do not contravene the Union values enshrined in Article 2 TEU. AI systems identified as high-risk should be limited to those that have a significant harmful impact on the health, safety and the fundamental rights of persons in the Union or the environment and such limitation minimises any potential restriction to international trade, if any.

Amendment 526
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 27
(27) High-risk AI systems should only be placed on the Union market or put into service if they comply with certain mandatory requirements. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as recognised and protected by Union law. AI systems identified as high-risk should be limited to those that have a significant harmful impact on the health, safety and fundamental rights of persons in the Union, as well as the public order and national security of the Member States, and such limitation minimises any potential restriction to international trade, if any.

Amendment 527
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 27
(27) High-risk AI systems should only be placed on the Union market or put into service if they comply with certain mandatory requirements. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as recognised and protected by Union law. AI systems identified as high-risk should be limited to those that have a significant harmful impact on the health, safety and fundamental rights of persons in the Union or to Union values as enshrined in Article 2 TEU and such limitation minimises any potential restriction to international trade, if any.

Amendment 528
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 27
(27) High-risk AI systems should only be placed on the Union market or put into service if they comply with certain mandatory requirements. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interests as recognised and protected by Union law. AI systems identified as high-risk should be limited to those that have a harmful impact on the health, safety and fundamental rights of persons, but also on the environment, democracy and the rule of law in the Union..

Amendment 529
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 28
(28) AI systems could produce adverse outcomes to health and safety of persons, in particular when such systems operate as components of products. Consistently with the objectives of Union harmonisation legislation to facilitate the free movement of products in the internal market and to ensure that only safe and otherwise compliant products find their way into the market, it is important that the safety risks that may be generated by a product as a whole due to its digital components, including AI systems, are duly prevented and mitigated. For instance, increasingly autonomous robots, whether in the context of manufacturing or personal assistance and care should be able to safely operate and performs their functions in complex environments. Similarly, in the health sector where the stakes for life and health are particularly high, increasingly sophisticated diagnostics systems and systems supporting human decisions should be reliable and accurate. Conversely, industrial robots used in manufacturing processes that operate within a predefined and restricted area entail considerably lower safety risks and are already subject to harmonised safety legislation. The extent of the adverse impact caused by the AI system on the fundamental rights protected by the Charter is of particular relevance when classifying an AI system as high-risk. Those rights include the right to human dignity, respect for private and family life, protection of personal data, freedom of expression and information, freedom of assembly and of association, and non-discrimination, consumer protection, workers’ rights, rights of persons with disabilities, right to an effective remedy and to a fair trial, right of defence and the presumption of innocence, right to good administration. In addition to those rights, it is important to highlight that children have specific rights as enshrined in Article 24 of the EU Charter and in the United Nations Convention on the Rights of the Child (further elaborated in the UNCRC General Comment No. 25 as regards the digital environment), both of which require consideration of the children’s vulnerabilities and provision of such protection and care as necessary for their well-being. The fundamental right to a high level of environmental protection enshrined in the Charter and implemented in Union policies should also be considered when assessing the severity of the harm that an AI system can cause, including in relation to the health and safety of persons.

Amendment 530
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 28
(28) AI systems could have an adverse impact on persons, in particular when such systems operate as components of products. Consistently with the objectives of Union harmonisation legislation to facilitate the free movement of products in the internal market and to ensure that only safe and otherwise compliant products find their way into the market, it is important that the safety risks that may be generated by a product as a whole due to its digital components, including AI systems, are duly prevented and mitigated. For instance, increasingly autonomous robots, whether in the context of manufacturing or personal assistance and care should be able to safely operate and performs their functions in complex environments. Similarly, in the health sector where the stakes for life and health are particularly high, increasingly sophisticated diagnostics systems and systems supporting human decisions should be reliable and accurate. The extent of the adverse impact caused by the AI system on the fundamental rights protected by the Charter is of particular relevance when classifying an AI system as high-risk. Those rights include the right to human dignity, respect for private and family life, protection of personal data, freedom of expression and information, freedom of assembly and of association, and non-discrimination, consumer protection, workers’ rights, rights of persons with disabilities, right to an effective remedy and to a fair trial, right of defence and the presumption of innocence, right to good administration. In addition to those rights, it is important to highlight that children have specific rights as enshrined in Article 24 of the EU Charter and in the United Nations Convention on the Rights of the Child (further elaborated in the UNCRC General Comment No. 25 as regards the digital environment), both of which require consideration of the children’s vulnerabilities and provision of such protection and care as necessary for their well-being. The fundamental right to a high level of environmental protection enshrined in the Charter and implemented in Union policies should also be considered when assessing the severity of the harm that an AI system can cause.

Amendment 531
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 28 a (new)
(28 a) The risk-assessment of AI systems as regards their environmental impact and use of resources should not only focus on sectors related to the protection of the environment, but be common to all sectors, as environmental impacts can stem from any kind of AI systems, including those not originally directly related to the protection of the environment, in terms of energy production and distribution, waste management and emissions control.

Amendment 532
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 29
(29) As regards high-risk AI systems that are safety components of products or systems, or which are themselves products or systems falling within the scope of Regulation (EC) No 300/2008 of the European Parliament and of the Council39 , Regulation (EU) No 167/2013 of the European Parliament and of the Council40 , Regulation (EU) No 168/2013 of the European Parliament and of the Council41 , Directive 2014/90/EU of the European Parliament and of the Council42 , Directive (EU) 2016/797 of the European Parliament and of the Council43 , Regulation (EU) 2018/858 of the European Parliament and of the Council44 , Regulation (EU) 2018/1139 of the European Parliament and of the Council45 , and Regulation (EU) 2019/2144 of the European Parliament and of the Council46, Regulation (EU) 2017/745 of the European Parliament and of the Council, and Regulation (EU) 2017/746 of the European Parliament and of the Council, it is appropriate to amend those acts to ensure that the Commission takes into account, on the basis of the technical and regulatory specificities of each sector, and without interfering with existing governance, conformity assessment, market surveillance and enforcement mechanisms and authorities established therein, the mandatory requirements for high-risk AI systems laid down in this Regulation when adopting any relevant future delegated or implementing acts on the basis of those acts.' '39 Regulation (EC) No 300/2008 of the European Parliament and of the Council of 11 March 2008 on common rules in the field of civil aviation security and repealing Regulation (EC) No 2320/2002 (OJ L 97, 9.4.2008, p. 72).', '40 Regulation (EU) No 167/2013 of the European Parliament and of the Council of 5 February 2013 on the approval and market surveillance of agricultural and forestry vehicles (OJ L 60, 2.3.2013, p. 1).', '41 Regulation (EU) No 168/2013 of the European Parliament and of the Council of 15 January 2013 on the approval and market surveillance of two- or three-wheel vehicles and quadricycles (OJ L 60, 2.3.2013, p. 52).', '42 Directive 2014/90/EU of the European Parliament and of the Council of 23 July 2014 on marine equipment and repealing Council Directive 96/98/EC (OJ L 257, 28.8.2014, p. 146).', '43 Directive (EU) 2016/797 of the European Parliament and of the Council of 11 May 2016 on the interoperability of the rail system within the European Union (OJ L 138, 26.5.2016, p. 44).', '44 Regulation (EU) 2018/858 of the European Parliament and of the Council of 30 May 2018 on the approval and market surveillance of motor vehicles and their trailers, and of systems, components and separate technical units intended for such vehicles, amending Regulations (EC) No 715/2007 and (EC) No 595/2009 and repealing Directive 2007/46/EC (OJ L 151, 14.6.2018, p. 1).', '45 Regulation (EU) 2018/1139 of the European Parliament and of the Council of 4 July 2018 on common rules in the field of civil aviation and establishing a European Union Aviation Safety Agency, and amending Regulations (EC) No 2111/2005, (EC) No 1008/2008, (EU) No 996/2010, (EU) No 376/2014 and Directives 2014/30/EU and 2014/53/EU of the European Parliament and of the Council, and repealing Regulations (EC) No 552/2004 and (EC) No 216/2008 of the European Parliament and of the Council and Council Regulation (EEC) No 3922/91 (OJ L 212, 22.8.2018, p. 1).', '46 Regulation (EU) 2019/2144 of the European Parliament and of the Council of 27 November 2019 on type-approval requirements for motor vehicles and their trailers, and systems, components and separate technical units intended for such vehicles, as regards their general safety and the protection of vehicle occupants and vulnerable road users, amending Regulation (EU) 2018/858 of the European Parliament and of the Council and repealing Regulations (EC) No 78/2009, (EC) No 79/2009 and (EC) No 661/2009 of the European Parliament and of the Council and Commission Regulations (EC) No 631/2009, (EU) No 406/2010, (EU) No 672/2010, (EU) No 1003/2010, (EU) No 1005/2010, (EU) No 1008/2010, (EU) No 1009/2010, (EU) No 19/2011, (EU) No 109/2011, (EU) No 458/2011, (EU) No 65/2012, (EU) No 130/2012, (EU) No 347/2012, (EU) No 351/2012, (EU) No 1230/2012 and (EU) 2015/166 (OJ L 325, 16.12.2019, p. 1).

Amendment 533
EPP - Group of the European Peoples Party (Christian Democrats)
Deirdre Clune, Axel Voss, Andreas Schwab
Recital 29
(29) As regards high-risk AI systems that are safety components of products or systems, or which are themselves products or systems falling within the scope of Regulation (EC) No 300/2008 of the European Parliament and of the Council39 , Regulation (EU) No 167/2013 of the European Parliament and of the Council40 , Regulation (EU) No 168/2013 of the European Parliament and of the Council41 , Directive 2014/90/EU of the European Parliament and of the Council42 , Directive (EU) 2016/797 of the European Parliament and of the Council43 , Regulation (EU) 2018/858 of the European Parliament and of the Council44 , Regulation (EU) 2018/1139 of the European Parliament and of the Council45 , and Regulation (EU) 2019/2144 of the European Parliament and of the Council46 , Regulation (EU)2017/745 of the European Parliament and of the Council, and Regulation (EU)2017/746 of the European Parliament and of the Council, it is appropriate to amend those acts to ensure that the Commission takes into account, on the basis of the technical and regulatory specificities of each sector, and without interfering with existing governance, conformity assessment and enforcement mechanisms and authorities established therein, the mandatory requirements for high-risk AI systems laid down in this Regulation when adopting any relevant future delegated or implementing acts on the basis of those acts.' '39 Regulation (EC) No 300/2008 of the European Parliament and of the Council of 11 March 2008 on common rules in the field of civil aviation security and repealing Regulation (EC) No 2320/2002 (OJ L 97, 9.4.2008, p. 72).', '40 Regulation (EU) No 167/2013 of the European Parliament and of the Council of 5 February 2013 on the approval and market surveillance of agricultural and forestry vehicles (OJ L 60, 2.3.2013, p. 1).', '41 Regulation (EU) No 168/2013 of the European Parliament and of the Council of 15 January 2013 on the approval and market surveillance of two- or three-wheel vehicles and quadricycles (OJ L 60, 2.3.2013, p. 52).', '42 Directive 2014/90/EU of the European Parliament and of the Council of 23 July 2014 on marine equipment and repealing Council Directive 96/98/EC (OJ L 257, 28.8.2014, p. 146).', '43 Directive (EU) 2016/797 of the European Parliament and of the Council of 11 May 2016 on the interoperability of the rail system within the European Union (OJ L 138, 26.5.2016, p. 44).', '44 Regulation (EU) 2018/858 of the European Parliament and of the Council of 30 May 2018 on the approval and market surveillance of motor vehicles and their trailers, and of systems, components and separate technical units intended for such vehicles, amending Regulations (EC) No 715/2007 and (EC) No 595/2009 and repealing Directive 2007/46/EC (OJ L 151, 14.6.2018, p. 1).', '45 Regulation (EU) 2018/1139 of the European Parliament and of the Council of 4 July 2018 on common rules in the field of civil aviation and establishing a European Union Aviation Safety Agency, and amending Regulations (EC) No 2111/2005, (EC) No 1008/2008, (EU) No 996/2010, (EU) No 376/2014 and Directives 2014/30/EU and 2014/53/EU of the European Parliament and of the Council, and repealing Regulations (EC) No 552/2004 and (EC) No 216/2008 of the European Parliament and of the Council and Council Regulation (EEC) No 3922/91 (OJ L 212, 22.8.2018, p. 1).', '46 Regulation (EU) 2019/2144 of the European Parliament and of the Council of 27 November 2019 on type-approval requirements for motor vehicles and their trailers, and systems, components and separate technical units intended for such vehicles, as regards their general safety and the protection of vehicle occupants and vulnerable road users, amending Regulation (EU) 2018/858 of the European Parliament and of the Council and repealing Regulations (EC) No 78/2009, (EC) No 79/2009 and (EC) No 661/2009 of the European Parliament and of the Council and Commission Regulations (EC) No 631/2009, (EU) No 406/2010, (EU) No 672/2010, (EU) No 1003/2010, (EU) No 1005/2010, (EU) No 1008/2010, (EU) No 1009/2010, (EU) No 19/2011, (EU) No 109/2011, (EU) No 458/2011, (EU) No 65/2012, (EU) No 130/2012, (EU) No 347/2012, (EU) No 351/2012, (EU) No 1230/2012 and (EU) 2015/166 (OJ L 325, 16.12.2019, p. 1).

Amendment 534
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Dita Charanzová, Andrus Ansip, Morten Løkkegaard,
Recital 30
(30) As regards AI systems that are safety components of products, or which are themselves products, falling within the scope of certain Union harmonisation legislation, it is appropriate to classify them as high-risk under this Regulation if the product in question undergoes the conformity assessment procedure in order to ensure compliance with essential safety requirements with a third-party conformity assessment body pursuant to that relevant Union harmonisation legislation. In particular, such products are machinery, toys, lifts, equipment and protective systems intended for use in potentially explosive atmospheres, radio equipment, pressure equipment, recreational craft equipment, cableway installations, appliances burning gaseous fuels, medical devices, and in vitro diagnostic medical devices.

Amendment 535
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 30
(30) As regards AI systems that are safety components of products, or which are themselves products, falling within the scope of certain Union harmonisation legislation (as specified in Annex II), it is appropriate to classify them as high-risk under this Regulation if the product in question undergoes the conformity assessment procedure with a third-party conformity assessment body pursuant to that relevant Union harmonisation legislation. In particular, such products are machinery, toys, lifts, equipment and protective systems intended for use in potentially explosive atmospheres, radio equipment, pressure equipment, recreational craft equipment, cableway installations, appliances burning gaseous fuels, medical devices, and in vitro diagnostic medical devices.

Amendment 536
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 31
(31) The classification of an AI system as high-risk pursuant to this Regulation should not necessarily mean that the product whose safety component is the AI system, or the AI system itself as a product, is considered ‘high-risk’ under the criteria established in the relevant Union harmonisation legislation that applies to the product. This is notably the case for Regulation (EU) 2017/745 of the European Parliament and of the Council47 and Regulation (EU) 2017/746 of the European Parliament and of the Council48, where a third-party conformity assessment is provided for medium-risk and high-risk products. However, the classification of an AI system as high risk for the sole purpose of this Regulation will apply to all products which use that AI system or which are themselves AI systems, irrespective of their classification under the sector-specific harmonisation legislation of the Union under which they are otherwise covered.' '47 Regulation (EU) 2017/745 of the European Parliament and of the Council of 5 April 2017 on medical devices, amending Directive 2001/83/EC, Regulation (EC) No 178/2002 and Regulation (EC) No 1223/2009 and repealing Council Directives 90/385/EEC and 93/42/EEC (OJ L 117, 5.5.2017, p. 1).', '48 Regulation (EU) 2017/746 of the European Parliament and of the Council of 5 April 2017 on in vitro diagnostic medical devices and repealing Directive 98/79/EC and Commission Decision 2010/227/EU (OJ L 117, 5.5.2017, p. 176).

Amendment 537
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 31
(31) The classification of an AI system as high-risk pursuant to this Regulation shall not mean that the product whose safety component is the AI system, or the AI system itself as a product, is considered ‘high-risk’ under the criteria established in the relevant Union harmonisation legislation that applies to the product. This is notably the case for Regulation (EU) 2017/745 of the European Parliament and of the Council47 and Regulation (EU) 2017/746 of the European Parliament and of the Council48.' '47 Regulation (EU) 2017/745 of the European Parliament and of the Council of 5 April 2017 on medical devices, amending Directive 2001/83/EC, Regulation (EC) No 178/2002 and Regulation (EC) No 1223/2009 and repealing Council Directives 90/385/EEC and 93/42/EEC (OJ L 117, 5.5.2017, p. 1).', '48 Regulation (EU) 2017/746 of the European Parliament and of the Council of 5 April 2017 on in vitro diagnostic medical devices and repealing Directive 98/79/EC and Commission Decision 2010/227/EU (OJ L 117, 5.5.2017, p. 176).

Amendment 538
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 32
(32) As regards stand-alone AI systems, meaning high-risk AI systems other than those that are safety components of products, or which are themselves products, it is appropriate to classify them as high-risk if, in the light of their intended purpose, they pose a high risk of harm to the health, safety or the fundamental rights of persons or to Union values as enshrined in Article 2 TEU, taking into account both the severity of the possible harm and its probability of occurrence and they are used in a number of specifically pre-defined areas specified in the Regulation. The identification of those systems is based on the same methodology and criteria envisaged also for any future amendments of the list of high-risk AI systems. Such systems should be classified as high-risk only insofar as they are built and operated with biometric, biometrics-based, or personal data or they influence decisions of natural persons or make decisions or influence decisions affecting natural persons. This ensures that, when referencing AI systems in pre-defined areas of human activity, this Regulation does not inadvertently apply to AI systems that can have no impact on the health, safety, fundamental rights of natural persons or the values of the Union as enshrined in Article 2 TEU.

Amendment 539
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 32
(32) As regards stand-alone AI systems, meaning high-risk AI systems other than those that are safety components of products, or which are themselves products, it is appropriate to classify them as high-risk if, in the light of their intended purpose, they pose a significant risk of harm to the health and safety or the fundamental rights of persons, as well as the environment, society, rule of law, democracy, economic interests and consumer protection, taking into account both the severity of the possible harm and its probability of occurrence and they are used in a number of specifically pre-defined areas specified in the Regulation. The identification of those systems is based on the same methodology and criteria envisaged also for any future amendments of the list of high-risk AI systems. Such classification should take place before the placing onto the market but also during the life-cycle of an AI system.

Amendment 540
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 32
(32) As regards stand-alone AI systems, meaning high-risk AI systems other than those that are safety components of products, or which are themselves products, it is appropriate to classify them as high-risk if, in the light of their intended purpose or reasonably foreseeable uses, they pose a high risk of harm to the health and safety or the fundamental rights of persons, taking into account both the severity of the possible harm and its probability of occurrence and they are used in a number of specifically pre-defined areas specified in the Regulation. The identification of those systems is based on the same methodology and criteria envisaged also for any future amendments of the list of high-risk AI systems.', '(This amendment should apply throughout the text, i.e. any occurrence of "intended purpose" should be followed by "or reasonably foreseeable uses")

Amendment 541
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Patryk Jaki, Adam Bielan
Recital 32
(32) As regards stand-alone AI systems, meaning high-risk AI systems other than those that are safety components of products, or which are themselves products, it is appropriate to classify them as high-risk if, in the light of their intended purpose, they pose a high risk of harm to the health, natural environment, and safety or the fundamental rights of persons, taking into account both the severity of the possible harm and its probability of occurrence and they are used in a number of specifically pre-defined areas specified in the Regulation. The identification of those systems is based on the same methodology and criteria envisaged also for any future amendments of the list of high-risk AI systems.

Amendment 542
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 32
(32) As regards stand-alone AI systems, meaning high-risk AI systems other than those that are safety components of products, or which are themselves products, it is appropriate to classify them as high-risk if, in the light of their foreseeable uses, they pose a high risk of harm to the health and safety or the fundamental rights of persons, taking into account both the severity of the possible harm and its probability of occurrence and they are used in a number of specifically pre-defined areas specified in the Regulation. The identification of those systems is based on the same methodology and criteria envisaged also for any future amendments of the list of high-risk AI systems.

Amendment 543
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 32 a (new)
(32 a) In the light of the nature and complexity of the value chain for AI systems, it is essential to consider the foreseeable high-risks they can create when combined. Particular attention should be paid to the foreseeable uses and reasonably foreseeable misuses of AI systems with indeterminate uses.

Amendment 544
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 33
deleted

Amendment 545
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Recital 33
deleted

Amendment 546
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Dita Charanzová,
Recital 33
(33) Technical inaccuracies of AI systems intended for the remote biometric identification of natural persons can lead to biased results and entail discriminatory effects. This is particularly relevant when it comes to age, ethnicity, sex or disabilities. Therefore, ‘real-time’ and ‘post’ remote biometric identification systems should be classified as high-risk, except for verification or authentification systems whose sole purpose is to confirm that a specific natural person is the person he or she claims to be, and systems that are used to confirm the identity of a natural person for the sole purpose of having access to a service, a device or premises. In view of the risks that they pose, both types of remote biometric identification systems should be subject to specific requirements on logging capabilities and human oversight.

Amendment 547
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Recital 33
(33) Technical inaccuracies of AI systems intended for the remote biometric identification of natural persons can lead to biased results and entail discriminatory effects. This is particularly relevant when it comes to age, ethnicity, sex or disabilities. Therefore, ‘real-time’ and ‘post’ remote biometric identification systems should be classified as high-risk, except for the purpose of remote client on-boarding or verification of a user through a device. In view of the risks that they may pose, both types of remote biometric identification systems should be subject to specific requirements on logging capabilities and, when appropriate and justified by a proven added value to the protection of health, safety and fundamental rights, human oversight.

Amendment 548
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Recital 33
(33) Technical inaccuracies of AI systems intended for the remote biometric identification of natural persons can lead to biased results and entail discriminatory effects. This is particularly relevant when it comes to age, ethnicity, sex or disabilities. Therefore, ‘real-time’ and ‘post’ remote biometric identification systems should be classified as high-risk. In view of the risks that they may pose, both types of remote biometric identification systems should be subject to specific requirements on logging capabilities and, when appropriate and justified by a proven added value to the protection of health, safety and fundamental rights, human oversight.

Amendment 549
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Recital 33
(33) Technical inaccuracies of AI systems intended for the biometric identification of natural persons, including remote biometric identification, can lead to biased results and entail discriminatory effects. This is particularly relevant when it comes to age, ethnicity, sex or disabilities. Therefore, ‘real-time’ and ‘post’ remote biometric identification systems , including remote biometric identification, should be classified as high-risk. In view of the risks that they pose, both types of remote biometric identification systems should be subject to specific requirements on logging capabilities and human oversight.

Amendment 550
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 33
(33) Technical inaccuracies of AI systems intended for the remote biometric identification of natural persons can lead to biased results and entail discriminatory effects. This is particularly relevant when it comes to age, ethnicity, sex or disabilities. Therefore, ‘real-time’ and ‘post’ remote biometric identification systems should be classified as high-risk. In view of the risks that they pose, both types of remote biometric identification systems should be prohibited.

Amendment 551
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Patrick
Recital 33
(33) Technical inaccuracies, as well as conscious or subconscious design decisions, and the use of training data which codify and reinforce structural inequalities, mean that AI systems intended for the remote biometric identification of natural persons can lead to biased results and entail discriminatory effects. This is particularly relevant when it comes to age, ethnicity, sex or disabilities. As a result, ‘real-time’ and ‘post’ remote biometric identification systems undermine the essence of fundamental rights and therefore must be prohibited.

Amendment 552
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 33 a (new)
(33 a) Human oversight should target high-risk AI systems as a priority, with the aim of serving human-centric objectives. The individuals to whom human oversight is assigned shall be provided with adequate education and training on the functioning of the application, its capabilities to influence or make decisions, and to have harmful effects, notably on fundamental rights. The persons in charge of the assignment of these individuals shall provide them with relevant staff and psychological support.

Amendment 553
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 34
(34) As regards the management and operation of critical infrastructure, it is appropriate to classify as high-risk the AI systems intended to be used as safety or security components in the management and operation of road traffic and the supply of water, gas, heating and electricity, since their failure or malfunctioning may infringe the security and integrity of such critical infrastructure and thus put at risk the life and health of persons at large scale and lead to appreciable disruptions in the ordinary conduct of social and economic activities.

Amendment 554
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 34
(34) As regards the management and operation of critical infrastructure, it is appropriate to classify as high-risk the AI systems intended to be used as safety components in the management and operation of road traffic and the supply of water, gas, heating and electricity, and internet, since their failure or malfunctioning may put at risk the life and health of persons at large scale and lead to appreciable disruptions in the ordinary conduct of social and economic activities.

Amendment 555
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 34
(34) It is appropriate to classify as high-risk the AI systems intended to be used as safety components in the management and operation of critical infrastructure such as road traffic or the supply of water, gas, heating and electricity, since their failure or malfunctioning may put at risk the life and health of persons at large scale and lead to appreciable disruptions in the ordinary conduct of social and economic activities.

Amendment 556
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 35
(35) AI systems used in education or vocational training, notably for determining access or assigning persons to educational and vocational training institutions or to evaluate persons on tests as part of or as a precondition for their education should be considered high-risk, since they may determine the educational and professional course of a person’s life and therefore affect their ability to secure their livelihood. When improperly designed and used, such systems may violate the right to education and training as well as the right not to be discriminated against and perpetuate historical patterns of discrimination. Therefore, AI systems in education shall be prohibited to be used by public authorities in education of underaged children to meet the requirement in this regulation, to not exploit any of the vulnerabilities of the group of persons due to their age.

Amendment 557
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 35
(35) AI systems used in education or vocational training, notably for determining access or assigning persons to educational and vocational training institutions or to evaluate persons on tests as part of or as a precondition for their education should be considered high-risk, since they may determine the educational and professional course of a person’s life and therefore affect their ability to secure their livelihood. AI systems that are designed to constantly monitor individuals are particuarly intrusive and violate the right to education and training, the right not to be discriminated against and perpetuate historical patterns of discrimination and should therefore be prohibited.

Amendment 558
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 35
(35) AI systems used in education or vocational training, notably for determining access or assigning persons to educational and vocational training institutions or to evaluate persons on tests as part of or as a precondition for their education should be considered high-risk, since they may determine the educational and professional course of a person’s life and therefore affect their ability to secure their livelihood. When improperly designed and used, such systems may violate the right to education and training as well as the right not to be discriminated against.

Amendment 559
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 35
(35) AI systems used in education or vocational training, notably for determining access or assigning persons to educational and vocational training institutions or to evaluate or monitor persons on tests as part of or as a precondition for their education should be considered high-risk, since they may determine the educational and professional course of a person’s life and therefore affect their ability to secure their livelihood. When improperly designed and used, such systems may violate the right to education and training as well as the right not to be discriminated against and perpetuate historical patterns of discrimination.

Amendment 560
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 36
(36) AI systems used in employment, workers management and access to self-employment, notably affecting the initiation, establishment, implementation and termination of an employment relationship, including AI systems intended to support collective legal and regulatory matters should be high risk. Particularly AI affecting recruitment and selection of persons, for making decisions on promotion and for task allocation, for measuring and monitoring of performance or for evaluation of persons in work-related contractual relationships, should also be classified as high-risk, since those systems may appreciably impact future career prospects and livelihoods of these persons. AI systems used for constant monitoring of workers pose an unacceptable risk to their fundamental rights, and should be therefore prohibited. Relevant work-related contractual relationships should meaningfully involve employees and persons providing services through platforms as referred to in the Commission Work Programme 2021. Throughout the recruitment process and in the evaluation, promotion, or retention of persons in work-related contractual relationships, such systems may perpetuate historical patterns of discrimination, for example against women, certain age groups, persons with disabilities, or persons of certain racial or ethnic origins or sexual orientation. AI systems used to monitor the performance and behaviour of these persons may also undermine the essence of their fundamental rights to data protection and privacy. This Regulation applies without prejudice to Union and Member State competences to provide for more specific rules for the use of AI-systems in the employment context.

Amendment 561
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 36
(36) AI systems used in employment, workers management and access to self-employment, notably for the recruitment and selection of persons, for making decisions on promotion and termination and for personalised task allocation based on personal or biometric data, monitoring or evaluation of persons in work-related contractual relationships, should also be classified as high-risk, since those systems may appreciably impact future career prospects and livelihoods of these persons. Relevant work-related contractual relationships should involve employees and persons providing services through platforms as referred to in the Commission Work Programme 2021. Such persons should in principle not be considered users within the meaning of this Regulation. Throughout the recruitment process and in the evaluation, promotion, or retention of persons in work-related contractual relationships, such systems may perpetuate historical patterns of discrimination, for example against women, certain age groups, persons with disabilities, or persons of certain racial or ethnic origins or sexual orientation. AI systems used to monitor the performance and behaviour of these persons may also impact their rights to data protection and privacy.

Amendment 562
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 36
(36) AI systems used in employment, workers management and access to self-employment, notably for the recruitment and selection of persons, for making decisions on promotion and termination and for task allocation, monitoring or evaluation of persons in work-related contractual relationships, should also be classified as high-risk, in so far as such use does not correspond to practices prohibited by this Regulation, since those systems may appreciably impact future career prospects and livelihoods of these persons. Relevant work-related contractual relationships should involve employees and persons providing services through platforms as referred to in the Commission Work Programme 2021. Such persons should in principle not be considered users within the meaning of this Regulation. Throughout the recruitment process and in the evaluation, promotion, or retention of persons in work-related contractual relationships, such systems may lead to discrimination, for example against women, certain age groups, persons with disabilities, or persons of certain racial or ethnic origins or sexual orientation. AI systems used to monitor the performance and behaviour of these persons may also impact their rights to data protection and privacy.

Amendment 563
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Karen Melchior, Dita Charanzová, Andrus Ansip, Morten
Recital 36
(36) AI systems used for making autonomous decisions or materially influencing decisions in employment, workers management and access to self-employment, notably for the selection of persons, for making decisions on promotion and termination and for monitoring or evaluation of persons in work-related contractual relationships, should also be classified as high-risk, since those systems may appreciably impact future career prospects and livelihoods of these persons. Relevant work-related contractual relationships should involve employees and persons providing services through platforms as referred to in the Commission Work Programme 2021. Such persons should in principle not be considered users within the meaning of this Regulation. Throughout the recruitment process and in the evaluation, promotion, or retention of persons in work-related contractual relationships, such systems may perpetuate historical patterns of discrimination, for example against women, certain age groups, persons with disabilities, or persons of certain racial or ethnic origins or sexual orientation. AI systems used to monitor the performance and behaviour of these persons may also impact their rights to data protection and privacy.

Amendment 564
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst
Recital 36
(36) AI systems used in employment, workers management and access to self-employment, notably but not limited to, for the recruitment and selection of persons, for making decisions on promotion and termination and for task allocation, monitoring or evaluation of persons in work-related contractual relationships, should also be classified as high-risk, since those systems impact future career prospects, livelihoods of these persons and workers’ rights. Relevant work-related contractual relationships should involve employees and persons providing services through platforms as referred to in the Commission Work Programme 2021. Such persons should in principle not be considered users within the meaning of this Regulation. Throughout the recruitment process and in the evaluation, promotion, or retention of persons in work-related contractual relationships, such systems may perpetuate historical patterns of discrimination, for example against women, certain age groups, persons with disabilities, or persons of certain racial or ethnic origins or sexual orientation. AI systems used to monitor the performance and behaviour of these persons may also impact their rights to data protection and privacy.

Amendment 565
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 36 a (new)
(36) AI systems used in employment, workers management and access to self-employment, notably for the recruitment and selection of persons, for making decisions on promotion and termination, monitoring or evaluation of persons in work-related contractual relationships, should also be classified as high-risk, since those systems may appreciably impact future career prospects and livelihoods of these persons. Relevant work-related contractual relationships should involve employees and persons providing services through platforms as referred to in the Commission Work Programme 2021. Such persons should in principle not be considered users within the meaning of this Regulation. Throughout the recruitment process and in the evaluation, promotion, or retention of persons in work-related contractual relationships, such systems may perpetuate historical patterns of discrimination, for example against women, certain age groups, persons with disabilities, or persons of certain racial or ethnic origins or sexual orientation. AI systems used to monitor the performance and behaviour of these persons may also impact their rights to data protection and privacy.

Amendment 566
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Cornelia Ernst
Recital 36 a (new)
(36 a) In line with Article 114 (2) TFEU, this Regulation does not in any way affect the rights and interests of employed persons. This Regulation is without prejudice to Community law on social policy and national labour law and practice.

Amendment 567
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 36 b (new)
(36 b) Given the significance of Artificial Intelligence impact assessments according to the usage Artificial Intelligence applications in the workplace, the EU will consider a corresponding directive with specific provisions for an impact assessment to ensure the protection of the rights and freedoms of workers affected by AI systems through collective agreements of national legislation.

Amendment 568
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Recital 37
(37) Another area in which the use of AI systems deserves special consideration is the access to and enjoyment of certain essential private and public services and benefits necessary for people to fully participate in society or to improve one’s standard of living. In particular, AI systems that automatically generate models used to evaluate the credit score or creditworthiness of natural persons should be classified as high-risk AI systems, since they determine those persons’ access to financial resources or essential services such as housing, electricity, and telecommunication services. In contrast, ancillary applications to those systems determining whether an individual should be granted access to credit, such as AI applications used for the acceleration of the credit disbursement process, in the valuation of collateral, or for the internal process efficiency, as well as other subsequent applications based on the credit scoring which do not create high risks for individuals should be exempt from the scope. AI systems used to evaluate the credit score or creditworthiness may lead to discrimination of persons or groups and perpetuate historical patterns of discrimination, for example based on racial or ethnic origins, disabilities, age, sexual orientation, or create new forms of discriminatory impacts. Considering the very limited scale of the impact and the available alternatives on the market, it is appropriate to exempt AI systems for the purpose of creditworthiness assessment and credit scoring when put into service by small-scale providers for their own use. Natural persons applying for or receiving public assistance benefits and services from public authorities are typically dependent on those benefits and services and in a vulnerable position in relation to the responsible authorities. If AI systems are used for determining whether such benefits and services should be denied, reduced, revoked or reclaimed by authorities, they may have a significant impact on persons’ livelihood and may infringe their fundamental rights, such as the right to social protection, non-discrimination, human dignity or an effective remedy. Those systems should therefore be classified as high-risk. Infact, this Regulation should not hamper the development and use of innovative approaches in the public administration, which would stand to benefit from a wider use of compliant and safe AI systems, provided that those systems do not entail a high risk to legal and natural persons. Finally, AI systems used to dispatch or establish priority in the dispatching of emergency first response services should also be classified as high-risk since they make decisions in very critical situations for the life and health of persons and their property.

Amendment 569
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 37
(37) Another area in which the use of AI systems deserves special consideration is the access to and enjoyment of certain essential private and public services and benefits necessary for people to fully participate in society or to improve one’s standard of living. In particular, AI systems used to evaluate the credit score or creditworthiness of natural persons should be classified as high-risk AI systems, since they determine those persons’ access to financial resources or essential services such as housing, electricity, and telecommunication services. AI systems used for this purpose may lead to discrimination of persons or groups and perpetuate historical patterns of discrimination, for example based on racial or ethnic origins, disabilities, age, sexual orientation, or create new forms of discriminatory impacts. Natural persons applying for or receiving public assistance benefits and services from public authorities are typically dependent on those benefits and services and in a vulnerable position in relation to the responsible authorities. If AI systems are used for determining whether such benefits and services should be denied, reduced, revoked or reclaimed by authorities, they may have a significant impact on persons’ livelihood and may infringe their fundamental rights, such as the right to social protection, non-discrimination, human dignity or an effective remedy. Those systems should therefore be classified as high-risk. Finally, AI systems used to dispatch or establish priority in the dispatching of emergency first response services should also be classified as high-risk since they make decisions in very critical situations for the life and health of persons and their property.

Amendment 570
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 37
(37) Another area in which the use of AI systems deserves special consideration is the access to and enjoyment of certain essential private and public services and benefits necessary for people to fully participate in society or to improve one’s standard of living. In particular, AI systems used to evaluate the credit score or creditworthiness of natural persons should be prohibited, since they determine those persons’ access to financial resources or essential services such as housing, electricity, and telecommunication services. AI systems used for this purpose may lead to discrimination of persons or groups and perpetuate historical patterns of discrimination, for example based on racial or ethnic origins, disabilities, age, sexual orientation, or create new forms of discriminatory impacts. Considering the very limited scale of the impact and the available alternatives on the market, it is appropriate to exempt AI systems for the purpose of creditworthiness assessment and credit scoring when put into service by small-scale providers for their own use. Natural persons applying for or receiving public assistance benefits and services from public authorities are typically dependent on those benefits and services and in a vulnerable position in relation to the responsible authorities. If AI systems are used for determining whether such benefits and services should be denied, reduced, revoked or reclaimed by authorities, they may have a significant impact on persons’ livelihood and may infringe their fundamental rights, such as the right to social protection, non-discrimination, human dignity or an effective remedy. Finally, AI systems used to dispatch or establish priority in the dispatching of emergency first response services should also be classified as high-risk since they make decisions in very critical situations for the life and health of persons and their property.

Amendment 571
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 37
(37) Another area in which the use of AI systems deserves special consideration is the access to and enjoyment of certain essential private and public services and benefits necessary for people to fully participate in society or to improve one’s standard of living. In particular, AI systems used to evaluate the credit score or creditworthiness of natural persons should be prohibited, since they determine those persons’ access to financial resources or essential services such as housing, electricity, and telecommunication services. AI systems used for this purpose lead to an unacceptably high risk of discrimination against persons or groups and perpetuate historical patterns of discrimination, for example based on racial or ethnic origins, disabilities, age, sexual orientation, or create new forms of discriminatory impacts. Natural persons applying for or receiving public assistance benefits and services from public authorities are typically dependent on those benefits and services and in a vulnerable position in relation to the responsible authorities. If AI systems are used for determining whether such benefits and services should be denied, reduced, revoked or reclaimed by authorities, they have a significant impact on persons’ livelihood and infringe their fundamental rights, such as the right to social protection, non-discrimination, human dignity or an effective remedy. Those systems should therefore be prohibited. Nonetheless, this Regulation should not hamper the development and use of innovative approaches in the public administration, which would stand to benefit from a wider use of compliant and safe AI systems, provided that those systems do not entail a high risk to legal and natural persons. Finally, AI systems used to dispatch or establish priority in the dispatching of emergency first response services should also be classified as high-risk since they make decisions in very critical situations for the life and health of persons and their property.

Amendment 572
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Recital 37
(37) Another area in which the use of AI systems deserves special consideration is the access to and enjoyment of certain essential private and public services and benefits necessary for people to fully participate in society or to improve one’s standard of living. In particular, AI systems used to evaluate the credit score or creditworthiness of natural persons should be classified as high-risk AI systems, since they determine those persons’ access to financial resources or essential services such as housing, electricity, and telecommunication services. AI systems used for this purpose may lead to discrimination of persons or groups and perpetuate historical patterns of discrimination, for example based on racial or ethnic origins, disabilities, age, sexual orientation, or create new forms of discriminatory impacts. Considering the very limited scale of the impact and the available alternatives on the market, it is appropriate to exempt AI systems for the purpose of creditworthiness assessment and credit scoring when put into service by small-scale providers for their own use. Due to the fact that AI systems related to low-value credits for the purchase of movables do not cause high risk, it is proposed to exclude this category from the scope of high-risk AI category as well. . Natural persons applying for or receiving public assistance benefits and services from public authorities are typically dependent on those benefits and services and in a vulnerable position in relation to the responsible authorities. If AI systems are used for determining whether such benefits and services should be denied, reduced, revoked or reclaimed by authorities, they may have a significant impact on persons’ livelihood and may infringe their fundamental rights, such as the right to social protection, non-discrimination, human dignity or an effective remedy. Those systems should therefore be classified as high-risk. Nonetheless, this Regulation should not hamper the development and use of innovative approaches in the public administration, which would stand to benefit from a wider use of compliant and safe AI systems, provided that those systems do not entail a high risk to legal and natural persons. Finally, AI systems used to dispatch or establish priority in the dispatching of emergency first response services should also be classified as high-risk since they make decisions in very critical situations for the life and health of persons and their property.

Amendment 573
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Recital 37
(37) Another area in which the use of AI systems deserves special consideration is the access to and enjoyment of certain essential private and public services and benefits necessary for people to fully participate in society or to improve one’s standard of living. In particular, AI systems that automatically generate models used to evaluate the credit score or creditworthiness of natural persons should be classified as high-risk AI systems, since they determine those persons’ access to financial resources or essential services such as housing, electricity, and telecommunication services. In contrast, ancillary applications to those systems determining whether an individual should be granted access to credit, such as AI applications used for the acceleration of the credit disbursement process, in the valuation of collateral, or for the internal process efficiency, as well as other subsequent applications based on the credit scoring which do not create high risks for individuals should be exempt from the scope. AI systems used to evaluate the credit score or creditworthiness may lead to discrimination of persons or groups and perpetuate historical patterns of discrimination, for example based on racial or ethnic origins, disabilities, age, sexual orientation, or create new forms of discriminatory impacts. Natural persons applying for or receiving public assistance benefits and services from public authorities are typically dependent on those benefits and services and in a vulnerable position in relation to the responsible authorities. If AI systems are used for determining whether such benefits and services should be denied, reduced, revoked or reclaimed by authorities, they may have a significant impact on persons’ livelihood and may infringe their fundamental rights, such as the right to social protection, non-discrimination, human dignity or an effective remedy. Those systems should therefore be classified as high-risk. In fact, this Regulation should not hamper the development and use of innovative approaches in the public administration, which would stand to benefit from a wider use of compliant and safe AI systems, provided that those systems do not entail a high risk to legal and natural persons. Finally, AI systems used to dispatch or establish priority in the dispatching of emergency first response services should also be classified as high-risk since they make decisions in very critical situations for the life and health of persons and their property.

Amendment 574
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Patryk Jaki, Eugen Jurzyca
Recital 37
(37) Another area in which the use of AI systems deserves special consideration is the access to and enjoyment of certain essential private and public services and benefits necessary for people to fully participate in society or to improve one’s standard of living. In particular, AI systems used to evaluate the credit score or creditworthiness of natural persons should be classified as high-risk AI systems, since they determine those persons’ access to financial resources or essential services such as housing, electricity, and telecommunication services. AI systems used for this purpose may lead to discrimination of persons or groups and perpetuate historical patterns of discrimination, for example based on racial or ethnic origins, disabilities, age, sexual orientation, or create new forms of discriminatory impacts. Considering the very limited scale of the impact and the available alternatives on the market, it is appropriate to exempt AI systems for the purpose of creditworthiness assessment and credit scoring when put into service by small-scale providers for their own use. Due to the fact that AI systems related to low-value credits for the purchase of moveables does not cause high risk, it is proposed to exclude this category from the scope of high-risk AI category as well. Natural persons applying for or receiving public assistance benefits and services from public authorities are typically dependent on those benefits and services and in a vulnerable position in relation to the responsible authorities. If AI systems are used for determining whether such benefits and services should be denied, reduced, revoked or reclaimed by authorities, they may have a significant impact on persons’ livelihood and may infringe their fundamental rights, such as the right to social protection, non-discrimination, human dignity or an effective remedy. Those systems should therefore be classified as high-risk. Nonetheless, this Regulation should not hamper the development and use of innovative approaches in the public administration, which would stand to benefit from a wider use of compliant and safe AI systems, provided that those systems do not entail a high risk to legal and natural persons. Finally, AI systems used to dispatch or establish priority in the dispatching of emergency first response services should also be classified as high-risk since they make decisions in very critical situations for the life and health of persons and their property.

Amendment 575
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Markus Buchheit, Hélène Laporte
Recital 37
(37) Another area in which the use of AI systems deserves special consideration is the access to and enjoyment of certain essential private and public services and benefits necessary for people to fully participate in society or to improve one’s standard of living. In particular, AI systems used to evaluate the credit score or creditworthiness of natural persons should be classified as high-risk AI systems, in so far as such use does not correspond to practices prohibited by this Regulation, since they determine those persons’ access to financial resources or essential services such as housing, electricity, and telecommunication services. AI systems used for this purpose may lead to discrimination of persons or groups, for example based on racial or ethnic origins, disabilities, age, sexual orientation, or create new forms of discriminatory impacts. Considering the very limited scale of the impact and the available alternatives on the market, it is appropriate to exempt AI systems for the purpose of creditworthiness assessment and credit scoring when put into service by small-scale providers for their own use. Natural persons applying for or receiving public assistance benefits and services from public authorities are typically dependent on those benefits and services and in a vulnerable position in relation to the responsible authorities. If AI systems are used for determining whether such benefits and services should be denied, reduced, revoked or reclaimed by authorities, they will have a significant impact on persons’ livelihood and will infringe their fundamental rights, such as the right to social protection, non-discrimination, human dignity or an effective remedy. Those systems should therefore be classified as high-risk. Nonetheless, this Regulation should allow for experimentation in the public administration, in a regulatory sandbox, with innovative approaches which would stand to benefit from a wider use of compliant and safe AI systems, in accordance with the established rules.  Finally, AI systems used to dispatch or establish priority in the dispatching of emergency first response services should be prohibited as they make decisions in very critical situations for the life and health of persons and their property, and such ethical choices should not be given over to computer systems.

Amendment 576
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Dita Charanzová, Andrus Ansip, Morten
Recital 37
(37) Another area in which the use of AI systems deserves special consideration is the access to and enjoyment of certain essential private and public services and benefits necessary for people to fully participate in society or to improve one’s standard of living. In particular, AI systems used to evaluate the credit score or creditworthiness of natural persons should be classified as high-risk AI systems, since they determine those persons’ access to financial resources or essential services such as housing, electricity, and telecommunication services. AI systems used for this purpose may lead to discrimination of persons or groups and perpetuate historical patterns of discrimination, for example based on racial or ethnic origins, disabilities, age, sexual orientation, or create new forms of discriminatory impacts. Considering the very limited scale of the impact and the available alternatives on the market, it is appropriate to exempt AI systems for the purpose of creditworthiness assessment and credit scoring when put into service by SMEs and start-ups for their own use. Natural persons applying for or receiving public assistance benefits and services from public authorities are typically dependent on those benefits and services and in a vulnerable position in relation to the responsible authorities. If AI systems are used for determining whether such benefits and services should be denied, reduced, revoked or reclaimed by authorities, they may have a significant impact on persons’ livelihood and may infringe their fundamental rights, such as the right to social protection, non-discrimination, human dignity or an effective remedy. Those systems should therefore be classified as high-risk. Nonetheless, this Regulation should not hamper the development and use of innovative approaches in the public administration, which would stand to benefit from a wider use of compliant and safe AI systems, provided that those systems do not entail a high risk to legal and natural persons. Finally, AI systems used to dispatch or establish priority in the dispatching of emergency first response services should also be classified as high-risk since they make decisions in very critical situations for the life and health of persons and their property.

Amendment 577
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 37 a (new)
(37 a) Given the speed at which AI applications are being developed around the world, it is not feasible to compile an exhaustive listing of applications that should be prohibited or considered high-risk. What is needed is a clear and coherent governance model guaranteeing both the fundamental rights of individuals and legal clarity for operators, considering the continuous evolution of technology. Nevertheless, given the role and responsibility of police and judicial authorities, and the impact of decisions they take for the purposes of the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, the use of AI applications has to be categorised as high-risk in instances where there is the potential to significantly affect the lives of individuals.

Amendment 578
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 38
(38) Actions by law enforcement authorities involving certain uses of AI systems are characterised by a significant degree of power imbalance and may lead to surveillance, arrest or deprivation of a natural person’s liberty as well as other adverse impacts on fundamental rights guaranteed in the Charter. In particular, if the AI system is not trained with high quality data, does not meet adequate requirements in terms of its accuracy or robustness, or is not properly designed and tested before being put on the market or otherwise put into service, it may single out people in a discriminatory or otherwise incorrect or unjust manner. In addition, some applications, such as to make predictions, profiles, or risk assessments based on data analysis or profiling of groups or individuals for the purpose of predicting the occurrence or recurrence of actual or potential offences or rule-breaking undermine the essence of fundamental rights and should be prohibited. Furthermore, the exercise of important procedural fundamental rights, such as the right to an effective remedy and to a fair trial as well as the right of defence and the presumption of innocence, could be hampered, in particular, where such AI systems are not sufficiently transparent, explainable and documented. It is therefore appropriate to classify as prohibited a number of AI systems intended to be used in the law enforcement context as well as for crime analytics regarding natural persons.

Amendment 579
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 38
(38) Actions by law enforcement authorities involving certain uses of AI systems are characterised by a significant degree of power imbalance and may lead to surveillance, arrest or deprivation of a natural person’s liberty as well as other adverse impacts on fundamental rights guaranteed in the Charter. In particular, if the AI system is not trained with high quality data, does not meet adequate requirements in terms of its performance, including its accuracy or robustness, or is not properly designed and tested before being put on the market or otherwise put into service, it may single out people in a discriminatory or otherwise incorrect or unjust manner. Furthermore, the exercise of important procedural fundamental rights, such as the right to an effective remedy and to a fair trial as well as the right of defence and the presumption of innocence, could be hampered, in particular, where such AI systems are not sufficiently transparent, explainable and documented. It is therefore appropriate to classify as high-risk a number of AI systems intended to be used in the law enforcement context where accuracy, reliability and transparency is particularly important to avoid adverse impacts, retain public trust and ensure accountability and effective redress. AI systems specifically intended to be used for administrative proceedings by tax and customs authorities should not be considered high-risk AI systems used by law enforcement authorities for the purposes of prevention, detection, investigation and prosecution of criminal offences.

Amendment 580
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Markus Buchheit, Hélène Laporte
Recital 38
(38) Actions by law enforcement authorities involving certain uses of AI systems are characterised by a significant degree of power imbalance and may lead to surveillance, arrest or deprivation of a natural person’s liberty as well as other adverse impacts on fundamental rights guaranteed in the Charter. In particular, if the AI system is not trained with high quality data, does not meet adequate requirements in terms of its accuracy or robustness, or is not properly designed and tested before being put on the market or otherwise put into service, it may single out people in a discriminatory or otherwise incorrect or unjust manner. Furthermore, the exercise of important procedural fundamental rights, such as the right to an effective remedy and to a fair trial as well as the right of defence and the presumption of innocence, could be hampered, in particular, where such AI systems are not sufficiently transparent, explainable and documented. AI systems intended to assess or rank the reliability of natural persons, to identify natural persons based on biometric data, to serve as polygraphs or similar tools, to detect the emotional state of natural persons, to predict the occurrence or reoccurrence of an actual or potential criminal offence based on profiling of natural persons or to assess personality traits of natural persons or groups for profiling in the course of detection, investigation or prosecution of criminal offences, shall be prohibited except in the three specific cases provided for in this Regulation. AI systems other than the aforementioned and intended to be used in a law enforcement context where accuracy, reliability and transparency is particularly important shall be classed as high-risk AI systems to avoid adverse impacts, retain public trust and ensure accountability and effective redress. In view of the nature of the activities in question and the risks relating thereto, those high-risk AI systems should include in particular AI systems intended to be used by law enforcement authorities for individual risk assessments, to detect ‘deep fakes’, for the evaluation of the reliability of evidence in criminal proceedings, or assessing characteristics or past criminal behaviour of natural persons or groups for profiling in the course of detection, investigation or prosecution of criminal offences, as well as for crime analytics regarding natural persons. AI systems specifically intended to be used for administrative proceedings by tax and customs authorities should not be considered high-risk AI systems used by law enforcement authorities for the purposes of prevention, detection, investigation and prosecution of criminal offences.

Amendment 581
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 38
(38) Actions by law enforcement authorities involving certain uses of AI systems are characterised by a significant degree of power imbalance and may lead to surveillance, arrest or deprivation of a natural person’s liberty as well as other adverse impacts on fundamental rights guaranteed in the Charter. In particular, if the AI system is not trained with high quality data, does not meet adequate requirements in terms of its accuracy or robustness, or is not properly designed and tested before being put on the market or otherwise put into service, it may single out people in a discriminatory or otherwise incorrect or unjust manner. Furthermore, the exercise of important procedural fundamental rights, such as the right to an effective remedy and to a fair trial as well as the right of defence and the presumption of innocence, could be hampered, in particular, where such AI systems are not sufficiently transparent, explainable and documented. It is therefore appropriate to classify as high-risk a number of AI systems intended to be used in the law enforcement context where accuracy, reliability and transparency is particularly important to avoid adverse impacts, retain public trust and ensure accountability and effective redress. In view of the nature of the activities in question and the risks relating thereto, those high-risk AI systems should include in particular AI systems intended to be used by law enforcement authorities or on their behalf to detect ‘deep fakes’, for the evaluation of the reliability of evidence in criminal proceedings, as well as for crime analytics regarding natural persons. AI systems specifically intended to be used for administrative proceedings by tax and customs authorities should not be considered high-risk AI systems used by law enforcement authorities for the purposes of prevention, detection, investigation and prosecution of criminal offences.

Amendment 582
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,
Recital 38
(38) Actions by law enforcement authorities involving certain uses of AI systems are characterised by a significant degree of power imbalance and may lead to surveillance, arrest or deprivation of a natural person’s liberty as well as other adverse impacts on fundamental rights guaranteed in the Charter. In particular, if the AI system is not trained with high quality data, does not meet adequate requirements in terms of its accuracy or robustness, or is not properly designed and tested before being put on the market or otherwise put into service, it may single out people in a discriminatory or otherwise incorrect or unjust manner. Furthermore, the exercise of important procedural fundamental rights, such as the right to an effective remedy and to a fair trial as well as the right of defence and the presumption of innocence, could be hampered, in particular, where such AI systems are not sufficiently transparent, explainable and documented. It is therefore appropriate to classify as high-risk a number of AI systems intended to be used in the law enforcement context where accuracy, reliability and transparency is particularly important to avoid adverse impacts, retain public trust and ensure accountability and effective redress. In view of the nature of the activities in question and the risks relating thereto, those high-risk AI systems should include in particular AI systems intended to be used by law enforcement authorities for individual risk assessments, polygraphs and similar tools or to detect the emotional state of natural person, to detect ‘deep fakes’, for the evaluation of the reliability of evidence in criminal proceedings, for profiling in the course of detection, investigation or prosecution of criminal offences, as well as for crime analytics regarding natural persons. AI systems specifically intended to be used for administrative proceedings by tax and customs authorities should not be considered high-risk AI systems used by law enforcement authorities for the purposes of prevention, detection, investigation and prosecution of criminal offences.

Amendment 583
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 38
(38) Actions by law enforcement authorities involving certain uses of AI systems are characterised by a significant degree of power imbalance and may lead to surveillance, arrest or deprivation of a natural person’s liberty as well as other adverse impacts on fundamental rights guaranteed in the Charter. In particular, if the AI system is not trained with high quality data, does not meet adequate requirements in terms of its accuracy or robustness, or is not properly designed and tested before being put on the market or otherwise put into service, it may single out people in a discriminatory or otherwise incorrect or unjust manner. Furthermore, the exercise of important procedural fundamental rights, such as the right to an effective remedy and to a fair trial as well as the right of defence and the presumption of innocence, could be hampered, in particular, where such AI systems are not sufficiently transparent, explainable and documented. It is therefore appropriate to classify as high-risk a number of AI systems intended to be used in the law enforcement context where accuracy, reliability and transparency is particularly important to avoid adverse impacts, retain public trust and ensure accountability and effective redress. In view of the nature of the activities in question and the risks relating thereto, those high-risk AI systems should include in particular AI systems intended to be used by law enforcement authorities for individual risk assessments, polygraphs and similar tools or to detect the emotional state of natural person, to detect ‘deep fakes’, for the evaluation of the reliability of evidence in criminal proceedings, for profiling in the course of detection, investigation or prosecution of criminal offences, as well as for crime analytics regarding natural persons. AI systems specifically intended to be used for administrative proceedings by tax and customs authorities should not be considered high-risk AI systems used by law enforcement authorities for the purposes of prevention, detection, investigation and prosecution of criminal offences.

Amendment 584
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 38
(38) Actions by law enforcement authorities involving certain uses of AI systems are characterised by a significant degree of power imbalance and may lead to surveillance, arrest or deprivation of a natural person’s liberty as well as other adverse impacts on fundamental rights guaranteed in the Charter. In particular, if the AI system is not trained with high quality data, does not meet adequate requirements in terms of its accuracy or robustness, or is not properly designed and tested before being put on the market or otherwise put into service, it may single out people in a discriminatory or otherwise incorrect or unjust manner. Furthermore, the exercise of important procedural fundamental rights, such as the right to an effective remedy and to a fair trial as well as the right of defence and the presumption of innocence, could be hampered, in particular, where such AI systems are not sufficiently transparent, explainable and documented and where a redress procedure is not foreseen. It is therefore appropriate to prohibit some AI systems intended to be used in the law enforcement context where accuracy, reliability and transparency is particularly important to avoid adverse impacts, retain public trust and ensure accountability and effective redress, including the availability of redress-by-design mechanisms and procedures. In view of the nature of the activities in question and the risks relating thereto, those prohibited systems should include in particular AI systems intended to be used by law enforcement authorities for individual risk assessments, polygraphs and similar tools or to detect the emotional state of natural person, for predicting the occurrence or reoccurrence of an actual or potential criminal offence based on profiling of natural persons, or assessing personality traits and characteristics or past criminal behaviour of natural persons or groups, for profiling in the course of detection, investigation or prosecution of criminal offences. AI systems specifically intended to be used for administrative proceedings by tax and customs authorities should not be included in such a ban.

Amendment 585
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 38 a (new)
(38 a) The use of AI tools by law enforcement and judicial authorities should not become a factor of inequality, social fracture or exclusion. The impact of the use of AI tools on the defence rights of suspects should not be ignored, notably the difficulty in obtaining meaningful information on their functioning and the consequent difficulty in challenging their results in court, in particular by individuals under investigation.

Amendment 586
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 39
(39) AI systems used in migration, asylum and border control management affect people who are often in particularly vulnerable position and who are dependent on the outcome of the actions of the competent public authorities. The accuracy, non-discriminatory nature and transparency of the AI systems used in those contexts are therefore particularly important to guarantee the respect of the fundamental rights of the affected persons, notably their rights to free movement, non-discrimination, protection of private life and personal data, international protection and good administration. AI systems in the area of migration, asylum and border control management covered by this Regulation should comply with the relevant procedural requirements set by the Directive 2013/32/EU of the European Parliament and of the Council49 , the Regulation (EC) No 810/2009 of the European Parliament and of the Council50 and other relevant legislation.' '49 Directive 2013/32/EU of the European Parliament and of the Council of 26 June 2013 on common procedures for granting and withdrawing international protection (OJ L 180, 29.6.2013, p. 60).', '50 Regulation (EC) No 810/2009 of the European Parliament and of the Council of 13 July 2009 establishing a Community Code on Visas (Visa Code) (OJ L 243, 15.9.2009, p. 1).

Amendment 587
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 39
(39) AI systems used in migration, asylum and border control management affect people who are often in particularly vulnerable position and who are dependent on the outcome of the actions of the competent public authorities. The accuracy, non-discriminatory nature and transparency of the AI systems used in those contexts are therefore particularly important to guarantee the respect of the fundamental rights of the affected persons, notably their rights to free movement, non-discrimination, protection of private life and personal data, international protection and good administration. It is therefore appropriate to classify as high-risk AI systems intended to be used by the competent public authorities charged with tasks in the fields of migration, asylum and border control management. AI systems in the area of migration, asylum and border control management covered by this Regulation should comply with the relevant procedural requirements set by the Directive 2013/32/EU of the European Parliament and of the Council49 , the Regulation (EC) No 810/2009 of the European Parliament and of the Council50 and other relevant legislation.' '49 Directive 2013/32/EU of the European Parliament and of the Council of 26 June 2013 on common procedures for granting and withdrawing international protection (OJ L 180, 29.6.2013, p. 60).', '50 Regulation (EC) No 810/2009 of the European Parliament and of the Council of 13 July 2009 establishing a Community Code on Visas (Visa Code) (OJ L 243, 15.9.2009, p. 1).

Amendment 588
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 39
(39) AI systems used in migration, asylum and border control management affect people who are often in particularly vulnerable position and who are dependent on the outcome of the actions of the competent public authorities. The accuracy, non-discriminatory nature and transparency of the AI systems used in those contexts are therefore particularly important to guarantee the respect of the fundamental rights of the affected persons, notably their rights to free movement, non-discrimination, protection of private life and personal data, international protection and good administration. It is therefore appropriate to classify as high-risk AI systems intended to be used by the competent public authorities charged with tasks in the fields of migration, asylum and border control management; for verifying the authenticity of the relevant documents of natural persons; AI systems in the area of migration, asylum and border control management covered by this Regulation should comply with the relevant procedural requirements set by the Directive 2013/32/EU of the European Parliament and of the Council, the Regulation (EC) No 810/2009 of the European Parliament and of the Council and other relevant legislation.

Amendment 589
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Tineke
Recital 39
(39) AI systems used in migration, asylum and border control management affect people who are often in a particularly vulnerable position and who are dependent on the outcome of the actions of the competent public authorities. The accuracy, non-discriminatory nature and transparency of the AI systems used in those contexts are therefore particularly important to guarantee the respect of the fundamental rights of the affected persons, notably their rights to free movement, non-discrimination, protection of private life and personal data, international protection and good administration. It is therefore appropriate to classify as high-risk AI systems intended to be used by the competent public authorities charged with tasks in the fields of migration, asylum and border control management as applying for visa or asylum; for verifying the authenticity of the relevant documents of natural persons; for assisting competent public authorities for the examination of applications for asylum, visa and residence permits and associated complaints with regard to the objective to establish the eligibility of the natural persons applying for a status. AI systems in the area of migration, asylum and border control management covered by this Regulation should comply with the relevant procedural requirements set by the Directive 2013/32/EU of the European Parliament and of the Council, the Regulation (EC) No 810/2009 of the European Parliament and of the Council and other relevant legislation

Amendment 590
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte
Recital 39
(39) AI systems used in migration, asylum and border control management affect people who are sometimes in a vulnerable position and who are dependent on the outcome of the actions of the competent public authorities. The accuracy, non-discriminatory nature and transparency of the AI systems used in those contexts are therefore particularly important to guarantee the respect of the fundamental rights of the affected persons, notably, and where applicable, their rights to free movement, non-discrimination, protection of private life and personal data, international protection and good administration. It is therefore appropriate to classify as high-risk AI systems intended to be used by the competent public authorities charged with tasks in the fields of migration, asylum and border control management as polygraphs and similar tools or to detect the emotional state of a natural person; for assessing certain risks posed by natural persons entering the territory of a Member State or applying for visa or asylum; for verifying the authenticity of the relevant documents of natural persons; for assisting competent public authorities for the examination of applications for asylum, visa and residence permits and associated complaints with regard to the objective to establish the eligibility of the natural persons applying for a status. AI systems in the area of migration, asylum and border control management covered by this Regulation should comply with the relevant procedural requirements set by the Directive 2013/32/EU of the European Parliament and of the Council49, the Regulation (EC) No 810/2009 of the European Parliament and of the Council50 and other relevant legislation.' '49 Directive 2013/32/EU of the European Parliament and of the Council of 26 June 2013 on common procedures for granting and withdrawing international protection (OJ L 180, 29.6.2013, p. 60).', '50 Regulation (EC) No 810/2009 of the European Parliament and of the Council of 13 July 2009 establishing a Community Code on Visas (Visa Code) (OJ L 243, 15.9.2009, p. 1).

Amendment 591
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä, Tineke
Recital 39 a (new)
(39 a) The use of AI systems in migration, asylum and border control management should in no circumstances be used by Member States or European Union institutions as a means to circumvent their international obligations under the Convention of 28 July 1951 relating to the Status of Refugees as amended by the Protocol of 31 January 1967, nor should they be used to in any way infringe on the principle of non-refoulement, or or deny safe and effective legal avenues into the territory of the Union, including the right to international protection;

Amendment 592
Renew - Renew Europe Group
Salima Yenbou, Samira Rafaela, Monica Semedo, Karen Melchior, Peter Pollák
Recital 39 a (new)
(39 a) The use of AI systems in migration, asylum and border control management should in no circumstances be used by Member States or European Union institutions as a means to circumvent their international obligations under the Convention of 28 July 1951 relating to the Status of Refugees as amended by the Protocol of 31 January 1967, nor should they be used to in any way infringe on the principle of non-refoulement, or deny safe and effective legal avenues into the territory of the Union, including the right to international protection;

Amendment 593
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 39 a (new)
(39 a) The use of AI systems in migration, asylum and border control management should in no circumstances be used by Member States or European Union institutions as a means to circumvent their international obligations under the Convention of 28 July 1951 relating to the Status of Refugees as amended by the Protocol of 31 January 1967, nor should they be used to in any way infringe on the principle of non-refoulement, or deny safe and effective legal avenues into the territory of the Union, including the right to international protection;

Amendment 594
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 39 a (new)
(39 a) The use of AI systems in migration, asylum and border control management should in no circumstances be used by Member States or European Union institutions as a means to circumvent their international obligations under the Convention of 28 July 1951 relating to the Status of Refugees as amended by the Protocol of 31 January1967, nor should they be used to in any way infringe on the principle of non-refoulement, or deny safe and effective legal avenues into the territory of the Union, including the right to international protection;

Amendment 595
Renew - Renew Europe Group
Abir Al-Sahlani, Svenja Hahn, Samira Rafaela, Monica Semedo
Recital 39 a (new)
(39 a) The use of AI systems in migration, asylum and border management should however not, at any point, be used by Member States or by the institutions or agencies of the Union to infringe on the principle of non-refoulement, the right to asylum or to circumvent international obligations under the Convention of 28 July 1951 relating to the Status of Refugees as amended by the Protocol of 31 January 1967.

Amendment 596
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 40
(40) Certain AI systems intended for the administration of justice and democratic processes should be classified as high-risk, considering their potentially significant impact on democracy, rule of law, individual freedoms as well as the right to an effective remedy and to a fair trial. The use of Artificial Intelligence tools can support, but should not interfere with the decision-making power of judges or judicial independence, as the final decision-making must remain a human-driven activity and decision. In particular, to address the risks of potential biases, errors and opacity, it is appropriate to qualify as high-risk AI systems intended to assist judicial authorities in researching and interpreting facts and the law and in applying the law. Such qualification should not extend, however, to AI systems intended for purely ancillary administrative activities that do not affect the actual administration of justice in individual cases, such as anonymisation or pseudonymisation of judicial decisions, documents or data, communication between personnel, administrative tasks or allocation of resources

Amendment 597
ECR - European Conservatives and Reformists Group
Vincenzo Sofo, Kosma Złotowski
Recital 40
(40) Certain AI systems intended for the administration of justice and democratic processes should be classified as high-risk, considering their potentially significant impact on democracy, rule of law, individual freedoms as well as the right to an effective remedy and to a fair trial. In particular, to address the risks of potential biases, errors and opacity, it is appropriate to qualify as high-risk AI systems intended to assist judicial authorities in researching facts and the law. Such qualification should not extend, however, to AI systems intended for purely ancillary administrative activities that do not affect the actual administration of justice in individual cases, such as anonymisation or pseudonymisation of judicial decisions, documents or data, communication between personnel, administrative tasks or allocation of resources.

Amendment 598
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte
Recital 40
(40) Certain AI systems intended for the administration of justice and democratic processes should be prohibited, considering their potentially significant impact on democracy, rule of law, individual freedoms as well as the right to an effective remedy and to a fair trial. In particular, to address the risks of potential biases, errors and opacity, it is appropriate to prohibit the use of AI systems intended to assist judicial authorities in researching and interpreting facts and the law and in applying the law to a concrete set of facts. Such qualification should not extend, however, to AI systems intended for purely ancillary administrative activities that do not affect the actual administration of justice in individual cases, such as anonymisation or pseudonymisation of judicial decisions, documents or data, communication between personnel, administrative tasks or allocation of resources.

Amendment 599
Renew - Renew Europe Group
Svenja Hahn, Nicola Beer, Dita Charanzová, Andrus Ansip, Morten Løkkegaard, Vlad-
Recital 40
(40) Certain AI systems intended for the administration of justice and democratic processes should be classified as high-risk, considering their potentially significant impact on democracy, rule of law, individual freedoms as well as the right to an effective remedy and to a fair trial. In particular, to address the risks of potential biases, errors and opacity, it is appropriate to qualify as high-risk AI systems intended to assist judicial authorities in interpreting facts or the law for applying the law to a concrete set of facts. Such qualification should not extend, however, to AI systems intended for purely ancillary administrative activities that do not affect the actual administration of justice in individual cases, such as anonymisation or pseudonymisation of judicial decisions, documents or data, communication between personnel, administrative tasks or allocation of resources.

Amendment 600
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 40 a (new)
(40 a) Another area in which the use of AI systems deserves special consideration is the use for health-related purposes, including healthcare. Next to medical devices (as per EU regulation 2017/745), other health-related AI systems also bring about risks which should be regulated. These include systems that influence individual’s health outcomes but do not meet the criteria for a medical device, systems that influence population health outcomes or health equality, systems that impact the distribution of healthcare resources and systems used by pharmaceutical and medical technology companies in research and development, pharmacovigilance, market optimisation and pharmaceutical marketing. Bias and errors in health-related AI systems can have major and immediate consequences for individuals’ and populations’ health and wellbeing. Further, many systems will use sensitive and personal data, which needs to be justified, and about which patients need to be properly informed. What is more, systems that work on hospital, health system, or population level may have a major effect on societal health because they influence the distribution of healthcare resources and health policy design. For these reasons, there is a need for trustworthy AI in healthcare, meaning people must be able to trust that systems used in healthcare are scientifically, technically and clinically valid, safe and accountable, and safeguard individuals’ autonomy and privacy.

Amendment 601
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 40 a (new)
(40 a) Certain AI systems should at the same time be subject to transparency requirements and be classified as high-risk AI systems, given their potential to deceive and cause both individual and societal harm. In particular, AI systems that generate deep fakes representing existing persons have the potential to both manipulate the natural persons that are exposed to those deep fakes and harm the persons they are representing or misrepresenting, while AI systems that, based on limited human input, generate complex text such as news articles, opinion articles, novels, scripts and scientific articles have the potential to manipulate, to deceive, or to expose natural persons to built-in biases or inaccuracies. These should not include AI systems intended to translate text, or cases where the content forms part of an evidently artistic, creative or fictional cinematographic and analogous work.

Amendment 602
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 40 a (new)
(40 a) When the “deep fake” content forms part of an evidently artistic, creative, or fictional cinematographic and analogous work, or when the “AI authors” generate content that undergoes human review and for the publication of which a natural or legal person established in the Union is liable or holds editorial responsibility, the AI systems should not be considered high-risk but should nevertheless be subject to adequate transparency requirements, where appropriate.

Amendment 603
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 40 a (new)
(40 a) Certain AI-systems used in the area of healthcare that are not covered by Regulation (EU) 2017/745 (Regulation on Medical Devices) should be high-risk. Uses such as software impacting diagnostics, treatments or medical prescriptions and access to health insurance can clearly impact health and safety, but also can also obstruct access to health services, impact the right to health care and cause physical harm in the long run.

Amendment 604
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Recital 40 a (new)
(40 a) Transparency requirements shall not apply where the content forms part of an evidently artistic, creative, satirical, fictional or analogous work or programme.

Amendment 605
Renew - Renew Europe Group
Morten Løkkegaard
Recital 40 a (new)
(40 a) Transparency requirements shall not apply where the content forms part of an evidently artistic, creative, satirical, fictional and analogous work or programme.

Amendment 606
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 40 b (new)
(40 b) Subliminal techniques are techniques that expose natural persons to sensorial stimuli that the natural persons cannot consciously perceive but that are assumed to register in the brain unconsciously, such as flashing images or text for fractions of a second or playing sounds outside the range of perceptible hearing. AI systems deploying such techniques should be prohibited, because these techniques are by their very nature intended to be manipulative. Nevertheless, exceptions are warranted for AI systems using subliminal techniques for research and therapeutical purposes, based on the consent of the natural persons that are being exposed to them. In such limited cases, the AI systems should be considered high-risk and comply with the requirements for high-risk AI systems as set forth in this Regulation.

Amendment 607
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 40 b (new)
(40 b) Certain AI-systems used in the area of media, particularly in the area of social media, due to their potentially large reach and the specific risk of large scale spread of disinformation and exacerbation of societal polarisation should be high-risk due to their potential impact on individuals’ rights, but also on society and democracy at large.

Amendment 608
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 41
(41) The fact that an AI system is classified as high risk under this Regulation should not be interpreted as indicating that the use of the system is necessarily lawful under other acts of Union law or under national law compatible with Union law, such as on the protection of personal data. Any such use should continue to occur solely in accordance with the applicable requirements resulting from the Charter and from the applicable acts of secondary Union law and national law. This Regulation should not be understood as providing for the legal ground for processing of personal data, including special categories of personal data.

Amendment 609
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 41
(41) The fact that an AI system is classified as high risk under this Regulation should not be interpreted as indicating that the use of the system is necessarily lawful under other acts of Union law or under national law compatible with Union law, such as on the protection of personal data. Any such use should continue to occur solely in accordance with the applicable requirements resulting from the Charter and from the applicable acts of secondary Union law and national law. This Regulation should not be understood as providing for the legal ground for processing of personal data, including special categories of personal data, where relevant.

Amendment 610
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 41
(41) The fact that an AI system is classified as high risk under this Regulation should not be interpreted as indicating that the use of the system is necessarily lawful under other acts of Union law or under national law compatible with Union law, such as on the protection of personal data. Any such use should continue to occur solely in accordance with the applicable requirements resulting from the Charter and from the applicable acts of secondary Union law and national law. This Regulation should not be understood as providing for the legal ground for processing of personal data, including special categories of personal data, where relevant.

Amendment 611
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 41
(41) The fact that an AI system is compliant with the requirements for high-risk AI under this Regulation should not be interpreted as indicating that the use of the system is necessarily unlawful under other acts of Union law or under national law compatible with Union law, such as on the protection of personal data, on the use of polygraphs and similar tools or other systems to detect the emotional state of natural persons. Any such use should continue to occur solely in accordance with the applicable requirements resulting from the Charter and from the applicable acts of secondary Union law and national law. As far as is applicable and proportionate, this Regulation may, where duly justified, be understood as providing for the legal ground for processing of personal data where relevant.

Amendment 612
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 41 a (new)
(41 a) AI systems do not operate in a lawless world. A number of legally binding rules at European, national and international level already apply or are relevant to AI systems today. Legal sources include, but are not limited to EU primary law (the Treaties of the European Union and its Charter of Fundamental Rights), EU secondary law (such as the General Data Protection Regulation, the Product Liability Directive, the Regulation on the Free Flow of Non-Personal Data, anti-discrimination Directives, consumer law and Safety and Health at Work Directives), the UN Human Rights treaties and the Council of Europe conventions (such as the European Convention on Human Rights), and numerous EU Member State laws. Besides horizontally applicable rules, various domain-specific rules exist that apply to particular AI applications (such as for instance the Medical Device Regulation in the healthcare sector).

Amendment 613
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 42
(42) To mitigate the risks from high-risk AI systems placed or otherwise put into service on the Union market for users and affected persons, certain mandatory requirements should apply, taking into account the intended purpose of the use of the system and according to the risk management system to be established by the provider. These requirements should be objective-driven, fit to purpose, reasonable and effective, without adding undue regulatory burdens or costs on operators.

Amendment 614
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 42
(42) To mitigate the risks from high-risk AI systems placed or otherwise put into service on the Union market for users and affected persons, certain mandatory requirements should apply, taking into account the intended purpose of the use of the system, level of reliance of the user or business user on the output of the AI system for the final decision or outcome and according to the risk management system to be established by the provider.

Amendment 615
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 42
(42) To mitigate the risks from high-risk AI systems placed or otherwise put into service on the Union market for deployers and AI subjects, certain mandatory requirements should apply, taking into account the intended purpose, the potential or reasonably foreseeable use or misuse of the system, and should be in accordance with the risk management system to be established by the provider.

Amendment 616
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 42
(42) To mitigate the risks from high-risk AI systems placed or otherwise put into service on the Union market for users and affected persons, certain mandatory requirements should apply, taking into account the intended purpose or reasonably foreseeable use of the system and according to the risk management system to be established by the provider.

Amendment 617
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 42
(42) To mitigate the risks from high-risk AI systems placed or otherwise put into service on the Union market for users and affected persons, certain mandatory requirements should apply, taking into account the foreseeable uses of the system and according to the risk management system to be established by the provider.

Amendment 618
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 43
(43) Requirements should apply to high-risk AI systems as regards the quality and relevance of data sets used, technical documentation and record-keeping, transparency and the provision of information to users, human oversight, and robustness, accuracy and security. Those requirements are necessary to effectively mitigate the risks for health, safety and fundamental rights, as well as the environment, society, rule of law, democracy, economic interests and consumer protection, as applicable in the light of the intended purpose, the potential or reasonably foreseeable use or misuse of the system, and no other less trade restrictive measures are reasonably available, thus avoiding unjustified restrictions to trade.

Amendment 619
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 43
(43) Requirements should apply to high-risk AI systems as regards the quality of data sets used, technical documentation and record-keeping, transparency and the provision of information to users, human oversight, and robustness, accuracy and cybersecurity. Those requirements are necessary to effectively mitigate the risks for health, safety, fundamental rights, the environment and the Union values enshrined in Article 2 TEU, as applicable in the light of the intended purpose or reasonably foreseeable use of the system, and no other less trade restrictive measures are reasonably available, thus avoiding unjustified restrictions to trade.

Amendment 620
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 43
(43) Requirements should apply to high-risk AI systems as regards the quality of data sets used, technical documentation and record-keeping, transparency and the provision of information to users, human oversight, and robustness, accuracy and cybersecurity. Those requirements are necessary to effectively mitigate the risks for health, safety and fundamental rights, as applicable in the light of the intended purpose or reasonably foreseeable use of the system, and no other less trade restrictive measures are reasonably available, thus avoiding unjustified restrictions to trade.

Amendment 621
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 43
(43) Requirements should apply to high-risk AI systems as regards the quality of data sets used, technical documentation and record-keeping, transparency and the provision of information to users, human oversight, and robustness, accuracy and cybersecurity. Those requirements are necessary to effectively mitigate the risks for health, safety and fundamental rights, as applicable in the light of the foreseeable uses of the system, and no other less trade restrictive measures are reasonably available, thus avoiding unjustified restrictions to trade.

Amendment 622
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Andrzej Halicki, Adam Jarubas, Jerzy Buzek, Janusz Lewandowski,
Recital 43 a (new)
(43 a) Fundamental rights impact assessments for high-risk AI systems may include a clear outline of the intended purpose for which the system will be used, a clear outline of the intended geographic and temporal scope of the system’s use, categories of natural persons and groups likely to be affected by the use of the system or any specific risk of harm likely to impact marginalised persons or groups at risk of discrimination, or increase societal inequalities;

Amendment 623
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 44
(44) High data quality and having simple and accessible data plays a vital role in providing structure and ground truth for AI and are essential for purpose-ready data analytics and the performance of many AI systems, especially when techniques involving the training of models are used, with a view to ensure that the high-risk AI system performs as intended and safely and it does not become the source of discrimination prohibited by Union law. To achieve simple access to and usability of high quality data for AI, the Commission should examine ways to facilitate the lawful processing of personal data to train legitimate AI systems by appropriate amendments to applicable laws. High quality training, validation and testing data sets require the implementation of appropriate data governance and management practices. Training, machine learning validation and testing data sets should be sufficiently relevant and representative in view of the intended purpose of the system. They should also have the appropriate statistical properties, including as regards the persons or groups of persons on which the high-risk AI system is intended to be used. In particular, training, machine learning validation and testing data sets should take into account, to the extent required in the light of their intended purpose, the features, characteristics or elements that are particular to the specific geographical, behavioural or functional setting or context within which the AI system is intended to be used. If it is necessary for the aforementioned purpose to use existing sets of data that includes personal data originally collected and stored for a different purpose, their use for the aforementioned purpose should be deemed compatible with the original purpose so long as the personal data is not transferred to any third party. In order to protect the right of others from the discrimination that might result from the bias in AI systems, the providers should be able to process also special categories of personal data, as a matter of substantial public interest, in order to ensure the bias monitoring, detection and correction in relation to high-risk AI systems.

Amendment 624
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 44
(44) High data quality is essential for the performance of many AI systems, especially when techniques involving the training of models are used, with a view to ensure that the high-risk AI system performs as intended and safely and it does not become the source of discrimination prohibited by Union law. High quality training, validation and testing data sets require the implementation of appropriate data governance and management practices. Training, validation and testing data sets should be sufficiently relevant, representative and free of errors and complete in view of the intended purpose of the system. They should also have the appropriate statistical properties, including as regards the persons or groups of persons on which the high-risk AI system is intended to be used. In particular, training, validation and testing data sets should take into account, to the extent required in the light of their intended purpose, the features, characteristics or elements that are particular to the specific geographical, behavioural or functional setting or context within which the AI system is intended to be used.

Amendment 625
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Recital 44
(44) High data quality is essential for the performance of many AI systems, especially when techniques involving the training of models are used, with a view to ensure that the high-risk AI system performs as intended and safely and it does not become the source of discrimination prohibited by Union law. High quality training, validation and testing data sets require the implementation of appropriate data governance and management practices. Training, validation and testing data sets should be sufficiently relevant, representative as complete and close to zero error as possible. A procedure to check data and completeness in view of the intended purpose of the system should be implemented. They should also have the appropriate statistical properties, including as regards the persons or groups of persons on which the high-risk AI system is intended to be used. In particular, training, validation and testing data sets should take into account, to the extent required in the light of their intended purpose, the features, characteristics or elements that are particular to the specific geographical, behavioural or functional setting or context within which the AI system is intended to be used. In order to protect the right of others from the discrimination that might result from the unfair bias in AI systems, the providers shouldbe able to process also special categories of personal data, as a matter of substantial public interest, in order to ensure the unfair bias monitoring, detection and correction in relation to high-risk AI systems.

Amendment 626
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 44
(44) High data quality is essential for the performance of many AI systems, especially when techniques involving the training of models are used, with a view to ensure that the high-risk AI system performs as intended and safely and it does not become the source of discrimination prohibited by Union law. High quality training, validation and testing data sets require the implementation of appropriate data governance and management practices. Training, validation and testing data sets should be sufficiently relevant, representative and free of errors and complete in view of the foreseeable uses of the system. They should also have the appropriate statistical properties, including as regards the persons or groups of persons on which the high-risk AI system is intended to be used. In particular, training, validation and testing data sets should take into account, to the extent required in the light of their foreseeable uses, the features, characteristics or elements that are particular to the specific geographical, behavioural or functional setting or context within which the AI system is intended to be used. In order to protect the right of others from the discrimination that might result from the bias in AI systems, the providers should ensure the bias monitoring, detection and correction in relation to high-risk AI systems.

Amendment 627
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 44
(44) High data quality is essential for the performance of many AI systems, especially when techniques involving the training of models are used, with a view to ensure that the high-risk AI system performs as intended and safely and it does not become the source of discrimination prohibited by Union law. High quality training, validation and testing data sets require the implementation of appropriate data governance and management practices. Training, validation and testing data sets should be sufficiently relevant, representative and free of errors and complete in view of the intended purpose or reasonably foreseeable use of the system. They should also have the appropriate statistical properties, including as regards the persons or groups of persons on which the high-risk AI system is intended to be used. In particular, training, validation and testing data sets should take into account, to the extent required in the light of their intended purpose or reasonably foreseeable use , the features, characteristics or elements that are particular to the specific geographical, behavioural or functional setting or context within which the AI system is intended or foreseeable to be used. In order to protect the right of others from the discrimination that might result from the bias in AI systems, the providers should be able to process also special categories of personal data, as a matter of substantial public interest, in order to ensure the bias monitoring, detection and correction in relation to high-risk AI systems.

Amendment 628
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 44
(44) High data quality is essential for the performance of many AI systems, especially when techniques involving the training of models are used, with a view to ensure that the high-risk AI system performs as intended and safely and it does not become a source of discrimination prohibited by Union law. High quality training, validation and testing data sets require the implementation of appropriate data governance and management practices. Training, validation and testing data sets should be sufficiently relevant, representative and free of errors, statistically complete and relevant in view of the intended purpose of the system and the context of its use. They should also have the appropriate statistical properties, including as regards the persons or groups of persons in relation to whom the high-risk AI system is intended to be used. In particular, training, validation and testing data sets should take into account, to the extent necessary in the light of their intended purpose, the features, characteristics or elements that are particular to the specific geographical, behavioural or functional setting or context within which the AI system is intended to be used. Solely in order to protect the right of others from the discrimination that might result from the bias in AI systems, the providers should be able to process special categories of personal data, as a matter of substantial public interest, in order to ensure bias monitoring, detection and correction in relation to high-risk AI systems.

Amendment 629
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 44
(44) High data quality is essential for the performance of many AI systems, especially when techniques involving the training of models are used, with a view to ensure that the high-risk AI system performs as intended and safely and it does not become the source of discrimination prohibited by Union law. High quality training, validation and testing data sets require the implementation of appropriate data governance and management practices. Training datasets, and where applicable, validation and testing datasets, including the labels, shall be relevant, representative, up-to-date, and to the best extent possible, free of errors and complete. They should also have the appropriate statistical properties, including as regards the persons or groups of persons on which the high-risk AI system is intended to be used. In particular, data sets should take into account, to the extent required by the intended purpose, the foreseeable uses and reasonably foreseeable misuses of AI systems with indeterminate uses, the features, characteristics or elements that are particular to the specific geographical, behavioural or functional setting or context within which the AI system is intended to be used.

Amendment 630
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Recital 44
(44) High data quality is essential for the performance of many AI systems, especially when techniques involving the training of models are used, with a view to ensure that the high-risk AI system performs as intended and safely and it does not become the source of discrimination prohibited by Union law. High quality training, validation and testing data sets require the implementation of appropriate data governance and management practices. Training, validation and testing data sets should be sufficiently relevant, representative in view of the intended purpose of the system. They should also have the appropriate statistical properties, including as regards the persons or groups of persons on which the high-risk AI system is intended to be used. In particular, training, validation and testing data sets should take into account, to the extent required in the light of their intended purpose, the features, characteristics or elements that are particular to the specific geographical, behavioural or functional setting or context within which the AI system is intended to be used. In order to protect the right of others from the discrimination that might result from the bias in AI systems, the providers shouldbe able to process also special categories of personal data, as a matter of substantial public interest, in order to ensure the bias monitoring, detection and correction in relation to high-risk AI systems.

Amendment 631
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 44 a (new)
(44 a) Biases can be inherent in underlying datasets, especially when historical data is being used, introduced by the developers of the algorithms, or generated when the systems are implemented in real world settings. Any result provided by an AI system is necessarily influenced by the quality of the data used, and such inherent biases are inclined to gradually increase and thereby perpetuate and amplify existing discrimination, in particular for persons belonging to certain ethnic groups or racialised communities.

Amendment 632
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 45
(45) For the development of high-risk AI systems, certain actors, such as providers, notified bodies and other relevant entities, such as digital innovation hubs, testing experimentation facilities and researchers, should be able to access and use high quality datasets within their respective fields of activities which are related to this Regulation. European common data spaces established by the Commission, developed and operated by European actors and which do not transfer any data outside the territory or legal jurisdiction of the European Union, and the facilitation of data sharing between businesses and with government in the public interest will be instrumental to provide trustful, accountable and non-discriminatory access to high quality data for the training, validation and testing of AI systems. For example, in health, the European health data space will facilitate non-discriminatory access to health data and the training of artificial intelligence algorithms on those datasets, in a privacy-preserving, secure, timely, transparent and trustworthy manner, and with an appropriate institutional governance. Relevant competent authorities, including sectoral ones, providing or supporting the access to data may also support the provision of high-quality data for the training, validation and testing of AI systems.

Amendment 633
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 46
(45) For the development and assessment of high-risk AI systems, certain actors, such as providers, notified bodies and other relevant entities, such as digital innovation hubs, testing experimentation facilities and researchers, should be able to access and use high quality datasets within their respective fields of activities which are related to this Regulation. European common data spaces established by the Commission and the facilitation of data sharing between businesses and with government in the public interest will be instrumental to provide trustful, accountable and non-discriminatory access to high quality data for the training, validation and testing of AI systems. For example, in health, the European health data space will facilitate non-discriminatory access to health data and the training of artificial intelligence algorithms on those datasets, in a privacy-preserving, secure, timely, transparent and trustworthy manner, and with an appropriate institutional governance. Relevant competent authorities, including sectoral ones, providing or supporting the access to data may also support the provision of high-quality data for the training, validation and testing of AI systems.

Amendment 634
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 46
(46) Having information on how high-risk AI systems have been developed and how they perform throughout their lifecycle is essential to verify compliance with the requirements under this Regulation. This requires keeping records and the availability of a technical documentation, containing information which is necessary to assess the compliance of the AI system with the relevant requirements. Such information should include the general characteristics, capabilities and limitations of the system, algorithms, data, training, testing and validation processes used as well as documentation on the relevant risk management system. The technical documentation should be kept up to date. The required technical documentation may contain trade secrets in accordance with Directive (EU) 2016/943 of the European Parliament and of the Council of 8 June 2016 on the protection of undisclosed know-how and business information (trade secrets) against their unlawful acquisition, use and disclosure. Possible trade secrets in the required documentation must be treated and kept in accordance with national legislation put in place in accordance with mentioned directive.

Amendment 635
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 46
(46) Having information on how high-risk AI systems have been developed and how they perform throughout their lifecycle is essential to verify compliance with the requirements under this Regulation. This requires keeping records and the availability of a technical documentation, containing information which is necessary to assess the compliance of the AI system with the relevant requirements. Such information should include the general characteristics, capabilities and limitations of the system, algorithms, data, training, testing and validation processes used as well as documentation on the relevant risk management system. The technical documentation should be kept up to date throughout the entire lifecycle of the AI system.

Amendment 636
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 46
(46) Having information on how high-risk AI systems have been developed and how they perform throughout their lifetime is essential to verify compliance with the requirements under this Regulation. This requires keeping records and the availability of a technical documentation, containing information which is necessary to assess the compliance of the AI system with the relevant requirements, while preserving trade secrets. Such information should include the general characteristics, capabilities and limitations of the system, algorithms, data, training, testing and validation processes used as well as documentation on the relevant risk management system. The technical documentation should be kept up to date.

Amendment 637
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 47
(47) To address the opacity that may make certain AI systems incomprehensible to or too complex for natural persons, a certain degree of transparency should be required for high-risk AI systems. Deployers should be able to interpret the system’s goals, priorities and output and use it appropriately. High-risk AI systems should therefore be accompanied by relevant documentation and instructions of use and include concise and clear information, including in relation to possible risks to fundamental rights and discrimination, where appropriate. Where individuals are passively subject to AI systems (AI subjects), information to ensure an appropriate type and degree of transparency should be made publicly available, with full respect to the privacy, personality, and related rights of subjects.

Amendment 638
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 47 a (new)
(47 a) It is vital to ensure that the development, deployment and use of AI systems for the judiciary and law enforcement comply with fundamental rights, and are trusted by citizens, as well as in order to ensure that results generated by AI algorithms can be rendered intelligible to users and to those subject to these systems, and that there is transparency on the source data and how the system arrived at a certain conclusion. To this aim, law enforcement or judiciary authorities in the Union should use only such AI systems whose algorithms and logic are auditable and accessible at least to the police and the judiciary, as well as independent auditors, to allow for their evaluation, auditing and vetting, and such systems should not be closed or labelled as proprietary by the vendors.

Amendment 639
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 48
(48) High-risk AI systems should be designed and developed in such a way that natural persons may, when appropriate, oversee their functioning. For this purpose, when it brings proven added value to the protection of health, safety and fundamental rights, appropriate human oversight measures should be identified by the provider of the system before its placing on the market or putting into service. In particular, where appropriate, such measures should guarantee that the system is subject to in-built operational constraints and are responsive to the human operator during the expected lifetime of the device where necessary to reduce risks as far as possible and achieve performance in consideration of the generally acknowledged state-of-the-art and technological and scientific progress, and that the natural persons to whom human oversight has been assigned have the necessary competence, training and authority to carry out that role. By way of derogation regarding high-risk AI systems within the scope of Regulation (EU) 2017/745 and Regulation (EU) 2017/746 of the European Parliament and of the Council, the established benefit-risk ratio requirements under the sectoral medical device legislation should apply.

Amendment 640
EPP - Group of the European Peoples Party (Christian Democrats)
Deirdre Clune, Axel Voss, Andreas Schwab
Recital 48
(48) High-risk AI systems should be designed and developed in such a way that natural persons may, when appropriate, oversee their functioning. For this purpose, when it brings proven added value to the protection of health, safety and fundamental rights, appropriate human oversight measures should be identified by the provider of the system before its placing on the market or putting into service. In particular, where appropriate, such measures should guarantee that the system is subject to in-built operational constraints and are responsive to the human operator during the expected lifetime of the device where necessary to reduce risks as far as possible and achieve performance in consideration of the generally acknowledged state-of-the-art technological and scientific progress, and that the natural persons to whom human oversight has been assigned have the necessary competence, training and authority to carry out that role. By way of derogation regarding high-risk AI systems within the scope of Regulation (EU) 2017/745 and Regulation (EU) 2017/746 of the European Parliament and of the Council, the established benefit-risk ratio requirements under the sectoral medical device legislation should apply.

Amendment 641
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki
Recital 48
(48) High-risk AI systems should be designed and developed in such a way that natural persons may, when appropriate, oversee their functioning. For this purpose, when it brings a proven added value to the protection of health, safety and fundamental rights, appropriate human oversight measures should be identified by the provider of the system before its placing on the market or putting into service. In particular, where appropriate, such measures should guarantee that the system is subject to in-built operational constraints that cannot be overridden by the system itself and is responsive to the human operator, and that the natural persons to whom human oversight has been assigned have the necessary competence, training and authority to carry out that role.

Amendment 642
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 48
(48) High-risk AI systems should be designed and developed in such a way that natural persons can actually oversee their functioning. For this purpose, appropriate human oversight measures should be identified by the provider of the system before its placing on the market or putting into service. In particular, where appropriate, such measures should guarantee that the system is subject to in-built operational constraints that cannot be overridden by the system itself, that it cannot make decisions without approval by the human operator, that it is responsive to the human operator, and that the natural persons to whom human oversight has been assigned have the necessary competence, training and authority to carry out that role.

Amendment 643
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 48
(48) High-risk AI systems should be designed and developed in such a way that natural persons can meaningfully oversee and regulate their functioning or investigate in case of an accident. For this purpose, appropriate human oversight measures should be ensured by the provider of the system before its placing on the market or putting into service. In particular, where appropriate, such measures should guarantee that the system is subject to in-built operational constraints that cannot be overridden by the system itself and is responsive to the human operator, and that the natural persons to whom human oversight has been assigned have the necessary competence, training and authority to carry out that role.

Amendment 644
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 48 a (new)
(48 a) In order to protect natural persons that are developers or users of AI systems against retaliation from their employers and colleagues, and to prevent misconduct or breaches of this Regulation and other relevant Union law, they should have the right to rely on the whistleblower protections set in Directive (EU) 2019/1937 of the European Parliament and of the Council.

Amendment 645
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 49
(49) High-risk AI systems should perform consistently throughout their lifetime and meet an appropriate level of accuracy, robustness and cybersecurity in accordance with the generally acknowledged state of the art. The level of accuracy and accuracy metrics should be communicated to the users. While standardisation organisations exist to establish standards, coordination on benchmarking is needed to establish how these standards should be met and measured. The European Artificial Intelligence Board should bring together national metrology and benchmarking authorities and provide guidance to address the technical aspects of how to measure the appropriate levels of accuracy and robustness. Their work should not be seen as a replacement of the standardisation organisations, but as a complementary function to provide specific technical expertise on measurement.

Amendment 646
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 49
(49) High-risk AI systems should perform consistently throughout their lifecycle and meet an appropriate level of accuracy, robustness and cybersecurity in accordance with the generally acknowledged state of the art. The level of accuracy and accuracy metrics should be defined by standards or common technical specifications and communicated to the users. The European Commission should be able to decide on such standards or common technical specifications or to adopt existing ones developed by third parties such as suppliers, stakeholders or standardisation bodies.

Amendment 647
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 49
(49) High-risk AI systems should perform consistently throughout their lifecycle and meet an appropriate level of accuracy, robustness, reliability and security in accordance with the generally acknowledged state of the art. The level of accuracy and accuracy metrics should be communicated to the deployers.

Amendment 648
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 50
(50) Technical robustness is a key requirement for high-risk AI systems. They should be resilient against risks connected to the limitations of the system (e.g. errors, faults, inconsistencies, unexpected situations) as well as adequately protected against malicious actions that may compromise the security of the AI system and result in harmful or otherwise undesirable behaviour. Failure to protect against these risks could lead to safety impacts or negatively affect fundamental rights, for example due to erroneous decisions or wrong or biased outputs generated by the AI system.

Amendment 649
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 51
(51) Cybersecurity plays a crucial role in ensuring that AI systems are resilient against attempts to alter their use, behaviour, performance or compromise their security properties by malicious third parties exploiting the system’s vulnerabilities. Cyberattacks against AI systems can leverage AI specific assets, such as training data sets (e.g. data poisoning) or trained models (e.g. adversarial attacks), or exploit vulnerabilities in the AI system’s digital assets or the underlying ICT infrastructure. To ensure a level of cybersecurity appropriate to the risks, state-of-the-art measures should therefore be taken into account by the providers of high-risk AI systems but also by the national competent authorities, market surveillance authorities and notified bodies that are accessing the data of providers of high-risk AI systems, next to appropriate underlying ICT infrastructure. It should be further taken into account that AI in the form of machine learning is a critical defence against malware representing a legitimate interest of the AI user.

Amendment 650
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan, Vincenzo Sofo
Recital 51
(51) Cybersecurity plays a crucial role in ensuring that AI systems are resilient against attempts to alter their use, behaviour, performance or compromise their security properties by malicious third parties exploiting the system’s vulnerabilities. Cyberattacks against AI systems can leverage AI specific assets, such as training data sets (e.g. data poisoning) or trained models (e.g. adversarial attacks), or exploit vulnerabilities in the AI system’s digital assets or the underlying ICT infrastructure. To ensure a level of cybersecurity appropriate to the risks, suitable measures should therefore be taken by the providers of high-risk AI systems, as well as the notified bodies, competent national authorities and market surveillance authorities accessing the data of providers of high-risk AI systems, also taking into account as appropriate the underlying ICT infrastructure.

Amendment 651
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 51
(51) Cybersecurity plays a crucial role in ensuring that AI systems are resilient against attempts to alter their use, behaviour, performance or compromise their security properties by malicious third parties exploiting the system’s vulnerabilities. Cyberattacks against AI systems can leverage AI specific assets, such as training data sets (e.g. data poisoning) or trained models (e.g. adversarial attacks), or exploit vulnerabilities in the AI system’s digital assets or the underlying ICT infrastructure. To ensure a level of cybersecurity appropriate to the risks, suitable measures should therefore be taken by the providers of high-risk AI systems, as well as the notified bodies, competent national authorities and market surveillance authorities, also taking into account as appropriate the underlying ICT infrastructure.

Amendment 652
EPP - Group of the European Peoples Party (Christian Democrats)
Karlo Ressler
Recital 51
(51) Cybersecurity plays a crucial role in ensuring that AI systems are resilient against attempts to alter their use, behaviour, performance or compromise their security properties by malicious third parties exploiting the system’s vulnerabilities. Cyberattacks against AI systems can leverage AI specific assets, such as training data sets (e.g. data poisoning) or trained models (e.g. adversarial attacks), or exploit vulnerabilities in the AI system’s digital assets or the underlying ICT infrastructure. To ensure a level of cybersecurity appropriate to the risks, suitable measures should therefore be taken by the providers of high-risk AI systems, as well as the competent public authorities accessing the data of providers of high-risk AI systems, also taking into account as appropriate the underlying ICT infrastructure.

Amendment 653
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 51
(51) Cybersecurity plays a crucial role in ensuring that AI systems are resilient against attempts to alter their use, behaviour, performance or compromise their security properties by malicious third parties exploiting the system’s vulnerabilities. Cyberattacks against AI systems can target AI specific assets, such as training data sets (e.g. data poisoning) or trained models (e.g. adversarial attacks), or exploit vulnerabilities in the AI system’s digital assets or the underlying ICT infrastructure. To ensure a level of cybersecurity appropriate to the risks, suitable measures should therefore be taken by the providers of high-risk AI systems, also taking into account as appropriate the underlying ICT infrastructure.

Amendment 654
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 51
(51) Cybersecurity plays a crucial role in ensuring that AI systems are resilient against attempts to alter their use, behaviour, performance or compromise their security properties by malicious third parties exploiting the system’s vulnerabilities. Cyberattacks against AI systems can leverage AI specific assets, such as training data sets (e.g. data poisoning) or trained models (e.g. adversarial attacks), or exploit vulnerabilities in the AI system’s digital assets or the underlying ICT infrastructure. To ensure a level of cybersecurity appropriate to the risks, suitable measures should therefore be taken by the providers of high-risk AI systems, also taking into account the underlying ICT infrastructure.

Amendment 655
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 53
(53) It is appropriate that a specific natural or legal person, defined as the provider, takes the responsibility for the placing on the market or putting into service of a high-risk AI system, regardless of whether that natural or legal person is the person who designed or developed the system, without prejudice to the right of a provider to take action against the manufacturer of that system.

Amendment 656
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 53
(53) It is appropriate that a specific natural or legal person, defined as the provider, takes the responsibility for the placing on the market, putting into service or deploying of a high-risk AI system, regardless of whether that natural or legal person is the person who designed or developed the system.

Amendment 657
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 54
(54) The provider and, where applicable, deployer should establish a sound quality management system, ensure the accomplishment of the required conformity assessment procedure, draw up the relevant documentation and establish a robust post-market monitoring system. Public authorities which put into service high-risk AI systems for their own use may adopt and implement the rules for the quality management system as part of the quality management system adopted at a national or regional level, as appropriate, taking into account the specificities of the sector and the competences and organisation of the public authority in question. Deployers should have strategies in place to ensure that the data management, including data acquisition, data collection, data analysis, data labelling, data storage, data filtration, data mining, data aggregation, data retention and any other operation regarding the data during the deployment lifetime of high-risk AI systems, complies with applicable rules and ensure regulatory compliance, in particular regarding modifications to the high-risk AI systems.

Amendment 658
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Recital 54
(54) The provider should establish a sound quality management system, ensure the accomplishment of the required conformity assessment procedure, draw up the relevant documentation in the language of the Member State concerned and establish a robust post-market monitoring system. All elements, from design to future development, must be transparent for the user. Public authorities which put into service high-risk AI systems for their own use may adopt and implement the rules for the quality management system as part of the quality management system adopted at a national or regional level, as appropriate, taking into account the specificities of the sector and the competences and organisation of the public authority in question.

Amendment 659
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Recital 54
(54) Unless the provider has already implemented a risk management system warranting quality and conformity, the provider should establish a sound quality management system, ensure the accomplishment of the required conformity assessment procedure, draw up the relevant documentation and establish a robust post-market monitoring system. Public authorities which put into service high-risk AI systems for their own use may adopt and implement the rules for the quality management system as part of the quality management system adopted at a national or regional level, as appropriate, taking into account the specificities of the sector and the competences and organisation of the public authority in question.

Amendment 660
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Recital 54
(54) In case there are no risk management systems already in place, the provider should establish a sound quality management system, ensure the accomplishment of the required conformity assessment procedure, draw up the relevant documentation and establish a robust post-market monitoring system. Public authorities which put into service high-risk AI systems for their own use may adopt and implement the rules for the quality management system as part of the quality management system adopted at a national or regional level, as appropriate, taking into account the specificities of the sector and the competences and organisation of the public authority in question.

Amendment 661
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 56
(56) To enable enforcement of this Regulation and create a level-playing field for operators, and taking into account the different forms of making available of digital products, it is important to ensure that, under all circumstances, a person established in the Union can provide authorities with all the necessary information on the compliance of an AI system. Therefore, prior to placing any AI system on the Union market, putting it into service or using it, where an importer cannot be identified, operators established outside the Union should, by written mandate, appoint a legal representative established in the Union. The legal representative should act on behalf of the operator and may be addressed by any competent authorities for the purpose of this Regulation. The designation of such a legal representative does not affect the responsibility or liability of the operator under this Regulation. Such a legal representative should perform its tasks according to the mandate received from the operator, including cooperating with the national supervisory authorities with regard to any action taken to ensure compliance with this Regulation. The designated legal representative should be subject to enforcement proceedings in the event of non-compliance by the operator.

Amendment 662
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Sandro Gozi, Vlad-Marius Botoş, Moritz
Recital 56
(56) To enable enforcement of this Regulation and create a level-playing field for operators, and taking into account the different forms of making available of digital products, it is important to ensure that, under all circumstances, a person established in the Union can provide authorities with all the necessary information on the compliance of an AI system. Therefore, prior to making their AI systems available in the Union, providers established outside the Union shall, by written mandate, appoint an authorised representative established in the Union.

Amendment 663
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 58
(58) Given the nature of AI systems and the risks to safety and fundamental rights possibly associated with their use, including as regard the need to ensure proper monitoring of the performance of an AI system in a real-life setting, it is appropriate to set specific responsibilities for users. Users should in particular use high-risk AI systems in accordance with the instructions of use and certain other obligations should be provided for with regard to monitoring of the functioning of the AI systems and with regard to record-keeping, as appropriate. Given the potential impact and the need for democratic oversight and scrutiny, users of high-risk AI systems that are public authorities or Union institutions, bodies, offices and agencies should be required to conduct a fundamental rights impact assessment prior to commencing the use of a high-risk AI system should be required to register the use of any high-risk AI systems in a public database.

Amendment 664
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 58
(58) Given the nature of AI systems and the risks to safety and fundamental rights possibly associated with their use, including as regard the need to ensure proper monitoring of the performance of an AI system in a real-life setting, it is appropriate to set specific responsibilities for users. Users should in particular use high-risk AI systems for the purpose for which they were intended and in accordance with the instructions of use, to that end high-risk AI systems should structurally limit, to the greatest extent possible, the technical possibility for a user to use these AI systems in another way, and certain other obligations should be provided for with regard to monitoring of the functioning of the AI systems and with regard to record-keeping, as appropriate.

Amendment 665
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 58
(58) Given the nature of AI systems and the risks to safety and fundamental rights possibly associated with their use, including as regards the need to ensure proper monitoring of the performance of an AI system in a real-life setting, it is appropriate to set specific responsibilities for deployers. Deployers should in particular use high-risk AI systems in accordance with the instructions of use and certain other obligations should be provided for with regard to monitoring of the functioning of the AI systems and with regard to record-keeping and quality management, as appropriate.

Amendment 666
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 58 a (new)
(58 a) Whilst risks related to AI systems can generate from the way such systems are designed, risks can as well stem from how such AI systems are used. Users of high-risk AI system therefore play a critical role in ensuring that fundamental rights are protected, complementing the obligations of the provider when developing the AI system. Users are best placed to understand how the high-risk AI system will be used concretely and can therefore identify potential risks that were not foreseen in the development phase, thanks to a more precise knowledge of the context of use, the people or groups of people likely to be affected, including marginalised and vulnerable groups. In order to efficiently ensure that fundamental rights are protected, the user of high-risk AI systems should therefore carry out a fundamental rights impact assessment on how it intends to use such AI systems, and prior to putting it into use. The impact assessment should be accompanied by a detailed plan describing the measures or tools that will help mitigating the risks to fundamental rights identified. When performing this impact assessment, the user should notify the national supervisory authority, the market surveillance authority as well as relevant stakeholders. It should also involve representatives of groups of persons likely to be affected by the AI system in order to collect relevant information which is deemed necessary to perform the impact assessment.

Amendment 667
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 58 a (new)
(58 a) To ensure that fundamental rights, the environment and the public interest are effectively protected where an AI-system is classified as high-risk under Annex III, both producers and deployers before each deployment should perform a fundamental rights impact assessment of the systems’ impact in the context of use throughout the entire lifecycle and include measures to mitigate any impact on fundamental rights, the environment or the public interest. The fundamental rights impact assessment should be registered in the public EU database for stand-alone high-risk AI systems and be publicly accessible. The supervisory authority should have the power to review these fundamental rights impact assessments.

Amendment 668
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 58 a (new)
(58 a) Risks for people affected by AI systems often arise from uses of an AI system in a specific context and with respect to a specific group of people, and might not always be foreseeable for the provider. Therefore, prior to putting a high-risk AI system into use, the user should conduct an assessment of the system’s impact on the fundamental rights in particular, within the context of use, and publish the results.

Amendment 669
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 59
(59) It is appropriate to envisage that the user of the AI system should be the natural or legal person, public authority, agency or other body under whose authority the AI system is operated.

Amendment 670
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 59
(59) It is appropriate to envisage that the deployer of the AI system should be the natural or legal person, public authority, agency or other body under whose authority the AI system is operated except where the use is made in the course of a personal non-professional activity.

Amendment 671
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Recital 60
(60) In the light of the complexity of the artificial intelligence value chain, relevant third parties, notably the ones involved in the sale and the supply of software, software tools and components, pre-trained models and data, or providers of network services, should cooperate, as appropriate, with providers and users to enable their compliance with the obligations under this Regulation and with competent authorities established under this Regulation. This provision shall qualify as a legal obligation in the context of the processing of personal data where necessary for the cooperation between the relevant providers.

Amendment 672
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 60
(60) In the light of the complexity of the artificial intelligence value chain, relevant third parties, notably the ones involved in the sale and the supply of software, software tools and components, pre-trained models and data, or providers of network services, should cooperate, as appropriate, with providers and deployers to enable their compliance with the obligations under this Regulation and with competent authorities established under this Regulation.

Amendment 673
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul Garraud
Recital 61
(61) Standardisation should play a key role to provide technical solutions to providers to ensure compliance with this Regulation, in particular as regards the levels and metrics of accuracy and robustness for high-risk AI systems. The Commission should be able to adopt common technical specifications in areas where no harmonised standards exist or where they are insufficient. The Commission should also be able to adopt standards or common technical specifications developed by third parties such as suppliers, stakeholders or standardisation bodies. Compliance with the common technical specifications adopted by the Commission should be a means for suppliers to demonstrate compliance with the requirements of this Regulation. Compliance with other harmonised standards set out in Regulation (EU) No 1025/2012 of the European Parliament and of the Council54 should also help to demonstrate suppliers’ compliance with the requirements of this Regulation, without having the same probative value as the common technical specifications adopted by the Commission.' '54 Regulation (EU) No 1025/2012 of the European Parliament and of the Council of 25 October 2012 on European standardisation, amending Council Directives 89/686/EEC and 93/15/EEC and Directives 94/9/EC, 94/25/EC, 95/16/EC, 97/23/EC, 98/34/EC, 2004/22/EC, 2007/23/EC, 2009/23/EC and 2009/105/EC of the European Parliament and of the Council and repealing Council Decision 87/95/EEC and Decision No 1673/2006/EC of the European Parliament and of the Council (OJ L 316, 14.11.2012, p. 12).

Amendment 674
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Morten Løkkegaard, Sandro Gozi, Vlad-
Recital 61
(61) Standardisation should play a key role to provide technical solutions to providers to ensure compliance with this Regulation. Compliance with harmonised standards as defined in Regulation (EU) No 1025/2012 of the European Parliament and of the Council54 should be a means for providers to demonstrate conformity with the requirements of this Regulation. However, the Commission could adopt common technical specifications in areas where no harmonised standards exist and are not expected to be published within a reasonable period or where they are insufficient, only after consulting the Artificial Intelligence Board, the European standardisation organisations as well as the relevant stakeholders. The Commission should duly justify why it decided not to use harmonised standards.' '54 Regulation (EU) No 1025/2012 of the European Parliament and of the Council of 25 October 2012 on European standardisation, amending Council Directives 89/686/EEC and 93/15/EEC and Directives 94/9/EC, 94/25/EC, 95/16/EC, 97/23/EC, 98/34/EC, 2004/22/EC, 2007/23/EC, 2009/23/EC and 2009/105/EC of the European Parliament and of the Council and repealing Council Decision 87/95/EEC and Decision No 1673/2006/EC of the European Parliament and of the Council (OJ L 316, 14.11.2012, p. 12).

Amendment 675
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 61
(61) Standardisation should play a key role to provide technical solutions to providers to ensure compliance with this Regulation. Compliance with harmonised standards as defined in Regulation (EU) No 1025/2012 of the European Parliament and of the Council54 should be a means for providers to demonstrate conformity with the requirements of this Regulation. However, in exceptional cases, where industry and technical experts consider that pressing and specific safety or fundamental rights concerns cannot be addressed by established standardisation processes, the Commission may adopt common technical specifications in areas where no harmonised standards exist or where they are evidently insufficient.' '54 Regulation (EU) No 1025/2012 of the European Parliament and of the Council of 25 October 2012 on European standardisation, amending Council Directives 89/686/EEC and 93/15/EEC and Directives 94/9/EC, 94/25/EC, 95/16/EC, 97/23/EC, 98/34/EC, 2004/22/EC, 2007/23/EC, 2009/23/EC and 2009/105/EC of the European Parliament and of the Council and repealing Council Decision 87/95/EEC and Decision No 1673/2006/EC of the European Parliament and of the Council (OJ L 316, 14.11.2012, p. 12).

Amendment 676
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 61 a (new)
(61 a) As part of the new legal framework on corporate sustainable reporting and due diligence, minimum common standards for the reporting of businesses on the societal and environmental impacts of the AI systems that they develop, sell or distribute should be established and used at an early stage of the development and life-cycle of AI systems. Such common standard obligations should notably consist of mandatory human rights due diligence rules, thus enabling a level-playing field among European businesses and non-European businesses operating in the EU.

Amendment 677
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Tomas Tobé, Arba Kokalari
Recital 61 a (new)
(61 a) Striving for regulatory alignment on AI with likeminded global partners is key to fostering mutual innovation and cross-border partnerships within the field of AI. Coordination with international standardisation bodies is therefore of great importance.

Amendment 678
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 62
(62) In order to ensure a high level of trustworthiness of high-risk AI systems, those systems should be subject to a conformity assessment prior to their placing on the market or putting into service. AI systems, including general purpose AI systems, that may not necessarily be high-risk, are frequently used as components of other AI or non-AI software systems. In order to increase trust in the value chain and to give certainty to businesses about the performance of their systems, providers may voluntarily apply for a third-party conformity assessment.

Amendment 679
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 62
(62) In order to ensure a high level of trustworthiness of high-risk AI systems, those systems should be subject to a third party conformity assessment prior to their placing on the market or putting into service.

Amendment 680
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 63
(63) It is appropriate that, in order to minimise the burden on operators and avoid any possible duplication, for high-risk AI systems related to products which are covered by existing Union harmonisation legislation following the New Legislative Framework approach, the compliance of those AI systems with the requirements of this Regulation should be assessed as part of the conformity assessment already foreseen under that legislation. The applicability of the requirements of this Regulation should thus not affect the specific logic, methodology or general structure of conformity assessment under the relevant specific New Legislative Framework legislation. This approach is fully reflected in the interplay between this Regulation and the [Machinery Regulation]. While safety risks of AI systems ensuring safety functions in machinery are addressed by the requirements of this Regulation, certain specific requirements in the [Machinery Regulation] will ensure the safe integration of the AI system into the overall machinery, so as not to compromise the safety of the machinery as a whole. The [Machinery Regulation] applies the same definition of AI system as this Regulation. However, should this Regulation and another legislative act of the European Union both cover the same product or component of a product and provide diverging definitions or impose different safety requirements, the applicable text shall be the one with the definition or safety requirements offering the best protection for people, Member States, society and fundamental rights.

Amendment 681
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 64
deleted

Amendment 682
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul Garraud
Recital 64
(64) Given the more extensive experience of professional pre-market certifiers in the field of product safety and the different nature of risks involved, it is appropriate to allow them to carry out a conformity assessment for AI systems, including high-risk AI systems, as qualified bodies, to the extent that these systems are not prohibited.

Amendment 683
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,
Recital 64
(64) Given the more extensive experience of professional pre-market certifiers in the field of product safety and the different nature of risks involved, it is appropriate to limit, at least in an initial phase of application of this Regulation, the scope of application of third-party conformity assessment for high-risk AI systems other than those related to products. Therefore, the conformity assessment of such systems should be carried out as a general rule by the provider under its own responsibility, with the exception of AI systems intended to be used for the remote biometric identification of persons and AI systems intended to be used to make inferences on the basis of biometric data that produce legal effects or affect the rights and freedoms of natural persons. For those types of AI systems the involvement of a notified body in the conformity assessment should be foreseen, to the extent they are not prohibited..

Amendment 684
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 64
(64) Given the more extensive experience of professional pre-market certifiers in the field of product safety and the different nature of risks involved, it is essential to ensure, particularly in the period before application of this Regulation, the development of adequate capacity for the application of third-party conformity assessment for high-risk AI systems other than those related to products. Therefore, the conformity assessment of such systems should be carried out as a general rule by the provider under its own responsibility.

Amendment 685
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 64
(64) Given the more extensive experience of professional pre-market certifiers in the field of product safety and the different nature of risks involved, it is appropriate to limit, at least in an initial phase of application of this Regulation, the scope of application of third-party conformity assessment for high-risk AI systems other than those related to products. Therefore, the conformity assessment of such systems should be carried out as a general rule by the provider under its own responsibility, with the only exception of AI systems intended to be used for the remote biometric identification of persons, for which the involvement of a notified body in the conformity assessment should be foreseen.

Amendment 686
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 65
deleted

Amendment 687
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Recital 65
(65) In order to carry out third-party conformity assessment for AI systems intended to be used for the remote biometric identification of persons, notified bodies should be designated under this Regulation by the national competent authorities, provided they are compliant with a set of requirements, notably on independence, competence, absence of conflicts of interests and minimum cybersecurity requirements.

Amendment 688
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 65
(65) In order to carry out third-party conformity assessments when so required, notified bodies should be designated under this Regulation by the national competent authorities, provided they are compliant with a set of requirements, notably on independence, competence and absence of conflicts of interests.

Amendment 689
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 65
(65) In order to carry out third-party conformity assessment for AI systems intended to be used for any of the use-cases listed in Annex III, notified bodies should be designated under this Regulation by the national competent authorities, provided they are compliant with a set of requirements, notably on independence, competence and absence of conflicts of interests.

Amendment 690
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 65 a (new)
(65 a) Third party conformity assessments for products listed in Annex III are essential as a precautionary measure and to ensure that trust is not lost in AI products, to the detriment of innovation, competition and growth. Due to the particularly sensitive nature of the tasks at hand, third party conformity assessments in the fields of law enforcement, asylum and immigration should be carried out by the market surveillance authority.

Amendment 691
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 66
(66) In line with the commonly established notion of substantial modification for products regulated by Union harmonisation legislation, it is appropriate that an AI system undergoes a new conformity assessment whenever a change occurs which may create a new or increased risk and significantly affect the compliance of the system with this Regulation or when the intended purpose of the system changes. If such a case materialises, the provider should follow a clear procedure with fixed deadlines, transparency requirements and reporting duties involving, where appropriate and applicable, external oversight by notified bodies or, where it is covered already under the relevant sectoral legislation, post market monitoring if that is needed. In addition, as regards AI systems which continue to ‘learn’ after being placed on the market or put into service (i.e. they automatically adapt how functions are carried out), it is necessary to provide rules establishing that changes to the algorithm and its performance that have been considered by the provider and assessed at the moment of the conformity assessment should not constitute a substantial modification. In addition, it should not be considered a substantial modification if the user trains an AI system. In this situation, the user should clearly delimit the effects that the learning can have for the AI system. The notion of substantial modification should be assessed in light of the essential requirements set in this Regulation and be left to the manufacturer to determine if a modification is deemed to be substantial.

Amendment 692
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 66
(66) In line with the commonly established notion of substantial modification for products regulated by Union harmonisation legislation, it is appropriate that an AI system undergoes a new conformity assessment whenever a change occurs which may affect the compliance of the system with this Regulation or when the intended purpose of the system changes.  In addition, as regards AI systems which continue to ‘learn’ after being placed on the market or put into service (i.e. they automatically adapt how functions are carried out), it is necessary that changes to the algorithm and its performance that constitute substantial modifications are subject to new conformity assessments, including in cases where the substantial modifications have been pre-determined by the provider and assessed at the moment of the initial conformity assessment.

Amendment 693
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 66
(66) In line with the commonly established notion of substantial modification for products regulated by Union harmonisation legislation, it is appropriate that an AI system undergoes a new conformity assessment whenever a change occurs which may affect the compliance of the system with this Regulation or when the intended purpose or reasonably foreseeable use of the system changes. In addition, as regards AI systems which continue to ‘learn’ after being placed on the market or put into service (i.e. they automatically adapt how functions are carried out), it is necessary to provide rules establishing that changes to the algorithm and its performance that have been pre-determined by the provider and assessed at the moment of the conformity assessment should not constitute a substantial modification.

Amendment 694
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Recital 66
(66) In line with the commonly established notion of substantial modification for products regulated by Union harmonisation legislation, it is appropriate that an AI system undergoes a new third party conformity assessment whenever a change occurs which may affect the compliance of the system with this Regulation or when the intended purpose of the system changes. In addition, as regards AI systems which continue to ‘learn’ after being placed on the market or put into service (i.e. they automatically adapt how functions are carried out), it is necessary to provide rules establishing that changes to the algorithm and its performance that have been pre-determined by the provider and assessed at the moment of the conformity assessment should not constitute a substantial modification.

Amendment 695
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 66
(66) In line with the commonly established notion of substantial modification for products regulated by Union harmonisation legislation, it is appropriate that an AI system undergoes a new conformity assessment whenever a change occurs which may affect the compliance of the system with this Regulation or when the foreseeable uses of the system changes. In addition, as regards AI systems which continue to ‘learn’ after being placed on the market or put into service (i.e. they automatically adapt how functions are carried out), it is necessary to provide rules establishing that changes to the algorithm and its performance that have been pre-determined by the provider and assessed at the moment of the conformity assessment should not constitute a substantial modification.

Amendment 696
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 66 a (new)
(66 a) To prevent any deterioration in the expected safety of the algorithm subject to significant changes independent of the providers control, a clearly developed plan to address such significant changes should be subject to oversight by the relevant competent authorities or notified bodies when it is already addressed in principle in the respective sectoral Union harmonisation legislation regarding post-market monitoring

Amendment 697
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 67
(67) High-risk AI systems should bear the CE marking to indicate their conformity with this Regulation so that they can move freely within the internal market. Member States should not create obstacles to the placing on the market or putting into service of high-risk AI systems that comply with the requirements laid down in this Regulation and bear the CE marking.

Amendment 698
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 68
deleted

Amendment 699
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 68
deleted

Amendment 700
ECR - European Conservatives and Reformists Group
Vincenzo Sofo, Kosma Złotowski
Recital 68
deleted

Amendment 701
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 68
deleted

Amendment 702
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 69
(69) In order to facilitate the work of the Commission and the Member States in the artificial intelligence field as well as to increase the transparency towards the public, providers and users of high-risk AI systems other than those related to products falling within the scope of relevant existing Union harmonisation legislation, should be required to register their high-risk AI system or the use thereof in a EU database, to be established and managed by the Commission. Certain AI systems listed in Article 52 (1b) and (2) and uses thereof shall be registered in the EU database. In order to facilitate this, users shall request information listed in Annex VIII point 2(g) from providers of AI systems. Any uses of AI systems by public authorities or on their behalf shall also be registered in the EU database. In order to facilitate this, public authorities shall request information listed in Annex VIII point 3(g) from providers of AI systems. The Commission should be the controller of that database, in accordance with Regulation (EU) 2018/1725 of the European Parliament and of the Council. In order to ensure the full functionality of the database, when deployed, the procedure for setting the database should include the elaboration of functional specifications by the Commission and an independent audit report. In order to maximise the availability and use of the database by the public, the database, including the information made available through it, should comply with requirements under the European Accessibility Act.

Amendment 703
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Pernando Barrena Arza, Kateřina Konečná, Cornelia Ernst, Elena Kountoura
Recital 69
(69) In order to facilitate the work of the Commission and the Member States in the artificial intelligence field as well as to increase the transparency towards the public, providers and users of high-risk AI systems other than those related to products falling within the scope of relevant existing Union harmonisation legislation, should be required to register their high-risk AI system or the use thereof in a EU database, to be established and managed by the Commission. The Commission should be the controller of that database, in accordance with Regulation (EU) 2018/1725 of the European Parliament and of the Council55 . In order to ensure the full functionality of the database, when deployed, the procedure for setting the database should include the elaboration of functional specifications by the Commission and an independent audit report. In order to maximise the availability and use of the database by the public, the database, including the information made available through it, should comply with requirements under the European Accessibility Act.' '55 Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation) (OJ L 119, 4.5.2016, p. 1).

Amendment 704
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 69
(69) In order to facilitate the work of the Commission and the Member States in the artificial intelligence field as well as to increase the transparency towards the public, both providers and users of high-risk AI systems other than those related to products falling within the scope of relevant existing Union harmonisation legislation, should be required to register their high-risk AI system in a EU database, to be established and managed by the Commission. Users who are public authorities or European Union institutions, bodies, offices and agencies or users acting on their behalf should also register in the EU database before putting into service or using any AI system. The Commission should be the controller of that database, in accordance with Regulation (EU) 2018/1725 of the European Parliament and of the Council55 . In order to ensure the full functionality of the database, when deployed, the procedure for setting the database should include the elaboration of functional specifications by the Commission and an independent audit report.' '55 Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation) (OJ L 119, 4.5.2016, p. 1).

Amendment 705
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 69
(69) In order to facilitate the work of the Commission and the Member States in the artificial intelligence field as well as to increase the transparency towards the public, providers and deployers of high-risk AI systems should be required to register their high-risk AI system in a EU database, to be established and managed by the Commission. The Commission should be the controller of that database, in accordance with Regulation (EU) 2018/1725 of the European Parliament and of the Council55 . In order to ensure the full functionality of the database, when deployed, the procedure for setting the database should include the elaboration of functional specifications by the Commission and an independent audit report.' '55 Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation) (OJ L 119, 4.5.2016, p. 1).

Amendment 706
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Recital 69
(69) In order to facilitate the work of the Commission and the Member States in the artificial intelligence field as well as to increase the transparency towards regulators, providers of high-risk AI systems other than those related to products falling within the scope of relevant existing Union harmonisation legislation, should be required to register their high-risk AI system in a EU database, to be established and managed by the Commission. The Commission should be the controller of that database, in accordance with Regulation (EU) 2018/1725 of the European Parliament and of the Council55 . In order to ensure the full functionality of the database, when deployed, the procedure for setting the database should include the elaboration of functional specifications by the Commission and an independent audit report.' '55 Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation) (OJ L 119, 4.5.2016, p. 1).

Amendment 707
EPP - Group of the European Peoples Party (Christian Democrats)
Geoffroy Didier
Recital 70
(70) Certain AI systems intended to interact with natural persons or to generate content may pose specific risks of impersonation, deception or EU principles and values irrespective of whether they qualify as high-risk or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems. In particular, natural persons should be notified that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use. Moreover, natural persons should be notified when they are exposed to an emotion recognition system or a biometric categorisation system. Such information and notifications should be provided in accessible formats for persons with disabilities. Further, users, who use an AI system to generate or manipulate image, audio, text, script, or video content that appreciably resembles existing persons, places or events and would falsely appear to a person to be authentic, should disclose that the content has been artificially created or manipulated by labelling the artificial intelligence output accordingly and disclosing its artificial origin. Besides, recommendation systems, in particular automated decision-making algorithms that disseminate and order cultural and creative content displayed to users, should be designed in such a way that their personalised suggestions are explainable and non-discriminatory. A clear explanation of the parameters used for the personalised suggestions should be easily accessible and understandable to the users. Natural persons should have a right to opt out of recommended and personalised services without affecting their right to use the core service.

Amendment 708
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Recital 70
(70) Certain AI systems intended to interact with natural persons or to generate content may pose specific risks of impersonation or deception irrespective of whether they qualify as high-risk or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems. In particular, natural persons should be notified that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use. Moreover, natural persons should be notified when they are exposed to an emotion recognition system or a biometric categorisation system. Such information and notifications should be provided in accessible formats for persons with disabilities. Further, users, who use an AI system to generate or manipulate image, audio or video content that appreciably resembles existing persons, places or events and would falsely appear to a person to be authentic, should disclose that the content has been artificially created or manipulated by labelling the artificial intelligence output accordingly and disclosing its artificial origin. Images generated through the use of AI in the creation of audio-visual content such as films and video game visuals should not be considered “deep fakes” as defined in Article 52 (3), which must be consistent with the principle of artistic freedom under the Charter of Fundamental Rights.

Amendment 709
Renew - Renew Europe Group
Morten Løkkegaard
Recital 70
(70) Certain AI systems intended to interact with natural persons or to generate content may pose specific risks of impersonation or deception irrespective of whether they qualify as high-risk or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems. In particular, natural persons should be notified that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use. Moreover, natural persons should be notified when they are exposed to an emotion recognition system or a biometric categorisation system. Such information and notifications should be provided in accessible formats for persons with disabilities. Further, users, who use an AI system to generate or manipulate image, audio or video content that appreciably resembles existing persons, places or events and would falsely appear to a person to be authentic, should disclose that the content has been artificially created or manipulated by labelling the artificial intelligence output accordingly and disclosing its artificial origin. Images generated through the use of AI in the creation of audiovisual content such as films and video game visuals should not be considered “deep fakes” as defined in Article 52 (3), which must be consistent with the principle of artistic freedom under the Charter of Fundamental Rights.

Amendment 710
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 70
(70) Certain AI systems intended to interact with natural persons or to generate content may pose specific risks of impersonation or deception irrespective of whether they qualify as high-risk or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems. In particular, natural persons should be notified that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use or where the content forms part of an evidently creative, satirical, artistic or fictional cinematographic, video game visuals or analogous work. Moreover, natural persons should be notified when they are exposed to an emotion recognition system or a biometric categorisation system. Such information and notifications should be provided in accessible formats for persons with disabilities. Further, users, who use an AI system to generate or manipulate image, audio or video content that appreciably resembles existing persons, places or events and would falsely appear to a person to be authentic, should disclose in an appropriate, clear and visible manner that the content has been artificially created or manipulated by labelling the artificial intelligence output accordingly and disclosing its artificial origin.

Amendment 711
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 70
(70) Certain AI systems intended to interact with natural persons or to generate content may pose specific risks of impersonation or deception irrespective of whether they qualify as high-risk or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems. In particular, natural persons should be notified that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use. Such information and notifications should be provided in accessible formats for persons with disabilities. Further, deployers, who use an AI system to generate or manipulate image, audio or video content that appreciably resembles existing persons, places or events and would falsely appear to a person to be authentic, should disclose that the content has been artificially created or manipulated by labelling the artificial intelligence output accordingly and disclosing its artificial origin. Additionally, the use of an AI system to generate or manipulate image, audio or video content that appreciably resembles a natural person should be permitted only when used for freedom of expression and artistic purposes and while respecting the limits of these purposes, or with the explicit consent of that person.

Amendment 712
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 70
(70) Certain AI systems intended to interact with natural persons or to generate content may pose specific risks of impersonation or deception irrespective of whether they qualify as high-risk or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems. In particular, natural persons should be notified that they are interacting with an AI system. Such information and notifications should be provided in accessible formats for persons with disabilities. Further, users, who use an AI system to generate or manipulate image, audio or video content that appreciably resembles existing persons, places or events and would falsely appear to a person to be authentic, should disclose that the content has been artificially created or manipulated by labelling the artificial intelligence output accordingly and disclosing its artificial origin.

Amendment 713
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Dita Charanzová, Andrus Ansip, Morten
Recital 70
(70) Certain AI systems intended to interact with natural persons or to generate content may pose specific risks of impersonation or deception irrespective of whether they qualify as high-risk or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems. In particular, natural persons should be notified that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use or where the content is part of an obviously artistic, creative or fictional cinematographic work. Moreover, natural persons should be notified when they are exposed to an emotion recognition system or a biometric categorisation system. Such information and notifications should be provided in accessible formats for persons with disabilities. Further, users, who use an AI system to generate or manipulate image, audio or video content that appreciably resembles existing persons, places or events and would falsely appear to a person to be authentic, should disclose, in an appropriate, clear and visible manner, that the content has been artificially created or manipulated by labelling the artificial intelligence output accordingly and disclosing its artificial origin.

Amendment 714
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Andreas Schieder, Alex Agius Saliba, Bettina Vollath, Tsvetelina
Recital 70
(70) Certain AI systems intended to interact with natural persons or to generate content may pose specific risks of impersonation or deception irrespective of whether they qualify as high-risk or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems. In particular, natural persons should be notified that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use. Such information and notifications should be provided in accessible formats for persons with disabilities. Further, users, who use an AI system to generate or manipulate image, audio or video content that appreciably resembles existing persons, places or events and would falsely appear to a person to be authentic, should disclose that the content has been artificially created or manipulated by labelling the artificial intelligence output accordingly and disclosing its artificial origin.

Amendment 715
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 70
(70) Certain AI systems intended to interact with natural persons or to generate content may pose specific risks of impersonation or deception irrespective of whether they qualify as high-risk or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems. In particular, natural persons should be notified that they are interacting with an AI system. Moreover, natural persons should be notified when they are exposed to an emotion recognition system or a biometric categorisation system. Such information and notifications should be provided in accessible formats for persons with disabilities. Further, AI systems used to generate or manipulate image, audio or video content that appreciably resembles existing persons, places or events and would falsely appear to a person to be authentic, should systematically contain an indication on the content generated that the content has been artificially created or manipulated, and users who use such AI systems or reuse the content generated should not be allowed to remove or conceal that indication.

Amendment 716
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 70 a (new)
(70 a) In light of the nature and complexity of the value chain for AI systems, it is essential to clarify the role of humans who may contribute to the development of AI systems covered by this Regulation, without being providers, no longer being providers or when other natural or legal persons have also become providers. Therefore, it is particularly important to clarify the legal situation when it comes to general purpose AI systems. Those AI system are able to perform generally applicable functions such as image/speech recognition, audio/video generation, pattern detection, question answering or translation in a plurality of contexts. Every natural or legal person can become a new provider by adapting a general purpose AI system, already placed on the market or put into service, to a specific intended purpose. Due to their peculiar nature and in order to ensure a fair sharing of responsibilities along the AI value chain, such general purpose AI system should however already be subject to proportionate and tailored requirements and obligations under this Regulation even before placing it on the Union market or putting it into service. The original provider of a general purpose AI system should furthermore cooperate, as appropriate, with the new provider to enable its compliance with the relevant obligations under this Regulation.

Amendment 717
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Eugen Jurzyca, Patryk Jaki, Adam Bielan
Recital 70 a (new)
(70 a) Suppliers of general purpose AI systems and, as relevant, other third parties that may supply other software tools and components, including pre-trained models and data, should cooperate, as appropriate, with providers that use such systems or components for an intended purpose under this Regulation in order to enable their compliance with applicable obligations under this Regulation and their cooperation, as appropriate, with the competent authorities established under this Regulation. In such cases, the provider may, by written agreement, specify the information or other assistance that such supplier will furnish in order to enable the provider to comply with its obligations herein.

Amendment 718
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 71
(71) Artificial intelligence is a rapidly developing family of technologies that requires novel forms of regulatory oversight and a safe and fully controlled space for experimentation, while ensuring responsible innovation and integration of appropriate ethical safeguards and risk mitigation measures. To ensure a legal framework that is innovation-friendly, future-proof and resilient to disruption, national competent authorities from one or more Member States should be encouraged to establish artificial intelligence regulatory sandboxes to facilitate the development and testing of innovative AI systems under strict regulatory oversight before these systems are placed on the market or otherwise put into service. Regulatory sandboxes involving activities that may impact health, safety and fundamental rights, democracy and the rule of law or the environment should be developed in accordance with redress-by-design principles. Any significant risks identified during the development and testing of such systems should result in immediate mitigation and, failing that, in the suspension of the development and testing process until such mitigation takes place. The legal basis of such sandboxes should comply with the requirements established in the existing data protection framework and should be consistent with the Charter of fundamental rights of the European Union.

Amendment 719
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 71
(71) Artificial intelligence is a rapidly developing family of technologies that benefits from clear rules and legal certainty, and requires regulatory oversight. In order to fulfill its potential to benefit society, a safe space for controlled experimentation, ensuring respect for Union law and the protection of fundamental rights, can help foster responsible innovation and integration of appropriate safeguards and risk mitigation measures. To ensure a legal framework that promotes sustainable innovation, is future-proof and resilient to disruption, national competent authorities from one or more Member States should be encouraged to cooperate in establishing artificial intelligence regulatory sandboxes to facilitate the development and testing of AI systems under strict regulatory oversight before these systems are placed on the market or otherwise put into service.

Amendment 720
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 71
(71) Artificial intelligence is a rapidly developing family of technologies that requires novel forms of regulatory oversight and a safe space for experimentation, while ensuring responsible innovation and integration of appropriate safeguards and risk mitigation measures. To ensure a legal framework that is innovation-friendly, future-proof and resilient to disruption, Member States should establish artificial intelligence regulatory sandboxes to facilitate the development and testing of innovative AI systems under strict regulatory oversight before these systems are placed on the market or otherwise put into service. Member States should ensure that the regulatory sandboxes have the adequate financial and human resources for their proper functioning.

Amendment 721
EPP - Group of the European Peoples Party (Christian Democrats)
Karlo Ressler
Recital 71
(71) Artificial intelligence is a rapidly developing family of technologies that requires novel forms of regulatory oversight and a safe space for experimentation, while ensuring responsible innovation and integration of appropriate safeguards and risk mitigation measures. To ensure a legal framework that is innovation-friendly, future-proof and resilient to disruption, national competent authorities from one or more Member States should establish artificial intelligence regulatory sandboxes to facilitate the development and testing of innovative AI systems under strict regulatory oversight before these systems are placed on the market or otherwise put into service. All other relevant actors should be encouraged to do so as well.

Amendment 722
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 71
(71) Artificial intelligence is a rapidly developing family of technologies that requires novel forms of regulatory oversight and a safe space for experimentation, while ensuring responsible innovation and integration of appropriate safeguards and risk mitigation measures. To ensure a legal framework that safeguards fundamental rights and is innovation-friendly, future-proof and resilient to disruption, national supervisory authorities from one or more Member States could establish artificial intelligence regulatory sandboxes to facilitate the development and testing of innovative AI systems under strict regulatory oversight before these systems are placed on the market or otherwise put into service.

Amendment 723
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 71
(71) Artificial intelligence is a rapidly developing family of technologies that requires novel forms of regulatory oversight and a safe space for experimentation, while ensuring responsible innovation and integration of appropriate safeguards and risk mitigation measures. To ensure a legal framework that is innovation-friendly, future-proof and resilient to disruption, national competent authorities from one or more Member States should establish artificial intelligence regulatory sandboxes to facilitate the development and testing of innovative AI systems under strict regulatory oversight before these systems are placed on the market or otherwise put into service.

Amendment 724
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 72
(72) The objectives of the regulatory sandboxes should be to foster AI innovation for the benefit of society by establishing a controlled experimentation and testing environment in the development and pre-marketing phase with a view to ensuring respect for and protection of fundamental rights, compliance of the innovative AI systems with this Regulation and other relevant Union and Member States legislation; to enhance legal certainty for innovators and the competent authorities’ oversight and understanding of the opportunities, emerging risks and the impacts of AI use, and to accelerate access to markets, including by removing barriers for small and medium enterprises (SMEs) and start-ups. To ensure uniform implementation across the Union and economies of scale, it is appropriate to establish common rules for the regulatory sandboxes’ implementation and a framework for cooperation between the relevant authorities involved in the supervision of the sandboxes. Personal data that had originally been collected for different purposes should be processed in a sandbox only under specified conditions and within the limits of Regulation (EU) 2016/679. Such further processing should be considered as for statistical purposes in the meaning of Article 5(1)(b) of that Regulation. Participants in the sandbox should ensure appropriate safeguards and cooperate with the competent authorities, including by following their guidance and acting expeditiously and in good faith to mitigate any risks to safety and fundamental rights that may arise during the development and experimentation in the sandbox. The conduct of the participants in the sandbox should be taken into account when competent authorities decide over the suspending or banning them from participating in the sandbox, or whether to impose an administrative fine under Article 83(2) of Regulation 2016/679 and Article 57 of Directive 2016/680. This Regulation should also provide the legal basis for the use of data protected by intellectual property or trade-secrets for developing certain AI systems in the public interest within the AI regulatory sandbox, without prejudice to Directive (EU) 2019/790 and to Directive (EU) 2016/943. The authorised use of data protected by intellectual property or trade-secrets under Article 54 of this Regulation should be covered by Article 4 of Directive (EU) 2019/790.

Amendment 725
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 72
(72) The objectives of the regulatory sandboxes should be to foster AI innovation by establishing a strictly controlled experimentation and testing environment in the development and pre-marketing phase with a view to ensuring compliance of the innovative AI systems with this Regulation and other relevant Union and Member States legislation, as well as with the Charter of Fundamental Rights of the European Union and the General Data Protection Regulation; to enhance legal certainty for innovators and the competent authorities’ oversight and understanding of the opportunities, emerging risks and the impacts of AI use, to provide safeguards needed to build trust and reliance on AI systems, to accelerate access to markets, including by removing barriers for the public sector, small and medium enterprises (SMEs) and start-ups; and to contribute to the development of ethical, socially responsible and environmentally sustainable AI systems. To ensure uniform implementation across the Union and economies of scale, it is appropriate to establish common rules for the regulatory sandboxes’ implementation and a framework for cooperation between the relevant authorities involved in the supervision of the sandboxes. This Regulation should provide the legal basis for the use of personal data collected for other purposes for developing certain AI systems in the public interest within the AI regulatory sandbox, in line with Article 6(4) of Regulation (EU) 2016/679, and Article 6 of Regulation (EU) 2018/1725, and without prejudice to Article 4(2) of Directive (EU) 2016/680. Participants in the sandbox should ensure appropriate safeguards and cooperate with the competent authorities, including by following their guidance and acting expeditiously and in good faith to mitigate any high-risks to safety and fundamental rights that may arise during the development and experimentation in the sandbox. The conduct of the participants in the sandbox should be taken into account when competent authorities decide whether to impose an administrative fine under Article 83(2) of Regulation 2016/679 and Article 57 of Directive 2016/680.

Amendment 726
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 72
(72) The objectives of the regulatory sandboxes should be to foster AI innovation by establishing a controlled experimentation and testing environment in the development and pre-marketing phase with a view to ensuring compliance of the innovative AI systems with this Regulation and other relevant Union and Member States legislation; to enhance legal certainty for innovators and the competent authorities’ oversight and understanding of the opportunities, emerging risks and the impacts of AI use, and to accelerate access to markets, including by removing barriers for small and medium enterprises (SMEs) and start-ups. To ensure uniform implementation across the Union and economies of scale, it is appropriate to establish common rules for the regulatory sandboxes’ implementation and a framework for cooperation between the relevant authorities involved in the supervision of the sandboxes. Participants in the sandbox should ensure appropriate safeguards and cooperate with the competent authorities, including by following their guidance and acting expeditiously and in good faith to mitigate any high-risks to safety and fundamental rights that may arise during the development and experimentation in the sandbox. The conduct of the participants in the sandbox should be taken into account when competent authorities decide whether to impose an administrative fine under Article 83(2) of Regulation 2016/679 and Article 57 of Directive 2016/680.

Amendment 727
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 72
(72) The objectives of the regulatory sandboxes should be to foster AI innovation, while safeguarding fundamental rights and the values enshrined in Article 2 TFEU, by establishing a controlled experimentation and testing environment in the development and pre-marketing phase with a view to ensuring compliance of the innovative AI systems with this Regulation and other relevant Union and Member States legislation; to enhance legal certainty for innovators and the national supervisory authorities’ oversight and understanding of the opportunities, emerging risks and the impacts of AI use, and to accelerate access to markets, including by removing barriers for small and medium enterprises (SMEs) and start-ups. To ensure uniform implementation across the Union and economies of scale, it is appropriate to establish common rules for the regulatory sandboxes’ implementation and a framework for cooperation between the national supervisory authorities involved in the supervision of the sandboxes. Participants in the sandbox should ensure appropriate safeguards and cooperate with the national supervisory authorities, including by following their guidance and acting expeditiously and in good faith to mitigate any high-risks to safety and fundamental rights that may arise during the development and experimentation in the sandbox. The conduct of the participants in the sandbox should be taken into account when competent authorities decide whether to impose an administrative fine under Article 83(2) of Regulation 2016/679 and Article 57 of Directive 2016/680.

Amendment 728
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 72 a (new)
(72 a) To ensure that Artificial Intelligence leads to socially and environmentally beneficial outcomes, Member States should support and promote research and development of AI in support of socially and environmentally beneficial outcomes by allocating sufficient resources, including public and Union funding, and giving priority access to regulatory sandboxes to projects led by civil society. Such projects should be based on the principle of interdisciplinary cooperation between AI developers, experts on inequality and non-discrimination, accessibility, consumer, environmental, and digital rights, as well as academics.

Amendment 729
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 73
(73) In order to promote and protect innovation, it is important that the interests of SME providers and users of AI systems are taken into particular account. To this objective, AI solutions and services designed to combat fraud and protect consumers against fraudulent activities should not be considered high-risk, nor be prohibited. As a matter of substantial public interest, it is vital that this Regulation does not undermine the incentive of industry to create and roll out solutions designed to combat fraud across the Union. Furthermore, Member States should develop initiatives, which are targeted at those operators, including on awareness raising and information communication. Moreover, the specific interests and needs of SME providers shall be taken into account when Notified Bodies set conformity assessment fees. Translation costs related to mandatory documentation and communication with authorities may constitute a significant cost for providers and other operators, notably those of a smaller scale. Member States should possibly ensure that one of the languages determined and accepted by them for relevant providers’ documentation and for communication with operators is one which is broadly understood by the largest possible number of cross-border users. Member States should also be encouraged to do the same for small and medium enterprises, which may sometimes lack the requisite administrative and legal resources to ensure proper understanding and compliance with the provisions under this act. In the event that Member States request it, the Commission may also provide assistance in this regard.

Amendment 730
EPP - Group of the European Peoples Party (Christian Democrats)
Marion Walsmann
Recital 73
(73) In order to promote and protect innovation, it is important that the interests of small-scale providers, like SMEs, micro-enterprises and users of AI systems are taken into particular account. SMEs are the backbone of the European economy and they face more challenges adapting to new legislations therefore measures should be foreseen to support them to cope with the new obligations or to exclude them from certain requirements. To this objective, Member States should develop initiatives, which are targeted at those operators, including on awareness raising and information communication. Moreover, the specific interests and needs of small-scale providers shall be taken into account when Notified Bodies set conformity assessment fees. Translation costs related to mandatory documentation and communication with authorities may constitute a significant cost for providers and other operators, notably those of a smaller scale. Member States should ensure that one of the languages determined and accepted by them for relevant providers’ documentation and for communication with operators is one which is broadly understood by the largest possible number of cross-border users.

Amendment 731
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 73
(73) In order to promote and protect innovation, it is important that the interests of small-scale providers and users of AI systems are taken into particular account. To this objective, Member States should develop initiatives, which are targeted at those operators, including on awareness raising and information communication. Moreover, the specific interests and needs of small-scale providers shall be taken into account when Notified Bodies set conformity assessment fees. Translation costs related to mandatory documentation and communication with authorities may constitute a significant cost for providers and other operators, notably those of a smaller scale.

Amendment 732
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 73
(73) In order to promote and protect innovation, it is important that the interests of small-scale providers and deployers of AI systems are taken into particular account. To this objective, Member States should develop initiatives, which are targeted at those operators, including on awareness raising and information communication, and including the cooperation across borders. Moreover, the specific interests and needs of small-scale providers shall be taken into account when Notified Bodies set conformity assessment fees. Translation costs related to mandatory documentation and communication with authorities may constitute a significant cost for providers and other operators, notably those of a smaller scale. Member States should ensure that one of the languages determined and accepted by them for relevant providers’ documentation and for communication with operators is one which is broadly understood by the largest possible number of cross-border deployers.

Amendment 733
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Dita Charanzová, Andrus Ansip, Morten
Recital 73
(73) In order to promote and protect innovation, it is important that the interests of start-ups and SME providers and users of AI systems are taken into particular account. To this objective, Member States should develop initiatives, which are targeted at those operators, including on awareness raising and information communication. Moreover, the specific interests and needs of SMEs and start-ups shall be taken into account when Notified Bodies set conformity assessment fees. Translation costs related to mandatory documentation and communication with authorities may constitute a significant cost for providers and other operators, notably those of a smaller scale. Member States should possibly ensure that one of the languages determined and accepted by them for relevant providers’ documentation and for communication with operators is one which is broadly understood by the largest possible number of cross-border users.

Amendment 734
ECR - European Conservatives and Reformists Group
Kosma Złotowski, Patryk Jaki, Adam Bielan
Recital 73 a (new)
(73 a) AI solutions and services designed to combat fraud and protect consumers against fraudulent activities should not be considered high risk, nor prohibited. As a matter of substantial public interest, it is vital that this Regulation does not undermine the incentive of the industry to create and roll out solutions designed to combat fraud across the European Union.

Amendment 735
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 74
(74) In order to minimise the risks to implementation resulting from lack of knowledge and expertise in the market as well as to facilitate compliance of providers and notified bodies with their obligations under this Regulation, Member States should utilise existing dedicated channels for communication with SMEs and start-ups. Such existing channels could include but are not limited to ENISA’s Computer Security Incident Response Teams, National data protection agencies, the AI-on demand platform, the European Digital Innovation Hubs and the Testing and Experimentation Facilities established by the Commission and the Member States at national or EU level. Within their respective mission and fields of competence, they may provide in particular technical and scientific support to providers and notified bodies.

Amendment 736
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 74
(74) In order to minimise the risks to implementation resulting from lack of knowledge and expertise in the market as well as to facilitate compliance of providers and notified bodies with their obligations under this Regulation, the AI-on demand platform, the European Digital Innovation Hubs and the Testing and Experimentation Facilities established by the Commission and the Member States at national or EU level, as well as the ENISA, the EU Agency for Fundamental Rights, EIGE, and the European Data Protection Supervisor should constantly contribute to the implementation of this Regulation. Within their respective mission and fields of competence, they may provide in particular technical and scientific support to providers and notified bodies.

Amendment 737
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 74
(74) In order to minimise the risks to implementation resulting from lack of knowledge and expertise in the market as well as to facilitate compliance of providers and notified bodies with their obligations under this Regulation, the AI-on demand platform, the European Digital Innovation Hubs and the Testing and Experimentation Facilities established by the Commission and the Member States at national or EU level should contribute to the implementation of this Regulation. Within their respective mission and fields of competence, they may provide in particular technical and scientific support to providers and notified bodies.

Amendment 738
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 76
(76) In order to facilitate a smooth, effective and consistent implementation of this Regulation an independent European Artificial Intelligence Board should be established. The Board should be responsible for a number of tasks, including issuing opinions, recommendations, advice or guidance on matters related to the implementation of this Regulation, including on technical specifications or existing standards regarding the requirements established in this Regulation and providing advice to and assisting the Commission on specific questions related to artificial intelligence, including on possible amendments of the annexes, in particular the annex listing high-risk AI systems. To contribute to the effective and harmonised enforcement of this Regulation, the Board should also be able to adopt binding decisions for the settlement of cases involving two or more Member States in which the national supervisory authorities are in disagreement or when it is not clear who the lead national supervisory authority is. The Board should also be able to adopt a binding decision in those cases when a national supervisory authority of a Member State finds that although an AI system is in compliance with this Regulation, it presents a risk to the compliance with obligations under Union or national law intended to protect fundamental rights, the principles of Article 4a, the values as enshrined in Article 2 TEU, the environment, or to other aspects of public interest protection.

Amendment 739
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona Strugariu, Dragoş Pîslaru, Lucia Ďuriš Nicholsonová, Irena Joveva, Karen Melchior, Alin Mituța
Recital 76
(76) In order to ensure an effective and harmonised implementation of this Regulation, to achieve a high level of trustworthiness and of protection of health, safety, fundamental rights and the Union values enshrined in Article 2 TEU across the Union with regards to artificial intelligence systems, to actively support Member States, Union institutions, bodies, offices and agencies in matters pertaining to this Regulation, to reduce the fragmentation of the internal market, and to increase the uptake of artificial intelligence throughout the Union, an European Union Artificial Intelligence Office should be established. The AI Office should have legal personality, should act in full independence, and should be adequately funded and staffed. Member States should provide the strategic direction and control of the AI Office through the management board of the AI Office, alongside the Commission, the EDPS, and the FRA. An executive director should be responsible for the coordination of the AI Office’s operations and for the implementation of its work programme. Industry,start-ups and SMEs, and civil society should formally participate in the work of the AI Office through an advisory forum that should ensure varied stakeholder representation and should advise the AI Office on matters pertaining to this Regulation.

Amendment 740
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 76
(76) In order to facilitate a smooth, effective and harmonised implementation of this Regulation a European Artificial Intelligence Board should be established. The Board should be independent and responsible for a number of advisory and enforcement tasks, including issuing decisions, opinions, recommendations, advice or guidance on matters related to the implementation of this Regulation, including on technical specifications or existing standards regarding the requirements established in this Regulation and providing advice to and assisting the Commission on specific questions related to artificial intelligence. In order to ensure a consistent and appropriate enforcement vis-à-vis very large undertakings, the Board should be the supervisory authority for undertakings that meet the criteria of 'community dimension' as defined in Article 1(3) of Regulation 139/200 (Merger Regulation). The Board should have a secretariat with sufficient resources and expertise to be able to fulfil its role. In this respect, the secretariat should establish a European Centre of Excellence for Artificial Intelligence (ECE-AI).

Amendment 741
Renew - Renew Europe Group
Svenja Hahn, Dragoş Tudorache, Nicola Beer, Karen Melchior, Morten Løkkegaard,
Recital 76 a (new)
(76) In order to facilitate a smooth, effective and harmonised implementation of this Regulation a European Artificial Intelligence Board should be established as a body of the Union and should have legal personality. The Board should be responsible for a number of advisory tasks, including issuing opinions, recommendations, advice or guidance on matters related to the implementation of this Regulation, including on technical specifications or existing standards regarding the requirements established in this Regulation and providing advice to and assisting the Commission and the national competent authorities on specific questions related to artificial intelligence.

Amendment 742
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Radosław Sikorski,
Recital 76 a (new)
(76 a) An AI advisory council(‘the Advisory Council’) should be established as a sub-group of the Board consisting of relevant representatives from industry, research, academia, civil society, standardisation organisations, relevant common European data spaces, and other relevant stakeholders, including social partners, where appropriate depending on the subject matter discussed, representing all Member States to maintain geographical balance. The Advisory Council should support the work of the Board by providing advice relating to the tasks of the Board. The Advisory Council should nominate a representative to attend meetings of the Board and to participate in its work.

Amendment 743
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 76 a (new)
(76 a) The Commission should re-establish the High Level Expert Group or a similar body with a new and balanced membership comprising an equal number of experts from SMEs and start-ups, large enterprises, academia and Research, and civil society. This new High Level Expert Group should not only act as advisory body to the Commission but also to the Board. At least every quarter, the new High Level Expert Group must have the chance to share its practical and technical expertise in a special meeting with the Board.

Amendment 744
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 77
(77) Member States hold a key role in the application and enforcement of this Regulation. In this respect, each Member State should designate one or more national competent authorities for the purpose of supervising the application and implementation of this Regulation. In order to increase organisation efficiency on the side of Member States and to set an official point of contact vis-à-vis the public and other counterparts at Member State and Union levels, in each Member State one national authority should be designated as national supervisory authority. In order to avoid duplication and combine expertise and competences, this should be a supervisory authority established under Regulation (EU) 2016/679 (General Data Protection Regulation). The supervisory authorities should have sufficient investigative and corrective powers.

Amendment 745
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 77
(77) Each Member State should establish or designate a single national supervisory authority to act as the lead authority and be responsible for ensuring the effective coordination between the national competent authorities regarding the implementation of this Regulation. It should also represent its Member State on the Board. Each national supervisory authority should act with complete independence in performing its tasks and exercising its powers in accordance with this Regulation.

Amendment 746
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 77 a (new)
(77 a) The national supervisory authorities should monitor the application of the provisions pursuant to this Regulation and contribute to its consistent application throughout the Union. For that purpose, the national supervisory authorities should cooperate with each other, with the market surveillance authorities and with the Commission, without the need for any agreement between Member States on the provision of mutual assistance or on such cooperation.

Amendment 747
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 78
(78) In order to ensure that providers of high-risk AI systems can take into account the experience on the use of high-risk AI systems for improving their systems and the design and development process or can take any possible corrective action in a timely manner, all providers should have a post-market monitoring system in place. In view of the sensitive nature of high-risk AI systems, this post-market monitoring system should not be able to automatically send data or error reports to the supplier via the AI system. This system is also key to ensure that the possible risks emerging from AI systems which continue to ‘learn’ after being placed on the market or put into service can be more efficiently and timely addressed. In this context, providers should also be required to have a system in place to report to the relevant authorities any serious incidents or any breaches to national and Union law protecting fundamental rights resulting from the use of their AI systems.

Amendment 748
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 78
(78) In order to ensure that providers of high-risk AI systems can take into account the experience on the use of high-risk AI systems for improving their systems and the design and development process or can take any possible corrective action in a timely manner, all providers should have a post-market monitoring system in place. This system is also key to ensure that the possible risks emerging from AI systems which continue to ‘learn’ after being placed on the market or put into service can be more efficiently and timely addressed. In this context, providers should also be required to have a system in place to report to the relevant authorities any serious incidents or any breaches to national and Union law, including those protecting fundamental rights and consumer rights, resulting from the use of their AI systems.

Amendment 749
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 78
(78) In order to ensure that providers of high-risk AI systems can take into account the experience on the use of high-risk AI systems for improving their systems and the design and development process or can take any possible corrective action in a timely manner, all providers should have a post-market monitoring system in place. This system is also key to ensure that the possible risks emerging from AI systems which continue to ‘learn’ after being placed on the market or put into service can be more efficiently and timely addressed. In this context, providers should also be required to report to the relevant authorities any serious incidents or any breaches to national and Union law protecting fundamental rights resulting from the use of their AI systems.

Amendment 750
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 79
(79) In order to ensure an appropriate and effective enforcement of the requirements and obligations set out by this Regulation, which is Union harmonisation legislation, the system of market surveillance and compliance of products established by Regulation (EU) 2019/1020 should apply in its entirety. Where necessary for their mandate, national public authorities or bodies, which supervise the application of Union law protecting fundamental rights, including equality bodies, should also have access to any documentation created under this Regulation. A reasonable suspicion of breach of fundamental rights, which may arise from a complaint from an individual or a notification of a breach submitted by a civil society organisation, should be deemed as a sufficient reason for the commencement of an evaluation of an AI system at national level.

Amendment 751
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 79 a (new)
(79 a) As the rights and freedoms of individuals can be seriously undermined by AI systems, it is essential that affected individuals have meaningful access to reporting and redress mechanisms. They should be able to report infringements of this Regulation to their national supervisory authority and have the right to be heard and to be informed about the outcome of their complaint and the right to a timely decision. In addition, they should have the right to an effective remedy against competent authorities who fail to enforce these rights and the right to redress. Where applicable, deployers should provide internal complaints mechanisms to be used by affected individuals and should be liable for pecuniary and non-pecuniary damages in cases of breaches of individuals’ or groups’ rights. Collective representation of affected individuals must be possible.

Amendment 752
ID - Identity and Democracy Group
Alessandra Basso, Marco Campomenosi, Isabella Tovaglieri, Mara Bizzotto, Silvia
Recital 80
(80) Union legislation on financial services includes internal governance and risk management rules and requirements which are applicable to regulated financial institutions in the course of provision of those services, including when they make use of AI systems. In order to ensure coherent application and enforcement of the obligations under this Regulation and relevant rules and requirements of the Union financial services legislation, the authorities responsible for the supervision and enforcement of the financial services legislation, including where applicable the European Central Bank, should be designated as competent authorities for the purpose of supervising the implementation of this Regulation, including for market surveillance activities, as regards AI systems provided or used by regulated and supervised financial institutions. To further enhance the consistency between this Regulation and the rules applicable to credit institutions regulated under Directive 2013/36/EU of the European Parliament and of the Council56 , it is also appropriate to integrate the conformity assessment procedure and some of the providers’ procedural obligations in relation to risk management, post marketing monitoring and documentation into the existing obligations and procedures under Directive 2013/36/EU. In order to avoid overlaps, limited derogations should also be envisaged in relation to the quality management system of providers and the monitoring obligation placed on users of high-risk AI systems to the extent that these apply to credit institutions regulated by Directive 2013/36/EU. With regard to use case 5(b) in Annex III, areas covered by this Regulation relate to those outlined in Article 1(a). All other procedures relating to creditworthiness assessment are covered by the Directive of the European Parliament and of the Council on consumer credits .' '56 Directive 2013/36/EU of the European Parliament and of the Council of 26 June 2013 on access to the activity of credit institutions and the prudential supervision of credit institutions and investment firms, amending Directive 2002/87/EC and repealing Directives 2006/48/EC and 2006/49/EC (OJ L 176, 27.6.2013, p. 338).

Amendment 753
EPP - Group of the European Peoples Party (Christian Democrats)
Andrea Caroppo, Salvatore De Meo
Recital 80
(80) Union legislation on financial services includes internal governance and risk management rules and requirements which are applicable to regulated financial institutions in the course of provision of those services, including when they make use of AI systems. In order to ensure coherent application and enforcement of the obligations under this Regulation and relevant rules and requirements of the Union financial services legislation, the authorities responsible for the supervision and enforcement of the financial services legislation, including where applicable the European Central Bank, should be designated as competent authorities for the purpose of supervising the implementation of this Regulation, including for market surveillance activities, as regards AI systems provided or used by regulated and supervised financial institutions. To further enhance the consistency between this Regulation and the rules applicable to credit institutions regulated under Directive 2013/36/EU of the European Parliament and of the Council56 , it is also appropriate to integrate the conformity assessment procedure and some of the providers’ procedural obligations in relation to risk management, post marketing monitoring and documentation into the existing obligations and procedures under Directive 2013/36/EU. In order to avoid overlaps, limited derogations should also be envisaged in relation to the quality management system of providers and the monitoring obligation placed on users of high-risk AI systems to the extent that these apply to credit institutions regulated by Directive 2013/36/EU. With regard to use case 5(b) in Annex III, areas covered by this Regulation relate to those outlined in Article 1(a). All other procedures relating to creditworthiness assessment are covered by the Directive of the European Parliament and of the Council on consumer credits.' '56 Directive 2013/36/EU of the European Parliament and of the Council of 26 June 2013 on access to the activity of credit institutions and the prudential supervision of credit institutions and investment firms, amending Directive 2002/87/EC and repealing Directives 2006/48/EC and 2006/49/EC (OJ L 176, 27.6.2013, p. 338).

Amendment 754
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 80
(80) Union legislation on financial services includes internal governance and risk management rules and requirements which are applicable to regulated financial institutions in the course of provision of those services, including when they make use of AI systems. In order to ensure coherent application and enforcement of the obligations under this Regulation and relevant rules and requirements of the Union financial services legislation, the authorities responsible for the supervision and enforcement of the financial services legislation, including where applicable the European Central Bank, should be designated as competent authorities for the purpose of supervising the implementation of this Regulation, including for market surveillance activities, as regards AI systems provided or used by regulated and supervised financial institutions. To further enhance the consistency between this Regulation and the rules applicable to credit institutions regulated under Directive 2013/36/EU of the European Parliament and of the Council56 , it is also appropriate to integrate the conformity assessment procedure and some of the providers’ procedural obligations in relation to risk management, post marketing monitoring and documentation into the existing obligations and procedures under Directive 2013/36/EU.' '56 Directive 2013/36/EU of the European Parliament and of the Council of 26 June 2013 on access to the activity of credit institutions and the prudential supervision of credit institutions and investment firms, amending Directive 2002/87/EC and repealing Directives 2006/48/EC and 2006/49/EC (OJ L 176, 27.6.2013, p. 338).

Amendment 755
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune, Eva Maydell
Recital 80
(80) Union legislation on financial services includes internal governance and risk management rules and requirements which are applicable to regulated financial institutions in the course of provision of those services, including when they make use of AI systems. In order to ensure coherent application and enforcement of the obligations under this Regulation and relevant rules and requirements of the Union financial services legislation, the competent authorities responsible for the supervision and enforcement of the financial services legislation, including where applicable the competent authorities as defined in Directive 2013/36/EU of the European Parliament and of the Council, should be designated as competent authorities for the purpose of supervising the implementation of this Regulation, excluding market surveillance activities, as regards AI systems provided or used by regulated and supervised financial institutions. To further enhance the consistency between this Regulation and the rules applicable to credit institutions regulated under Directive 2013/36/EU of the European Parliament and of the Council56, it is also appropriate to integrate certain aspects of the conformity assessment procedure and some of the providers’ procedural obligations in relation to risk management, post marketing monitoring and documentation into the existing obligations and procedures under Directive 2013/36/EU. In order to avoid overlaps, limited derogations should also be envisaged in relation to the quality management system of providers and the monitoring obligation placed on users of high-risk AI systems to the extent that these apply to credit institutions regulated by Directive 2013/36/EU.' '56 Directive 2013/36/EU of the European Parliament and of the Council of 26 June 2013 on access to the activity of credit institutions and the prudential supervision of credit institutions and investment firms, amending Directive 2002/87/EC and repealing Directives 2006/48/EC and 2006/49/EC (OJ L 176, 27.6.2013, p. 338).

Amendment 756
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 80 a (new)
(80 a) Where the national market surveillance authority has not taken measures against an infringement to this Regulation, the Commission should be in possession of all the necessary resources, in terms of staffing, expertise, and financial means, for the performance of its tasks instead of the national market surveillance authority under this Regulation. In order to ensure the availability of the resources necessary for the adequate investigation and enforcement measures that the Commission could undertake under this Regulation, the Commission should charge fees on national market surveillance authorities, the level of which should be established on a case-by-case basis. The overall amount of fees charged should be established on the basis of the overall amount of the costs incurred by the Commission to exercise its investigation and enforcement powers under this Regulation. Such an amount should include costs relating to the exercise of the specific powers and tasks connected to Chapter 4 of Title VIII of this Regulation. The external assigned revenues resulting from the fees could be used to finance additional human resources, such as contractual agents and seconded national experts, and other expenditure related to the fulfilment of these tasks entrusted to the Commission by this Regulation.

Amendment 757
Renew - Renew Europe Group
Morten Løkkegaard
Recital 81
(81) The development of AI systems other than high-risk AI systems in a safe, trustworthy, and ethical manner may lead to a larger uptake of trustworthy artificial intelligence in the Union. Providers of non-high-risk AI systems should be encouraged to create voluntary market-based codes of conduct based on the requirements applicable to high-risk AI systems, adapted in light of the intended purpose of the systems and the lower risk involved. Providers should also be encouraged to apply on a voluntary basis additional requirements related, for example, to environmental sustainability, accessibility to persons with disability, stakeholders’ participation in the design and development of AI systems, and diversity of the development teams. Compliance with the codes of conduct can be signaled through a label, where relevant. The Digital Europe Programme should support the development and uptake of these codes of conduct. The Commission may develop initiatives, including of a sectorial nature, to facilitate the lowering of technical barriers hindering cross-border exchange of data for AI development, including on data access infrastructure, semantic and technical interoperability of different types of data.

Amendment 758
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Christel Schaldemose
Recital 81
(81) The development of AI systems other than high-risk AI systems in a safe, trustworthy and ethical manner may lead to a larger uptake of trustworthy artificial intelligence in the Union. Providers of non-high-risk AI systems should be encouraged to create voluntary market-based codes of conduct based on the requirements applicable to high-risk AI systems, adapted in light of the intended purpose of the systems and the lower risk involved. Providers should also be encouraged to apply on a voluntary basis additional requirements related, for example, to environmental sustainability, accessibility to persons with disability, stakeholders’ participation in the design and development of AI systems, and diversity of the development teams. Compliance with the codes of conduct can be signaled through a label, where relevant. The Digital Europe Programme should support the development and uptake of these codes of conduct. The Commission may develop initiatives, including of a sectorial nature, to facilitate the lowering of technical barriers hindering cross-border exchange of data for AI development, including on data access infrastructure, semantic and technical interoperability of different types of data.

Amendment 759
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 81
(81) The development of AI systems other than high-risk AI systems in accordance with the requirements of this Regulation may lead to a larger uptake of trustworthy artificial intelligence in the Union. Providers of non-high-risk AI systems should be encouraged to create codes of conduct intended to foster the voluntary application of the mandatory requirements applicable to high-risk AI systems or risk-appropriate codes of conduct that sufficiently increase trust in the underlying technology that is not high-risk. Providers should also be encouraged to apply on a voluntary basis additional requirements related, for example, to environmental sustainability, accessibility to persons with disability, stakeholders’ participation in the design and development of AI systems, and diversity of the development teams. The Commission may develop initiatives, including of a sectorial nature, to facilitate the lowering of technical barriers hindering cross-border exchange of data for AI development, including on data access infrastructure, semantic and technical interoperability of different types of data.

Amendment 760
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 81
(81) The development of AI systems other than high-risk AI systems in accordance with the requirements of this Regulation may lead to a larger uptake of trustworthy artificial intelligence in the Union. Providers of non-high-risk AI systems should be encouraged to create codes of conduct intended to foster the voluntary application of the mandatory requirements applicable to high-risk AI systems. Providers should also be encouraged to apply on a voluntary basis additional requirements related, for example, to energy efficiency, resource use and waste production, and environmental sustainability, accessibility to persons with disability, stakeholders’ participation in the design and development of AI systems, and diversity, equal representation and gender-balance of the development teams. The Commission may develop initiatives, including of a sectorial nature, to facilitate the lowering of technical barriers hindering cross-border exchange of data for AI development, including on data access infrastructure, semantic and technical interoperability of different types of data.

Amendment 761
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 82
(82) It is important that AI systems related to products that are not high-risk in accordance with this Regulation and thus are not required to comply with the requirements set out for high-risk AI systems are nevertheless safe when placed on the market or put into service. To contribute to this objective, the Directive 2001/95/EC of the European Parliament and of the Council57 would apply as a safety net.' '57 Directive 2001/95/EC of the European Parliament and of the Council of 3 December 2001 on general product safety (OJ L 11, 15.1.2002, p. 4).

Amendment 762
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 83
(83) In order to ensure trustful and constructive cooperation of competent authorities on Union and national level, all parties involved in the application of this Regulation should aim for transparency and openness. Where necessary for individual cases and internal deliberations, they should also respect the confidentiality of information and data obtained in carrying out their tasks.

Amendment 763
EPP - Group of the European Peoples Party (Christian Democrats)
Axel Voss, Deirdre Clune
Recital 84
(84) Member States should take all necessary measures to ensure that the provisions of this Regulation are implemented, including by laying down effective, proportionate and dissuasive penalties for their infringement. For certain specific infringements, Member States should take into account the margins and criteria set out in this Regulation. The European Data Protection Supervisor should have the power to impose fines on Union institutions, agencies and bodies falling within the scope of this Regulation. The penalties and litigation costs under this Regulation should not be subject to contractual clauses or any other arrangements.

Amendment 764
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 84 a (new)
(84 a) In order to strengthen and harmonise administrative penalties for infringements of this Regulation, each national supervisory authority should have the power to impose administrative fines. This Regulation should indicate infringements and the upper limit for setting the related administrative fines, which should be determined by the national supervisory authority in each individual case, taking into account all relevant circumstances of the specific situation, with due regard in particular to the nature, gravity and duration of the infringement and of its consequences and the measures taken to ensure compliance with the obligations under this Regulation and to prevent or mitigate the consequences of the infringement.

Amendment 765
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 84 a (new)
(84 a) An affected person should also have the right to mandate a not-for-profit body, organisation or association that has been properly constituted in accordance with the law of a Member State, to lodge the complaint on their behalf. To this end, Directive 2020/1828/EC on Representative Actions for the Protection of the Collective Interests of Consumers should be amended to include this Regulation among the provisions of Union law falling under its scope.

Amendment 766
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 84 a (new)
(84 a) Union legislation on the protection of whistleblowers (Directive (EU) 2019/1937) has full application to academics, designers, developers, project contributors, auditors, product managers, engineers and economic operators acquiring information on breaches of Union law by a provider of AI system or its AI system, even if they are not explicitly mentioned in Article 4(1)a-4(1)d of that Directive.

Amendment 767
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Petar Vitanov, Birgit Sippel, Bettina Vollath, Tsvetelina Penkova, Juan Fernando López
Recital 84 b (new)
(84 b) Natural persons, affected by an AI system falling within the scope of this Regulation, should have the right to lodge a complaint against the providers or users of such AI system with a national supervisory authority, if they consider that their fundamental rights, health or safety have been breached. An affected person should also have the right to mandate a not-for-profit body, organisation or association that has been properly constituted in accordance with the law of a Member State, to lodge the complaint on their behalf.

Amendment 768
GUE/NGL - The Left group in the European Parliament - GUE/NGL
Kateřina Konečná, Pernando Barrena Arza, Cornelia Ernst, Elena Kountoura
Recital 84 b (new)
(84 b) Union legislation on consumer protection(notably Directives (EU) 2019/2161, 2005/29/EC,2011/83/EU) applies to AI systems to the extent determined in these legislations, regardless of whether these systems are categorized as high-risk.

Amendment 769
ID - Identity and Democracy Group
Jean-Lin Lacapelle, Virginie Joron, Markus Buchheit, Hélène Laporte, Jean-Paul
Recital 85
(85) In order to ensure that the regulatory framework can be adapted where necessary, the power to adopt acts in accordance with Article 290 TFEU should be delegated to the Commission to amend the techniques and approaches referred to in Annex I to define AI systems, the Union harmonisation legislation listed in Annex II, the high-risk AI systems listed in Annex III, the provisions regarding technical documentation listed in Annex IV, the content of the EU declaration of conformity in Annex V, the provisions regarding the conformity assessment procedures in Annex VI and VII and the provisions establishing the high-risk AI systems to which the conformity assessment procedure based on assessment of the quality management system and assessment of the technical documentation should apply. As the purpose of delegating that power is to allow this Regulation to be adapted to technical advancements, the Commission should only be able to adopt such delegated acts to include non-restrictive additions or clarifications in the lists in those Annexes, whereas deletions, restrictive clarifications or amendments to the definitions of the items in those Annexes should only result from the adoption of amending regulations. It is of particular importance that the Commission carry out appropriate consultations during its preparatory work, including at expert level, and that those consultations be conducted in accordance with the principles laid down in the Interinstitutional Agreement of 13 April 2016 on Better Law-Making58. In particular, to ensure equal participation in the preparation of delegated acts, the European Parliament and the Council receive all documents at the same time as Member States’ experts, and their experts systematically have access to meetings of Commission expert groups dealing with the preparation of delegated acts.' '58 OJ L 123, 12.5.2016 p.1.

Amendment 770
EPP - Group of the European Peoples Party (Christian Democrats)
Jörgen Warborn, Arba Kokalari, Tomas Tobé
Recital 85
(85) In order to ensure that the regulatory framework can be adapted where necessary, the power to adopt acts in accordance with Article 290 TFEU should be delegated to the Commission to amend the techniques and approaches referred to in Annex I to define AI systems, the Union harmonisation legislation listed in Annex II and the content of the EU declaration of conformity in Annex V. It is of particular importance that the Commission carry out appropriate consultations during its preparatory work, including at expert level, and that those consultations be conducted in accordance with the principles laid down in the Interinstitutional Agreement of 13 April 2016 on Better Law-Making58 . In particular, to ensure equal participation in the preparation of delegated acts, the European Parliament and the Council receive all documents at the same time as Member States’ experts, and their experts systematically have access to meetings of Commission expert groups dealing with the preparation of delegated acts.' '58 OJ L 123, 12.5.2016, p. 1.

Amendment 771
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 85
(85) In order to ensure that the regulatory framework can be adapted where necessary, the power to adopt acts in accordance with Article 290 TFEU should be delegated to the Commission to amend the techniques and approaches referred to in Annex I to define AI systems, the Union harmonisation legislation listed in Annex II, the high-risk AI systems listed in Annex III, the provisions regarding technical documentation listed in Annex IV, the content of the EU declaration of conformity in Annex V, the provisions regarding the conformity assessment procedures in Annex VI and VII and the provisions establishing the high-risk AI systems to which the conformity assessment procedure based on assessment of the quality management system and assessment of the technical documentation should apply. It is of particular importance that the Commission carry out appropriate consultations during its preparatory work, including at expert level, and that those consultations be conducted in accordance with the principles laid down in the Interinstitutional Agreement of 13 April 2016 on Better Law-Making58 . These consultations should involve the participation of a balanced selection of stakeholders, including consumer organisations, associations representing affected persons, businesses representatives from different sectors and sizes, as well as researchers and scientists. In particular, to ensure equal participation in the preparation of delegated acts, the European Parliament and the Council receive all documents at the same time as Member States’ experts, and their experts systematically have access to meetings of Commission expert groups dealing with the preparation of delegated acts.' '58 OJ L 123, 12.5.2016, p. 1.

Amendment 772
S&D - Group of the Progressive Alliance of Socialists and Democrats in the European Parliament
Brando Benifei, Christel Schaldemose, Andreas Schieder, Alex Agius Saliba, Bettina
Recital 85
(85) In order to ensure that the regulatory framework can be adapted where necessary, the power to adopt acts in accordance with Article 290 TFEU should be delegated to the Commission to amend the Union harmonisation legislation listed in Annex II, the high-risk AI systems listed in Annex III, the provisions regarding technical documentation listed in Annex IV, the content of the EU declaration of conformity in Annex V and the provisions regarding the conformity assessment procedures in Annex VI and VII. It is of particular importance that the Commission carry out appropriate consultations during its preparatory work, including at expert level, and that those consultations be conducted in accordance with the principles laid down in the Interinstitutional Agreement of 13 April 2016 on Better Law-Making58 . In particular, to ensure equal participation in the preparation of delegated acts, the European Parliament and the Council receive all documents at the same time as Member States’ experts, and their experts systematically have access to meetings of Commission expert groups dealing with the preparation of delegated acts.' '58 OJ L 123, 12.5.2016, p. 1.

Amendment 773
Renew - Renew Europe Group
Dragoş Tudorache, Olivier Chastel, Vlad Gheorghe, Nicolae Ştefănuță, Ramona
Recital 85
(85) In order to ensure that the regulatory framework can be adapted where necessary, the power to adopt acts in accordance with Article 290 TFEU should be delegated to the Commission to amend the techniques and approaches referred to in Annex I to define AI systems, the Union harmonisation legislation listed in Annex II, the high-risk AI systems listed in Annex III, the provisions regarding technical documentation listed in Annex IV, the content of the EU declaration of conformity in Annex V, the provisions regarding the conformity assessment procedures in Annex VI and VII and the provisions establishing the high-risk AI systems to which the conformity assessment procedure based on assessment of the quality management system and assessment of the technical documentation should apply. It is of particular importance that the Commission carry out appropriate consultations during its preparatory work, including with industry, civil society, other stakeholders, and at expert level, and that those consultations be conducted in accordance with the principles laid down in the Interinstitutional Agreement of 13 April 2016 on Better Law-Making58 . In particular, to ensure equal participation in the preparation of delegated acts, the European Parliament and the Council receive all documents at the same time as Member States’ experts, and their experts systematically have access to meetings of Commission expert groups dealing with the preparation of delegated acts.' '58 OJ L 123, 12.5.2016, p. 1.

Amendment 774
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 86 a (new)
(86 a) Given the rapid technological developments and the required technical expertise in conducting the assessment of high-risk AI systems, the Commission should regularly review Annex III, at least every six months, while consulting with the relevant stakeholders, including ethics experts and anthropologists, sociologists, mental health specialists and any relevant scientists and researchers.

Amendment 775
EPP - Group of the European Peoples Party (Christian Democrats)
Krzysztof Hetman, Adam Jarubas, Andrzej Halicki, Jerzy Buzek, Janusz Lewandowski,
Recital 86 a (new)
(86 a) In order to ensure uniform conditions for the implementation of this Regulation, it should be accompanied by the publication of guidelines to help all stakeholders to interpret key concepts covered by the Regulation, such as prohibited or high-risk AI cases and the precise means and implementation rules of the Regulation by national competent authorities;

Amendment 776
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 86 b (new)
(86 b) When adopting delegated or implementing acts concerning high-risk sectors of AI development, notably those raising concerns with respect to ethical principles or entailing risks to the health or safety of humans, animals or plants, or the protection of the environment, Member States should also assume greater responsibility in the decision-making process. In particular, the abstentions of Member States representatives’ should be counted within a qualified majority, each Member State representative should give substantive reasons for votes and abstentions, each of their vote and abstention should be accompanied by a detailed justification, on the basis of Regulation XX/XX amending Regulation (EU) No 182/2011.

Amendment 777
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 87 a (new)
(87 a) As reliable information on the resource and energy use, waste production and other environmental impact of AI systems and related ICT technology, including software, hardware and in particular data centres, is limited, the Commission should evaluate the impact and effectiveness of this Regulation regarding these criteria and further evaluate bringing legislation for the sector to contribute to EU climate strategy and targets.

Amendment 778
Greens/EFA - Group of the Greens/European Free Alliance
Kim Van Sparrentak, Sergey Lagodinsky, Alexandra Geese, Alviina Alametsä
Recital 89
(89) The European Data Protection Supervisor and the European Data Protection Board were consulted in accordance with Article 42(2) of Regulation (EU) 2018/1725 and delivered an opinion on 18.6.2021”.
