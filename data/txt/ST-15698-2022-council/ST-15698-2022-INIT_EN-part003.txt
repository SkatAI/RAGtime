Article 55a 
Derogations for specific operators 
1. The obligations laid down in Article 17 of this Regulation shall not apply to microenterprises  as defined in Article 2(3) of the Annex to the Commission Recommendation 2003/361/EC  concerning the definition of micro, small and medium-sized enterprises, provided those  enterprises do not have partner enterprises or linked enterprises as defined in Article 3 of the  same Annex.  
2. Paragraph 1 shall not be interpreted as exempting those operators from fulfilling any other  requirements and obligations laid down in this Regulation, including those established in  Articles 9, 61 and 62. 
3. Requirements and obligations for general purpose AI systems laid down in Article 4b shall  not apply to micro, small and medium-sized enterprises, provided those enterprises do not  have partner enterprises or linked enterprises as defined in Article 3 of the the Annex to the  Commission Recommendation 2003/361/EC concerning the definition of micro, small and  medium-sized enterprises.
15698/22 RB/ek 141 TREE.2.B EN 
TITLE VI 
GOVERNANCE 
CHAPTER 1 
EUROPEAN ARTIFICIAL INTELLIGENCE BOARD 
Article 56 
Establishment and structure of the European Artificial Intelligence Board 
1. A ‘European Artificial Intelligence Board’ (the ‘Board’) is established. 
2. The Board shall be composed of one representative per Member State. The European Data  Protection Supervisor shall participate as an observer. The Commission shall also attend  the Board’s meetings without taking part in the votes. 
Other national and Union authorities, bodies or experts may be invited to the meetings by  the Board on a case by case basis, where the issues discussed are of relevance for them. 
2a. Each representative shall be designated by their Member State for a period of 3 years,  renewable once.  
2aa. Member States shall ensure that their representatives in the Board: 
(i) have the relevant competences and powers in their Member State so as to contribute  actively to the achievement of the board’s tasks referred to in Article 58; 
(ii) are designated as a single contact point vis-à-vis the Board and, where appropriate,  taking into account Member States’ needs, as a single contact point for stakeholders;
15698/22 RB/ek 142 TREE.2.B EN 
(iii) are empowered to facilitate consistency and coordination between national  competent authorities in their Member State as regards the implementation of this  Regulation, including through the collection of relevant data and information for the  purpose of fulfilling their tasks on the Board. 
3. The designated representatives of the Member States shall adopt the Board’s rules of  procedure by a two-thirds majority. 
The rules of procedure shall, in particular, lay down procedures for the selection process,  duration of mandate and specifications of the tasks of the Chair, the voting modalities, and  the organisation of the Board’s activities and its sub-groups.  
The Board shall establish a standing subgroup serving as a platform for stakeholders to  advise the Board on all issues related to the implementation of this Regulation, including  on the preparation of implementing and delegated acts. To this purpose, organisations  representing the interests of the providers and users of AI systems, including SMEs and  start-ups, as well as civil society organisations, representatives of affected persons,  researchers, standardisation organisations, notified bodies, laboratories and testing and  experimentation facilities shall be invited to participate to this sub-group. The Board shall  establish two standing sub-groups to provide a platform for cooperation and exchange  among market surveillance authorities and notifying authorities on issues related to market  surveillance and notified bodies respectively. 
The Board may establish other standing or temporary sub-groups as appropriate for the  purpose of examining specific issues. Where appropriate, stakeholders referred to in the  previous subparagraph may be invited to such sub-groups or to specific meetings of those  subgroups in the capacity of observers. 
3a. The Board shall be organised and operated so as to safeguard the objectivity and  impartiality of its activities.
15698/22 RB/ek 143 TREE.2.B EN 
4. The Board shall be chaired by one of the representatives of the Member States. Upon  request of the Chair, the Commission shall convene the meetings and prepare the agenda in  accordance with the tasks of the Board pursuant to this Regulation and its rules of  procedure. The Commission shall provide administrative and analytical support for the  activities of the Board pursuant to this Regulation.  
Article 57 
[deleted]  
Article 58 
Tasks of the Board 
The Board shall advice and assist the Commission and the Member States in order to facilitate the  consistent and effective application of this Regulation. For this purpose the Board may in particular: 
(a) collect and share technical and regulatory expertise and best practices among Member  States; 
(b) contribute to the harmonisation of administrative practices in the Member States, including  in relation to the derogation from the conformity assessment procedures referred to in  Article 47, the functioning of regulatory sandboxes and testing in real world conditions  referred to in Article 53, 54 and 54a; 
(c) upon the request of the Commission or on its own initiative, issue recommendations and  written opinions on any relevant matters related to the implementation of this Regulation  and to its consistent and effective application, including:  
(i) on technical specifications or existing standards regarding the requirements set out in  Title III, Chapter 2,  
(ii) on the use of harmonised standards or common specifications referred to in Articles  40 and 41,
15698/22 RB/ek 144 TREE.2.B EN 
(iii) on the preparation of guidance documents, including the guidelines concerning the  setting of administrative fines referred to in Article 71; 
(d) advise the Commission on the potential need for amendment of Annex III in accordance with  Articles 4 and 7, taking into account relevant available evidence and the latest develoments in  technology; 
(e) advise the Commission during the preparation of delegated or implementing act pursuant to  this Regulation; 
f) cooperate, as appropriate, with relevant EU bodies, experts groups and networks in particular  in the fields of product safety, cybersecurity, competition, digital and media services,  financial services, cryptocurrencies, consumer protection, data and fundamental rights  protection; 
g) contribute and provide relevant advice to the Commission in the development of the guidance  referred to in Article 58a or request the development of such guidance; 
(h) to assist the work of market surveillance authorities and, in cooperation and subject to  agreement of the concerned market surveillance authorities, promote and support cross-border  market surveillance investigations, including with respect to the emergence of risks of  systemic nature that may stem from AI systems; 
(i) contribute to the assessment of training needs for staff of Member States involved in  implementing this Regulation; 
(j) advise the Commission in relation to international matters on artificial intelligence.
15698/22 RB/ek 145 TREE.2.B EN 
CHAPTER 1A 
GUIDELINES FROM THE COMMISSION 
Article 58a 
Guidelines from the Commission on the implementation of this Regulation 
1. Upon the request of the Member States or the Board, or on its own initiative, the Commission  shall issue guidelines on the practical implementation of this Regulation, and in particular on 
(i) the application of the requirements referred to in Articles 8 - 15; 
(ii) the prohibited practices referred to in Article 5; 
(iii) the practical implementation of the provisions related to substantial modification; 
(iv) the practical implementation of uniform conditions referred to in Article 6, paragraph 3,  including examples in relation to high risk AI systems referred to in Annex III; 
(v) the practical implementation of transparency obligations laid down in Article 52; 
(vi) the relationship of this Regulation with other relevant Union legislation, including as  regards consistency in their enforcement. 
When issuing such guidelines, the Commission shall pay particular attention to the needs of SMEs  including start-ups, local public authorities and sectors most likely to be affected by this Regulation.
15698/22 RB/ek 146 TREE.2.B EN 
CHAPTER 2 
NATIONAL COMPETENT AUTHORITIES 
Article 59 
Designation of national competent authorities  
1. [deleted]  
2. Each Member State shall establish or designate at least one notifying authority and at least  one market surveillance authority for the purpose of this Regulation as national competent  authorities. These national competent authorities shall be organised so as to safeguard the  priniciples of objectivity and impartiality of their activities and tasks. Provided that those  prinicples are respected, such activities and tasks may be performed by one or several  designated authorities, in accordance with the organisational needs of the Member State.  
3. Member States shall inform the Commission of their designation or designations.  
4. Member States shall ensure that national competent authorities are provided with adequate  financial resources, technical equipment and well qualified human resources to effectively  fulfil their tasks under this Regulation.  
5. By [one year after entry into force of this Regulation] and afterwards six months before  the deadline referred to in Article 84(2) Member States shall inform the Commission on  the status of the financial resources, technical equipment and human resources of the  national competent authorities with an assessment of their adequacy. The Commission  shall transmit that information to the Board for discussion and possible recommendations.  
6. The Commission shall facilitate the exchange of experience between national competent  authorities.
15698/22 RB/ek 147 TREE.2.B EN 
7. National competent authorities may provide advice on the implementation of this  Regulation, including tailored to SME providers, including start-ups. Whenever national  competent authorities intend to provide guidance and advice with regard to an AI system in  areas covered by other Union legislation, the competent national authorities under that  Union legislation shall be consulted, as appropriate. Member States may also establish one central contact point for communication with operators. 
8. When Union institutions, agencies and bodies fall within the scope of this Regulation, the  European Data Protection Supervisor shall act as the competent authority for their  supervision. 
TITLE VII 
EU DATABASE FOR HIGH-RISK AI SYSTEMS LISTED IN ANNEX III 
Article 60 
EU database for high-risk AI systems listed in Annex III 
1. The Commission shall, in collaboration with the Member States, set up and maintain a EU  database containing information referred to in paragraph 2 concerning relevant operators  and high-risk AI systems listed in Annex III which are registered in accordance with  Articles 51 and 54a. When setting the fuctional specifications of such database, the  Commission shall consult the AI Board.
15698/22 RB/ek 148 TREE.2.B EN 
2. The data listed in Annex VIII, Part I, shall be entered into the EU database by the  providers, authorised representatives and relevant users, as applicable, upon their  registration. The data listed in Annex VIII, Part II, 1 to 11, shall be entered into the EU  database by the providers, or where applicable by the authorised representative, in  accordance with Article 51. The data referred in Annex VIII, Part II, 12 shall be  automatically generated by the database based on the information provided by relevant  users pursuant to Article 51(2). The data listed in Annex VIIIa shall be entered into the  database by the prospective providers or providers in accordance with Article 54a.  
3. [deleted]  
4. The EU database shall contain no personal data, except for the information listed in Annex  VIII, and shall be without prejudice to Article 70. 
5. The Commission shall be the controller of the EU database. It shall make available to  providers, prospective providers and users adequate technical and administrative support. 
5a. Information contained in the EU database registered in accordance with Article 51 shall be  accessible to the public. The information registered in accordance with Article 54a shall be  accessible only to market surveillance authorites and the Commission, unless the  prospective provider or provider has given consent for making this information also  accessible the public. 
15698/22 RB/ek 149 TREE.2.B EN 
TITLE VIII 
POST-MARKET MONITORING,INFORMATION SHARING, MARKET SURVEILLANCE 
CHAPTER 1 
POST-MARKET MONITORING 
Article 61 
Post-market monitoring by providers and post-market monitoring plan for high-risk AI systems 
1. Providers shall establish and document a post-market monitoring system in a manner that  is proportionate to the risks of the high-risk AI system. 
2. In order to allow the provider to evaluate the compliance of AI systems with the  requirements set out in Title III, Chapter 2 throughout their life cycle, the post-market  monitoring system shall collect, document and analyse relevant data, which may be  provided by users or which may be collected through other sources on the performance of  high-risk AI systems. This obligation shall not cover sensitive operational data of users of  AI systems which are law enforcement authorities. 
3. The post-market monitoring system shall be based on a post-market monitoring plan. The  post-market monitoring plan shall be part of the technical documentation referred to in  Annex IV. The Commission shall adopt an implementing act laying down detailed  provisions establishing a template for the post-market monitoring plan and the list of  elements to be included in the plan.
15698/22 RB/ek 150 TREE.2.B EN 
4. For high-risk AI systems covered by the legal acts referred to in Annex II, Section A,  where a post-market monitoring system and plan is already established under that  legislation, the post-market monitoring documentation as prepared under that legislation  shall be deemed sufficient, provided that the template referred to paragraph 3 is used. 
The first subparagraph shall also apply high-risk AI systems referred to in point 5 of  Annex III placed on the market or put into service by financial institutions that are subject  to requirements regarding their internal governance, arrangements or processes under  Union financial services legislation. 
CHAPTER 2 
SHARING OF INFORMATION ON SERIOUS INCIDENTS  
Article 62 
Reporting of serious incidents  
1. Providers of high-risk AI systems placed on the Union market shall report any serious  incident to the market surveillance authorities of the Member States where that incident  occurred.  
Such notification shall be made immediately after the provider has established a causal link  between the AI system and the serious incident or the reasonable likelihood of such a link,  and, in any event, not later than 15 days after the providers becomes aware of the serious  incident. 
2. Upon receiving a notification related to a serious incident referred to in Article 3(44)(c),  the relevant market surveillance authority shall inform the national public authorities or  bodies referred to in Article 64(3). The Commission shall develop dedicated guidance to  facilitate compliance with the obligations set out in paragraph 1. That guidance shall be  issued 12 months after the entry into force of this Regulation, at the latest.
15698/22 RB/ek 151 TREE.2.B EN 
3. For high-risk AI systems referred to in point 5 of Annex III which are placed on the market  or put into service by providers that are financial institutions that are subject to  requirements regarding their internal governance, arrangements or processes under Union  financial services legislation, the notification of serious incidents shall be limited to those  referred to in Article 3(44)(c). 
4. For high-risk AI systems which are safety components of devices, or are themselves  devices, covered by Regulation (EU) 2017/745 and Regulation (EU) 2017/746 the  notification of serious incidents shall be limited to those referred to in Article 3(44)(c) and  be made to the national competent authority chosen for this purpose by the Member States  where that incident occurred. 
CHAPTER 3 
ENFORCEMENT  
Article 63 
Market surveillance and control of AI systems in the Union market 
1. Regulation (EU) 2019/1020 shall apply to AI systems covered by this Regulation.  However, for the purpose of the effective enforcement of this Regulation: 
(a) any reference to an economic operator under Regulation (EU) 2019/1020 shall be  understood as including all operators identified in Article 2 of this Regulation; 
(b) any reference to a product under Regulation (EU) 2019/1020 shall be understood as  including all AI systems falling within the scope of this Regulation.
15698/22 RB/ek 152 TREE.2.B EN 
2. As part of their reporting obligations under Article 34(4) of Regulation (EU) 2019/1020,  the market surveillance authorities shall report to the Commission about the outcomes of  relevant market surveillance activities under this Regulation.  
3. For high-risk AI systems, related to products to which legal acts listed in Annex II, section  A apply, the market surveillance authority for the purposes of this Regulation shall be the  authority responsible for market surveillance activities designated under those legal acts or,  in justified circumstances and provided that coordination is ensured, another relevant  authority identified by the Member State.  
The procedures referred to in Articles 65, 66, 67 and 68 of this Regulation shall not apply  to AI systems related to products, to which legal acts listed in Annex II, section A apply,  when such legal acts already provide for procedures having the same objective. In such a  case, these sectoral procedures shall apply instead. 
4. For high-risk AI systems placed on the market, put into service or used by financial  institutions regulated by Union legislation on financial services, the market surveillance  authority for the purposes of this Regulation shall be the relevant national authority  responsible for the financial supervision of those institutions under that legislation in so far  as the placement on the market, putting into service or the use of the AI system is in direct  connection with the provision of those financial services.  
By way of a derogation from the previous subparagraph, in justified circumstances and  provided that coordination is ensured, another relevant authority may be identified by the  Member State as market surveillance authority for the purposes of this Regulation.  
National market surveillance authorities supervising regulated credit institutions regulated  under Directive 2013/36/EU, which are participating in the Single Supervisory Mechanism  (SSM) established by Council Regulation No 1204/2013, should report, without delay, to  
the European Central Bank any information identified in the course of their market  surveillance activities that may be of potential interest for the European Central Bank’s  prudential supervisory tasks as specified in that Regulation.
15698/22 RB/ek 153 TREE.2.B EN 
5. For high-risk AI systems listed in point 1(a) in so far as the systems are used for law  enforcement purposes, points 6, 7 and 8 of Annex III, Member States shall designate as  market surveillance authorities for the purposes of this Regulation either the national  authorities supervising the activities of the law enforcement, border control, immigration, asylum or judicial authorities, or the competent data protection supervisory authorities  under Directive (EU) 2016/680, or Regulation 2016/679. Market surveillance activities  shall in no way affect the independence of judicial authorities or otherwise interfere with  their activities when acting in their judicial capacity. 
6. Where Union institutions, agencies and bodies fall within the scope of this Regulation, the  European Data Protection Supervisor shall act as their market surveillance authority. 
7. Member States shall facilitate the coordination between market surveillance authorities  designated under this Regulation and other relevant national authorities or bodies which  supervise the application of Union harmonisation legislation listed in Annex II or other  Union legislation that might be relevant for the high-risk AI systems referred to in Annex  III.  
8. Without prejudice to powers provided under Regulation (EU) 2019/1020, and where  relevant and limited to what is necessary to fulfil their tasks, the market surveillance  authorities shall be granted full access by the provider to the documentation as well as the  training, validation and testing datasets used for the development of the high-risk AI  system, including, where appropriate and subject to security safeguards, through  application programming interfaces (‘API’) or other relevant technical means and tools  enabling remote access. 
9. Market surveillance authorities shall be granted access to the source code of the high-risk  AI system upon a reasoned request and only when the following cumulative conditions are  fulfilled: 
15698/22 RB/ek 154 TREE.2.B EN 
a) Access to source code is necessary to assess the conformity of a high-risk AI system  with the requirements set out in Title III, Chapter 2, and  
b) testing/auditing procedures and verifications based on the data and documentation  provided by the provider have been exhausted or proved insufficient.  
10. Any information and documentation obtained by market surveillance authorities shall be  treated in compliance with the confidentiality obligations set out in Article 70. 
11. Complaints to the relevant market surveillance authority can be submitted by any natural  or legal person having grounds to consider that there has been an infringement of the  provisions of this Regulation. 
In accordance with Article 11(3)(e) and (7)(a) of Regulation (EU) 2019/1020, complaints  shall be taken into account for the purpose of conducting the market surveillance activities  and be handled in line with the dedicated procedures established therefore by the market  surveillance authorities. 
Article 63a 
Supervision of testing in real world conditions by market surveillance authorities 
1. Market surveillance authorities shall have the competence and powers to ensure that testing  in real world conditions is in accordance with this Regulation.  
2. Where testing in real world conditions is conducted for AI systems that are supervised  within an AI regulatory sandbox under Article 54, the market surveillance authorities shall  verify the compliance with the provisions of Article 54a as part of their supervisory role  for the AI regulatory sandbox. Those authorities may, as appropriate, allow the testing in  real world conditions to be conducted by the provider or prospective provider in derogation  to the conditions set out in Article 54a(4) (f) and (g).
15698/22 RB/ek 155 TREE.2.B EN 
3. Where a market surveillance authority has been informed by the prospective provider, the  provider or any third party of a serious incident or has other grounds for considering  that the conditions set out in Articles 54a and 54b are not met, it may take any of the  following decisions on its territory, as appropriate: 
(a) suspend or terminate the testing in real world conditions; 
(b) require the provider or prospective provider and user(s) to modify any aspect of the  testing in real world conditions. 
4. Where a market surveillance authority has taken a decision referred to in paragraph 3 of  this Article or has issued an objection within the meaning of Article 54a(4)(b), the decision  or the objection shall indicate the grounds thereof and the modalities and conditions for the  provider or prospective provider to challenge the decision or objection.  
5. Where applicable, where a market surveillance authority has taken a decision referred to in  paragraph 3 of this Article, it shall communicate the grounds therefor to the market  surveillance authorities of the other Member States in which the AI system has been tested  in accordance with the testing plan. 
Article 64 
Powers of authorities protecting fundamental rights  
1. [deleted]  
2. [deleted] 
15698/22 RB/ek 156 TREE.2.B EN 
3. National public authorities or bodies which supervise or enforce the respect of obligations  under Union law protecting fundamental rights, including the right to non-discrimination, in relation to the use of high-risk AI systems referred to in Annex III shall have the power  to request and access any documentation created or maintained under this Regulation when  access to that documentation is necessary for the fulfilment of the competences under their  mandate within the limits of their jurisdiction. The relevant public authority or body shall  inform the market surveillance authority of the Member State concerned of any such  request. 
4. By 3 months after the entering into force of this Regulation, each Member State shall  identify the public authorities or bodies referred to in paragraph 3 and make the list  publicly available. Member States shall notify the list to the Commission and all other  Member States and keep the list up to date.  
5. Where the documentation referred to in paragraph 3 is insufficient to ascertain whether a  breach of obligations under Union law intended to protect fundamental rights has occurred,  the public authority or body referred to paragraph 3 may make a reasoned request to the  market surveillance authority to organise testing of the high-risk AI system through  technical means. The market surveillance authority shall organise the testing with the close  involvement of the requesting public authority or body within reasonable time following  the request.  
6. Any information and documentation obtained by the national public authorities or bodies  referred to in paragraph 3 pursuant to the provisions of this Article shall be treated in  compliance with the confidentiality obligations set out in Article 70.
15698/22 RB/ek 157 TREE.2.B EN 
Article 65 
Procedure for dealing with AI systems presenting a risk at national level 
1. AI systems presenting a risk shall be understood as a product presenting a risk defined in  Article 3, point 19 of Regulation (EU) 2019/1020 insofar as risks to the health or safety or  to fundamental rights of persons are concerned. 
2. Where the market surveillance authority of a Member State has sufficient reasons to  consider that an AI system presents a risk as referred to in paragraph 1, they shall carry out  an evaluation of the AI system concerned in respect of its compliance with all the  requirements and obligations laid down in this Regulation. When risks to fundamental  rights are identified, the market surveillance authority shall also inform the relevant  national public authorities or bodies referred to in Article 64(3). The relevant operators  shall cooperate as necessary with the market surveillance authorities and the other national  public authorities or bodies referred to in Article 64(3). 
Where, in the course of that evaluation, the market surveillance authority finds that the AI  system does not comply with the requirements and obligations laid down in this  Regulation, it shall without undue delay require the relevant operator to take all appropriate  corrective actions to bring the AI system into compliance, to withdraw the AI system from  the market, or to recall it, within a period it may prescribe. 
The market surveillance authority shall inform the relevant notified body accordingly.  Article 18 of Regulation (EU) 2019/1020 shall apply to the measures referred to in the  second subparagraph. 
3. Where the market surveillance authority considers that non-compliance is not restricted to  its national territory, it shall inform the Commission and the other Member States without  undue delay of the results of the evaluation and of the actions which it has required the  operator to take.
15698/22 RB/ek 158 TREE.2.B EN 
4. The operator shall ensure that all appropriate corrective action is taken in respect of all the  AI systems concerned that it has made available on the market throughout the Union. 
5. Where the operator of an AI system does not take adequate corrective action within the  period referred to in paragraph 2, the market surveillance authority shall take all appropriate provisional measures to prohibit or restrict the AI system's being made  available on its national market, to withdraw the product from that market or to recall it.  That authority shall notify the Commission and the other Member States, without undue  delay, of those measures. 
6. The notification referred to in paragraph 5 shall include all available details, in particular  the information necessary for the identification of the non-compliant AI system, the origin  of the AI system, the nature of the non-compliance alleged and the risk involved, the  nature and duration of the national measures taken and the arguments put forward by the  relevant operator. In particular, the market surveillance authorities shall indicate whether  the non-compliance is due to one or more of the following: 
(-a) non-compliance with the prohibition of the artificial intelligence practices referred to  in Article 5; 
(a) a failure of a high-risk AI system to meet requirements set out in Title III, Chapter 2;  
(b) shortcomings in the harmonised standards or common specifications referred to in  Articles 40 and 41 conferring a presumption of conformity. 
(c) non-compliance with provisions set out in Article 52; 
(d) non-compliance of general purpose AI systems with the requirements and obligations  referred to in Article 4a;
15698/22 RB/ek 159 TREE.2.B EN 
7. The market surveillance authorities of the Member States other than the market  surveillance authority of the Member State initiating the procedure shall without undue  delay inform the Commission and the other Member States of any measures adopted and of  any additional information at their disposal relating to the non-compliance of the AI  system concerned, and, in the event of disagreement with the notified national measure, of  their objections. 
8. Where, within three months of receipt of the notification referred to in paragraph 5, no  objection has been raised by either a Member State or the Commission in respect of a  provisional measure taken by a Member State, that measure shall be deemed justified. This  is without prejudice to the procedural rights of the concerned operator in accordance with  Article 18 of Regulation (EU) 2019/1020. The period referred to in the first sentence of  this paragraph shall be reduced to 30 days in the case of non-compliance with the  prohibition of the artificial intelligence practices referred to in Article 5. 
9. The market surveillance authorities of all Member States shall then ensure that appropriate  restrictive measures are taken in respect of the AI system concerned, such as withdrawal of  the product from their market, without undue delay.
15698/22 RB/ek 160 TREE.2.B EN 
Article 66 
Union safeguard procedure 
1. Where, within three months of receipt of the notification referred to in Article 65(5), or 30  days in the case of non-compliance with the prohibition of the artificial intelligence  practices referred to in Article 5, objections are raised by a Member State against a  measure taken by another Member State, or where the Commission considers the measure  to be contrary to Union law, the Commission shall without undue delay enter into  consultation with the relevant Member State’s market surveillance authority and operator  or operators and shall evaluate the national measure. On the basis of the results of that  evaluation, the Commission shall decide whether the national measure is justified or not  within 9 months, or 60 days in the case of non-compliance with the prohibition of the  artificial intelligence practices referred to in Article 5, starting from the notification  referred to in Article 65(5). It shall and notify such decision to the Member State  concerned. The Commission shall also inform all other Member States of such decision. 
2. If the measure taken by the relevant Member State’s market surveillance authority is  considered justified by the Commission, the market surveillance authorities of all Member  States shall ensure that appropriate restrictive measures are taken in respect of the AI  system concerned, such as withdrawal of the AI system from their market without undue  delay, and shall inform the Commission accordingly. If the national measure is considered  unjustified by the Commission, the market surveillance authority of the Member State  concerned shall withdraw the measure and inform the Commission accordingly. 
3. Where the national measure is considered justified and the non-compliance of the AI  system is attributed to shortcomings in the harmonised standards or common specifications  referred to in Articles 40 and 41 of this Regulation, the Commission shall apply the  procedure provided for in Article 11 of Regulation (EU) No 1025/2012.
15698/22 RB/ek 161 TREE.2.B EN 
Article 67 
Compliant high-risk or general purpose AI systems which present a risk 
1. Where, having performed an evaluation under Article 65, the market surveillance authority  of a Member State finds that although a high-risk or general purpose AI system is in  compliance with this Regulation, it presents a risk to the health or safety of persons or to  fundamental rights, it shall require the relevant operator to take all appropriate measures to  ensure that the AI system concerned, when placed on the market or put into service, no  longer presents that risk, to withdraw the AI system from the market or to recall it without  undue delay, within a period it may prescribe. 
2. The provider or other relevant operators shall ensure that corrective action is taken in  respect of all the AI systems concerned that they have made available on the market  throughout the Union within the timeline prescribed by the market surveillance authority of  the Member State referred to in paragraph 1. 
3. The Member State shall immediately inform the Commission and the other Member States.  That information shall include all available details, in particular the data necessary for the  identification of the AI system concerned, the origin and the supply chain of the AI system,  the nature of the risk involved and the nature and duration of the national measures taken. 
4. The Commission shall without undue delay enter into consultation with the Member States  concerned and the relevant operator and shall evaluate the national measures taken. On the  basis of the results of that evaluation, the Commission shall decide whether the measure is  justified or not and, where necessary, propose appropriate measures. 
5. The Commission shall address its decision to the Member States concerned, and inform all  other Member States.
15698/22 RB/ek 162 TREE.2.B EN 
Article 68 
Formal non-compliance 
1. Where the market surveillance authority of a Member State makes one of the following  findings, it shall require the relevant provider to put an end to the non-compliance  concerned, within a period it may prescribe: 
(a) the conformity marking has been affixed in violation of Article 49; 
(b) the conformity marking has not been affixed; 
(c) the EU declaration of conformity has not been drawn up; 
(d) the EU declaration of conformity has not been drawn up correctly; 
(e) the identification number of the notified body, which is involved in the conformity  assessment procedure, where applicable, has not been affixed; 
2. Where the non-compliance referred to in paragraph 1 persists, the Member State concerned  shall take all appropriate measures to restrict or prohibit the high-risk AI system being  made available on the market or ensure that it is recalled or withdrawn from the market. 
Article 68a 
Union testing facilities in the area of artificial intelligence 
1. The Commission shall designate one or more Union testing facilities pursuant to Article 21  of Regulation (EU) 1020/2019 in the area of artificial intelligence. 
15698/22 RB/ek 163 TREE.2.B EN 
2. Without prejudice to the activities of Union testing facilities referred to in Article 21(6) of  Regulation (EU) 1020/2019, Union testing facilities referred to in paragraph 1 shall also  provide independent technical or scientific advice at the request of the Board or market  surveillance authorities.  
Article 68b 
Central pool of independent experts 
1. Upon request of the AI Board, the Commission shall, by means of an implementing act,  make provisions on the creation, maintenance and financing of a central pool of  independent experts to support the enforcement activities under this Regulation.  
2. Experts shall be selected by the Commission and included in the central pool on the basis  of up-to-date scientific or technical expertise in the field of artificial intelligence, having  due regard to the technical areas covered by the requirements and obligations in this  Regulation and the activities of market surveillance authorities pursuant to Article 11 of  Regulation (EU) 1020/2019. The Commission shall determine the number of experts in the  pool in accordance with the required needs.  
3. Experts may have the following tasks: 
(a) provide advice to and support the work of market surveillance authorities, at their  request; 
(b) support cross-border market surveillance investigations as referred to in Article 58(h),  without prejudice of the powers of market surveillance authorities;  
(c) advise and support the Commission when carrying out its duties in the context of the  safeguard clause pursuant to Article 66.
15698/22 RB/ek 164 TREE.2.B EN 
4. The experts shall perform their tasks with impartiality, objectivity and ensure the  confidentiality of information and data obtained in carrying out their tasks and activities.  Each expert shall draw up a declaration of interests, which shall be made publicly  available. The Commission shall establish systems and procedures to actively manage and  prevent potential conflicts of interest. 
5. The Member States may be required to pay fees for the advice and support by the experts.  The structure and the level of fees as well as the scale and structure of recoverable costs  shall be adopted by the Commission by means of the implementing act referred to in  paragraph 1, taking into account the objectives of the adequate implementation of this  Regulation, cost-effectiveness and the necessity to ensure an effective access to experts by  all Member States.  
6. The Commission shall facilitate timely access to the experts by the Member States, as  needed, and ensure that the combination of support activities carried out by Union testing  facilities pursuant to Article 68a and experts pursuant to this Article is efficiently organised  and provides the best possible added value.
15698/22 RB/ek 165 TREE.2.B EN 
TITLE IX 
CODES OF CONDUCT 
Article 69 
Codes of conduct for voluntary application of specific requirements 
1. The Commission, and the Member States shall facilitate the drawing up of codes of  conduct intended to encourage the voluntary application to AI systems other than high-risk  AI systems of one or more of the requirements set out in Title III, Chapter 2 of this  Regulation to the best extent possible, taking into account the available, technical solutions  allowing for the application of such requirements.  
2. The Commission and the Member States shall facilitate the drawing up of codes of conduct  intended to encourage the voluntary application to all AI systems of specific requirements  related, for example, to environmental sustainability, including as regards energy-efficient  programming, accessibility for persons with a disability, stakeholders participation in the  design and development of the AI systems and diversity of development teams on the basis  of clear objectives and key performance indicators to measure the achievement of those  objectives. The Commission and the Member States shall also facilitate, where appropriate,  the drawing of codes of conduct applicable on a voluntary basis with regard to users'  obligations in relation to AI systems. 
3. Codes of conduct applicable on a voluntary basis may be drawn up by individual providers  of AI systems or by organisations representing them or by both, including with the  involvement of users and any interested stakeholders and their representative  organisations, or, where appropriate, by users with regard to their obligations. Codes of  conduct may cover one or more AI systems taking into account the similarity of the  intended purpose of the relevant systems. 
4. The Commission and the Member States shall take into account the specific interests and  needs of SME providers, including start-ups, when encouraging and facilitating the  drawing up of codes of conduct referred to in this Article.
15698/22 RB/ek 166 TREE.2.B EN 
TITLE X 
CONFIDENTIALITY AND PENALTIES 
Article 70 
Confidentiality 
1. National competent authorities, notified bodies, the Commission, the Board, and any other  natural or legal person involved in the application of this Regulation shall, in accordance  with Union or national law, put appropriate technical and organisational measures in place  to ensure the confidentiality of information and data obtained in carrying out their tasks  and activities in such a manner as to protect, in particular: 
(a) intellectual property rights, and confidential business information or trade secrets of a  natural or legal person, including source code, except the cases referred to in Article 5 of  Directive 2016/943 on the protection of undisclosed know-how and business information  (trade secrets) against their unlawful acquisition, use and disclosure apply.  
(b) the effective implementation of this Regulation, in particular for the purpose of  inspections, investigations or audits; 
(c) public and national security interests;  
(d) integrity of criminal or administrative proceedings; 
(e) the integrity of information classified in accordance with Union or national law.
15698/22 RB/ek 167 TREE.2.B EN 
2. Without prejudice to paragraph 1, information exchanged on a confidential basis between  the national competent authorities and between national competent authorities and the  Commission shall not be disclosed without the prior consultation of the originating  national competent authority and the user when high-risk AI systems referred to in points  1, 6 and 7 of Annex III are used by law enforcement, border control, immigration or  asylum authorities, when such disclosure would jeopardise public and national security  interests. This obligation to exchange information shall not cover sensitive operational  data in relation to the activities of law enforcement, border control, immigration or asylum  authorities. 
When the law enforcement, immigration or asylum authorities are providers of high-risk  AI systems referred to in points 1, 6 and 7 of Annex III, the technical documentation  referred to in Annex IV shall remain within the premises of those authorities. Those  authorities shall ensure that the market surveillance authorities referred to in Article 63(5)  and (6), as applicable, can, upon request, immediately access the documentation or obtain a  copy thereof. Only staff of the market surveillance authority holding the appropriate level  of security clearance shall be allowed to access that documentation or any copy thereof. 
3. Paragraphs 1 and 2 shall not affect the rights and obligations of the Commission, Member States and their relevant authorities, as well as notified bodies, with regard to the exchange  of information and the dissemination of warnings, including in the context of cross-border  cooperation, nor the obligations of the parties concerned to provide information under  criminal law of the Member States.
15698/22 RB/ek 168 TREE.2.B EN 
Article 71 
Penalties 
1. In compliance with the terms and conditions laid down in this Regulation, Member States  shall lay down the rules on penalties, including administrative fines, applicable to  infringements of this Regulation and shall take all measures necessary to ensure that they  are properly and effectively implemented. The penalties provided for shall be effective,  proportionate, and dissuasive. They shall take into particular account the size and interests  of SME providers, including start-ups, and their economic viability. They shall also take  into account whether the use of the AI system is in the context of personal non professional activity. 
2. The Member States shall without delay notify the Commission of those rules and of those  measures and of any subsequent amendment affecting them.  
3. Non-compliance with any of the prohibitions of the artificial intelligence practices referred  to in Article 5 shall be subject to administrative fines of up to 30 000 000 EUR or, if the  offender is company, up to 6 % of its total worldwide annual turnover for the preceding  financial year, whichever is higher. In case of SMEs, including start-ups, these fines shall  be up to 3% of their worldwide annual turnover for the preceding financial year. 
4. Infringements of the following provisions related to operators or notified bodies, shall be  subject to administrative fines of up to 20 000 000 EUR or, if the offender is a company,  up to 4 % of its total worldwide annual turnover for the preceding financial year,  whichever is higher: 
-a) obligations of providers pursuant to Articles 4b and 4c; 
a) obligations of providers pursuant to Article 16; 
b) obligations for certain other persons pursuant to Article 23a;
15698/22 RB/ek 169 TREE.2.B EN 
c) obligations of authorised representatives pursuant to Article 25; 
d) obligations of importers pursuant to Article 26; 
e) obligations of distributors pursuant to Article 27; 
f) obligations of users pursuant to Article 29, paragraphs 1 to 6a; 
g) requirements and obligations of notified bodies pursuant to Article 33, 34(1), 34(3),  34(4), 34a; 
h) transparency obligations for providers and users pursuant to Article 52. 
In case of SMEs, including start-ups, these fines shall be up to 2% of their worldwide  annual turnover for the preceding financial year. 
5. The supply of incorrect, incomplete or misleading information to notified bodies and  national competent authorities in reply to a request shall be subject to administrative fines  of up to 10 000 000 EUR or, if the offender is a company, up to 2 % of its total worldwide  annual turnover for the preceding financial year, whichever is higher. In case of SMEs,  including start-ups, these fines shall be up to 1% of their worldwide annual turnover for  the preceding financial year. 
6. When deciding on the amount of the administrative fine in each individual case, all  relevant circumstances of the specific situation shall be taken into account and due regard  shall be given to the following: 
(a) the nature, gravity and duration of the infringement and of its consequences; (aa) the intentional or negligent character of the infringement; 
(ab) any action taken by the operator in order to remedy the infringement and mitigate the  possible adverse effects of the infringement;
15698/22 RB/ek 170 TREE.2.B EN 
(b) whether administrative fines have been already applied by other market surveillance  authorities in other Member States to the same operator for the same infringement; 
(ba) whether administrative fines have been already applied by other authorities to the  same operator for infringements of other Union or national law, when such  infringements result from the same activity or omission constituting a relevant  infringement of this Act; 
(c) the size, the annual turnover and market share of the operator committing the  infringement; 
(d) any other aggravating or mitigating factor applicable to the circumstances of the  case, such as financial benefits gained, or losses avoided, directly or indirectly, from  the infringement. 
7. Each Member State shall lay down rules on whether and to what extent administrative  fines may be imposed on public authorities and bodies established in that Member State. 
8. Depending on the legal system of the Member States, the rules on administrative fines may  be applied in such a manner that the fines are imposed by competent national courts or  other bodies as applicable in those Member States. The application of such rules in those  Member States shall have an equivalent effect. 
9. The exercise by the market surveillance authority of its powers under this Article shall be  subject to appropriate procedural safeguards in accordance with Union and Member State  law, including effective judicial remedy and due process.
15698/22 RB/ek 171 TREE.2.B EN 
Article 72 
Administrative fines on Union institutions, agencies and bodies 
1. The European Data Protection Supervisor may impose administrative fines on Union  institutions, agencies and bodies falling within the scope of this Regulation. When deciding  whether to impose an administrative fine and deciding on the amount of the administrative  fine in each individual case, all relevant circumstances of the specific situation shall be  taken into account and due regard shall be given to the following: 
(a) the nature, gravity and duration of the infringement and of its consequences; 
(b) the cooperation with the European Data Protection Supervisor in order to remedy the  infringement and mitigate the possible adverse effects of the infringement, including compliance with any of the measures previously ordered by the European Data  Protection Supervisor against the Union institution or agency or body concerned with  regard to the same subject matter; 
(c) any similar previous infringements by the Union institution, agency or body; 
2. Non-compliance with any of the prohibitions of the artificial intelligence practices referred  to in Article 5 shall be subject to administrative fines of up to 500 000 EUR. 
3. Non-compliance of the AI system with any requirements or obligations under this  Regulation, other than those laid down in Articles 5 and 10, shall be subject to  administrative fines of up to 250 000 EUR. 
4. Before taking decisions pursuant to this Article, the European Data Protection Supervisor  shall give the Union institution, agency or body which is the subject of the proceedings  conducted by the European Data Protection Supervisor the opportunity of being heard on  the matter regarding the possible infringement. The European Data Protection Supervisor  shall base his or her decisions only on elements and circumstances on which the parties  concerned have been able to comment. Complainants, if any, shall be associated closely  with the proceedings.
15698/22 RB/ek 172 TREE.2.B EN 
5. The rights of defense of the parties concerned shall be fully respected in the proceedings.  They shall be entitled to have access to the European Data Protection Supervisor’s file,  subject to the legitimate interest of individuals or undertakings in the protection of their  personal data or business secrets. 
6. Funds collected by imposition of fines in this Article shall be the income of the general  budget of the Union. 
TITLE XI 
DELEGATION OF POWER AND COMMITTEE PROCEDURE 
Article 73 
Exercise of the delegation 
1. The power to adopt delegated acts is conferred on the Commission subject to the  conditions laid down in this Article. 
2. The delegation of power referred to in Article 7(1), Article 7(3), Article 11(3), Article  43(5) and (6) and Article 48(5) shall be conferred on the Commission for a period of five  years from [entering into force of the Regulation]. 
The Commission shall draw up a report in respect of the delegation of power not later than  nine months before the end of the 5 year period. The delegation of power shall be tacitly  extended for periods of an identical duration, unless the European Parliament or the  Council opposes such extension not later than three months before the end of each period.
15698/22 RB/ek 173 TREE.2.B EN 
3. The delegation of power referred to in Article 7(1), Article 7(3), Article 11(3), Article  43(5) and (6) and Article 48(5) may be revoked at any time by the European Parliament or  by the Council. A decision of revocation shall put an end to the delegation of power  specified in that decision. It shall take effect the day following that of its publication in the  Official Journal of the European Union or at a later date specified therein. It shall not  affect the validity of any delegated acts already in force. 
4. As soon as it adopts a delegated act, the Commission shall notify it simultaneously to the  European Parliament and to the Council. 
5. Any delegated act adopted pursuant to Article 7(1), Article 7(3), Article 11(3), Article  43(5) and (6) and Article 48(5) shall enter into force only if no objection has been  expressed by either the European Parliament or the Council within a period of three  months of notification of that act to the European Parliament and the Council or if, before  the expiry of that period, the European Parliament and the Council have both informed the  Commission that they will not object. That period shall be extended by three months at the  initiative of the European Parliament or of the Council. 
Article 74 
Committee procedure 
1. The Commission shall be assisted by a committee. That committee shall be a committee  within the meaning of Regulation (EU) No 182/2011. 
2. Where reference is made to this paragraph, Article 5 of Regulation (EU) No 182/2011 shall  apply.
15698/22 RB/ek 174 TREE.2.B EN 
TITLE XII 
FINAL PROVISIONS 
Article 75 
Amendment to Regulation (EC) No 300/2008 
In Article 4(3) of Regulation (EC) No 300/2008, the following subparagraph is added: 
“When adopting detailed measures related to technical specifications and procedures for approval  and use of security equipment concerning Artificial Intelligence systems in the meaning of  Regulation (EU) YYY/XX [on Artificial Intelligence] of the European Parliament and of the  Council*, the requirements set out in Chapter 2, Title III of that Regulation shall be taken into  account.” 
__________ 
* Regulation (EU) YYY/XX [on Artificial Intelligence] (OJ …).”
15698/22 RB/ek 175 TREE.2.B EN 
Article 76 
Amendment to Regulation (EU) No 167/2013 
In Article 17(5) of Regulation (EU) No 167/2013, the following subparagraph is added: 
“When adopting delegated acts pursuant to the first subparagraph concerning artificial intelligence  systems which are safety components in the meaning of Regulation (EU) YYY/XX [on Artificial  Intelligence] of the European Parliament and of the Council*, the requirements set out in Title III,  Chapter 2 of that Regulation shall be taken into account. 
__________ 
* Regulation (EU) YYY/XX [on Artificial Intelligence] (OJ …).” 
Article 77 
Amendment to Regulation (EU) No 168/2013 
In Article 22(5) of Regulation (EU) No 168/2013, the following subparagraph is added: 
“When adopting delegated acts pursuant to the first subparagraph concerning Artificial Intelligence  systems which are safety components in the meaning of Regulation (EU) YYY/XX on [Artificial  Intelligence] of the European Parliament and of the Council*, the requirements set out in Title III,  Chapter 2 of that Regulation shall be taken into account. 
__________ 
* Regulation (EU) YYY/XX [on Artificial Intelligence] (OJ …).”
15698/22 RB/ek 176 TREE.2.B EN 
Article 78 
Amendment to Directive 2014/90/EU 
In Article 8 of Directive 2014/90/EU, the following paragraph is added: 
“4. For Artificial Intelligence systems which are safety components in the meaning of Regulation  (EU) YYY/XX [on Artificial Intelligence] of the European Parliament and of the Council*, when  carrying out its activities pursuant to paragraph 1 and when adopting technical specifications and  testing standards in accordance with paragraphs 2 and 3, the Commission shall take into account the  
requirements set out in Title III, Chapter 2 of that Regulation. 
__________ 
* Regulation (EU) YYY/XX [on Artificial Intelligence] (OJ …).”.
15698/22 RB/ek 177 TREE.2.B EN 
Article 79 
Amendment to Directive (EU) 2016/797 
In Article 5 of Directive (EU) 2016/797, the following paragraph is added: 
“12. When adopting delegated acts pursuant to paragraph 1 and implementing acts pursuant to  paragraph 11 concerning Artificial Intelligence systems which are safety components in the  meaning of Regulation (EU) YYY/XX [on Artificial Intelligence] of the European Parliament and  of the Council*, the requirements set out in Title III, Chapter 2 of that Regulation shall be taken into  account. 
__________ 
* Regulation (EU) YYY/XX [on Artificial Intelligence] (OJ …).”. 
Article 80 
Amendment to Regulation (EU) 2018/858 
In Article 5 of Regulation (EU) 2018/858 the following paragraph is added: 
“4. When adopting delegated acts pursuant to paragraph 3 concerning Artificial Intelligence  systems which are safety components in the meaning of Regulation (EU) YYY/XX [on Artificial  Intelligence] of the European Parliament and of the Council *, the requirements set out in Title III,  Chapter 2 of that Regulation shall be taken into account. 
__________ 
* Regulation (EU) YYY/XX [on Artificial Intelligence] (OJ …).”.
15698/22 RB/ek 178 TREE.2.B EN 
Article 81 
Amendment to Regulation (EU) 2018/1139 
Regulation (EU) 2018/1139 is amended as follows: 
(1) In Article 17, the following paragraph is added: 
“3. Without prejudice to paragraph 2, when adopting implementing acts pursuant to paragraph 1  concerning Artificial Intelligence systems which are safety components in the meaning of  Regulation (EU) YYY/XX [on Artificial Intelligence] of the European Parliament and of the  Council*, the requirements set out in Title III, Chapter 2 of that Regulation shall be taken into  account. 
__________ 
* Regulation (EU) YYY/XX [on Artificial Intelligence] (OJ …).” 
(2) In Article 19, the following paragraph is added: 
“4. When adopting delegated acts pursuant to paragraphs 1 and 2 concerning Artificial Intelligence  systems which are safety components in the meaning of Regulation (EU) YYY/XX [on Artificial  Intelligence], the requirements set out in Title III, Chapter 2 of that Regulation shall be taken into  account.” 
(3) In Article 43, the following paragraph is added: 
“4. When adopting implementing acts pursuant to paragraph 1 concerning Artificial Intelligence  systems which are safety components in the meaning of Regulation (EU) YYY/XX [on Artificial  Intelligence], the requirements set out in Title III, Chapter 2 of that Regulation shall be taken into  account.”
15698/22 RB/ek 179 TREE.2.B EN 
(4) In Article 47, the following paragraph is added: 
“3. When adopting delegated acts pursuant to paragraphs 1 and 2 concerning Artificial Intelligence  systems which are safety components in the meaning of Regulation (EU) YYY/XX [on Artificial  Intelligence], the requirements set out in Title III, Chapter 2 of that Regulation shall be taken into  account.” 
(5) In Article 57, the following paragraph is added: 
“When adopting those implementing acts concerning Artificial Intelligence systems which are  safety components in the meaning of Regulation (EU) YYY/XX [on Artificial Intelligence], the  requirements set out in Title III, Chapter 2 of that Regulation shall be taken into account.” 
(6) In Article 58, the following paragraph is added: 
“3. When adopting delegated acts pursuant to paragraphs 1 and 2 concerning Artificial Intelligence  systems which are safety components in the meaning of Regulation (EU) YYY/XX [on Artificial  Intelligence] , the requirements set out in Title III, Chapter 2 of that Regulation shall be taken into  account.”. 
Article 82 
Amendment to Regulation (EU) 2019/2144 
In Article 11 of Regulation (EU) 2019/2144, the following paragraph is added: 
“3. When adopting the implementing acts pursuant to paragraph 2, concerning artificial intelligence  systems which are safety components in the meaning of Regulation (EU) YYY/XX [on Artificial  Intelligence] of the European Parliament and of the Council*, the requirements set out in Title III,  Chapter 2 of that Regulation shall be taken into account. 
__________ 
* Regulation (EU) YYY/XX [on Artificial Intelligence] (OJ …).”.
15698/22 RB/ek 180 TREE.2.B EN 
Article 83 
AI systems already placed on the market or put into service 
1. This Regulation shall not apply to the AI systems which are components of the large-scale  IT systems established by the legal acts listed in Annex IX that have been placed on the  market or put into service before [12 months after the date of application of this  Regulation referred to in Article 85(2)], unless the replacement or amendment of those  legal acts leads to a significant change in the design or intended purpose of the AI system  or AI systems concerned. 
The requirements laid down in this Regulation shall be taken into account, where  applicable, in the evaluation of each large-scale IT systems established by the legal acts  listed in Annex IX to be undertaken as provided for in those respective acts. 
2. This Regulation shall apply to the high-risk AI systems, other than the ones referred to in  paragraph 1, that have been placed on the market or put into service before [date of  application of this Regulation referred to in Article 85(2)], only if, from that date, those  systems are subject to significant changes in their design or intended purpose.  
Article 84 
Evaluation and review 
1. [deleted]  
1b. The Commission shall assess the need for amendment of the list in Annex III every 24  months following the entry into force of this Regulation and until the end of the period of  the delegation of power. The findings of that assessment shall be presented to the European  Parliament and the Council.
15698/22 RB/ek 181 TREE.2.B EN 
2. By [three years after the date of application of this Regulation referred to in Article 85(2)]  and every four years thereafter, the Commission shall submit a report on the evaluation and  review of this Regulation to the European Parliament and to the Council. The reports shall  be made public.  
3. The reports referred to in paragraph 2 shall devote specific attention to the following: 
(a) the status of the financial resources, technical equipment and human resources of the  national competent authorities in order to effectively perform the tasks assigned to  them under this Regulation; 
(b) the state of penalties, and notably administrative fines as referred to in Article 71(1),  applied by Member States to infringements of the provisions of this Regulation. 
4. Within [three years after the date of application of this Regulation referred to in Article  85(2)] and every four years thereafter, where appropriate, the Commission shall evaluate  the impact and effectiveness of voluntary codes of conduct to foster the application of the  requirements set out in Title III, Chapter 2 for AI systems other than high-risk AI systems and possibly other additional requirements for AI systems, including as regards  environmental sustainability.  
5. For the purpose of paragraphs 1a to 4 the Board, the Member States and national  competent authorities shall provide the Commission with information on its request. 
6. In carrying out the evaluations and reviews referred to in paragraphs 1a to 4 the  Commission shall take into account the positions and findings of the Board, of the  European Parliament, of the Council, and of other relevant bodies or sources. 
7. The Commission shall, if necessary, submit appropriate proposals to amend this  Regulation, in particular taking into account developments in technology and in the light of  the state of progress in the information society.
15698/22 RB/ek 182 TREE.2.B EN 
Article 85 
Entry into force and application 
1. This Regulation shall enter into force on the twentieth day following that of its publication  in the Official Journal of the European Union. 
2. This Regulation shall apply from [36 months following the entering into force of the  Regulation]. 
3. By way of derogation from paragraph 2: 
(a) Title III, Chapter 4 and Title VI shall apply from [twelve months following the  entry into force of this Regulation]; 
(b) Article 71 shall apply from [twelve months following the entry into force of this  Regulation]. 
This Regulation shall be binding in its entirety and directly applicable in all Member States. Done at Brussels, 
For the European Parliament For the Council 
The President The President
15698/22 RB/ek 183 TREE.2.B EN 
ANNEX I [deleted] 
15698/22 RB/ek 184 TREE.2.B EN 
ANNEX II 
LIST OF UNION HARMONISATION LEGISLATION 
Section A – List of Union harmonisation legislation based on the New Legislative Framework 
1. Directive 2006/42/EC of the European Parliament and of the Council of 17 May 2006 on  machinery, and amending Directive 95/16/EC (OJ L 157, 9.6.2006, p. 24) [as repealed by  the Machinery Regulation]; 
2. Directive 2009/48/EC of the European Parliament and of the Council of 18 June 2009 on  the safety of toys (OJ L 170, 30.6.2009, p. 1); 
3. Directive 2013/53/EU of the European Parliament and of the Council of 20 November  2013 on recreational craft and personal watercraft and repealing Directive 94/25/EC (OJ L  354, 28.12.2013, p. 90); 
4. Directive 2014/33/EU of the European Parliament and of the Council of 26 February 2014  on the harmonisation of the laws of the Member States relating to lifts and safety  components for lifts (OJ L 96, 29.3.2014, p. 251); 
5. Directive 2014/34/EU of the European Parliament and of the Council of 26 February 2014  on the harmonisation of the laws of the Member States relating to equipment and  protective systems intended for use in potentially explosive atmospheres (OJ L 96,  29.3.2014, p. 309); 
6. Directive 2014/53/EU of the European Parliament and of the Council of 16 April 2014 on  the harmonisation of the laws of the Member States relating to the making available on the  market of radio equipment and repealing Directive 1999/5/EC (OJ L 153, 22.5.2014, p.  62); 
7. Directive 2014/68/EU of the European Parliament and of the Council of 15 May 2014 on  the harmonisation of the laws of the Member States relating to the making available on the  market of pressure equipment (OJ L 189, 27.6.2014, p. 164);
15698/22 RB/ek 185 TREE.2.B EN 
8. Regulation (EU) 2016/424 of the European Parliament and of the Council of 9 March 2016  on cableway installations and repealing Directive 2000/9/EC (OJ L 81, 31.3.2016, p. 1); 
9. Regulation (EU) 2016/425 of the European Parliament and of the Council of 9 March 2016  on personal protective equipment and repealing Council Directive 89/686/EEC (OJ L 81,  31.3.2016, p. 51); 
10. Regulation (EU) 2016/426 of the European Parliament and of the Council of 9 March 2016  on appliances burning gaseous fuels and repealing Directive 2009/142/EC (OJ L 81,  31.3.2016, p. 99); 
11. Regulation (EU) 2017/745 of the European Parliament and of the Council of 5 April 2017  on medical devices, amending Directive 2001/83/EC, Regulation (EC) No 178/2002 and  Regulation (EC) No 1223/2009 and repealing Council Directives 90/385/EEC and  93/42/EEC (OJ L 117, 5.5.2017, p. 1; 
12. Regulation (EU) 2017/746 of the European Parliament and of the Council of 5 April 2017  on in vitro diagnostic medical devices and repealing Directive 98/79/EC and Commission  Decision 2010/227/EU (OJ L 117, 5.5.2017, p. 176).
15698/22 RB/ek 186 TREE.2.B EN 
Section B. List of other Union harmonisation legislation 
1. Regulation (EC) No 300/2008 of the European Parliament and of the Council of 11 March  2008 on common rules in the field of civil aviation security and repealing Regulation (EC)  No 2320/2002 (OJ L 97, 9.4.2008, p. 72). 
2. Regulation (EU) No 168/2013 of the European Parliament and of the Council of 15  January 2013 on the approval and market surveillance of two- or three-wheel vehicles and  quadricycles (OJ L 60, 2.3.2013, p. 52); 
3. Regulation (EU) No 167/2013 of the European Parliament and of the Council of 5  February 2013 on the approval and market surveillance of agricultural and forestry  vehicles (OJ L 60, 2.3.2013, p. 1); 
4. Directive 2014/90/EU of the European Parliament and of the Council of 23 July 2014 on  marine equipment and repealing Council Directive 96/98/EC (OJ L 257, 28.8.2014, p.  146); 
5. Directive (EU) 2016/797 of the European Parliament and of the Council of 11 May 2016  on the interoperability of the rail system within the European Union (OJ L 138, 26.5.2016,  p. 44). 
6. Regulation (EU) 2018/858 of the European Parliament and of the Council of 30 May 2018  on the approval and market surveillance of motor vehicles and their trailers, and of  systems, components and separate technical units intended for such vehicles, amending  Regulations (EC) No 715/2007 and (EC) No 595/2009 and repealing Directive 2007/46/EC  (OJ L 151, 14.6.2018, p. 1); 
15698/22 RB/ek 187 TREE.2.B EN 
7. Regulation (EU) 2019/2144 of the European Parliament and of the Council of 27  November 2019 on type-approval requirements for motor vehicles and their trailers, and  systems, components and separate technical units intended for such vehicles, as regards  their general safety and the protection of vehicle occupants and vulnerable road users,  amending Regulation (EU) 2018/858 of the European Parliament and of the Council and  repealing Regulations (EC) No 78/2009, (EC) No 79/2009 and (EC) No 661/2009 of the  European Parliament and of the Council and Commission Regulations (EC) No 631/2009,  (EU) No 406/2010, (EU) No 672/2010, (EU) No 1003/2010, (EU) No 1005/2010, (EU) No  1008/2010, (EU) No 1009/2010, (EU) No 19/2011, (EU) No 109/2011, (EU) No 458/2011,  (EU) No 65/2012, (EU) No 130/2012, (EU) No 347/2012, (EU) No 351/2012, (EU) No  1230/2012 and (EU) 2015/166 (OJ L 325, 16.12.2019, p. 1); 
8. Regulation (EU) 2018/1139 of the European Parliament and of the Council of 4 July 2018  on common rules in the field of civil aviation and establishing a European Union Aviation  Safety Agency, and amending Regulations (EC) No 2111/2005, (EC) No 1008/2008, (EU)  No 996/2010, (EU) No 376/2014 and Directives 2014/30/EU and 2014/53/EU of the  
European Parliament and of the Council, and repealing Regulations (EC) No 552/2004 and  (EC) No 216/2008 of the European Parliament and of the Council and Council Regulation  (EEC) No 3922/91 (OJ L 212, 22.8.2018, p. 1), in so far as the design, production and  placing on the market of aircrafts referred to in points (a) and (b) of Article 2(1) thereof,  where it concerns unmanned aircraft and their engines, propellers, parts and equipment to  control them remotely, are concerned.
15698/22 RB/ek 188 TREE.2.B EN 
ANNEX III 
HIGH-RISK AI SYSTEMS REFERRED TO IN ARTICLE 6(3) 
In each of the areas listed under points 1-8, the AI systems specifically mentioned under each letter  are considered to be high-risk AI systems pursuant to Article 6(3): 
1. Biometrics: 
(a) Remote biometric identification systems. 
2. Critical infrastructure: 
(a) AI systems intended to be used as safety components in the management and  operation of critical digital infrastructure, road traffic and the supply of water, gas,  heating and electricity. 
3. Education and vocational training: 
(a) AI systems intended to be used to determine access, admission or to assign natural  persons to educational and vocational training institutions or programmes at all  levels;  
(b) AI systems intended to be used to evaluate learning outcomes, including when those  outcomes are used to steer the learning process of natural persons in educational and  vocational training institutions or programmes at all levels. 
4. Employment, workers management and access to self-employment: 
(a) AI systems intended to be used for recruitment or selection of natural persons, notably to place targeted job advertisements, to analyse and filter job applications,  and to evaluate candidates; 
15698/22 RB/ek 189 TREE.2.B EN 
(b) AI intended to be used to make decisions on promotion and termination of work related contractual relationships, to allocate tasks based on individual behavior or  personal traits or characteristics and to monitor and evaluate performance and  behavior of persons in such relationships. 
5. Access to and enjoyment of essential private services and essential public services and  benefits: 
(a) AI systems intended to be used by public authorities or on behalf of public  authorities to evaluate the eligibility of natural persons for essential public assistance  benefits and services, as well as to grant, reduce, revoke, or reclaim such benefits and  services; 
(b) AI systems intended to be used to evaluate the creditworthiness of natural persons or  establish their credit score, with the exception of AI systems put into service by  providers that are micro and small-sized enterprises as defined in the Annex of  Commission Recommendation 2003/361/EC for their own use; 
(c) AI systems intended to be used to dispatch, or to establish priority in the dispatching  of emergency first response services, including by firefighters and medical aid; 
(d) AI systems intended to be used for risk assessment and pricing in relation to natural  persons in the case of life and health insurance with the exception of AI systems put  into service by providers that are micro and small-sized enterprises as defined in the  Annex of Commission Recommendation 2003/361/EC for their own use. 
6. Law enforcement: 
(a) AI systems intended to be used by law enforcement authorities or on their behalf to  assess the risk of a natural person for offending or reoffending or the risk for a  natural person to become a potential victim of criminal offences;
15698/22 RB/ek 190 TREE.2.B EN 
(b) AI systems intended to be used by law enforcement authorities or on their behalf as  polygraphs and similar tools or to detect the emotional state of a natural person; 
(c) [deleted]  
(d) AI systems intended to be used by law enforcement authorities or on their behalf to  evaluate the reliability of evidence in the course of investigation or prosecution of  criminal offences; 
(e) AI systems intended to be used by law enforcement authorities or on their behalf to  predict the occurrence or reoccurrence of an actual or potential criminal offence  based on profiling of natural persons as referred to in Article 3(4) of Directive (EU)  2016/680 or to assess personality traits and characteristics or past criminal behaviour  of natural persons or groups; 
(f) AI systems intended to be used by law enforcement authorities or on their behalf to  profile natural persons as referred to in Article 3(4) of Directive (EU) 2016/680 in  the course of detection, investigation or prosecution of criminal offences. 
(g) [deleted]  
7. Migration, asylum and border control management: 
(a) AI systems intended to be used by competent public authorities or on their behalf as  polygraphs and similar tools or to detect the emotional state of a natural person; 
(b) AI systems intended to be used by competent public authorities or on their behalf to  assess a risk, including a security risk, a risk of irregular migration, or a health risk,  posed by a natural person who intends to enter or has entered into the territory of a  Member State; 
15698/22 RB/ek 191 TREE.2.B EN 
(c) [deleted]  
(d) AI systems intended to be used by competent public authorities or on their behalf to  examine applications for asylum, visa and residence permits and associated  complaints with regard to the eligibility of the natural persons applying for a status. 
8. Administration of justice and democratic processes: 
(a) AI systems intended to be used by a judicial authority or on their behalf to interpret  facts or the law and to apply the law to a concrete set of facts.
15698/22 RB/ek 192 TREE.2.B EN 
ANNEX IV 
TECHNICAL DOCUMENTATION referred to in Article 11(1) 
The technical documentation referred to in Article 11(1) shall contain at least the following  information, as applicable to the relevant AI system: 
1. A general description of the AI system including: 
(a) its intended purpose, the person/s developing the system the date and the version of  the system; 
(b) how the AI system interacts or can be used to interact with hardware or software that  is not part of the AI system itself, where applicable; 
(c) the versions of relevant software or firmware and any requirement related to version  update; 
(d) the description of all forms in which the AI system is placed on the market or put  into service (e.g. software package embedded into hardware, downloadable, API  etc.); 
(e) the description of hardware on which the AI system is intended to run; 
(f) where the AI system is a component of products, photographs or illustrations  showing external features, marking and internal layout of those products; 
(g) instructions of use for the user and, where applicable installation instructions; 
2. A detailed description of the elements of the AI system and of the process for its  development, including: 
(a) the methods and steps performed for the development of the AI system, including,  where relevant, recourse to pre-trained systems or tools provided by third parties and  how these have been used, integrated or modified by the provider;
15698/22 RB/ek 193 TREE.2.B EN 
(b) the design specifications of the system, namely the general logic of the AI system  and of the algorithms; the key design choices including the rationale and assumptions  made, also with regard to persons or groups of persons on which the system is  intended to be used; the main classification choices; what the system is designed to  optimise for and the relevance of the different parameters; the description of the  expected output of the system; the decisions about any possible trade-off made  regarding the technical solutions adopted to comply with the requirements set out in  Title III, Chapter 2; 
(c) the description of the system architecture explaining how software components build  on or feed into each other and integrate into the overall processing; the computational  resources used to develop, train, test and validate the AI system; 
(d) where relevant, the data requirements in terms of datasheets describing the training  methodologies and techniques and the training data sets used, including a general  description of these data sets, information about their provenance, scope and main  characteristics; how the data was obtained and selected; labelling procedures (e.g. for  supervised learning), data cleaning methodologies (e.g. outliers detection); 
(e) assessment of the human oversight measures needed in accordance with Article 14,  including an assessment of the technical measures needed to facilitate the  interpretation of the outputs of AI systems by the users, in accordance with Articles  13(3)(d); 
(f) where applicable, a detailed description of pre-determined changes to the AI system  and its performance, together with all the relevant information related to the technical  solutions adopted to ensure continuous compliance of the AI system with the  relevant requirements set out in Title III, Chapter 2;
15698/22 RB/ek 194 TREE.2.B EN 
(g) the validation and testing procedures used, including information about the validation  and testing data used and their main characteristics; metrics used to measure  accuracy, robustness, cybersecurity and compliance with other relevant requirements  set out in Title III, Chapter 2 as well as potentially discriminatory impacts; test logs  and all test reports dated and signed by the responsible persons, including with  regard to pre-determined changes as referred to under point (f). 
3. Detailed information about the monitoring, functioning and control of the AI system, in  particular with regard to: its capabilities and limitations in performance, including the  degrees of accuracy for specific persons or groups of persons on which the system is  intended to be used and the overall expected level of accuracy in relation to its intended  purpose; the foreseeable unintended outcomes and sources of risks to health and safety,  fundamental rights and discrimination in view of the intended purpose of the AI system;  the human oversight measures needed in accordance with Article 14, including the  technical measures put in place to facilitate the interpretation of the outputs of AI systems  by the users; specifications on input data, as appropriate; 
4. A detailed description of the risk management system in accordance with Article 9; 5. A description of relevant changes made by the provider to the system through its lifecycle; 
6. A list of the harmonised standards applied in full or in part the references of which have  been published in the Official Journal of the European Union; where no such harmonised  standards have been applied, a detailed description of the solutions adopted to meet the  requirements set out in Title III, Chapter 2, including a list of other relevant standards and  technical specifications applied; 
7. A copy of the EU declaration of conformity; 
8. A detailed description of the system in place to evaluate the AI system performance in the  post-market phase in accordance with Article 61, including the post-market monitoring  plan referred to in Article 61(3).
15698/22 RB/ek 195 TREE.2.B EN 
ANNEX V 
EU DECLARATION OF CONFORMITY 
The EU declaration of conformity referred to in Article 48, shall contain all of the following  information: 
1. AI system name and type and any additional unambiguous reference allowing  identification and traceability of the AI system; 
2. Name and address of the provider or, where applicable, their authorised representative; 
3. A statement that the EU declaration of conformity is issued under the sole responsibility of  the provider; 
4. A statement that the AI system in question is in conformity with this Regulation and, if  applicable, with any other relevant Union legislation that provides for the issuing of an EU  declaration of conformity; 
5. References to any relevant harmonised standards used or any other common specification  in relation to which conformity is declared; 
6. Where applicable, the name and identification number of the notified body, a description  of the conformity assessment procedure performed and identification of the certificate  issued; 
7. Place and date of issue of the declaration, name and function of the person who signed it as  well as an indication for, and on behalf of whom, that person signed, signature.
15698/22 RB/ek 196 TREE.2.B EN 
ANNEX VI 
CONFORMITY ASSESSMENT PROCEDURE BASED ON INTERNAL CONTROL 
1. The conformity assessment procedure based on internal control is the conformity  assessment procedure based on points 2 to 4. 
2. The provider verifies that the established quality management system is in compliance with  the requirements of Article 17.  
3. The provider examines the information contained in the technical documentation in order  to assess the compliance of the AI system with the relevant essential requirements set out  in Title III, Chapter 2. 
4. The provider also verifies that the design and development process of the AI system and its  post-market monitoring as referred to in Article 61 is consistent with the technical  documentation.
15698/22 RB/ek 197 TREE.2.B EN 
ANNEX VII 
CONFORMITY BASED ON ASSESSMENT OF QUALITY MANAGEMENT SYSTEM  AND ASSESSMENT OF TECHNICAL DOCUMENTATION 
1. Introduction 
Conformity based on assessment of quality management system and assessment of the  technical documentation is the conformity assessment procedure based on points 2 to 5.  
2. Overview 
The approved quality management system for the design, development and testing of AI  systems pursuant to Article 17 shall be examined in accordance with point 3 and shall be  subject to surveillance as specified in point 5. The technical documentation of the AI  system shall be examined in accordance with point 4. 
3. Quality management system 
3.1. The application of the provider shall include: 
(a) the name and address of the provider and, if the application is lodged by the  authorised representative, their name and address as well; 
(b) the list of AI systems covered under the same quality management system; 
(c) the technical documentation for each AI system covered under the same quality  management system; 
(d) the documentation concerning the quality management system which shall cover all  the aspects listed under Article 17;
15698/22 RB/ek 198 TREE.2.B EN 
(e) a description of the procedures in place to ensure that the quality management system  remains adequate and effective; 
(f) a written declaration that the same application has not been lodged with any other  notified body. 
3.2. The quality management system shall be assessed by the notified body, which shall  determine whether it satisfies the requirements referred to in Article 17. 
The decision shall be notified to the provider or its authorised representative. 
The notification shall contain the conclusions of the assessment of the quality management  system and the reasoned assessment decision. 
3.3. The quality management system as approved shall continue to be implemented and  maintained by the provider so that it remains adequate and efficient. 
3.4. Any intended change to the approved quality management system or the list of AI systems  covered by the latter shall be brought to the attention of the notified body by the provider. 
The proposed changes shall be examined by the notified body, which shall decide whether  the modified quality management system continues to satisfy the requirements referred to  in point 3.2 or whether a reassessment is necessary. 
The notified body shall notify the provider of its decision. The notification shall contain  the conclusions of the examination of the changes and the reasoned assessment decision. 
4. Control of the technical documentation. 
4.1. In addition to the application referred to in point 3, an application with a notified body of  their choice shall be lodged by the provider for the assessment of the technical  documentation relating to the AI system which the provider intends to place on the market  or put into service and which is covered by the quality management system referred to  under point 3.
15698/22 RB/ek 199 TREE.2.B EN 
4.2. The application shall include: 
(a) the name and address of the provider; 
(b) a written declaration that the same application has not been lodged with any other  notified body; 
(c) the technical documentation referred to in Annex IV. 
4.3. The technical documentation shall be examined by the notified body. Where relevant and  limited to what is necessary to fulfil their tasks, the notified body shall be granted full  access to the training, validation, and testing datasets used, including, where appropriate  and subject to security safeguards, through application programming interfaces (API) or  other relevant technical means and tools enabling remote access. 
4.4. In examining the technical documentation, the notified body may require that the provider  supplies further evidence or carries out further tests so as to enable a proper assessment of  conformity of the AI system with the requirements set out in Title III, Chapter 2.  Whenever the notified body is not satisfied with the tests carried out by the provider, the  notified body shall directly carry out adequate tests, as appropriate.  
4.5. Notified bodies shall be granted access to the source code of the AI system upon a  reasoned request and only when the following cumulative conditions are fulfilled:  
a) Access to source code is necessary to assess the conformity of the high-risk AI system  with the requirements set out in Title III, Chapter 2, and  
b) testing/auditing procedures and verifications based on the data and documentation  provided by the provider have been exhausted or proved insufficient. 
15698/22 RB/ek 200 TREE.2.B EN 
4.6. The decision shall be notified to the provider or its authorised representative. The  notification shall contain the conclusions of the assessment of the technical documentation  and the reasoned assessment decision. 
Where the AI system is in conformity with the requirements set out in Title III, Chapter 2,  an EU technical documentation assessment certificate shall be issued by the notified body.  The certificate shall indicate the name and address of the provider, the conclusions of the  examination, the conditions (if any) for its validity and the data necessary for the  identification of the AI system. 
The certificate and its annexes shall contain all relevant information to allow the  conformity of the AI system to be evaluated, and to allow for control of the AI system  while in use, where applicable. 
Where the AI system is not in conformity with the requirements set out in Title III, Chapter  2, the notified body shall refuse to issue an EU technical documentation assessment  certificate and shall inform the applicant accordingly, giving detailed reasons for its  refusal. 
Where the AI system does not meet the requirement relating to the data used to train it, re training of the AI system will be needed prior to the application for a new conformity  assessment. In this case, the reasoned assessment decision of the notified body refusing to  issue the EU technical documentation assessment certificate shall contain specific  considerations on the quality data used to train the AI system, notably on the reasons for  non-compliance.
15698/22 RB/ek 201 TREE.2.B EN 
4.7. Any change to the AI system that could affect the compliance of the AI system with the  requirements or its intended purpose shall be approved by the notified body which issued  the EU technical documentation assessment certificate. The provider shall inform such  notified body of its intention to introduce any of the above-mentioned changes or if it  becomes otherwise aware of the occurrence of such changes. The intended changes shall  be assessed by the notified body which shall decide whether those changes require a new  conformity assessment in accordance with Article 43(4) or whether they could be  addressed by means of a supplement to the EU technical documentation assessment  certificate. In the latter case, the notified body shall assess the changes, notify the provider  of its decision and, where the changes are approved, issue to the provider a supplement to  the EU technical documentation assessment certificate. 
5. Surveillance of the approved quality management system. 
5.1. The purpose of the surveillance carried out by the notified body referred to in Point 3 is to  make sure that the provider duly fulfils the terms and conditions of the approved quality  management system. 
5.2. For assessment purposes, the provider shall allow the notified body to access the premises  where the design, development, testing of the AI systems is taking place. The provider  shall further share with the notified body all necessary information. 
5.3. The notified body shall carry out periodic audits to make sure that the provider maintains  and applies the quality management system and shall provide the provider with an audit  report. In the context of those audits, the notified body may carry out additional tests of the  AI systems for which an EU technical documentation assessment certificate was issued.
15698/22 RB/ek 202 TREE.2.B EN 
ANNEX VIII 
INFORMATION TO BE SUBMITTED UPON THE REGISTRATION OF OPERATORS  AND HIGH-RISK AI SYSTEMS IN ACCORDANCE WITH ARTICLE 51 
Providers, authorised representatives and users that are public authorities, agencies or bodies shall  submit the information referred to in Part I. Providers or, when applicable, authorised  representatives shall ensure that the information on their high-risk AI systems referred to in Part II,  1 to 11 is complete, correct and kept up-to-date. Information laid down in II.12 shall be  automatically generated by the database. 
Part I. Information related to operators (upon operators’registration) 
-1. Type of operator (provider, authorised representative or user); 
1. Name, address and contact details of the provider; 
2. Where submission of information is carried out by another person on behalf of the  operator, the name, address and contact details of that person; 
Part II. Information related to the high-risk AI system 
1. Name, address and contact details of the provider 
2. Name, address and contact details of the authorised representative, where applicable; 
3. AI system trade name and any additional unambiguous reference allowing identification  and traceability of the AI system; 
4. Description of the intended purpose of the AI system;  
5. Status of the AI system (on the market, or in service; no longer placed on the market/in  service, recalled); 
6. Type, number and expiry date of the certificate issued by the notified body and the name or  identification number of that notified body, when applicable;
15698/22 RB/ek 203 TREE.2.B EN 
7. A scanned copy of the certificate referred to in point 6, when applicable; 
8. Member States in which the AI system is or has been placed on the market, put into service  or made available in the Union; 
9. A copy of the EU declaration of conformity referred to in Article 48; 10. Electronic instructions for use; 
11. URL for additional information (optional). 
12. Name, address and contact details of users
15698/22 RB/ek 204 TREE.2.B EN 
ANNEX VIIIa 
INFORMATION TO BE SUBMITTED UPON THE REGISTRATION OF HIGH-RISK AI  SYSTEMS LISTED IN ANNEX III IN RELATION TO TESTING IN REAL WORLD CONDITIONS  IN ACCORDANCE WITH ARTICLE 54a 
The following information shall be provided and thereafter kept up to date with regard to testing in  real world conditions to be registered in accordance with Article 54a: 
1. Union-wide unique single identification number of the testing in real world conditions; 
2. Name and contact details of the provider or prospective provider and users involved in the testing  in real world conditions; 
3. A brief description of the AI system, its intended purpose and other information necessary for the  identification of the system; 
4. A summary of the main characteristics of the plan for testing in real world conditions; 5. Information on the suspension or termination of the testing in real world conditions.
15698/22 RB/ek 205 TREE.2.B EN 
ANNEX IX 
UNION LEGISLATION ON LARGE-SCALE IT SYSTEMS IN THE AREA OF FREEDOM,  SECURITY AND JUSTICE 
1. Schengen Information System 
(a) Regulation (EU) 2018/1860 of the European Parliament and of the Council of 28  November 2018 on the use of the Schengen Information System for the return of  illegally staying third-country nationals (OJ L 312, 7.12.2018, p. 1). 
(b) Regulation (EU) 2018/1861 of the European Parliament and of the Council of 28  November 2018 on the establishment, operation and use of the Schengen Information  System (SIS) in the field of border checks, and amending the Convention  
implementing the Schengen Agreement, and amending and repealing Regulation  (EC) No 1987/2006 (OJ L 312, 7.12.2018, p. 14) 
(c) Regulation (EU) 2018/1862 of the European Parliament and of the Council of 28  November 2018 on the establishment, operation and use of the Schengen Information  System (SIS) in the field of police cooperation and judicial cooperation in criminal  matters, amending and repealing Council Decision 2007/533/JHA, and repealing  Regulation (EC) No 1986/2006 of the European Parliament and of the Council and  Commission Decision 2010/261/EU (OJ L 312, 7.12.2018, p. 56). 
2. Visa Information System 
(a) Proposal for a REGULATION OF THE EUROPEAN PARLIAMENT AND OF  THE COUNCIL amending Regulation (EC) No 767/2008, Regulation (EC) No  810/2009, Regulation (EU) 2017/2226, Regulation (EU) 2016/399, Regulation  XX/2018 [Interoperability Regulation], and Decision 2004/512/EC and repealing  Council Decision 2008/633/JHA - COM(2018) 302 final. To be updated once the  Regulation is adopted (April/May 2021) by the co-legislators.
15698/22 RB/ek 206 TREE.2.B EN 
3. Eurodac 
(a) Amended proposal for a REGULATION OF THE EUROPEAN PARLIAMENT  AND OF THE COUNCIL on the establishment of 'Eurodac' for the comparison of  biometric data for the effective application of Regulation (EU) XXX/XXX  
[Regulation on Asylum and Migration Management] and of Regulation (EU)  XXX/XXX [Resettlement Regulation], for identifying an illegally staying third country national or stateless person and on requests for the comparison with Eurodac  data by Member States' law enforcement authorities and Europol for law  
enforcement purposes and amending Regulations (EU) 2018/1240 and (EU)  2019/818 – COM(2020) 614 final.  
4. Entry/Exit System 
(a) Regulation (EU) 2017/2226 of the European Parliament and of the Council of 30  November 2017 establishing an Entry/Exit System (EES) to register entry and exit  data and refusal of entry data of third-country nationals crossing the external borders  of the Member States and determining the conditions for access to the EES for law  enforcement purposes, and amending the Convention implementing the Schengen  Agreement and Regulations (EC) No 767/2008 and (EU) No 1077/2011 (OJ L 327,  9.12.2017, p. 20). 
5. European Travel Information and Authorisation System 
(a) Regulation (EU) 2018/1240 of the European Parliament and of the Council of 12  September 2018 establishing a European Travel Information and Authorisation  System (ETIAS) and amending Regulations (EU) No 1077/2011, (EU) No 515/2014,  (EU) 2016/399, (EU) 2016/1624 and (EU) 2017/2226 (OJ L 236, 19.9.2018, p. 1).  
(b) Regulation (EU) 2018/1241 of the European Parliament and of the Council of 12  September 2018 amending Regulation (EU) 2016/794 for the purpose of establishing  a European Travel Information and Authorisation System (ETIAS) (OJ L 236,  19.9.2018, p. 72).
15698/22 RB/ek 207 TREE.2.B EN 
6. European Criminal Records Information System on third-country nationals and stateless  persons 
(a) Regulation (EU) 2019/816 of the European Parliament and of the Council of 17 April  2019 establishing a centralised system for the identification of Member States  holding conviction information on third-country nationals and stateless persons  (ECRIS-TCN) to supplement the European Criminal Records Information System  and amending Regulation (EU) 2018/1726 (OJ L 135, 22.5.2019, p. 1).  
7. Interoperability  
(a) Regulation (EU) 2019/817 of the European Parliament and of the Council of 20 May  2019 on establishing a framework for interoperability between EU information  systems in the field of borders and visa (OJ L 135, 22.5.2019, p. 27). 
(b) Regulation (EU) 2019/818 of the European Parliament and of the Council of 20 May  2019 on establishing a framework for interoperability between EU information  systems in the field of police and judicial cooperation, asylum and migration (OJ L  135, 22.5.2019, p. 85). 
______________
15698/22 RB/ek 208 TREE.2.B EN