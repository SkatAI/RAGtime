[
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"1",
        "uuid":"74cbca2f-0277-4ad1-8ce9-19e5a9073e0a",
        "path":"1. CONTEXT OF THE PROPOSAL",
        "header":true,
        "text":"1. CONTEXT OF THE PROPOSAL"
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"1",
        "uuid":"443fc2f4-37ae-4504-b61a-d1cbc23b7bfc",
        "path":"1. CONTEXT OF THE PROPOSAL >> 1.1. Reasons for and objectives of the proposal",
        "header":true,
        "text":"1.1. Reasons for and objectives of the proposal"
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"2",
        "uuid":"aafbf33f-e5b9-44ed-98de-34e5d0e1974a",
        "path":"1. CONTEXT OF THE PROPOSAL >> 1.1. Reasons for and objectives of the proposal",
        "header":false,
        "text":"This explanatory memorandum accompanies the proposal for a Regulation laying down harmonised rules on artificial intelligence (Artificial Intelligence Act). Artificial Intelligence (AI) is a fast evolving family of technologies that can bring a wide array of economic and societal benefits across the entire spectrum of industries and social activities. By improving prediction, optimising operations and resource allocation, and personalising service delivery, the use of artificial intelligence can support socially and environmentally beneficial outcomes and provide key competitive advantages to companies and the European economy. Such action is especially needed in high-impact sectors, including climate change, environment and health, the public sector, finance, mobility, home affairs and agriculture. However, the same elements and techniques that power the socio-economic benefits of AI can also bring about new risks or negative consequences for individuals or the society. In light of the speed of technological change and possible challenges, the EU is committed to strive for a balanced approach. It is in the Union interest to preserve the EU's technological leadership and to ensure that Europeans can benefit from new technologies developed and functioning according to Union values, fundamental rights and principles."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"3",
        "uuid":"67a2676e-a9f5-442e-b79c-a90fafd1d89a",
        "path":"1. CONTEXT OF THE PROPOSAL >> 1.1. Reasons for and objectives of the proposal",
        "header":false,
        "text":"This proposal delivers on the political commitment by President von der Leyen, who announced in her political guidelines for the 2019-2024 Commission “A Union that strives for more” 1 , that the Commission would put forward legislation for a coordinated European approach on the human and ethical implications of AI. Following on that announcement, on 19 February 2020 the Commission published the White Paper on AI - A European approach to excellence and trust 2. The White Paper sets out policy options on how to achieve the twin objective of promoting the uptake of AI and of addressing the risks associated with certain uses of such technology. This proposal aims to implement the second objective for the development of an ecosystem of trust by proposing a legal framework for trustworthy AI. The proposal is based on EU values and fundamental rights and aims to give people and other users the confidence to embrace AI-based solutions, while encouraging businesses to develop them. AI should be a tool for people and be a force for good in society with the ultimate aim of increasing human well-being. Rules for AI available in the Union market or otherwise affecting people in the Union should therefore be human centric, so that people can trust that the technology is used in a way that is safe and compliant with the law, including the respect of fundamental rights. Following the publication of the White Paper, the Commission launched a broad stakeholder consultation, which was met with a great interest by a large number of stakeholders who were largely supportive of regulatory intervention to address the challenges and concerns raised by the increasing use of AI."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"4",
        "uuid":"d5da3515-11c6-48c4-a3e1-2fb77bd0b4b3",
        "path":"1. CONTEXT OF THE PROPOSAL >> 1.1. Reasons for and objectives of the proposal",
        "header":false,
        "text":"The proposal also responds to explicit requests from the European Parliament (EP) and the European Council, which have repeatedly expressed calls for legislative action to ensure a well-functioning internal market for artificial intelligence systems ('AI systems') where both benefits and risks of AI are adequately addressed at Union level. It supports the objective of the Union being a global leader in the development of secure, trustworthy and ethical artificial intelligence as stated by the European Council 3 and ensures the protection of ethical principles as specifically requested by the European Parliament 4."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"5",
        "uuid":"94939363-4a8c-4953-bf83-3167ce9dc38c",
        "path":"1. CONTEXT OF THE PROPOSAL >> 1.1. Reasons for and objectives of the proposal",
        "header":false,
        "text":"In 2017, the European Council called for a 'sense of urgency to address emerging trends' including 'issues such as artificial intelligence ..., while at the same time ensuring a high level of data protection, digital rights and ethical standards' 5. In its 2019 Conclusions on the Coordinated Plan on the development and use of artificial intelligence Made in Europe 6 , the Council further highlighted the importance of ensuring that European citizens' rights are fully respected and called for a review of the existing relevant legislation to make it fit for purpose for the new opportunities and challenges raised by AI. The European Council has also called for a clear determination of the AI applications that should be considered high-risk 7."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"6",
        "uuid":"cdeb5a90-88db-4ec4-81db-b1cf55d2577c",
        "path":"1. CONTEXT OF THE PROPOSAL >> 1.1. Reasons for and objectives of the proposal",
        "header":false,
        "text":"The most recent Conclusions from 21 October 2020 further called for addressing the opacity, complexity, bias, a certain degree of unpredictability and partially autonomous behaviour of certain AI systems, to ensure their compatibility with fundamental rights and to facilitate the enforcement of legal rules 8."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"7",
        "uuid":"334246df-4945-40fe-a0e6-1e07a6155583",
        "path":"1. CONTEXT OF THE PROPOSAL >> 1.1. Reasons for and objectives of the proposal",
        "header":false,
        "text":"The European Parliament has also undertaken a considerable amount of work in the area of AI. In October 2020, it adopted a number of resolutions related to AI, including on ethics 9 , liability 10 and copyright 11. In 2021, those were followed by resolutions on AI in criminal matters 12 and in education, culture and the audio-visual sector 13. The EP Resolution on a Framework of Ethical Aspects of Artificial Intelligence, Robotics and Related Technologies specifically recommends to the Commission to propose legislative action to harness the opportunities and benefits of AI, but also to ensure protection of ethical principles. The resolution includes a text of the legislative proposal for a regulation on ethical principles for the development, deployment and use of AI, robotics and related technologies. In accordance with the political commitment made by President von der Leyen in her Political Guidelines as regards resolutions adopted by the European Parliament under Article 225 TFEU, this proposal takes into account the aforementioned resolution of the European Parliament in full respect of proportionality, subsidiarity and better law making principles."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"8",
        "uuid":"8b4d5cbe-7f76-4952-8e1a-c1b0c259762f",
        "path":"1. CONTEXT OF THE PROPOSAL >> 1.1. Reasons for and objectives of the proposal",
        "header":false,
        "text":"Against this political context, the Commission puts forward the proposed regulatory framework on Artificial Intelligence with the following specific objectives: - ensure that AI systems placed on the Union market and used are safe and respect existing law on fundamental rights and Union values; - ensure legal certainty to facilitate investment and innovation in AI; - enhance governance and effective enforcement of existing law on fundamental rights and safety requirements applicable to AI systems; - facilitate the development of a single market for lawful, safe and trustworthy AI applications and prevent market fragmentation."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"9",
        "uuid":"9bc89039-25bd-4bcb-bce3-5ee3e31201ee",
        "path":"1. CONTEXT OF THE PROPOSAL >> 1.1. Reasons for and objectives of the proposal",
        "header":false,
        "text":"To achieve those objectives, this proposal presents a balanced and proportionate horizontal regulatory approach to AI that is limited to the minimum necessary requirements to address the risks and problems linked to AI, without unduly constraining or hindering technological development or otherwise disproportionately increasing the cost of placing AI solutions on the market. The proposal sets a robust and flexible legal framework. On the one hand, it is comprehensive and future-proof in its fundamental regulatory choices, including the principle-based requirements that AI systems should comply with. On the other hand, it puts in place a proportionate regulatory system centred on a well-defined risk-based regulatory approach that does not create unnecessary restrictions to trade, whereby legal intervention is tailored to those concrete situations where there is a justified cause for concern or where such concern can reasonably be anticipated in the near future. At the same time, the legal framework includes flexible mechanisms that enable it to be dynamically adapted as the technology evolves and new concerning situations emerge."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"10",
        "uuid":"dcb54152-7a51-4492-bb57-547cda0230cb",
        "path":"1. CONTEXT OF THE PROPOSAL >> 1.1. Reasons for and objectives of the proposal",
        "header":false,
        "text":"The proposal sets harmonised rules for the development, placement on the market and use of AI systems in the Union following a proportionate risk-based approach. It proposes a single future-proof definition of AI. Certain particularly harmful AI practices are prohibited as contravening Union values, while specific restrictions and safeguards are proposed in relation to certain uses of remote biometric identification systems for the purpose of law enforcement. The proposal lays down a solid risk methodology to define “high-risk” AI systems that pose significant risks to the health and safety or fundamental rights of persons. Those AI systems will have to comply with a set of horizontal mandatory requirements for trustworthy AI and follow conformity assessment procedures before those systems can be placed on the Union market. Predictable, proportionate and clear obligations are also placed on providers and users of those systems to ensure safety and respect of existing legislation protecting fundamental rights throughout the whole AI systems' lifecycle. For some specific AI systems, only minimum transparency obligations are proposed, in particular when chatbots or 'deep fakes' are used."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"11",
        "uuid":"45795615-f647-405d-a09b-57db0c802b0d",
        "path":"1. CONTEXT OF THE PROPOSAL >> 1.1. Reasons for and objectives of the proposal",
        "header":false,
        "text":"The proposed rules will be enforced through a governance system at Member States level, building on already existing structures, and a cooperation mechanism at Union level with the establishment of a European Artificial Intelligence Board. Additional measures are also proposed to support innovation, in particular through AI regulatory sandboxes and other measures to reduce the regulatory burden and to support Small and Medium-Sized Enterprises ('SMEs') and start-ups."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"11",
        "uuid":"6e1c0601-10a5-4746-bb05-86a9ca3eda5d",
        "path":"1. CONTEXT OF THE PROPOSAL >> 1.2. Consistency with existing policy provisions in the policy area",
        "header":true,
        "text":"1.2. Consistency with existing policy provisions in the policy area"
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"12",
        "uuid":"be4b202d-85e7-41a3-b945-d224cd9df36c",
        "path":"1. CONTEXT OF THE PROPOSAL >> 1.2. Consistency with existing policy provisions in the policy area",
        "header":false,
        "text":"The horizontal nature of the proposal requires full consistency with existing Union legislation applicable to sectors where high-risk AI systems are already used or likely to be used in the near future."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"13",
        "uuid":"5ced4823-7c51-461f-9496-ad361c2dfbf1",
        "path":"1. CONTEXT OF THE PROPOSAL >> 1.2. Consistency with existing policy provisions in the policy area",
        "header":false,
        "text":"Consistency is also ensured with the EU Charter of Fundamental Rights and the existing secondary Union legislation on data protection, consumer protection, non-discrimination and gender equality. The proposal is without prejudice and complements the General Data Protection Regulation (Regulation (EU) 2016\/679) and the Law Enforcement Directive (Directive (EU) 2016\/680) with a set of harmonised rules applicable to the design, development and use of certain high-risk AI systems and restrictions on certain uses of remote biometric identification systems. Furthermore, the proposal complements existing Union law on non-discrimination with specific requirements that aim to minimise the risk of algorithmic discrimination, in particular in relation to the design and the quality of data sets used for the development of AI systems complemented with obligations for testing, risk management, documentation and human oversight throughout the AI systems' lifecycle. The proposal is without prejudice to the application of Union competition law."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"14",
        "uuid":"fb56cdb1-43ef-46bc-99de-c4f3bbeb7d42",
        "path":"1. CONTEXT OF THE PROPOSAL >> 1.2. Consistency with existing policy provisions in the policy area",
        "header":false,
        "text":"As regards high-risk AI systems which are safety components of products, this proposal will be integrated into the existing sectoral safety legislation to ensure consistency, avoid duplications and minimise additional burdens. In particular, as regards high-risk AI systems related to products covered by the New Legislative Framework (NLF) legislation (e.g. machinery, medical devices, toys) , the requirements for AI systems set out in this proposal will be checked as part of the existing conformity assessment procedures under the relevant NLF legislation. With regard to the interplay of requirements, while the safety risks specific to AI systems are meant to be covered by the requirements of this proposal, NLF legislation aims at ensuring the overall safety of the final product and therefore may contain specific requirements regarding the safe integration of an AI system into the final product. The proposal for a Machinery Regulation, which is adopted on the same day as this proposal fully reflects this approach. As regards high-risk AI systems related to products covered by relevant Old Approach legislation (e.g. aviation, cars) , this proposal would not directly apply. However, the ex-ante essential requirements for high-risk AI systems set out in this proposal will have to be taken into account when adopting relevant implementing or delegated legislation under those acts."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"15",
        "uuid":"0312f070-04bc-4d9b-9438-960c621e85b0",
        "path":"1. CONTEXT OF THE PROPOSAL >> 1.2. Consistency with existing policy provisions in the policy area",
        "header":false,
        "text":"As regards AI systems provided or used by regulated credit institutions, the authorities responsible for the supervision of the Union's financial services legislation should be designated as competent authorities for supervising the requirements in this proposal to ensure a coherent enforcement of the obligations under this proposal and the Union's financial services legislation where AI systems are to some extent implicitly regulated in relation to the internal governance system of credit institutions. To further enhance consistency, the conformity assessment procedure and some of the providers' procedural obligations under this proposal are integrated into the procedures under Directive 2013\/36\/EU on access to the activity of credit institutions and the prudential supervision 14."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"16",
        "uuid":"76b508e9-6407-468b-8614-2d58826117aa",
        "path":"1. CONTEXT OF THE PROPOSAL >> 1.2. Consistency with existing policy provisions in the policy area",
        "header":false,
        "text":"This proposal is also consistent with the applicable Union legislation on services, including on intermediary services regulated by the e-Commerce Directive 2000\/31\/EC 15 and the Commission's recent proposal for the Digital Services Act (DSA) 16."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"17",
        "uuid":"54d26a82-7ba4-4008-b9a3-ce42817041e7",
        "path":"1. CONTEXT OF THE PROPOSAL >> 1.2. Consistency with existing policy provisions in the policy area",
        "header":false,
        "text":"In relation to AI systems that are components of large-scale IT systems in the Area of Freedom, Security and Justice managed by the European Union Agency for the Operational Management of Large-Scale IT Systems (eu-LISA) , the proposal will not apply to those AI systems that have been placed on the market or put into service before one year has elapsed from the date of application of this Regulation, unless the replacement or amendment of those legal acts leads to a significant change in the design or intended purpose of the AI system or AI systems concerned."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"17",
        "uuid":"20a833bf-93d0-4ce5-aae2-952c4501ecad",
        "path":"1. CONTEXT OF THE PROPOSAL >> 1.3. Consistency with other Union policies",
        "header":true,
        "text":"1.3. Consistency with other Union policies"
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"18",
        "uuid":"259f78e6-6514-4113-b935-fe904a660d27",
        "path":"1. CONTEXT OF THE PROPOSAL >> 1.3. Consistency with other Union policies",
        "header":false,
        "text":"The proposal is part of a wider comprehensive package of measures that address problems posed by the development and use of AI, as examined in the White Paper on AI. Consistency and complementarity is therefore ensured with other ongoing or planned initiatives of the Commission that also aim to address those problems, including the revision of sectoral product legislation (e.g. the Machinery Directive, the General Product Safety Directive) and initiatives that address liability issues related to new technologies, including AI systems. Those initiatives will build on and complement this proposal in order to bring legal clarity and foster the development of an ecosystem of trust in AI in Europe."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"19",
        "uuid":"d8dd5eb1-65ca-4430-ac99-08443a0aa563",
        "path":"1. CONTEXT OF THE PROPOSAL >> 1.3. Consistency with other Union policies",
        "header":false,
        "text":"The proposal is also coherent with the Commission's overall digital strategy in its contribution to promoting technology that works for people, one of the three main pillars of the policy orientation and objectives announced in the Communication 'Shaping Europe's digital future' 17. It lays down a coherent, effective and proportionate framework to ensure AI is developed in ways that respect people's rights and earn their trust, making Europe fit for the digital age and turning the next ten years into the Digital Decade 18."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"20",
        "uuid":"eea6f532-1fe5-4e04-83b9-577a51f4da26",
        "path":"1. CONTEXT OF THE PROPOSAL >> 1.3. Consistency with other Union policies",
        "header":false,
        "text":"Furthermore, the promotion of AI-driven innovation is closely linked to the Data Governance Act 19 , the Open Data Directive 20 and other initiatives under the EU strategy for data 21 , which will establish trusted mechanisms and services for the re-use, sharing and pooling of data that are essential for the development of data-driven AI models of high quality."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"21",
        "uuid":"c99e2e7f-ea7a-44f0-adaa-1d41b210e771",
        "path":"1. CONTEXT OF THE PROPOSAL >> 1.3. Consistency with other Union policies",
        "header":false,
        "text":"The proposal also strengthens significantly the Union's role to help shape global norms and standards and promote trustworthy AI that is consistent with Union values and interests. It provides the Union with a powerful basis to engage further with its external partners, including third countries, and at international fora on issues relating to AI."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"21",
        "uuid":"0a7c7e68-410f-4bff-a2e3-404eb36a4351",
        "path":"2. LEGAL BASIS, SUBSIDIARITY AND PROPORTIONALITY",
        "header":true,
        "text":"2. LEGAL BASIS, SUBSIDIARITY AND PROPORTIONALITY"
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"21",
        "uuid":"e72ef453-4a3d-42f2-abd1-b510020c743f",
        "path":"2. LEGAL BASIS, SUBSIDIARITY AND PROPORTIONALITY >> 2.1. Legal basis",
        "header":true,
        "text":"2.1. Legal basis"
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"22",
        "uuid":"3c5b5d42-a743-465c-a477-1bbec25066d9",
        "path":"2. LEGAL BASIS, SUBSIDIARITY AND PROPORTIONALITY >> 2.1. Legal basis",
        "header":false,
        "text":"The legal basis for the proposal is in the first place Article 114 of the Treaty on the Functioning of the European Union (TFEU) , which provides for the adoption of measures to ensure the establishment and functioning of the internal market."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"23",
        "uuid":"3eac308e-3791-4e72-b047-1b619213ae35",
        "path":"2. LEGAL BASIS, SUBSIDIARITY AND PROPORTIONALITY >> 2.1. Legal basis",
        "header":false,
        "text":"This proposal constitutes a core part of the EU digital single market strategy. The primary objective of this proposal is to ensure the proper functioning of the internal market by setting harmonised rules in particular on the development, placing on the Union market and the use of products and services making use of AI technologies or provided as stand-alone AI systems. Some Member States are already considering national rules to ensure that AI is safe and is developed and used in compliance with fundamental rights obligations. This will likely lead to two main problems: i) a fragmentation of the internal market on essential elements regarding in particular the requirements for the AI products and services, their marketing, their use, the liability and the supervision by public authorities, and ii) the substantial diminishment of legal certainty for both providers and users of AI systems on how existing and new rules will apply to those systems in the Union. Given the wide circulation of products and services across borders, these two problems can be best solved through EU harmonizing legislation."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"24",
        "uuid":"8ce5baad-2c19-41fd-9cd5-1c2aa58768f4",
        "path":"2. LEGAL BASIS, SUBSIDIARITY AND PROPORTIONALITY >> 2.1. Legal basis",
        "header":false,
        "text":"Indeed, the proposal defines common mandatory requirements applicable to the design and development of certain AI systems before they are placed on the market that will be further operationalised through harmonised technical standards. The proposal also addresses the situation after AI systems have been placed on the market by harmonising the way in which ex-post controls are conducted."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"25",
        "uuid":"a65e8589-efaa-410d-be38-38c24c7e6511",
        "path":"2. LEGAL BASIS, SUBSIDIARITY AND PROPORTIONALITY >> 2.1. Legal basis",
        "header":false,
        "text":"In addition, considering that this proposal contains certain specific rules on the protection of individuals with regard to the processing of personal data, notably restrictions of the use of AI systems for 'real-time' remote biometric identification in publicly accessible spaces for the purpose of law enforcement, it is appropriate to base this regulation, in as far as those specific rules are concerned, on Article 16 of the TFEU."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"25",
        "uuid":"e46452c5-b153-4f25-83a2-611e53845512",
        "path":"2. LEGAL BASIS, SUBSIDIARITY AND PROPORTIONALITY >> 2.2. Subsidiarity (for non-exclusive competence)",
        "header":true,
        "text":"2.2. Subsidiarity (for non-exclusive competence)"
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"26",
        "uuid":"cbb6e31c-d3fe-4dfe-bac3-19d5d94cd609",
        "path":"2. LEGAL BASIS, SUBSIDIARITY AND PROPORTIONALITY >> 2.2. Subsidiarity (for non-exclusive competence)",
        "header":false,
        "text":"The nature of AI, which often relies on large and varied datasets and which may be embedded in any product or service circulating freely within the internal market, entails that the objectives of this proposal cannot be effectively achieved by Member States alone. Furthermore, an emerging patchwork of potentially divergent national rules will hamper the seamless circulation of products and services related to AI systems across the EU and will be ineffective in ensuring the safety and protection of fundamental rights and Union values across the different Member States. National approaches in addressing the problems will only create additional legal uncertainty and barriers, and will slow market uptake of AI."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"27",
        "uuid":"a0ee8736-54fb-4180-9cc5-ac6d99ef76e1",
        "path":"2. LEGAL BASIS, SUBSIDIARITY AND PROPORTIONALITY >> 2.2. Subsidiarity (for non-exclusive competence)",
        "header":false,
        "text":"The objectives of this proposal can be better achieved at Union level to avoid a further fragmentation of the Single Market into potentially contradictory national frameworks preventing the free circulation of goods and services embedding AI. A solid European regulatory framework for trustworthy AI will also ensure a level playing field and protect all people, while strengthening Europe's competitiveness and industrial basis in AI. Only common action at Union level can also protect the Union's digital sovereignty and leverage its tools and regulatory powers to shape global rules and standards."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"27",
        "uuid":"c2798f1e-8226-4696-950a-7084bc251933",
        "path":"2. LEGAL BASIS, SUBSIDIARITY AND PROPORTIONALITY >> 2.3. Proportionality",
        "header":true,
        "text":"2.3. Proportionality"
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"28",
        "uuid":"495c47e1-2bb4-4b9d-9034-a8425cb12361",
        "path":"2. LEGAL BASIS, SUBSIDIARITY AND PROPORTIONALITY >> 2.3. Proportionality",
        "header":false,
        "text":"The proposal builds on existing legal frameworks and is proportionate and necessary to achieve its objectives, since it follows a risk-based approach and imposes regulatory burdens only when an AI system is likely to pose high risks to fundamental rights and safety. For other, non-high-risk AI systems, only very limited transparency obligations are imposed, for example in terms of the provision of information to flag the use of an AI system when interacting with humans. For high-risk AI systems, the requirements of high quality data, documentation and traceability, transparency, human oversight, accuracy and robustness, are strictly necessary to mitigate the risks to fundamental rights and safety posed by AI and that are not covered by other existing legal frameworks. Harmonised standards and supporting guidance and compliance tools will assist providers and users in complying with the requirements laid down by the proposal and minimise their costs. The costs incurred by operators are proportionate to the objectives achieved and the economic and reputational benefits that operators can expect from this proposal."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"28",
        "uuid":"35e41218-597c-4fd1-8847-22b28b8e80bf",
        "path":"2. LEGAL BASIS, SUBSIDIARITY AND PROPORTIONALITY >> 2.4. Choice of the instrument",
        "header":true,
        "text":"2.4. Choice of the instrument"
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"29",
        "uuid":"0b57b456-6b75-4ab0-92c7-0cad6037e746",
        "path":"2. LEGAL BASIS, SUBSIDIARITY AND PROPORTIONALITY >> 2.4. Choice of the instrument",
        "header":false,
        "text":"The choice of a regulation as a legal instrument is justified by the need for a uniform application of the new rules, such as definition of AI, the prohibition of certain harmful AI-enabled practices and the classification of certain AI systems. The direct applicability of a Regulation, in accordance with Article 288 TFEU, will reduce legal fragmentation and facilitate the development of a single market for lawful, safe and trustworthy AI systems. It will do so, in particular, by introducing a harmonised set of core requirements with regard to AI systems classified as high-risk and obligations for providers and users of those systems, improving the protection of fundamental rights and providing legal certainty for operators and consumers alike."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"30",
        "uuid":"aac40c57-5e80-4314-a6de-734b8aeb427b",
        "path":"2. LEGAL BASIS, SUBSIDIARITY AND PROPORTIONALITY >> 2.4. Choice of the instrument",
        "header":false,
        "text":"At the same time, the provisions of the regulation are not overly prescriptive and leave room for different levels of Member State action for elements that do not undermine the objectives of the initiative, in particular the internal organisation of the market surveillance system and the uptake of measures to foster innovation."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"30",
        "uuid":"9757c8e2-ffe6-49c7-b6ce-dd430b0c72a4",
        "path":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS",
        "header":true,
        "text":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS"
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"30",
        "uuid":"37df0fff-db90-4717-b602-ab17ad5199f6",
        "path":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS >> 3.1. Stakeholder consultation",
        "header":true,
        "text":"3.1. Stakeholder consultation"
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"31",
        "uuid":"531d192c-d4e8-42e6-b764-bfcd8771acf9",
        "path":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS >> 3.1. Stakeholder consultation",
        "header":false,
        "text":"This proposal is the result of extensive consultation with all major stakeholders, in which the general principles and minimum standards for consultation of interested parties by the Commission were applied."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"32",
        "uuid":"542a70c1-9829-42ab-b3d8-6bf0bfe7577f",
        "path":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS >> 3.1. Stakeholder consultation",
        "header":false,
        "text":"An online public consultation was launched on 19 February 2020 along with the publication of the White Paper on Artificial Intelligence and ran until 14 June 2020. The objective of that consultation was to collect views and opinions on the White Paper. It targeted all interested stakeholders from the public and private sectors, including governments, local authorities, commercial and non-commercial organisations, social partners, experts, academics and citizens. After analysing all the responses received, the Commission published a summary outcome and the individual responses on its website 22."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"33",
        "uuid":"703306cc-fe6f-4a66-a0a2-2f9e98bde644",
        "path":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS >> 3.1. Stakeholder consultation",
        "header":false,
        "text":"In total, 1215 contributions were received, of which 352 were from companies or business organisations\/associations, 406 from individuals (92%individuals from EU ) , 152 on behalf of academic\/research institutions, and 73 from public authorities. Civil society's voices were represented by 160 respondents (among which 9 consumers' organisations, 129 non-governmental organisations and 22 trade unions) , 72 respondents contributed as 'others'. Of the 352 business and industry representatives, 222 were companies and business representatives, 41.5% of which were micro, small and medium-sized enterprises. The rest were business associations. Overall, 84% of business and industry replies came from the EU-27. Depending on the question, between 81 and 598 of the respondents used the free text option to insert comments. Over 450 position papers were submitted through the EU Survey website, either in addition to questionnaire answers (over 400) or as stand-alone contributions (over 50)."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"34",
        "uuid":"bb489f0c-837d-4f88-a53b-abe904c22f78",
        "path":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS >> 3.1. Stakeholder consultation",
        "header":false,
        "text":"Overall, there is a general agreement amongst stakeholders on a need for action. A large majority of stakeholders agree that legislative gaps exist or that new legislation is needed. However, several stakeholders warn the Commission to avoid duplication, conflicting obligations and overregulation. There were many comments underlining the importance of a technology neutral and proportionate regulatory framework."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"35",
        "uuid":"7c9b3779-736a-48a6-8eb2-c92e9a537625",
        "path":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS >> 3.1. Stakeholder consultation",
        "header":false,
        "text":"Stakeholders mostly requested a narrow, clear and precise definition for AI. Stakeholders also highlighted that besides the clarification of the term of AI, it is important to define 'risk', 'high-risk', 'low-risk', 'remote biometric identification' and 'harm'."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"36",
        "uuid":"50a13cdc-1dda-4b70-bdf8-54f3b9f6302e",
        "path":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS >> 3.1. Stakeholder consultation",
        "header":false,
        "text":"Most of the respondents are explicitly in favour of the risk-based approach. Using a risk-based framework was considered a better option than blanket regulation of all AI systems. The types of risks and threats should be based on a sector-by-sector and case-by-case approach. Risks also should be calculated taking into account the impact on rights and safety."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"37",
        "uuid":"012c636d-6c31-433f-ab59-cff184de2036",
        "path":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS >> 3.1. Stakeholder consultation",
        "header":false,
        "text":"Regulatory sandboxes could be very useful for the promotion of AI and are welcomed by certain stakeholders, especially the Business Associations."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"38",
        "uuid":"f65ecfe9-a3f6-40cd-ada8-036c2642da0b",
        "path":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS >> 3.1. Stakeholder consultation",
        "header":false,
        "text":"Among those who formulated their opinion on the enforcement models, more than 50%, especially from the business associations, were in favour of a combination of an ex-ante risk self-assessment and an ex-post enforcement for high-risk AI systems."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"38",
        "uuid":"fecbfd41-c6c0-414b-ba34-24c25be40708",
        "path":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS >> 3.2. Collection and use of expertise",
        "header":true,
        "text":"3.2. Collection and use of expertise"
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"39",
        "uuid":"103c9c29-fb52-458a-945c-995666a16ce0",
        "path":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS >> 3.2. Collection and use of expertise",
        "header":false,
        "text":"The proposal builds on two years of analysis and close involvement of stakeholders, including academics, businesses, social partners, non-governmental organisations, Member States and citizens. The preparatory work started in 2018 with the setting up of a High-Level Expert Group on AI (HLEG) which had an inclusive and broad composition of 52 well-known experts tasked to advise the Commission on the implementation of the Commission's Strategy on Artificial Intelligence. In April 2019, the Commission supported 23 the key requirements set out in the HLEG ethics guidelines for Trustworthy AI 24 , which had been revised to take into account more than 500 submissions from stakeholders. The key requirements reflect a widespread and common approach, as evidenced by a plethora of ethical codes and principles developed by many private and public organisations in Europe and beyond, that AI development and use should be guided by certain essential value-oriented principles. The Assessment List for Trustworthy Artificial Intelligence (ALTAI) 25 made those requirements operational in a piloting process with over 350 organisations."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"40",
        "uuid":"383b7f12-0683-4121-abc4-514f017256ec",
        "path":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS >> 3.2. Collection and use of expertise",
        "header":false,
        "text":"In addition, the AI Alliance 26 was formed as a platform for approximately 4000 stakeholders to debate the technological and societal implications of AI, culminating in a yearly AI Assembly."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"41",
        "uuid":"7c8f2960-ab20-4620-9802-f0af61d233da",
        "path":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS >> 3.2. Collection and use of expertise",
        "header":false,
        "text":"The White Paper on AI further developed this inclusive approach, inciting comments from more than 1250 stakeholders, including over 450 additional position papers. As a result, the Commission published an Inception Impact Assessment, which in turn attracted more than 130 comments 27. Additional stakeholder workshops and events were also organised the results of which support the analysis in the impact assessment and the policy choices made in this proposal 28. An external study was also procured to feed into the impact assessment."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"41",
        "uuid":"89b36151-4be5-45f8-a39b-96a4274e4a34",
        "path":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS >> 3.3. Impact assessment",
        "header":true,
        "text":"3.3. Impact assessment"
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"42",
        "uuid":"0f3c58dc-8c80-4977-b7f5-e8fe5be9f146",
        "path":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS >> 3.3. Impact assessment",
        "header":false,
        "text":"In line with its “Better Regulation” policy, the Commission conducted an impact assessment for this proposal examined by the Commission's Regulatory Scrutiny Board. A meeting with the Regulatory Scrutiny Board was held on 16 December 2020, which was followed by a negative opinion. After substantial revision of the impact assessment to address the comments and a resubmission of the impact assessment, the Regulatory Scrutiny Board issued a positive opinion on 21 March 2021. The opinions of the Regulatory Scrutiny Board, the recommendations and an explanation of how they have been taken into account are presented in Annex 1 of the impact assessment."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"43",
        "uuid":"091761a8-58a3-4530-a7cf-a30fbb87e25f",
        "path":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS >> 3.3. Impact assessment",
        "header":false,
        "text":"The Commission examined different policy options to achieve the general objective of the proposal, which is to ensure the proper functioning of the single market by creating the conditions for the development and use of trustworthy AI in the Union."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"44",
        "uuid":"21ec9b2d-d69b-4c29-b2ef-e3d36507a3fe",
        "path":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS >> 3.3. Impact assessment",
        "header":false,
        "text":"Four policy options of different degrees of regulatory intervention were assessed: - Option 1: EU legislative instrument setting up a voluntary labelling scheme; - Option 2: a sectoral, “ad-hoc” approach; - Option 3: Horizontal EU legislative instrument following a proportionate risk-based approach; - Option 3+: Horizontal EU legislative instrument following a proportionate risk-based approach + codes of conduct for non-high-risk AI systems; - Option 4: Horizontal EU legislative instrument establishing mandatory requirements for all AI systems, irrespective of the risk they pose."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"45",
        "uuid":"90a9f437-9ad2-4f09-91b4-c16b3f061aad",
        "path":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS >> 3.3. Impact assessment",
        "header":false,
        "text":"According to the Commission's established methodology, each policy option was evaluated against economic and societal impacts, with a particular focus on impacts on fundamental rights. The preferred option is option 3+, a regulatory framework for high-risk AI systems only, with the possibility for all providers of non-high-risk AI systems to follow a code of conduct. The requirements will concern data, documentation and traceability, provision of information and transparency, human oversight and robustness and accuracy and would be mandatory for high-risk AI systems. Companies that introduced codes of conduct for other AI systems would do so voluntarily."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"46",
        "uuid":"ea5a1cd1-3f03-4712-ba3c-c3421e9d663f",
        "path":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS >> 3.3. Impact assessment",
        "header":false,
        "text":"The preferred option was considered suitable to address in the most effective way the objectives of this proposal. By requiring a restricted yet effective set of actions from AI developers and users, the preferred option limits the risks of violation of fundamental rights and safety of people and foster effective supervision and enforcement, by targeting the requirements only to systems where there is a high risk that such violations could occur. As a result, that option keeps compliance costs to a minimum, thus avoiding an unnecessary slowing of uptake due to higher prices and compliance costs. In order to address possible disadvantages for SMEs, this option includes several provisions to support their compliance and reduce their costs, including creation of regulatory sandboxes and obligation to consider SMEs interests when setting fees related to conformity assessment."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"47",
        "uuid":"e186156e-d631-4b16-ae30-1213c37612f0",
        "path":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS >> 3.3. Impact assessment",
        "header":false,
        "text":"The preferred option will increase people's trust in AI, companies will gain in legal certainty, and Member States will see no reason to take unilateral action that could fragment the single market. As a result of higher demand due to higher trust, more available offers due to legal certainty, and the absence of obstacles to cross-border movement of AI systems, the single market for AI will likely flourish. The European Union will continue to develop a fast-growing AI ecosystem of innovative services and products embedding AI technology or stand-alone AI systems, resulting in increased digital autonomy."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"48",
        "uuid":"cb366155-dfbe-407c-b5a3-a76f8f88e9f1",
        "path":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS >> 3.3. Impact assessment",
        "header":false,
        "text":"Businesses or public authorities that develop or use AI applications that constitute a high risk for the safety or fundamental rights of citizens would have to comply with specific requirements and obligations. Compliance with these requirements would imply costs amounting to approximately EUR € 6000 to EUR € 7000 for the supply of an average high-risk AI system of around EUR € 170000 by 2025. For AI users, there would also be the annual cost for the time spent on ensuring human oversight where this is appropriate, depending on the use case. Those have been estimated at approximately EUR € 5000 to EUR € 8000 per year. Verification costs could amount to another EUR € 3000 to EUR € 7500 for suppliers of high-risk AI. Businesses or public authorities that develop or use any AI applications not classified as high risk would only have minimal obligations of information. However, they could choose to join others and together adopt a code of conduct to follow suitable requirements, and to ensure that their AI systems are trustworthy. In such a case, costs would be at most as high as for high-risk AI systems, but most probably lower."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"49",
        "uuid":"dfbdfd94-cc41-473e-94cc-f271c37d735d",
        "path":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS >> 3.3. Impact assessment",
        "header":false,
        "text":"The impacts of the policy options on different categories of stakeholders (economic operators\/ business; conformity assessment bodies, standardisation bodies and other public bodies; individuals\/citizens; researchers) are explained in detail in Annex 3 of the Impact assessment supporting this proposal."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"49",
        "uuid":"82a26aad-d066-453a-a91f-ac9962ed65d6",
        "path":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS >> 3.4. Regulatory fitness and simplification",
        "header":true,
        "text":"3.4. Regulatory fitness and simplification"
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"50",
        "uuid":"79f9263e-88a7-43b3-b896-77193f4b7693",
        "path":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS >> 3.4. Regulatory fitness and simplification",
        "header":false,
        "text":"This proposal lays down obligation that will apply to providers and users of high-risk AI systems. For providers who develop and place such systems on the Union market, it will create legal certainty and ensure that no obstacle to the cross-border provision of AI-related services and products emerge. For companies using AI, it will promote trust among their customers. For national public administrations, it will promote public trust in the use of AI and strengthen enforcement mechanisms (by introducing a European coordination mechanism, providing for appropriate capacities, and facilitating audits of the AI systems with new requirements for documentation, traceability and transparency). Moreover, the framework will envisage specific measures supporting innovation, including regulatory sandboxes and specific measures supporting small-scale users and providers of high-risk AI systems to comply with the new rules."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"51",
        "uuid":"f00256c5-4765-4655-8daf-0df8ac01a3e4",
        "path":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS >> 3.4. Regulatory fitness and simplification",
        "header":false,
        "text":"The proposal also specifically aims at strengthening Europe's competitiveness and industrial basis in AI. Full consistency is ensured with existing sectoral Union legislation applicable to AI systems (e.g. on products and services) that will bring further clarity and simplify the enforcement of the new rules."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"51",
        "uuid":"668b35a3-71b0-458b-b39b-60299363b356",
        "path":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS >> 3.5. Fundamental rights",
        "header":true,
        "text":"3.5. Fundamental rights"
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"52",
        "uuid":"ca29e463-e877-4f0d-87a1-ad3ec6b0c149",
        "path":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS >> 3.5. Fundamental rights",
        "header":false,
        "text":"The use of AI with its specific characteristics (e.g. opacity, complexity, dependency on data, autonomous behaviour) can adversely affect a number of fundamental rights enshrined in the EU Charter of Fundamental Rights ('the Charter'). This proposal seeks to ensure a high level of protection for those fundamental rights and aims to address various sources of risks through a clearly defined risk-based approach. With a set of requirements for trustworthy AI and proportionate obligations on all value chain participants, the proposal will enhance and promote the protection of the rights protected by the Charter: the right to human dignity (Article 1) , respect for private life and protection of personal data (Articles 7 and 8) , non-discrimination (Article 21) and equality between women and men (Article 23). It aims to prevent a chilling effect on the rights to freedom of expression (Article 11) and freedom of assembly (Article 12) , to ensure protection of the right to an effective remedy and to a fair trial, the rights of defence and the presumption of innocence (Articles 47 and 48) , as well as the general principle of good administration. Furthermore, as applicable in certain domains, the proposal will positively affect the rights of a number of special groups, such as the workers' rights to fair and just working conditions (Article 31) , a high level of consumer protection (Article 28) , the rights of the child (Article 24) and the integration of persons with disabilities (Article 26). The right to a high level of environmental protection and the improvement of the quality of the environment (Article 37) is also relevant, including in relation to the health and safety of people. The obligations for ex ante testing, risk management and human oversight will also facilitate the respect of other fundamental rights by minimising the risk of erroneous or biased AI-assisted decisions in critical areas such as education and training, employment, important services, law enforcement and the judiciary. In case infringements of fundamental rights still happen, effective redress for affected persons will be made possible by ensuring transparency and traceability of the AI systems coupled with strong ex post controls."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"53",
        "uuid":"ab7ee974-8a84-4d79-8406-a1d90f5ee7af",
        "path":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS >> 3.5. Fundamental rights",
        "header":false,
        "text":"This proposal imposes some restrictions on the freedom to conduct business (Article 16) and the freedom of art and science (Article 13) to ensure compliance with overriding reasons of public interest such as health, safety, consumer protection and the protection of other fundamental rights ('responsible innovation') when high-risk AI technology is developed and used. Those restrictions are proportionate and limited to the minimum necessary to prevent and mitigate serious safety risks and likely infringements of fundamental rights."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"54",
        "uuid":"fc50b449-a858-4fa2-98e0-3e31ab9248b6",
        "path":"3. RESULTS OF EX-POST EVALUATIONS, STAKEHOLDER CONSULTATIONS AND IMPACT ASSESSMENTS >> 3.5. Fundamental rights",
        "header":false,
        "text":"The increased transparency obligations will also not disproportionately affect the right to protection of intellectual property (Article 17(2) ) , since they will be limited only to the minimum necessary information for individuals to exercise their right to an effective remedy and to the necessary transparency towards supervision and enforcement authorities, in line with their mandates. Any disclosure of information will be carried out in compliance with relevant legislation in the field, including Directive 2016\/943 on the protection of undisclosed know-how and business information (trade secrets) against their unlawful acquisition, use and disclosure. When public authorities and notified bodies need to be given access to confidential information or source code to examine compliance with substantial obligations, they are placed under binding confidentiality obligations."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"54",
        "uuid":"d1ab8f43-9ca9-4235-9746-ec80d294711c",
        "path":"4. BUDGETARY IMPLICATIONS",
        "header":true,
        "text":"4. BUDGETARY IMPLICATIONS"
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"55",
        "uuid":"e67c9230-4680-4783-bccb-0a2ac5adda64",
        "path":"4. BUDGETARY IMPLICATIONS",
        "header":false,
        "text":"Member States will have to designate supervisory authorities in charge of implementing the legislative requirements. Their supervisory function could build on existing arrangements, for example regarding conformity assessment bodies or market surveillance, but would require sufficient technological expertise and human and financial resources. Depending on the pre-existing structure in each Member State, this could amount to 1 to 25 Full Time Equivalents per Member State."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"56",
        "uuid":"0ad43e7c-8484-4c73-a3f1-d5c15be8706c",
        "path":"4. BUDGETARY IMPLICATIONS",
        "header":false,
        "text":"A detailed overview of the costs involved is provided in the 'financial statement' linked to this proposal."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"56",
        "uuid":"16039441-be2f-4322-b8c8-01b5fe8614d0",
        "path":"5. OTHER ELEMENTS",
        "header":true,
        "text":"5. OTHER ELEMENTS"
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"56",
        "uuid":"e1fb87b4-bf6a-4ebc-a85d-a936a6e18e62",
        "path":"5. OTHER ELEMENTS >> 5.1. Implementation plans and monitoring, evaluation and reporting arrangements",
        "header":true,
        "text":"5.1. Implementation plans and monitoring, evaluation and reporting arrangements"
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"57",
        "uuid":"489a5186-f799-4361-b618-55bd1e332fcf",
        "path":"5. OTHER ELEMENTS >> 5.1. Implementation plans and monitoring, evaluation and reporting arrangements",
        "header":false,
        "text":"Providing for a robust monitoring and evaluation mechanism is crucial to ensure that the proposal will be effective in achieving its specific objectives. The Commission will be in charge of monitoring the effects of the proposal. It will establish a system for registering stand-alone high-risk AI applications in a public EU-wide database. This registration will also enable competent authorities, users and other interested people to verify if the high-risk AI system complies with the requirements laid down in the proposal and to exercise enhanced oversight over those AI systems posing high risks to fundamental rights. To feed this database, AI providers will be obliged to provide meaningful information about their systems and the conformity assessment carried out on those systems."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"58",
        "uuid":"f4b513ae-7b1a-448b-995a-091b57256ca6",
        "path":"5. OTHER ELEMENTS >> 5.1. Implementation plans and monitoring, evaluation and reporting arrangements",
        "header":false,
        "text":"Moreover, AI providers will be obliged to inform national competent authorities about serious incidents or malfunctioning that constitute a breach of fundamental rights obligations as soon as they become aware of them, as well as any recalls or withdrawals of AI systems from the market. National competent authorities will then investigate the incidents\/or malfunctioning, collect all the necessary information and regularly transmit it to the Commission with adequate metadata. The Commission will complement this information on the incidents by a comprehensive analysis of the overall market for AI."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"59",
        "uuid":"9f945f62-e716-4cbb-938e-b42ee8d4af37",
        "path":"5. OTHER ELEMENTS >> 5.1. Implementation plans and monitoring, evaluation and reporting arrangements",
        "header":false,
        "text":"The Commission will publish a report evaluating and reviewing the proposed AI framework five years following the date on which it becomes applicable."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"59",
        "uuid":"fca29ec5-3b50-46ea-ac58-d3eb40d526da",
        "path":"5. OTHER ELEMENTS >> 5.2. Detailed explanation of the specific provisions of the proposal",
        "header":true,
        "text":"5.2. Detailed explanation of the specific provisions of the proposal"
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"59",
        "uuid":"f4fd3649-865c-4d92-b40c-fb11ce27d3ba",
        "path":"5. OTHER ELEMENTS >> 5.2. Detailed explanation of the specific provisions of the proposal >> 5.2.1. SCOPE AND DEFINITIONS (TITLE I)",
        "header":true,
        "text":"5.2.1. SCOPE AND DEFINITIONS (TITLE I)"
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"60",
        "uuid":"79b446f2-febf-4f80-8b4a-c810ed28f21a",
        "path":"5. OTHER ELEMENTS >> 5.2. Detailed explanation of the specific provisions of the proposal >> 5.2.1. SCOPE AND DEFINITIONS (TITLE I)",
        "header":false,
        "text":"Title I defines the subject matter of the regulation and the scope of application of the new rules that cover the placing on the market, putting into service and use of AI systems. It also sets out the definitions used throughout the instrument. The definition of AI system in the legal framework aims to be as technology neutral and future proof as possible, taking into account the fast technological and market developments related to AI. In order to provide the needed legal certainty, Title I is complemented by Annex I, which contains a detailed list of approaches and techniques for the development of AI to be adapted by the Commission in line with new technological developments. Key participants across the AI value chain are also clearly defined such as providers and users of AI systems that cover both public and private operators to ensure a level playing field."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"60",
        "uuid":"9205c6a2-d7ab-4144-bc12-8061165f32ed",
        "path":"5. OTHER ELEMENTS >> 5.2. Detailed explanation of the specific provisions of the proposal >> 5.2.2. PROHIBITED ARTIFICIAL INTELLIGENCE PRACTICES (TITLE II)",
        "header":true,
        "text":"5.2.2. PROHIBITED ARTIFICIAL INTELLIGENCE PRACTICES (TITLE II)"
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"61",
        "uuid":"99191a0e-370f-4068-ae3e-95b518a740d1",
        "path":"5. OTHER ELEMENTS >> 5.2. Detailed explanation of the specific provisions of the proposal >> 5.2.2. PROHIBITED ARTIFICIAL INTELLIGENCE PRACTICES (TITLE II)",
        "header":false,
        "text":"Title II establishes a list of prohibited AI. The regulation follows a risk-based approach, differentiating between uses of AI that create (i) an unacceptable risk, (ii) a high risk, and (iii) low or minimal risk. The list of prohibited practices in Title II comprises all those AI systems whose use is considered unacceptable as contravening Union values, for instance by violating fundamental rights. The prohibitions covers practices that have a significant potential to manipulate persons through subliminal techniques beyond their consciousness or exploit vulnerabilities of specific vulnerable groups such as children or persons with disabilities in order to materially distort their behaviour in a manner that is likely to cause them or another person psychological or physical harm. Other manipulative or exploitative practices affecting adults that might be facilitated by AI systems could be covered by the existing data protection, consumer protection and digital service legislation that guarantee that natural persons are properly informed and have free choice not to be subject to profiling or other practices that might affect their behaviour. The proposal also prohibits AI-based social scoring for general purposes done by public authorities. Finally, the use of 'real time' remote biometric identification systems in publicly accessible spaces for the purpose of law enforcement is also prohibited unless certain limited exceptions apply."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"61",
        "uuid":"65b5c79e-2047-45c8-94ff-5e6e18f77b53",
        "path":"5. OTHER ELEMENTS >> 5.2. Detailed explanation of the specific provisions of the proposal >> 5.2.3. HIGH-RISK AI SYSTEMS (TITLE III)",
        "header":true,
        "text":"5.2.3. HIGH-RISK AI SYSTEMS (TITLE III)"
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"62",
        "uuid":"9fd1d1da-8be4-4615-ab7a-69410e35e51a",
        "path":"5. OTHER ELEMENTS >> 5.2. Detailed explanation of the specific provisions of the proposal >> 5.2.3. HIGH-RISK AI SYSTEMS (TITLE III)",
        "header":false,
        "text":"Title III contains specific rules for AI systems that create a high risk to the health and safety or fundamental rights of natural persons. In line with a risk-based approach, those high-risk AI systems are permitted on the European market subject to compliance with certain mandatory requirements and an ex-ante conformity assessment. The classification of an AI system as high-risk is based on the intended purpose of the AI system, in line with existing product safety legislation. Therefore, the classification as high-risk does not only depend on the function performed by the AI system, but also on the specific purpose and modalities for which that system is used."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"63",
        "uuid":"927300ca-a21c-4f80-b0cb-57dc8a9439bc",
        "path":"5. OTHER ELEMENTS >> 5.2. Detailed explanation of the specific provisions of the proposal >> 5.2.3. HIGH-RISK AI SYSTEMS (TITLE III)",
        "header":false,
        "text":"Chapter 1 of Title III sets the classification rules and identifies two main categories of high-risk AI systems: - AI systems intended to be used as safety component of products that are subject to third party ex-ante conformity assessment; - other stand-alone AI systems with mainly fundamental rights implications that are explicitly listed in Annex III."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"64",
        "uuid":"4e27f3a9-db0c-43d0-bdfb-8fa6780d245c",
        "path":"5. OTHER ELEMENTS >> 5.2. Detailed explanation of the specific provisions of the proposal >> 5.2.3. HIGH-RISK AI SYSTEMS (TITLE III)",
        "header":false,
        "text":"This list of high-risk AI systems in Annex III contains a limited number of AI systems whose risks have already materialised or are likely to materialise in the near future. To ensure that the regulation can be adjusted to emerging uses and applications of AI, the Commission may expand the list of high-risk AI systems used within certain pre-defined areas, by applying a set of criteria and risk assessment methodology."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"65",
        "uuid":"f75ae0cd-cc17-4595-9918-f851345b9298",
        "path":"5. OTHER ELEMENTS >> 5.2. Detailed explanation of the specific provisions of the proposal >> 5.2.3. HIGH-RISK AI SYSTEMS (TITLE III)",
        "header":false,
        "text":"Chapter 2 sets out the legal requirements for high-risk AI systems in relation to data and data governance, documentation and recording keeping, transparency and provision of information to users, human oversight, robustness, accuracy and security. The proposed minimum requirements are already state-of-the-art for many diligent operators and the result of two years of preparatory work, derived from the Ethics Guidelines of the HLEG 29 , piloted by more than 350 organisations 30. They are also largely consistent with other international recommendations and principles, which ensures that the proposed AI framework is compatible with those adopted by the EU's international trade partners. The precise technical solutions to achieve compliance with those requirements may be provided by standards or by other technical specifications or otherwise be developed in accordance with general engineering or scientific knowledge at the discretion of the provider of the AI system. This flexibility is particularly important, because it allows providers of AI systems to choose the way to meet their requirements, taking into account the state-of-the-art and technological and scientific progress in this field."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"66",
        "uuid":"b5a440ed-2816-4fa5-bce5-044c6976dcbc",
        "path":"5. OTHER ELEMENTS >> 5.2. Detailed explanation of the specific provisions of the proposal >> 5.2.3. HIGH-RISK AI SYSTEMS (TITLE III)",
        "header":false,
        "text":"Chapter 3 places a clear set of horizontal obligations on providers of high-risk AI systems. Proportionate obligations are also placed on users and other participants across the AI value chain (e.g., importers, distributors, authorized representatives)."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"67",
        "uuid":"dcbe7e7e-2db7-4bac-bf72-b12d447b53c8",
        "path":"5. OTHER ELEMENTS >> 5.2. Detailed explanation of the specific provisions of the proposal >> 5.2.3. HIGH-RISK AI SYSTEMS (TITLE III)",
        "header":false,
        "text":"Chapter 4 sets the framework for notified bodies to be involved as independent third parties in conformity assessment procedures, while Chapter 5 explains in detail the conformity assessment procedures to be followed for each type of high-risk AI system. The conformity assessment approach aims to minimise the burden for economic operators as well as for notified bodies, whose capacity needs to be progressively ramped up over time. AI systems intended to be used as safety components of products that are regulated under the New Legislative Framework legislation (e.g. machinery, toys, medical devices, etc.) will be subject to the same ex-ante and ex-post compliance and enforcement mechanisms of the products of which they are a component. The key difference is that the ex-ante and ex-post mechanisms will ensure compliance not only with the requirements established by sectorial legislation, but also with the requirements established by this regulation."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"68",
        "uuid":"79cb3eb9-eb1a-49fd-9fa2-ded417f2f386",
        "path":"5. OTHER ELEMENTS >> 5.2. Detailed explanation of the specific provisions of the proposal >> 5.2.3. HIGH-RISK AI SYSTEMS (TITLE III)",
        "header":false,
        "text":"As regards stand-alone high-risk AI systems that are referred to in Annex III, a new compliance and enforcement system will be established. This follows the model of the New Legislative Framework legislation implemented through internal control checks by the providers with the exception of remote biometric identification systems that would be subject to third party conformity assessment. A comprehensive ex-ante conformity assessment through internal checks, combined with a strong ex-post enforcement, could be an effective and reasonable solution for those systems, given the early phase of the regulatory intervention and the fact the AI sector is very innovative and expertise for auditing is only now being accumulated. An assessment through internal checks for 'stand-alone' high-risk AI systems would require a full, effective and properly documented ex ante compliance with all requirements of the regulation and compliance with robust quality and risk management systems and post-market monitoring. After the provider has performed the relevant conformity assessment, it should register those stand-alone high-risk AI systems in an EU database that will be managed by the Commission to increase public transparency and oversight and strengthen ex post supervision by competent authorities. By contrast, for reasons of consistency with the existing product safety legislation, the conformity assessments of AI systems that are safety components of products will follow a system with third party conformity assessment procedures already established under the relevant sectoral product safety legislation. New ex ante re-assessments of the conformity will be needed in case of substantial modifications to the AI systems (and notably changes which go beyond what is pre-determined by the provider in its technical documentation and checked at the moment of the ex-ante conformity assessment)."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"68",
        "uuid":"d683f367-8322-47d1-a10c-557b1f1295f4",
        "path":"5. OTHER ELEMENTS >> 5.2. Detailed explanation of the specific provisions of the proposal >> 5.2.4. TRANSPARENCY OBLIGATIONS FOR CERTAIN AI SYSTEMS (TITLE IV)",
        "header":true,
        "text":"5.2.4. TRANSPARENCY OBLIGATIONS FOR CERTAIN AI SYSTEMS (TITLE IV)"
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"69",
        "uuid":"a4e880ad-5005-4a31-bcdd-aaa4873ae4b8",
        "path":"5. OTHER ELEMENTS >> 5.2. Detailed explanation of the specific provisions of the proposal >> 5.2.4. TRANSPARENCY OBLIGATIONS FOR CERTAIN AI SYSTEMS (TITLE IV)",
        "header":false,
        "text":"Title IV concerns certain AI systems to take account of the specific risks of manipulation they pose. Transparency obligations will apply for systems that (i) interact with humans, (ii) are used to detect emotions or determine association with (social) categories based on biometric data, or (iii) generate or manipulate content ('deep fakes'). When persons interact with an AI system or their emotions or characteristics are recognised through automated means, people must be informed of that circumstance. If an AI system is used to generate or manipulate image, audio or video content that appreciably resembles authentic content, there should be an obligation to disclose that the content is generated through automated means, subject to exceptions for legitimate purposes (law enforcement, freedom of expression). This allows persons to make informed choices or step back from a given situation."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"69",
        "uuid":"f1dbe608-d530-46f4-8306-b85a000a7681",
        "path":"5. OTHER ELEMENTS >> 5.2. Detailed explanation of the specific provisions of the proposal >> 5.2.5. MEASURES IN SUPPORT OF INNOVATION (TITLE V)",
        "header":true,
        "text":"5.2.5. MEASURES IN SUPPORT OF INNOVATION (TITLE V)"
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"70",
        "uuid":"38a6f237-195b-4265-add5-7694083faadd",
        "path":"5. OTHER ELEMENTS >> 5.2. Detailed explanation of the specific provisions of the proposal >> 5.2.5. MEASURES IN SUPPORT OF INNOVATION (TITLE V)",
        "header":false,
        "text":"Title V contributes to the objective to create a legal framework that is innovation-friendly, future-proof and resilient to disruption. To that end, it encourages national competent authorities to set up regulatory sandboxes and sets a basic framework in terms of governance, supervision and liability. AI regulatory sandboxes establish a controlled environment to test innovative technologies for a limited time on the basis of a testing plan agreed with the competent authorities. Title V also contains measures to reduce the regulatory burden on SMEs and start-ups."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"70",
        "uuid":"f4c753b3-ba30-4314-a497-f0b885654a03",
        "path":"5. OTHER ELEMENTS >> 5.2. Detailed explanation of the specific provisions of the proposal >> 5.2.6. GOVERNANCE AND IMPLEMENTATION (TITLES VI, VII AND VII)",
        "header":true,
        "text":"5.2.6. GOVERNANCE AND IMPLEMENTATION (TITLES VI, VII AND VII)"
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"71",
        "uuid":"84397c60-ad53-4708-b084-18ba85d5ed6a",
        "path":"5. OTHER ELEMENTS >> 5.2. Detailed explanation of the specific provisions of the proposal >> 5.2.6. GOVERNANCE AND IMPLEMENTATION (TITLES VI, VII AND VII)",
        "header":false,
        "text":"Title VI sets up the governance systems at Union and national level. At Union level, the proposal establishes a European Artificial Intelligence Board (the 'Board') , composed of representatives from the Member States and the Commission. The Board will facilitate a smooth, effective and harmonised implementation of this regulation by contributing to the effective cooperation of the national supervisory authorities and the Commission and providing advice and expertise to the Commission. It will also collect and share best practices among the Member States."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"72",
        "uuid":"906dcbf7-fd7e-41f6-8392-8be065f1a2e9",
        "path":"5. OTHER ELEMENTS >> 5.2. Detailed explanation of the specific provisions of the proposal >> 5.2.6. GOVERNANCE AND IMPLEMENTATION (TITLES VI, VII AND VII)",
        "header":false,
        "text":"At national level, Member States will have to designate one or more national competent authorities and, among them, the national supervisory authority, for the purpose of supervising the application and implementation of the regulation. The European Data Protection Supervisor will act as the competent authority for the supervision of the Union institutions, agencies and bodies when they fall within the scope of this regulation."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"73",
        "uuid":"003e0afb-f20f-48fa-a70c-2425d9f73a00",
        "path":"5. OTHER ELEMENTS >> 5.2. Detailed explanation of the specific provisions of the proposal >> 5.2.6. GOVERNANCE AND IMPLEMENTATION (TITLES VI, VII AND VII)",
        "header":false,
        "text":"Title VII aims to facilitate the monitoring work of the Commission and national authorities through the establishment of an EU-wide database for stand-alone high-risk AI systems with mainly fundamental rights implications. The database will be operated by the Commission and provided with data by the providers of the AI systems, who will be required to register their systems before placing them on the market or otherwise putting them into service."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"74",
        "uuid":"7ef8d884-a5f1-4c4d-9df2-3c1734f7f72d",
        "path":"5. OTHER ELEMENTS >> 5.2. Detailed explanation of the specific provisions of the proposal >> 5.2.6. GOVERNANCE AND IMPLEMENTATION (TITLES VI, VII AND VII)",
        "header":false,
        "text":"Title VIII sets out the monitoring and reporting obligations for providers of AI systems with regard to post-market monitoring and reporting and investigating on AI-related incidents and malfunctioning. Market surveillance authorities would also control the market and investigate compliance with the obligations and requirements for all high-risk AI systems already placed on the market. Market surveillance authorities would have all powers under Regulation (EU) 2019\/1020 on market surveillance. Ex-post enforcement should ensure that once the AI system has been put on the market, public authorities have the powers and resources to intervene in case AI systems generate unexpected risks, which warrant rapid action. They will also monitor compliance of operators with their relevant obligations under the regulation. The proposal does not foresee the automatic creation of any additional bodies or authorities at Member State level. Member States may therefore appoint (and draw upon the expertise of) existing sectorial authorities, who would be entrusted also with the powers to monitor and enforce the provisions of the regulation."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"75",
        "uuid":"9125cced-7c90-40c1-9563-ddd92fa5a436",
        "path":"5. OTHER ELEMENTS >> 5.2. Detailed explanation of the specific provisions of the proposal >> 5.2.6. GOVERNANCE AND IMPLEMENTATION (TITLES VI, VII AND VII)",
        "header":false,
        "text":"All this is without prejudice to the existing system and allocation of powers of ex-post enforcement of obligations regarding fundamental rights in the Member States. When necessary for their mandate, existing supervision and enforcement authorities will also have the power to request and access any documentation maintained following this regulation and, where needed, request market surveillance authorities to organise testing of the high-risk AI system through technical means."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"75",
        "uuid":"f6ff6cd2-3666-4c5b-bbf9-c5f10ab12157",
        "path":"5. OTHER ELEMENTS >> 5.2. Detailed explanation of the specific provisions of the proposal >> 5.2.7. CODES OF CONDUCT (TITLE IX)",
        "header":true,
        "text":"5.2.7. CODES OF CONDUCT (TITLE IX)"
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"76",
        "uuid":"2a83570f-829e-47bd-8ae5-3e1edc2787dd",
        "path":"5. OTHER ELEMENTS >> 5.2. Detailed explanation of the specific provisions of the proposal >> 5.2.7. CODES OF CONDUCT (TITLE IX)",
        "header":false,
        "text":"Title IX creates a framework for the creation of codes of conduct, which aim to encourage providers of non-high-risk AI systems to apply voluntarily the mandatory requirements for high-risk AI systems (as laid out in Title III). Providers of non-high-risk AI systems may create and implement the codes of conduct themselves. Those codes may also include voluntary commitments related, for example, to environmental sustainability, accessibility for persons with disability, stakeholders' participation in the design and development of AI systems, and diversity of development teams."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"76",
        "uuid":"f8c3fdbd-12be-4901-842f-e172b7604960",
        "path":"5. OTHER ELEMENTS >> 5.2. Detailed explanation of the specific provisions of the proposal >> 5.2.8. FINAL PROVISIONS (TITLES X, XI AND XII)",
        "header":true,
        "text":"5.2.8. FINAL PROVISIONS (TITLES X, XI AND XII)"
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"77",
        "uuid":"4e9dbf17-d3dc-40ff-a601-d39aae87f531",
        "path":"5. OTHER ELEMENTS >> 5.2. Detailed explanation of the specific provisions of the proposal >> 5.2.8. FINAL PROVISIONS (TITLES X, XI AND XII)",
        "header":false,
        "text":"Title X emphasizes the obligation of all parties to respect the confidentiality of information and data and sets out rules for the exchange of information obtained during the implementation of the regulation. Title X also includes measures to ensure the effective implementation of the regulation through effective, proportionate, and dissuasive penalties for infringements of the provisions."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"78",
        "uuid":"24524db4-917c-418a-b86e-01ac8a5c72fc",
        "path":"5. OTHER ELEMENTS >> 5.2. Detailed explanation of the specific provisions of the proposal >> 5.2.8. FINAL PROVISIONS (TITLES X, XI AND XII)",
        "header":false,
        "text":"Title XI sets out rules for the exercise of delegation and implementing powers. The proposal empowers the Commission to adopt, where appropriate, implementing acts to ensure uniform application of the regulation or delegated acts to update or complement the lists in Annexes I to VII."
    },
    {
        "document_uuid":"3ee2bbd9-defb-47d0-b065-a8a40f1e5369",
        "document_section":"explanatory memorandum",
        "document_section_number":1,
        "type":"context",
        "id":"79",
        "uuid":"00c5926f-4cec-49ec-ab9c-cc5727d8c27c",
        "path":"5. OTHER ELEMENTS >> 5.2. Detailed explanation of the specific provisions of the proposal >> 5.2.8. FINAL PROVISIONS (TITLES X, XI AND XII)",
        "header":false,
        "text":"Title XII contains an obligation for the Commission to assess regularly the need for an update of Annex III and to prepare regular reports on the evaluation and review of the regulation. It also lays down final provisions, including a differentiated transitional period for the initial date of the applicability of the regulation to facilitate the smooth implementation for all parties concerned."
    }
]